#!/usr/bin/env perl
$ni::is_lib = caller();
$ni::self{license} = <<'_';
ni: https://github.com/spencertipping/ni
Copyright (c) 2016-2018 Spencer Tipping | MIT license

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
_
eval($ni::self{ni} = <<'_');
use strict;
$ni::data = \*DATA;

sub ni::boot_header
{ join "\n", '#!/usr/bin/env perl',
             "\$ni::is_lib = caller();",
             "\$ni::self{license} = <<'_';\n$ni::self{license}_",
             "eval(\$ni::self{ni} = <<'_');\n$ni::self{ni}_",
             "die \$@ if \$@;",
             "1;",
             "__DATA__" }

sub ni::eval($;$)
{ @ni::evals{eval('__FILE__') =~ /\(eval (\d+)\)/} = ($_[1] || "anon {$_[0]}");
  my @r = eval "package ni;$_[0]";
  $@ =~ s/\(eval (\d+)\)/$ni::evals{$1 - 1}/eg, die $@ if $@;
  @r }

sub ni::set
{ my $k = $_[0];
  chomp($ni::self{$k} = $_[1]);
  ni::eval $_[1], $k if $k =~ /\.pl$/ }

ni::set $2, join '', map $_ = <DATA>, 1..$1
while defined($_ = <DATA>) && /^\s*(\d+)\s+(.*)$/;
ni::eval 'exit main @ARGV', 'main' unless $ni::is_lib;
_
die $@ if $@;
1;
__DATA__
57 core/boot/ni.map
# Resource layout map.
# ni is assembled by following the instructions here. This script is also
# included in the ni image itself so it can rebuild accordingly.

bootcode
resource core/boot/ni.map

resource core/boot/util.pl
resource core/boot/doc.pl
resource core/boot/dev.pl
resource core/boot/parse.pl
resource core/boot/common.pl
resource core/boot/cli.pl
resource core/boot/op.pl
resource core/boot/self.pl
resource core/boot/main.pl
lib core/gen
lib core/json
lib core/deps
lib core/conf
lib core/stream
lib core/meta
lib core/monitor
lib core/uri
lib core/fn
lib core/closure
lib core/destructure
lib core/checkpoint
lib core/net
lib core/buffer
lib core/script
lib core/assert
lib core/col
lib core/row
lib core/pl
lib core/bloom
lib core/cell
lib core/c
lib core/git
lib core/archive
lib core/rb
lib core/lisp
lib core/sql
lib core/python
lib core/binary
lib core/matrix
lib core/gnuplot
lib core/image
lib core/http
lib core/caterwaul
lib core/jsplot
lib core/mapomatic
lib core/inspect
lib core/docker
lib core/hadoop
lib core/pyspark
lib doc
105 core/boot/util.pl
# Utility functions.
# Generally useful stuff, some of which makes up for the old versions of Perl we
# need to support.

sub weval($) {my @r = eval "package ni;$_[0]"; print STDERR $@ if $@; @r}

sub sgr($$$) {(my $x = $_[0]) =~ s/$_[1]/$_[2]/g; $x}
sub sr($$$)  {(my $x = $_[0]) =~ s/$_[1]/$_[2]/;  $x}
sub swap($$) {@_[0, 1] = @_[1, 0]}
sub dor($$)  {defined $_[0] ? $_[0] : $_[1]}

sub sum {local $_; my $x = 0; $x += $_ for @_; $x}

sub rf  {open my $fh, "< $_[0]" or die "rf $_[0]: $!"; my $r = join '', <$fh>; close $fh; $r}
sub rl  {open my $fh, "< $_[0]" or die "rl $_[0]: $!"; my @r =          <$fh>; close $fh; @r}
sub rfc {chomp(my $r = rf @_); $r}

sub dirbase($)  {my @xs = $_[0] =~ /^(.*)\/+([^\/]+)\/*$/; @xs ? @xs : ('', $_[0])}
sub basename($) {(dirbase $_[0])[1]}
sub dirname($)  {(dirbase $_[0])[0]}

sub mkdir_p {-d $_[0] or !length $_[0] or mkdir_p(dirname $_[0]) && mkdir $_[0]}

sub wf {
  mkdir_p dirname $_[0];
  open my $fh, "> $_[0]" or die "wf $_[0]: $!";
  print $fh $_[1];
  close $fh;
  $_[0];
}

sub max    {local $_; my $m = pop @_; $m = $m >  $_ ? $m : $_ for @_; $m}
sub min    {local $_; my $m = pop @_; $m = $m <  $_ ? $m : $_ for @_; $m}
sub maxstr {local $_; my $m = pop @_; $m = $m gt $_ ? $m : $_ for @_; $m}
sub minstr {local $_; my $m = pop @_; $m = $m lt $_ ? $m : $_ for @_; $m}

use constant noise_chars => '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ';
sub noise_char() {substr noise_chars, rand(length noise_chars), 1}
sub noise_str($) {join '', map noise_char, 1..$_[0]}

sub abbrev($$) {length($_[0]) < $_[1] ? $_[0] : substr($_[0], 0, $_[1] - 3) . '...'}

sub indent($;$) {
  my ($s, $indent) = (@_, 2);
  join "\n", map ' ' x $indent . $_, split /\n/, $s;
}

# Module loading.
# ni can include .pm files in its resource stream, which contain Perl code but
# aren't evaluated by default. This function is used to eval them into the
# current runtime.

sub load($) {ni::eval $ni::self{$_[0]}, $_[0]}

# Shell quoting/unquoting.
# Useful for two cases. One is when you have a structured list and want a shell
# string that will send those arguments to a command; the other is when you have
# a single string and want to get the ARGV list a shell would pass to a command
# (modulo dollar substitution, which we don't do).

sub shell_quote {
  local $_;
  join ' ', map /[^-A-Za-z_0-9\/:@.]/
                  ? "'" . sgr($_, qr/'/, "'\\''") . "'"
                  : $_,
            map 'ARRAY' eq ref($_) ? shell_quote(@$_) : $_, @_;
}

sub shell_unquote_one($) {
  my ($x) = @_;
  $x =~ s/\\(["\\])/$1/g, return substr $x, 1, -1 if $x =~ /^"/;
  return                         substr $x, 1, -1 if $x =~ /^'/;
  return                         substr $x, 1     if $x =~ /^\\/;
  $x;
}

sub shell_unquote($) {
  local $_;
  (my $c = $_[0]) =~ s/\\\n//g;
  1 while $c =~ s/^\s+|\s+$//g || $c =~ s/(?:^|\s)#.*/$1/gm;
  my @ps = $c =~ /"(?:[^"\\]+|\\[\s\S])*"|'[^']*'|\\[\s\S]|[^\s"'\\]+|\s+/g;
  my @s  = (-1, grep($ps[$_] =~ /^\s/, 0..$#ps), scalar @ps);
  map join('', map shell_unquote_one $_, @ps[$s[$_]+1 .. $s[$_+1]-1]), 0..$#s-1;
}

# Quoted function support.
# Functions that store their code in string form. This is useful for two
# purposes: first, it enables you to recompile things, e.g. for dynamic inlining;
# and second, it makes functions self-documenting, particularly in the context of
# parser combinators.

{
package ni::fn;
use overload qw/ &{} f "" source /;
sub new {
  my ($class, $code) = @_;
  bless {f => ni::eval("sub {$code\n}", "anon sub{$code}"), code => $code},
        $class;
}

sub f($)      {${$_[0]}{f}}
sub source($) {${$_[0]}{code}}
}

sub fn($) {ref($_[0]) ? $_[0] : ni::fn->new($_[0])}
30 core/boot/doc.pl
# Documentation generator.
# Produces documentation by inspecting data structures. For the most part this is
# delegated.

our %doc;
our %doc_fns;
our %doc_entities;

sub documentation_for($$) {
  my ($type, $thing) = @_;
  $doc_fns{$type}->($thing, $doc{$type}{$thing}, $type);
}
sub default_doc_fn($$) {$_[1]}

sub doc_sections(@) {
  my %sections      = @_;
  my @section_order = map $_[$_ * 2], 0..$#_ >> 1;
  join "\n", map {('', ($_ ? '## ' : '# ') . $section_order[$_],
                   map "\t$_", split /\n/, $sections{$section_order[$_]})}
             0..$#section_order;
}

sub defdocumentable($$;$) {
  my ($name, $global_hash, $fn) = @_;
  $doc{$name}          = {};
  $doc_fns{$name}      = defined $fn ? fn $fn : \&default_doc_fn;
  $doc_entities{$name} = $global_hash;
  ni::eval "sub doc$name(\$\$) {\$ni::doc{'$name'}{\$_[0]} = \$_[1]}";
  ni::eval "sub ${name}_doc(\$) {documentation_for '$name', \$_[0]}";
}
42 core/boot/dev.pl
# Development functions.
# Utilities helpful for debugging and developing ni.

sub try_to_resolve_coderef($) {
  for my $f (keys %{ni::}) {
    return "ni::$f" if \&{"ni::$f"} eq $_[0];
  }
  return '<opaque code reference>';
}

sub dev_inspect($;\%);
sub dev_inspect($;\%) {
  local $_;
  my ($x, $refs) = (@_, {});
  return "<circular $x>" if defined $x && exists $$refs{$x};

  $$refs{$x} = $x if defined $x;
  my $r = 'ARRAY' eq ref $x ? '[' . join(', ', map dev_inspect($_, %$refs), @$x) . ']'
        : 'HASH'  eq ref $x ? '{' . join(', ', map "$_ => " . dev_inspect($$x{$_}, %$refs), keys %$x) . '}'
        : 'CODE'  eq ref $x ? try_to_resolve_coderef($x)
        : defined $x        ? "" . $x
        :                     'undef';
  delete $$refs{$x} if defined $x;
  $r;
}

sub dev_inspect_nonl($) {(my $r = dev_inspect $_[0]) =~ s/\s+/ /g; $r}

sub dev_trace($) {
  no strict 'refs';
  my ($fname) = @_;
  my $f = \&{$fname};
  my $indent = '';
  *{$fname} = sub {
    printf STDERR "$indent$fname %s ...\n", dev_inspect [@_];
    $indent .= "  ";
    my @r = &$f(@_);
    $indent =~ s/  $//;
    printf STDERR "$indent$fname %s = %s\n", dev_inspect([@_]), dev_inspect [@r];
    @r;
  };
}
227 core/boot/parse.pl
# Parser combinators.
# List-structured combinators. These work like normal parser combinators, but are
# indirected through data structures to make them much easier to inspect. This
# allows ni to build an operator mapping table.

our %parsers;
BEGIN {defdocumentable 'parser', \%parsers, q{
  my ($p, $doc) = @_;
  if (ref $p) {
    my ($name, @args) = @$p;
    return $ni::doc{parser}{$name}->($p) if ref $ni::doc{parser}{$name};
    parser_doc($name);
  } else {
    doc_sections
      "PARSER $p"  => $doc,
      "DEFINITION" => parser_ebnf($ni::parsers{$p});
  }
}}

our %parser_ebnf;
sub defparserebnf($$) {$parser_ebnf{$_[0]} = fn $_[1]}
sub parser_ebnf($) {
  my ($p) = @_;
  return "<$p>" unless ref $p;
  return "<core parser {\n" . indent($p, 2) . "\n}>" unless 'ARRAY' eq ref $p;
  my ($name, @args) = @$p;
  return "<" . join(' ', $name, map dev_inspect($_), @args) . ">" unless exists $parser_ebnf{$name};
  $parser_ebnf{$name}->($p);
}

sub parser($);
sub parser($) {
  return $_[0] if ref $_[0];
  die "ni: parser $_[0] is not defined" unless exists $parsers{$_[0]};
  parser $parsers{$_[0]};
}

sub defparser($$$) {
  my ($name, $proto, $f) = @_;
  (my $code_name = $name) =~ s/\W+/_/g;
  die "ni: defparser cannot redefine $name" if exists $parsers{$name};
  $parsers{$name} = fn $f;
  eval "sub $code_name($proto) {['$name', \@_]}";
}

sub defparseralias($$) {
  my ($name, $alias) = @_;
  (my $code_name = $name) =~ s/\W+/_/g;
  die "ni: defparseralias cannot redefine $name" if exists $parsers{$name};
  $parsers{$name} = $alias;
  eval "sub $code_name() {['$name']}" unless exists ${ni::}{$code_name};
}

# Parse function.
# ($result, @remaining) = parse($parser, @inputs). $parser can take one of three
# forms:

# | ['parser-name', @args]: $parsers{'parser-name'} is a function
#   ['parser-name']: $parsers{'parser-name'} could be a function or an array
#   'parser-name': $parsers{'parser-name'} is an array

our $recursion_level = 0;
sub parse;
sub parse {
  local $_;
  local $recursion_level = $recursion_level + 1;
  my ($p, @args) = @{parser $_[0]};
  die "ni: runaway parse of $p [@args] on @_[1..$#_] ($recursion_level levels)"
    if $recursion_level > 1024;
  my $f = $parsers{$p};
  'ARRAY' eq ref $f ? parse $f, @_[1..$#_] : &$f([$p, @args], @_[1..$#_]);
}

# Base parsers.
# Stuff for dealing with some base cases.

BEGIN {
  defparser 'pend',   '',  q{@_ > 1                        ? () : (0)};
  defparser 'pempty', '',  q{defined $_[1] && length $_[1] ? () : (0, @_[2..$#_])};
  defparser 'pk',     '$', q{(${$_[0]}[1], @_[1..$#_])};
  defparser 'pnone',  '',  q{(undef,       @_[1..$#_])};
}

defparserebnf pend   => q{'<argv_end>'};
defparserebnf pempty => q{'<empty>'};
defparserebnf pk     => q{"<'', evaluate as " . dev_inspect($_[0][1]) . ">"};
defparserebnf pnone  => q{"''"};

# Basic combinators.
# Sequence, alternation, etc. 'alt' implies a sequence of alternatives; 'dsp' is
# a dispatch on specified prefixes. The 'r' suffix means that the parser
# combinator takes a reference to a collection; this allows you to modify the
# collection later on to add more alternatives.

BEGIN {
  defparser 'paltr', '\@',
    q{my ($self, @xs, @ps, @r) = @_;
      @r = parse $_, @xs and return @r for @ps = @{parser $$self[1]}; ()};

  defparser 'pdspr', '\%',
    q{my ($self, $x, @xs, $k, @ys, %ls, $c) = @_;
      my (undef, $ps) = @$self;
      return () unless defined $x;
      ++$ls{length $_} for keys %$ps;
      for my $l (sort {$b <=> $a} keys %ls) {
        return (@ys = parse $$ps{$c}, substr($x, $l), @xs) ? @ys : ()
        if exists $$ps{$c = substr $x, 0, $l} and $l <= length $x;
      }
      ()};
}

sub palt(@) {my @ps = @_; paltr @ps}
sub pdsp(%) {my %ps = @_; pdspr %ps}

defparserebnf paltr => fn q{
  my ($self, $alt) = @{$_[0]};
  my @docs = map "| " . sr(indent(parser_ebnf $_, 2), qr/^  /, ''), @$alt;
  "(\n" . join("\n", @docs) . "\n)";
};

defparserebnf pdspr => fn q{
  my ($self, $dsp) = @{$_[0]};
  my @docs = map "| '$_' " . sr(indent(parser_ebnf $$dsp{$_}, 2), qr/^  /, ''),
             sort keys %$dsp;
  "(\n" . join("\n", @docs) . "\n)";
};

BEGIN {
  defparser 'pseq', '@',
    q{my ($self, @is, $x, @xs, @ys) = @_;
      my (undef, @ps) = @$self;
      (($x, @is) = parse $_, @is) ? push @xs, $x : return () for @ps;
      (\@xs, @is)};

  defparser 'prep', '$;$',
    q{my ($self, @is, @c, @r) = @_;
      my (undef, $p, $n) = (@$self, 0);
      push @r, $_ while ($_, @is) = parse $p, (@c = @is);
      @r >= $n ? (\@r, @c) : ()};

  defparser 'popt', '$',
    q{my ($self, @is) = @_;
      my @xs = parse $$self[1], @is; @xs ? @xs : (undef, @is)};

  defparser 'pmap', '$$',
    q{my ($self, @is) = @_;
      my (undef, $f, $p) = @$self;
      $f = fn $f;
      my @xs = parse $p, @is; @xs ? (&$f($_ = $xs[0]), @xs[1..$#xs]) : ()};

  defparser 'pcond', '$$',
    q{my ($self, @is) = @_;
      my (undef, $f, $p) = @$self;
      $f = fn $f;
      my @xs = parse $p, @is; @xs && &$f($_ = $xs[0]) ? @xs : ()};
}

defparserebnf pseq => fn q{
  my ($self, @ps) = @{$_[0]};
  "(\n" . join("\n", map indent(parser_ebnf $_, 2), @ps) . "\n)";
};

defparserebnf prep => fn q{
  my ($self, $p, $n) = (@{$_[0]}, 0);
  my $rep_symbol = $n == 0 ? '*' : $n == 1 ? '+' : "{$n+ times}";
  parser_ebnf($p) . "$rep_symbol";
};

defparserebnf popt => fn q{
  my ($self, $p) = @{$_[0]};
  parser_ebnf($p) . '?';
};

defparserebnf pmap => fn q{
  my ($self, $f, $p) = @{$_[0]};
  parser_ebnf($p) . " -> {$f}";
};

defparserebnf pcond => fn q{
  my ($self, $f, $p) = @{$_[0]};
  parser_ebnf($p) . " such that {$f}";
};

sub pn($@)
{ my ($n, @ps) = @_;
  'ARRAY' eq ref $n ? pmap fn "[\@\$_[" . join(',', @$n) . "]]", pseq @ps
                    : pmap fn "\$\$_[$n]", pseq @ps }

sub pc($) {pn 0, $_[0], popt pempty}

# Regex parsing.
# Consumes the match, returning either the matched text or the first match group
# you specify. Always matches from the beginning of a string.

BEGIN {
  defparser 'prx', '$',
    q{my ($self, $x, @xs) = @_;
      defined $x && $x =~ s/^($$self[1])// ? (dor($2, $1), $x, @xs) : ()};

  defparser 'pstr', '$',
    q{my ($self, $x, @xs) = @_;
      defined $x && index($x, $$self[1]) == 0
        ? ($$self[1], substr($x, length $$self[1]), @xs)
        : ()};

  defparser 'pnx', '$',
    q{my ($self, $x, @xs) = @_;
      !defined $x || $x =~ /^(?:$$self[1])/ ? () : ($x, @xs)};
}

sub prc($)  {pn 0, prx  $_[0], popt pempty}
sub pstc($) {pn 0, pstr $_[0], popt pempty}

defparserebnf pstr => fn q{
  my ($self, $s) = @{$_[0]};
  $s =~ /'/ ? json_encode($s) : "'$s'";
};

defparserebnf prx => fn q{
  my ($self, $r) = @{$_[0]};
  "/$r/";
};

defparserebnf pnx => fn q{
  my ($self, $r) = @{$_[0]};
  "!/$r/";
};
90 core/boot/common.pl
# Regex parsing.
# Sometimes we'll have an operator that takes a regex, which is subject to the
# CLI reader problem the same way code arguments are. Rather than try to infer
# brackets the same way, we just require that regexes are terminated with /
# (which should be ok because that's also how they typically start).

BEGIN {defparseralias regex => pmap q{s/\/$//; $_}, prx qr{^(?:[^\\/]+|\\.)*/}}

docparser regex => q{Regular expression, delimited by slashes};


docparser generic_code => <<'_';
Counts brackets outside quoted strings, which in our case are '' and "".
Doesn't look for regular expressions because these vary by language; but this
parser should be able to handle most straightforward languages with quoted
string literals and backslash escapes.
_

defparser 'generic_code', '',
  q{my ($self, $code, @xs) = @_;
    return ($code, '', @xs) unless $code =~ /\]$/;
    (my $tcode = $code) =~ s/"([^"\\\\]+|\\\\.)"|'([^'\\\\]+|\\\\.)'//g;
    my $balance = length(sgr $tcode, qr/[^[]/, '') - length(sgr $tcode, qr/[^]]/, '');
    $balance ? (substr($code, 0, $balance), substr($code, $balance), @xs)
             : ($code, '', @xs)};


# Basic CLI types.
# Some common argument formats for various commands, sometimes transformed for
# specific cases. These are documented somewhere in `doc/`.

# A parsed column spec is an N-element array: [floor, cols...]. `floor` indicates
# the first column that would be selected by a `.` ("the rest").

BEGIN {defparseralias neval => pmap q{eval}, prx '=([^]=]+)'}
BEGIN {defparseralias integer => palt pmap(q{int},       neval),
                                      pmap(q{10 ** $_},  prx 'E(-?\d+)'),
                                      pmap(q{1 << $_},   prx 'B(\d+)'),
                                      pmap(q{0 + "0$_"}, prx 'x[0-9a-fA-F]+'),
                                      pmap(q{0 + $_},    prx '-?[1-9]\d*(?:[eE]\d+)?'),
                                                         pstr '0'}
BEGIN {defparseralias float => pmap q{0 + $_},
                               pcond q{length},
                               prx '-?(?:\d+(?:\.\d*)?|\d*\.\d+)(?:[eE][-+]?\d+)?'}
BEGIN {defparseralias number => palt neval, float, integer}

BEGIN {defparseralias colspec1      => palt pn(1, pstr '#', integer),
                                            pmap q{ord() - 65}, prx '[A-Z]';
       defparseralias colspec_rest  => pmap q{-1}, pstr '.'}
BEGIN {defparseralias colspec_range => pmap q{[$$_[0] .. $$_[2]]},
                                       pseq colspec1, pstr '-', colspec1}
BEGIN {defparseralias colspec_fixed => pmap q{[max(@$_) + 1, @$_]},
                                       pmap q{[map ref() ? @$_ : $_, @$_]},
                                       prep pn(1, popt pstr ',',
                                                  palt(colspec_range, colspec1)), 1}
BEGIN {defparseralias colspec => pmap q{[max(@$_) + 1, @$_]},
                                 pmap q{[map ref() ? @$_ : $_, @$_]},
                                 prep pn(1, popt pstr ',',
                                            palt(colspec_range, colspec1, colspec_rest)), 1}

docparser neval => q{An expression evaluated by Perl; e.g. =3+4 for 7};
docparser colspec1 => q{A way to identify a single column; either A-Z or #N};
docparser colspec_rest => <<'_';
"The rest of the columns": everything to the right of the rightmost
explicitly-specified column
_

docparser colspec_range => q{A range of columns, e.g. A-Q or #10-#20};
docparser colspec_fixed => q{A set of definite columns; disallows '.' ("the rest")};
docparser colspec => q{A set of columns, possibly including '.' ("the rest")};

# Filenames, in general.
# Typically filenames won't include bracket characters, though they might include
# just about everything else. Two possibilities there: if we need special stuff,
# there's the `file://` prefix; otherwise we assume the non-bracket
# interpretation.
#
# There are cases where it's useful to compute the name of a file. If a filename
# begins with $, we evaluate the rest of it with perl to calculate its name.

BEGIN {defparseralias computed   => pmap q{eval "(sub {$_})->()"},
                                         pn 1, pstr"\$", prx '.*'}
BEGIN {defparseralias filename   => palt computed,
                                         prx 'file://(.+)',
                                         prx '\.?/(?:[^/]|$)[^]]*',
                                         pcond q{-e}, prx '[^][]+'}
BEGIN {defparseralias nefilename => palt filename, prx '[^][]+'}

docparser filename   => q{The name of an existing file};
docparser nefilename => q{The name of a possibly-nonexisting file};
130 core/boot/cli.pl
# CLI grammar.
# ni's command line grammar uses some patterns on top of the parser combinator
# primitives defined in parse.pl.sdoc. Probably the most important one to know
# about is the long/short option dispatch, which looks like this:

# | option = alt @longs, dsp %shorts

our %contexts;
our %shorts;
our %longs;
our %long_refs;
our %short_refs;
our %dsps;
our %alts;

BEGIN {
  defdocumentable context => \%contexts, q{
    my ($c, $doc) = @_;
    doc_sections
      "CONTEXT $c" => $doc,
      "LONG OPERATORS (ni --doc/long X)"   => join("\n", sort grep /^$c\//, keys %ni::longs),
      "SHORT OPERATORS (ni --doc/short X)" => join("\n", sort grep /^$c\//, keys %ni::shorts);
  };

  defdocumentable short => \%shorts, q{
    my ($s, $doc) = @_;
    doc_sections
      "SHORT OPERATOR $s" => $doc,
      "SYNTAX" => parser_ebnf $ni::shorts{$s};
  };

  defdocumentable long => \%longs, q{
    my ($l, $doc) = @_;
    doc_sections
      "LONG OPERATOR $l" => $doc,
      "SYNTAX" => parser_ebnf $ni::longs{$l};
  };

  defdocumentable dsp => \%dsps, q{
    my ($d, $doc) = @_;
    doc_sections
      "EXTENSIBLE DISPATCH TABLE $d" => $doc,
      "OPTIONS" => parser_ebnf parser "dsp/$d";
  };

  defdocumentable alt => \%alts, q{
    my ($a, $doc) = @_;
    doc_sections
      "EXTENSIBLE LIST $a" => $doc,
      "OPTIONS" => parser_ebnf parser "alt/$a";
  };
}

sub defcontext($$) {
  my ($c, $doc) = @_;
  $short_refs{$c} = {};
  $long_refs{$c}  = ["$c/short"];
  $contexts{$c}   = paltr @{$long_refs{$c}};

  doccontext $c, $doc;

  defparseralias "$c/short",  pdspr %{$short_refs{$c}};
  defparseralias "$c/op",     $contexts{$c};
  defparseralias "$c/suffix", prep "$c/op";
  defparseralias "$c/series", prep pn 1, popt pempty, "$c/op", popt pempty;
  defparseralias "$c/lambda", pn 1, pstc '[', "$c/series", pstr ']';
  defparseralias "$c/qfn",    palt "$c/lambda", "$c/suffix";

  docparser "$c/short" => qq{Dispatch table for short options in context '$c'};
  docparser "$c/op" => qq{A single operator in the context '$c'};
  docparser "$c/suffix" => qq{A string of operators unbroken by whitespace};
  docparser "$c/series" => qq{A string of operators, possibly including whitespace};
  docparser "$c/lambda" => qq{A bracketed lambda function in context '$c'};
  docparser "$c/qfn" => qq{Operators that are interpreted as a lambda, whether bracketed or written as a suffix};
}

sub defshort($$) {
  my ($context, $dsp) = split /\//, $_[0], 2;
  warn "ni: defshort is redefining '$_[0]' (use rmshort to avoid this warning)"
    if exists $short_refs{$context}{$dsp};
  $shorts{$_[0]} = $short_refs{$context}{$dsp} = $_[1];
}

sub deflong($$) {
  my ($context, $name) = split /\//, $_[0], 2;
  unshift @{$long_refs{$context}}, $longs{$_[0]} = $_[1];
}

sub rmshort($) {
  my ($context, $dsp) = split /\//, $_[0], 2;
  delete $shorts{$_[0]};
  delete $short_refs{$context}{$dsp};
}

sub cli_parse(@) {parse parser '/series', @_}
sub cli(@) {
  my ($r, @rest) = cli_parse @_;
  die "ni: failed to parse starting here:\n  @rest" if @rest;
  $r;
}

# Extensible parse elements.
# These patterns come up a lot, and it's worth being able to autogenerate their
# documentation.

sub defalt($$@) {
  no strict 'refs';
  my ($name, $doc, @entries) = @_;
  my $vname = __PACKAGE__ . "::$name";
  docalt $name, $doc;
  @{$vname} = @entries;
  $alts{$name} = \@{$vname};
  *{__PACKAGE__ . "::def$name"} = sub ($) {unshift @{$vname}, $_[0]};
  my $r = paltr @{$vname};
  defparseralias "alt/$name" => $r;
  $r;
}

sub defdsp($$%) {
  no strict 'refs';
  my ($name, $doc, %entries) = @_;
  my $vname = __PACKAGE__ . "::$name";
  docdsp $name, $doc;
  %{$vname} = %entries;
  $dsps{$name} = \%{$vname};
  *{__PACKAGE__ . "::def$name"} = sub ($$) {${$vname}{$_[0]} = $_[1]};
  my $r = pdspr %{$vname};
  defparseralias "dsp/$name" => $r;
  $r;
}
81 core/boot/op.pl
# Operator definition.
# Like ni's parser combinators, operators are indirected using names. This
# provides an intermediate representation that can be inspected and serialized.

# Meta operators are applied before any pipeline forking happens, and are at
# liberty to modify anything to their left. (Or anything at all really, but it's
# counterintuitive for them to act rightwards.)

# Note that only toplevel meta operators are evaluated pre-pipeline. Meta
# operators inside lambdas are applied when the lambdas are evaluated (this is a
# feature).

our %operators;
our %meta_operators;

defdocumentable operator => \%operators, q{
  my ($op, $doc) = @_;
  doc_sections
    "OPERATOR $op"   => $doc,
    "IMPLEMENTATION" => $ni::operators{$op};
};

defdocumentable meta_operator => \%meta_operators, q{
  my ($mop, $doc) = @_;
  doc_sections
    "META OPERATOR $mop" => $doc,
    "IMPLEMENTATION" => $ni::meta_operators{$mop};
};

sub defmetaoperator($$) {
  my ($name, $f) = @_;
  die "ni: cannot redefine meta operator $name" if exists $meta_operators{$name};
  warn "ni: overlapping op/meta definition $name" if exists $operators{$name};
  $meta_operators{$name} = fn $f;
  ni::eval "sub ${name}_op(@) {['$name', \@_]}", "defmetaoperator $name";
}

sub meta_operate($$$) {
  my ($operator, $position, $context) = @_;
  my ($op, @args) = @$operator;
  my ($left, $right) = ([$position ? @$context[0..$position-1] : ()],
                        [@$context[$position+1..$#{$context}]]);
  my ($new_left, $new_right) = $meta_operators{$op}->([@args], $left, $right);
  (@{$new_left || $left}, @{$new_right || $right});
}

sub flatten_operators($);
sub flatten_operators($) {
  my ($name) = @{$_[0]};
  return $_[0] unless ref $name;
  map flatten_operators $_, @{$_[0]};
}

sub apply_meta_operators;
sub apply_meta_operators(@) {
  local $_;
  exists $meta_operators{$_[$_]->[0]}
    and return apply_meta_operators meta_operate $_[$_], $_, [@_]
    for 0..$#_;
  @_;
}

# Regular operators.
# Each of these is a filter process that is forked and piped against standard
# input. Operators act independently of one another.

sub defoperator($$) {
  my ($name, $f) = @_;
  die "ni: cannot redefine operator $name" if exists $operators{$name};
  warn "ni: overlapping op/meta definition $name" if exists $meta_operators{$name};
  $operators{$name} = fn $f;
  ni::eval "sub ${name}_op(@) {['$name', \@_]}", "defoperator $name";
  ni::eval "sub ${name}_run(@) {\$ni::operators{$name}->(\@_)}",
           "defoperator $name ($f)";
}

sub operate {
  my ($name, @args) = @_;
  die "ni operate: undefined operator: $name" unless exists $operators{$name};
  $operators{$name}->(@args);
}
67 core/boot/self.pl
# Image functions.
# ni needs to be able to reconstruct itself from a map. These functions implement
# the map commands required to do this.

our %self;

our $ni_map = 'core/boot/ni.map';

sub self_append_resource($$) {
  my ($k, $v) = @_;
  $self{$ni_map} .= "\nresource $k";
  $self{$k} = $v;
}

sub lib_entries($$) {
  local $_;
  my ($name, $text) = @_;
  map "$name/$_", grep {s/#.*//; length} split /\n/, $text;
}

sub quote_resource {my @xs; map sprintf("%d %s\n%s", scalar(@xs = split /\n/, "$self{$_} "), $_, $self{$_}), @_}
sub quote_library  {map quote_resource("$_/lib", lib_entries $_, $self{"$_/lib"}), @_}

sub read_map {join '', map "$_\n",
                       (map {my ($c, @a) = split /\s+/;
                               $c eq 'bootcode'    ? ni::boot_header
                             : $c eq 'resource'    ? quote_resource @a
                             : $c =~ /^lib$|^ext$/ ? quote_library @a
                             : die "ni: unknown map command+args: $c @a"}
                        grep {s/#.*//g; length}
                        map split(/\n/), @self{@_}), "__END__"}

sub intern_lib($) {
  my ($l) = @_;
  if (-d $l) {
    set $_, rfc $_ for lib_entries $l, ($self{"$l/lib"} = rfc "$l/lib");
  } else {
    my $k = "lib/$l";
    self_append_resource $k, rfc $l;
    set $k, $ni::self{$k};
  }
}

sub modify_self() {
  die "ni: not a modifiable instance: $0" unless -w $0;
  open my $fh, "> $0" or die "ni: failed to open self: $!";
  print $fh read_map $ni_map;
  close $fh;
}

sub extend_self($$) {
  my ($type, $lib) = @_;
  intern_lib $lib;
  set $ni_map, "$self{$ni_map}\n$type $lib"
    unless grep /^(lib|ext)\s+$lib$/, split /\n/, $self{$ni_map};
}

sub image {read_map $ni_map}
sub image_with(%) {
  my %old_self = %self;
  my %h        = @_;
  $self{$ni_map} .= join '', map "\nresource $_", keys %h;
  @self{keys %h} = values %h;
  my $i = image;
  %self = %old_self;
  $i;
}
165 core/boot/main.pl
# CLI entry point.
# Some custom toplevel option handlers and the main function that ni uses to
# parse CLI options and execute the data pipeline.

our %cli_special;
BEGIN {defdocumentable 'clispecial', \%cli_special}

sub defclispecial($$$) {
  $cli_special{$_[0]} = fn $_[1];
  docclispecial $_[0], $_[2];
}

# Development options.
# Things useful for developing ni.

defclispecial '--dev/eval', q{print ni::eval($_[0], "anon $_[0]"), "\n"}, <<'_';
Development option: evaluate an expression within the `ni::` package, and print
the result. For example:

$ ni --dev/eval '3 + 4'
7
_

defclispecial '--dev/parse', q{dev_trace 'ni::parse'; cli_parse @_}, <<'_';
Development option: trace the ni::parse function and attempt to parse the
command line. Mostly useful for debugging.
_

defclispecial '--dev/parse-one', q{
  dev_trace 'ni::parse';
  parse ni::eval($_[0]), @_[1..$#_];
}, <<'_';
Development option: trace the ni::parse function and evaluate the specified
parser on the rest of the command line arguments. For example:

$ ni --dev/parse-one 'parser "/qfn"' [gc]
_

defclispecial '--dev/doc-check' => q{
  my $undocumented = 0;
  for my $type (sort keys %ni::doc_entities) {
    exists $ni::doc{$type}{$_} or ++$undocumented && print "$type\t$_\n"
      for sort keys %{$ni::doc_entities{$type}};
  }
  print "$undocumented undocumented thing(s)\n";
  !!$undocumented;
}, <<'_';
Development option: find things (parsers, ops, etc) that have been defined but
have no documentation associated with them.
_

# Extensions.
# Options to extend and modify the ni image.

defclispecial '--internal/lib', q{
  extend_self 'lib', $_ for @_;
  modify_self;
}, <<'_';
Usage: ni --internal/lib lib1 lib2 ... libN
Modifies the ni image in-place to include the specified libraries. See ni
//help/libraries for more information.
_

defclispecial '--lib', q{intern_lib shift; goto \&main}, <<'_';
Usage: ni --lib lib-dir normal-ni-options...
Preloads a library before running normally. ni does not self-modify on disk if
you do this, though the library will be available in remote contexts.
_

defclispecial '--run', q{
  $ni::self{"transient/eval"} .= "\n$_[0]\n";
  ni::eval $_[0], "--run $_[0]";
  shift;
  goto \&main;
}, <<'_';
Usage: ni --run 'perl code' normal-ni-options...
Runs code before running normally.
_

# Documentation.

defclispecial '--explain', q{
  my ($r, @rest) = cli_parse @_;
  print "UNPARSED: @rest\n" if @rest;
  if (ref $r) {
    print json_encode($_), "\n" for flatten_operators $r;
  }
}, <<'_';
Usage: ni --explain normal-ni-options...
Describes the operators and meta-operators produced from the specified command
line. Meta-operators are unevaluated in this form.
_

defclispecial '--explain-meta', q{
  my ($r, @rest) = cli_parse @_;
  print "UNPARSED: @rest\n" if @rest;
  if (ref $r) {
    print json_encode($_), "\n" for apply_meta_operators flatten_operators $r;
  }
}, <<'_';
Usage: ni --explain-meta normal-ni-options...
Describes the operators produced from the specified command line, after
evaluating all meta-operators. Each operator in the output corresponds to a
forked process in the pipeline.
_

defclispecial "--doc/$_", qq{
  if (\@_) {
    eval {print ${_}_doc \$_, "\\n"}, \$@ && warn \$@ for \@_;
  } else {
    print "\$_\\n" for sort keys \%{\$ni::doc_entities{'$_'}};
  }
}, <<_
Usage: ni --doc/$_ [<${_}-name>]
Print documentation for <${_}-name> if specified; otherwise list all ${_}s.
_
for keys %ni::doc;

defclispecial '--doc', q{print "--doc/$_\n" for sort keys %ni::doc}, <<'_';
Usage: ni --doc
Prints a list of all documentable types of things. For example, "parser" is one
such thing, and from there you can run `ni --doc/parser X`, where `X` is the
name of a parser. (`ni --doc/parser` will list all of them.)
_

# Root CLI context.
# This is used by extensions that define long and short options.

defcontext '', q{toplevel CLI context};

# Main stuff.
# sub main() is called by the ni boot header on @ARGV. I've separated
# $main_operator so it can be extended to handle various cases; for instance, ni
# launches a pager when its output is connected to a terminal, etc. This is
# handled by core/stream.

our $main_operator = sub {die "ni: no main operator defined (your ni is broken)"};

sub main {
  my ($cmd, @args) = @_;
  $ni::is_toplevel = 1;

  @_ = ('//help', @_[1..$#_])
    if -t STDIN and -t STDOUT and !@_ || $_[0] =~ /^-h$|^-\?$|^--help$/;

  if (exists $ENV{HOME} && !exists $ENV{NI_NO_HOME} && -d "$ENV{HOME}/.ni") {
    eval {intern_lib "$ENV{HOME}/.ni"};
    if ($@) {
      print STDERR "ni: note: failed to load ~/.ni as a library: $@\n";
      print STDERR "    (export NI_NO_HOME to disable ~/.ni autoloading,\n";
      print STDERR "     or run `ni //help/libraries` for details about libraries)\n";
    }
  }

  return $cli_special{$cmd}->(@args) if defined $cmd && exists $cli_special{$cmd};

  my ($r, @rest) = cli_parse @_;
  return &$main_operator(flatten_operators $r) if !@rest && ref $r;

  print STDERR "ni: failed to parse starting here (ni --dev/parse to trace):\n";
  print STDERR "  @rest\n";
  print STDERR "If ni is failing to parse a filename, start it with /, ./,\n";
  print STDERR "or file:// to qualify it.\n";
  exit 1;
}
1 core/gen/lib
gen.pl
34 core/gen/gen.pl
# Code generator.
# A general-purpose interface to do code-generation stuff. This is used when
# you've got a task that's mostly boilerplate of some kind, but you've got
# variable regions. For example, if you wanted to generalize JVM-hosted
# command-line filters:

# | my $java_linefilter = gen q{
#     import java.io.*;
#     public class %classname {
#       public static void main(String[] args) {
#         BufferedReader stdin = <the ridiculous crap required to do this>;
#         String %line;
#         while ((%line = stdin.readLine()) != null) {
#           %body;
#         }
#       }
#     }
#   };
#   my $code = &$java_linefilter(classname => 'Foo',
#                                line      => 'line',
#                                body      => 'System.out.println(line);');

our $gensym_index = 0;
sub gensym {join '_', '_gensym', ++$gensym_index, @_}

sub gen($) {
  my @pieces = split /(%\w+)/, $_[0];
  sub {
    my %vars = @_;
    my @r = @pieces;
    $r[$_] = $vars{substr $pieces[$_], 1} for grep $_ & 1, 0..$#pieces;
    join '', map defined $_ ? $_ : '', @r;
  };
}
1 core/json/lib
json.pl
78 core/json/json.pl
# JSON parser/generator.
# Perl has native JSON libraries available in CPAN, but we can't assume those are
# installed locally. The pure-perl library is unusably slow, and even it isn't
# always there. So I'm implementing an optimized pure-Perl library here to
# address this. Note that this library doesn't parse all valid JSON, but it does
# come close -- and I've never seen a real-world use case of JSON that it would
# fail to parse.

use Scalar::Util qw/looks_like_number/;

our %json_unescapes =
  ("\\" => "\\", "/" => "/", "\"" => "\"", b => "\b", n => "\n", r => "\r",
   t => "\t");

sub json_unescape_one($) {$json_unescapes{$_[0]} || chr hex substr $_[0], 1}
sub json_unescape($) {
  my $x = substr $_[0], 1, -1;
  $x =~ s/\\(["\\\/bfnrt]|u[0-9a-fA-F]{4})/json_unescape_one $1/eg;
  $x;
}

# Fully decode a string of JSON. Unless you need to extract everything, this is
# probably the slowest option; targeted attribute extraction should be much
# faster.

sub json_decode($) {
  local $_;
  my @v = [];
  for ($_[0] =~ /[][{}]|true|false|null|"(?:[^"\\]+|\\.)*"|[-+eE\d.]+/g) {
    if (/^[[{]$/) {
      push @v, [];
    } elsif (/^\]$/) {
      die "json_decode $_[0]: too many closing brackets" if @v < 2;
      push @{$v[-2]}, $v[-1];
      pop @v;
    } elsif (/^\}$/) {
      die "json_decode $_[0]: too many closing brackets" if @v < 2;
      push @{$v[-2]}, {@{$v[-1]}};
      pop @v;
    } else {
      push @{$v[-1]}, /^"/      ? json_unescape $_
                    : /^true$/  ? 1
                    : /^false$/ ? 0
                    : /^null$/  ? undef
                    :             0 + $_;
    }
  }
  my $r = pop @v;
  die "json_decode $_[0]: not enough closing brackets" if @v;
  wantarray ? @$r : $$r[0];
}

# Encode a string of JSON from a structured value. TODO: add the ability to
# generate true/false values.

our %json_escapes = map {;$json_unescapes{$_} => $_} keys %json_unescapes;

sub json_escape($) {
  (my $x = $_[0]) =~ s/([\b\f\n\r\t"\\])/"\\" . $json_escapes{$1}/eg;
  "\"$x\"";
}

sub json_encode($);
sub json_encode($) {
  local $_;
  my ($v) = @_;
  return "[" . join(',', map json_encode($_), @$v) . "]" if 'ARRAY' eq CORE::ref $v;
  return "{" . join(',', map json_escape($_) . ":" . json_encode($$v{$_}),
                             sort keys %$v) . "}" if 'HASH' eq CORE::ref $v;
  return json_escape $$v if 'SCALAR' eq CORE::ref $v;   # force string
  looks_like_number $v ? $v : defined $v ? json_escape $v : 'null';
}

if (__PACKAGE__ eq 'ni::pl') {
  no warnings 'once';
  *je = \&json_encode;
  *jd = \&json_decode;
}
1 core/deps/lib
sha1.pm
1031 core/deps/sha1.pm
package Digest::SHA::PurePerl;

require 5.003000;

use strict;
use warnings;
use vars qw($VERSION @ISA @EXPORT_OK);
use Fcntl qw(O_RDONLY);
use integer;
use Carp qw(croak);

$VERSION = '5.96';

require Exporter;
@ISA = qw(Exporter);
@EXPORT_OK = ();		# see "SHA and HMAC-SHA functions" below

# Inherit from Digest::base if possible

eval {
	require Digest::base;
	push(@ISA, 'Digest::base');
};

# ref. src/sha.c and sha/sha64bit.c from Digest::SHA

my $MAX32 = 0xffffffff;

my $uses64bit = (((1 << 16) << 16) << 16) << 15;

my @H01 = (			# SHA-1 initial hash value
	0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476,
	0xc3d2e1f0
);

my @H0224 = (			# SHA-224 initial hash value
	0xc1059ed8, 0x367cd507, 0x3070dd17, 0xf70e5939,
	0xffc00b31, 0x68581511, 0x64f98fa7, 0xbefa4fa4
);

my @H0256 = (			# SHA-256 initial hash value
	0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a,
	0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19
);

my(@H0384, @H0512, @H0512224, @H0512256);  # filled in later if $uses64bit

# Routines with a "_c_" prefix return Perl code-fragments which are
# eval'ed at initialization.  This technique emulates the behavior
# of the C preprocessor, allowing the optimized transform code from
# Digest::SHA to be more easily translated into Perl.

sub _c_SL32 {			# code to shift $x left by $n bits
	my($x, $n) = @_;
	"($x << $n)";		# even works for 64-bit integers
				# since the upper 32 bits are
				# eventually discarded in _digcpy
}

sub _c_SR32 {			# code to shift $x right by $n bits
	my($x, $n) = @_;
	my $mask = (1 << (32 - $n)) - 1;
	"(($x >> $n) & $mask)";		# "use integer" does arithmetic
					# shift, so clear upper bits
}

sub _c_Ch { my($x, $y, $z) = @_; "($z ^ ($x & ($y ^ $z)))" }
sub _c_Pa { my($x, $y, $z) = @_; "($x ^ $y ^ $z)" }
sub _c_Ma { my($x, $y, $z) = @_; "(($x & $y) | ($z & ($x | $y)))" }

sub _c_ROTR {			# code to rotate $x right by $n bits
	my($x, $n) = @_;
	"(" . _c_SR32($x, $n) . " | " . _c_SL32($x, 32 - $n) . ")";
}

sub _c_ROTL {			# code to rotate $x left by $n bits
	my($x, $n) = @_;
	"(" . _c_SL32($x, $n) . " | " . _c_SR32($x, 32 - $n) . ")";
}

sub _c_SIGMA0 {			# ref. NIST SHA standard
	my($x) = @_;
	"(" . _c_ROTR($x,  2) . " ^ " . _c_ROTR($x, 13) . " ^ " .
		_c_ROTR($x, 22) . ")";
}

sub _c_SIGMA1 {
	my($x) = @_;
	"(" . _c_ROTR($x,  6) . " ^ " . _c_ROTR($x, 11) . " ^ " .
		_c_ROTR($x, 25) . ")";
}

sub _c_sigma0 {
	my($x) = @_;
	"(" . _c_ROTR($x,  7) . " ^ " . _c_ROTR($x, 18) . " ^ " .
		_c_SR32($x,  3) . ")";
}

sub _c_sigma1 {
	my($x) = @_;
	"(" . _c_ROTR($x, 17) . " ^ " . _c_ROTR($x, 19) . " ^ " .
		_c_SR32($x, 10) . ")";
}

sub _c_M1Ch {			# ref. Digest::SHA sha.c (sha1 routine)
	my($a, $b, $c, $d, $e, $k, $w) = @_;
	"$e += " . _c_ROTL($a, 5) . " + " . _c_Ch($b, $c, $d) .
		" + $k + $w; $b = " . _c_ROTL($b, 30) . ";\n";
}

sub _c_M1Pa {
	my($a, $b, $c, $d, $e, $k, $w) = @_;
	"$e += " . _c_ROTL($a, 5) . " + " . _c_Pa($b, $c, $d) .
		" + $k + $w; $b = " . _c_ROTL($b, 30) . ";\n";
}

sub _c_M1Ma {
	my($a, $b, $c, $d, $e, $k, $w) = @_;
	"$e += " . _c_ROTL($a, 5) . " + " . _c_Ma($b, $c, $d) .
		" + $k + $w; $b = " . _c_ROTL($b, 30) . ";\n";
}

sub _c_M11Ch { my($k, $w) = @_; _c_M1Ch('$a', '$b', '$c', '$d', '$e', $k, $w) }
sub _c_M11Pa { my($k, $w) = @_; _c_M1Pa('$a', '$b', '$c', '$d', '$e', $k, $w) }
sub _c_M11Ma { my($k, $w) = @_; _c_M1Ma('$a', '$b', '$c', '$d', '$e', $k, $w) }
sub _c_M12Ch { my($k, $w) = @_; _c_M1Ch('$e', '$a', '$b', '$c', '$d', $k, $w) }
sub _c_M12Pa { my($k, $w) = @_; _c_M1Pa('$e', '$a', '$b', '$c', '$d', $k, $w) }
sub _c_M12Ma { my($k, $w) = @_; _c_M1Ma('$e', '$a', '$b', '$c', '$d', $k, $w) }
sub _c_M13Ch { my($k, $w) = @_; _c_M1Ch('$d', '$e', '$a', '$b', '$c', $k, $w) }
sub _c_M13Pa { my($k, $w) = @_; _c_M1Pa('$d', '$e', '$a', '$b', '$c', $k, $w) }
sub _c_M13Ma { my($k, $w) = @_; _c_M1Ma('$d', '$e', '$a', '$b', '$c', $k, $w) }
sub _c_M14Ch { my($k, $w) = @_; _c_M1Ch('$c', '$d', '$e', '$a', '$b', $k, $w) }
sub _c_M14Pa { my($k, $w) = @_; _c_M1Pa('$c', '$d', '$e', '$a', '$b', $k, $w) }
sub _c_M14Ma { my($k, $w) = @_; _c_M1Ma('$c', '$d', '$e', '$a', '$b', $k, $w) }
sub _c_M15Ch { my($k, $w) = @_; _c_M1Ch('$b', '$c', '$d', '$e', '$a', $k, $w) }
sub _c_M15Pa { my($k, $w) = @_; _c_M1Pa('$b', '$c', '$d', '$e', '$a', $k, $w) }
sub _c_M15Ma { my($k, $w) = @_; _c_M1Ma('$b', '$c', '$d', '$e', '$a', $k, $w) }

sub _c_W11 { my($s) = @_; '$W[' . (($s +  0) & 0xf) . ']' }
sub _c_W12 { my($s) = @_; '$W[' . (($s + 13) & 0xf) . ']' }
sub _c_W13 { my($s) = @_; '$W[' . (($s +  8) & 0xf) . ']' }
sub _c_W14 { my($s) = @_; '$W[' . (($s +  2) & 0xf) . ']' }

sub _c_A1 {
	my($s) = @_;
	my $tmp = _c_W11($s) . " ^ " . _c_W12($s) . " ^ " .
		_c_W13($s) . " ^ " . _c_W14($s);
	"((\$tmp = $tmp), (" . _c_W11($s) . " = " . _c_ROTL('$tmp', 1) . "))";
}

# The following code emulates the "sha1" routine from Digest::SHA sha.c

my $sha1_code = '

my($K1, $K2, $K3, $K4) = (	# SHA-1 constants
	0x5a827999, 0x6ed9eba1, 0x8f1bbcdc, 0xca62c1d6
);

sub _sha1 {
	my($self, $block) = @_;
	my(@W, $a, $b, $c, $d, $e, $tmp);

	@W = unpack("N16", $block);
	($a, $b, $c, $d, $e) = @{$self->{H}};
' .
	_c_M11Ch('$K1', '$W[ 0]'  ) . _c_M12Ch('$K1', '$W[ 1]'  ) .
	_c_M13Ch('$K1', '$W[ 2]'  ) . _c_M14Ch('$K1', '$W[ 3]'  ) .
	_c_M15Ch('$K1', '$W[ 4]'  ) . _c_M11Ch('$K1', '$W[ 5]'  ) .
	_c_M12Ch('$K1', '$W[ 6]'  ) . _c_M13Ch('$K1', '$W[ 7]'  ) .
	_c_M14Ch('$K1', '$W[ 8]'  ) . _c_M15Ch('$K1', '$W[ 9]'  ) .
	_c_M11Ch('$K1', '$W[10]'  ) . _c_M12Ch('$K1', '$W[11]'  ) .
	_c_M13Ch('$K1', '$W[12]'  ) . _c_M14Ch('$K1', '$W[13]'  ) .
	_c_M15Ch('$K1', '$W[14]'  ) . _c_M11Ch('$K1', '$W[15]'  ) .
	_c_M12Ch('$K1', _c_A1( 0) ) . _c_M13Ch('$K1', _c_A1( 1) ) .
	_c_M14Ch('$K1', _c_A1( 2) ) . _c_M15Ch('$K1', _c_A1( 3) ) .
	_c_M11Pa('$K2', _c_A1( 4) ) . _c_M12Pa('$K2', _c_A1( 5) ) .
	_c_M13Pa('$K2', _c_A1( 6) ) . _c_M14Pa('$K2', _c_A1( 7) ) .
	_c_M15Pa('$K2', _c_A1( 8) ) . _c_M11Pa('$K2', _c_A1( 9) ) .
	_c_M12Pa('$K2', _c_A1(10) ) . _c_M13Pa('$K2', _c_A1(11) ) .
	_c_M14Pa('$K2', _c_A1(12) ) . _c_M15Pa('$K2', _c_A1(13) ) .
	_c_M11Pa('$K2', _c_A1(14) ) . _c_M12Pa('$K2', _c_A1(15) ) .
	_c_M13Pa('$K2', _c_A1( 0) ) . _c_M14Pa('$K2', _c_A1( 1) ) .
	_c_M15Pa('$K2', _c_A1( 2) ) . _c_M11Pa('$K2', _c_A1( 3) ) .
	_c_M12Pa('$K2', _c_A1( 4) ) . _c_M13Pa('$K2', _c_A1( 5) ) .
	_c_M14Pa('$K2', _c_A1( 6) ) . _c_M15Pa('$K2', _c_A1( 7) ) .
	_c_M11Ma('$K3', _c_A1( 8) ) . _c_M12Ma('$K3', _c_A1( 9) ) .
	_c_M13Ma('$K3', _c_A1(10) ) . _c_M14Ma('$K3', _c_A1(11) ) .
	_c_M15Ma('$K3', _c_A1(12) ) . _c_M11Ma('$K3', _c_A1(13) ) .
	_c_M12Ma('$K3', _c_A1(14) ) . _c_M13Ma('$K3', _c_A1(15) ) .
	_c_M14Ma('$K3', _c_A1( 0) ) . _c_M15Ma('$K3', _c_A1( 1) ) .
	_c_M11Ma('$K3', _c_A1( 2) ) . _c_M12Ma('$K3', _c_A1( 3) ) .
	_c_M13Ma('$K3', _c_A1( 4) ) . _c_M14Ma('$K3', _c_A1( 5) ) .
	_c_M15Ma('$K3', _c_A1( 6) ) . _c_M11Ma('$K3', _c_A1( 7) ) .
	_c_M12Ma('$K3', _c_A1( 8) ) . _c_M13Ma('$K3', _c_A1( 9) ) .
	_c_M14Ma('$K3', _c_A1(10) ) . _c_M15Ma('$K3', _c_A1(11) ) .
	_c_M11Pa('$K4', _c_A1(12) ) . _c_M12Pa('$K4', _c_A1(13) ) .
	_c_M13Pa('$K4', _c_A1(14) ) . _c_M14Pa('$K4', _c_A1(15) ) .
	_c_M15Pa('$K4', _c_A1( 0) ) . _c_M11Pa('$K4', _c_A1( 1) ) .
	_c_M12Pa('$K4', _c_A1( 2) ) . _c_M13Pa('$K4', _c_A1( 3) ) .
	_c_M14Pa('$K4', _c_A1( 4) ) . _c_M15Pa('$K4', _c_A1( 5) ) .
	_c_M11Pa('$K4', _c_A1( 6) ) . _c_M12Pa('$K4', _c_A1( 7) ) .
	_c_M13Pa('$K4', _c_A1( 8) ) . _c_M14Pa('$K4', _c_A1( 9) ) .
	_c_M15Pa('$K4', _c_A1(10) ) . _c_M11Pa('$K4', _c_A1(11) ) .
	_c_M12Pa('$K4', _c_A1(12) ) . _c_M13Pa('$K4', _c_A1(13) ) .
	_c_M14Pa('$K4', _c_A1(14) ) . _c_M15Pa('$K4', _c_A1(15) ) .

'	$self->{H}->[0] += $a; $self->{H}->[1] += $b; $self->{H}->[2] += $c;
	$self->{H}->[3] += $d; $self->{H}->[4] += $e;
}
';

eval($sha1_code);

sub _c_M2 {			# ref. Digest::SHA sha.c (sha256 routine)
	my($a, $b, $c, $d, $e, $f, $g, $h, $w) = @_;
	"\$T1 = $h + " . _c_SIGMA1($e) . " + " . _c_Ch($e, $f, $g) .
		" + \$K256[\$i++] + $w; $h = \$T1 + " . _c_SIGMA0($a) .
		" + " . _c_Ma($a, $b, $c) . "; $d += \$T1;\n";
}

sub _c_M21 { _c_M2('$a', '$b', '$c', '$d', '$e', '$f', '$g', '$h', $_[0]) }
sub _c_M22 { _c_M2('$h', '$a', '$b', '$c', '$d', '$e', '$f', '$g', $_[0]) }
sub _c_M23 { _c_M2('$g', '$h', '$a', '$b', '$c', '$d', '$e', '$f', $_[0]) }
sub _c_M24 { _c_M2('$f', '$g', '$h', '$a', '$b', '$c', '$d', '$e', $_[0]) }
sub _c_M25 { _c_M2('$e', '$f', '$g', '$h', '$a', '$b', '$c', '$d', $_[0]) }
sub _c_M26 { _c_M2('$d', '$e', '$f', '$g', '$h', '$a', '$b', '$c', $_[0]) }
sub _c_M27 { _c_M2('$c', '$d', '$e', '$f', '$g', '$h', '$a', '$b', $_[0]) }
sub _c_M28 { _c_M2('$b', '$c', '$d', '$e', '$f', '$g', '$h', '$a', $_[0]) }

sub _c_W21 { my($s) = @_; '$W[' . (($s +  0) & 0xf) . ']' }
sub _c_W22 { my($s) = @_; '$W[' . (($s + 14) & 0xf) . ']' }
sub _c_W23 { my($s) = @_; '$W[' . (($s +  9) & 0xf) . ']' }
sub _c_W24 { my($s) = @_; '$W[' . (($s +  1) & 0xf) . ']' }

sub _c_A2 {
	my($s) = @_;
	"(" . _c_W21($s) . " += " . _c_sigma1(_c_W22($s)) . " + " .
		_c_W23($s) . " + " . _c_sigma0(_c_W24($s)) . ")";
}

# The following code emulates the "sha256" routine from Digest::SHA sha.c

my $sha256_code = '

my @K256 = (			# SHA-224/256 constants
	0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5,
	0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
	0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3,
	0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,
	0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc,
	0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
	0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7,
	0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,
	0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13,
	0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,
	0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3,
	0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
	0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5,
	0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,
	0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208,
	0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2
);

sub _sha256 {
	my($self, $block) = @_;
	my(@W, $a, $b, $c, $d, $e, $f, $g, $h, $i, $T1);

	@W = unpack("N16", $block);
	($a, $b, $c, $d, $e, $f, $g, $h) = @{$self->{H}};
' .
	_c_M21('$W[ 0]' ) . _c_M22('$W[ 1]' ) . _c_M23('$W[ 2]' ) .
	_c_M24('$W[ 3]' ) . _c_M25('$W[ 4]' ) . _c_M26('$W[ 5]' ) .
	_c_M27('$W[ 6]' ) . _c_M28('$W[ 7]' ) . _c_M21('$W[ 8]' ) .
	_c_M22('$W[ 9]' ) . _c_M23('$W[10]' ) . _c_M24('$W[11]' ) .
	_c_M25('$W[12]' ) . _c_M26('$W[13]' ) . _c_M27('$W[14]' ) .
	_c_M28('$W[15]' ) .
	_c_M21(_c_A2( 0)) . _c_M22(_c_A2( 1)) . _c_M23(_c_A2( 2)) .
	_c_M24(_c_A2( 3)) . _c_M25(_c_A2( 4)) . _c_M26(_c_A2( 5)) .
	_c_M27(_c_A2( 6)) . _c_M28(_c_A2( 7)) . _c_M21(_c_A2( 8)) .
	_c_M22(_c_A2( 9)) . _c_M23(_c_A2(10)) . _c_M24(_c_A2(11)) .
	_c_M25(_c_A2(12)) . _c_M26(_c_A2(13)) . _c_M27(_c_A2(14)) .
	_c_M28(_c_A2(15)) . _c_M21(_c_A2( 0)) . _c_M22(_c_A2( 1)) .
	_c_M23(_c_A2( 2)) . _c_M24(_c_A2( 3)) . _c_M25(_c_A2( 4)) .
	_c_M26(_c_A2( 5)) . _c_M27(_c_A2( 6)) . _c_M28(_c_A2( 7)) .
	_c_M21(_c_A2( 8)) . _c_M22(_c_A2( 9)) . _c_M23(_c_A2(10)) .
	_c_M24(_c_A2(11)) . _c_M25(_c_A2(12)) . _c_M26(_c_A2(13)) .
	_c_M27(_c_A2(14)) . _c_M28(_c_A2(15)) . _c_M21(_c_A2( 0)) .
	_c_M22(_c_A2( 1)) . _c_M23(_c_A2( 2)) . _c_M24(_c_A2( 3)) .
	_c_M25(_c_A2( 4)) . _c_M26(_c_A2( 5)) . _c_M27(_c_A2( 6)) .
	_c_M28(_c_A2( 7)) . _c_M21(_c_A2( 8)) . _c_M22(_c_A2( 9)) .
	_c_M23(_c_A2(10)) . _c_M24(_c_A2(11)) . _c_M25(_c_A2(12)) .
	_c_M26(_c_A2(13)) . _c_M27(_c_A2(14)) . _c_M28(_c_A2(15)) .

'	$self->{H}->[0] += $a; $self->{H}->[1] += $b; $self->{H}->[2] += $c;
	$self->{H}->[3] += $d; $self->{H}->[4] += $e; $self->{H}->[5] += $f;
	$self->{H}->[6] += $g; $self->{H}->[7] += $h;
}
';

eval($sha256_code);

sub _sha512_placeholder { return }
my $sha512 = \&_sha512_placeholder;

my $_64bit_code = '

no warnings qw(portable);

my @K512 = (
	0x428a2f98d728ae22, 0x7137449123ef65cd, 0xb5c0fbcfec4d3b2f,
	0xe9b5dba58189dbbc, 0x3956c25bf348b538, 0x59f111f1b605d019,
	0x923f82a4af194f9b, 0xab1c5ed5da6d8118, 0xd807aa98a3030242,
	0x12835b0145706fbe, 0x243185be4ee4b28c, 0x550c7dc3d5ffb4e2,
	0x72be5d74f27b896f, 0x80deb1fe3b1696b1, 0x9bdc06a725c71235,
	0xc19bf174cf692694, 0xe49b69c19ef14ad2, 0xefbe4786384f25e3,
	0x0fc19dc68b8cd5b5, 0x240ca1cc77ac9c65, 0x2de92c6f592b0275,
	0x4a7484aa6ea6e483, 0x5cb0a9dcbd41fbd4, 0x76f988da831153b5,
	0x983e5152ee66dfab, 0xa831c66d2db43210, 0xb00327c898fb213f,
	0xbf597fc7beef0ee4, 0xc6e00bf33da88fc2, 0xd5a79147930aa725,
	0x06ca6351e003826f, 0x142929670a0e6e70, 0x27b70a8546d22ffc,
	0x2e1b21385c26c926, 0x4d2c6dfc5ac42aed, 0x53380d139d95b3df,
	0x650a73548baf63de, 0x766a0abb3c77b2a8, 0x81c2c92e47edaee6,
	0x92722c851482353b, 0xa2bfe8a14cf10364, 0xa81a664bbc423001,
	0xc24b8b70d0f89791, 0xc76c51a30654be30, 0xd192e819d6ef5218,
	0xd69906245565a910, 0xf40e35855771202a, 0x106aa07032bbd1b8,
	0x19a4c116b8d2d0c8, 0x1e376c085141ab53, 0x2748774cdf8eeb99,
	0x34b0bcb5e19b48a8, 0x391c0cb3c5c95a63, 0x4ed8aa4ae3418acb,
	0x5b9cca4f7763e373, 0x682e6ff3d6b2b8a3, 0x748f82ee5defb2fc,
	0x78a5636f43172f60, 0x84c87814a1f0ab72, 0x8cc702081a6439ec,
	0x90befffa23631e28, 0xa4506cebde82bde9, 0xbef9a3f7b2c67915,
	0xc67178f2e372532b, 0xca273eceea26619c, 0xd186b8c721c0c207,
	0xeada7dd6cde0eb1e, 0xf57d4f7fee6ed178, 0x06f067aa72176fba,
	0x0a637dc5a2c898a6, 0x113f9804bef90dae, 0x1b710b35131c471b,
	0x28db77f523047d84, 0x32caab7b40c72493, 0x3c9ebe0a15c9bebc,
	0x431d67c49c100d4c, 0x4cc5d4becb3e42b6, 0x597f299cfc657e2a,
	0x5fcb6fab3ad6faec, 0x6c44198c4a475817);

@H0384 = (
	0xcbbb9d5dc1059ed8, 0x629a292a367cd507, 0x9159015a3070dd17,
	0x152fecd8f70e5939, 0x67332667ffc00b31, 0x8eb44a8768581511,
	0xdb0c2e0d64f98fa7, 0x47b5481dbefa4fa4);

@H0512 = (
	0x6a09e667f3bcc908, 0xbb67ae8584caa73b, 0x3c6ef372fe94f82b,
	0xa54ff53a5f1d36f1, 0x510e527fade682d1, 0x9b05688c2b3e6c1f,
	0x1f83d9abfb41bd6b, 0x5be0cd19137e2179);

@H0512224 = (
	0x8c3d37c819544da2, 0x73e1996689dcd4d6, 0x1dfab7ae32ff9c82,
	0x679dd514582f9fcf, 0x0f6d2b697bd44da8, 0x77e36f7304c48942,
	0x3f9d85a86a1d36c8, 0x1112e6ad91d692a1);

@H0512256 = (
	0x22312194fc2bf72c, 0x9f555fa3c84c64c2, 0x2393b86b6f53b151,
	0x963877195940eabd, 0x96283ee2a88effe3, 0xbe5e1e2553863992,
	0x2b0199fc2c85b8aa, 0x0eb72ddc81c52ca2);

use warnings;

sub _c_SL64 { my($x, $n) = @_; "($x << $n)" }

sub _c_SR64 {
	my($x, $n) = @_;
	my $mask = (1 << (64 - $n)) - 1;
	"(($x >> $n) & $mask)";
}

sub _c_ROTRQ {
	my($x, $n) = @_;
	"(" . _c_SR64($x, $n) . " | " . _c_SL64($x, 64 - $n) . ")";
}

sub _c_SIGMAQ0 {
	my($x) = @_;
	"(" . _c_ROTRQ($x, 28) . " ^ " .  _c_ROTRQ($x, 34) . " ^ " .
		_c_ROTRQ($x, 39) . ")";
}

sub _c_SIGMAQ1 {
	my($x) = @_;
	"(" . _c_ROTRQ($x, 14) . " ^ " .  _c_ROTRQ($x, 18) . " ^ " .
		_c_ROTRQ($x, 41) . ")";
}

sub _c_sigmaQ0 {
	my($x) = @_;
	"(" . _c_ROTRQ($x, 1) . " ^ " .  _c_ROTRQ($x, 8) . " ^ " .
		_c_SR64($x, 7) . ")";
}

sub _c_sigmaQ1 {
	my($x) = @_;
	"(" . _c_ROTRQ($x, 19) . " ^ " .  _c_ROTRQ($x, 61) . " ^ " .
		_c_SR64($x, 6) . ")";
}

my $sha512_code = q/
sub _sha512 {
	my($self, $block) = @_;
	my(@N, @W, $a, $b, $c, $d, $e, $f, $g, $h, $T1, $T2);

	@N = unpack("N32", $block);
	($a, $b, $c, $d, $e, $f, $g, $h) = @{$self->{H}};
	for ( 0 .. 15) { $W[$_] = (($N[2*$_] << 16) << 16) | $N[2*$_+1] }
	for (16 .. 79) { $W[$_] = / .
		_c_sigmaQ1(q/$W[$_- 2]/) . q/ + $W[$_- 7] + / .
		_c_sigmaQ0(q/$W[$_-15]/) . q/ + $W[$_-16] }
	for ( 0 .. 79) {
		$T1 = $h + / . _c_SIGMAQ1(q/$e/) .
			q/ + (($g) ^ (($e) & (($f) ^ ($g)))) +
				$K512[$_] + $W[$_];
		$T2 = / . _c_SIGMAQ0(q/$a/) .
			q/ + ((($a) & ($b)) | (($c) & (($a) | ($b))));
		$h = $g; $g = $f; $f = $e; $e = $d + $T1;
		$d = $c; $c = $b; $b = $a; $a = $T1 + $T2;
	}
	$self->{H}->[0] += $a; $self->{H}->[1] += $b; $self->{H}->[2] += $c;
	$self->{H}->[3] += $d; $self->{H}->[4] += $e; $self->{H}->[5] += $f;
	$self->{H}->[6] += $g; $self->{H}->[7] += $h;
}
/;

eval($sha512_code);
$sha512 = \&_sha512;

';

eval($_64bit_code) if $uses64bit;

sub _SETBIT {
	my($self, $pos) = @_;
	my @c = unpack("C*", $self->{block});
	$c[$pos >> 3] = 0x00 unless defined $c[$pos >> 3];
	$c[$pos >> 3] |= (0x01 << (7 - $pos % 8));
	$self->{block} = pack("C*", @c);
}

sub _CLRBIT {
	my($self, $pos) = @_;
	my @c = unpack("C*", $self->{block});
	$c[$pos >> 3] = 0x00 unless defined $c[$pos >> 3];
	$c[$pos >> 3] &= ~(0x01 << (7 - $pos % 8));
	$self->{block} = pack("C*", @c);
}

sub _BYTECNT {
	my($bitcnt) = @_;
	$bitcnt > 0 ? 1 + (($bitcnt - 1) >> 3) : 0;
}

sub _digcpy {
	my($self) = @_;
	my @dig;
	for (@{$self->{H}}) {
		push(@dig, (($_>>16)>>16) & $MAX32) if $self->{alg} >= 384;
		push(@dig, $_ & $MAX32);
	}
	$self->{digest} = pack("N" . ($self->{digestlen}>>2), @dig);
}

sub _sharewind {
	my($self) = @_;
	my $alg = $self->{alg};
	$self->{block} = ""; $self->{blockcnt} = 0;
	$self->{blocksize} = $alg <= 256 ? 512 : 1024;
	for (qw(lenll lenlh lenhl lenhh)) { $self->{$_} = 0 }
	$self->{digestlen} = $alg == 1 ? 20 : ($alg % 1000)/8;
	if    ($alg == 1)   { $self->{sha} = \&_sha1;   $self->{H} = [@H01]   }
	elsif ($alg == 224) { $self->{sha} = \&_sha256; $self->{H} = [@H0224] }
	elsif ($alg == 256) { $self->{sha} = \&_sha256; $self->{H} = [@H0256] }
	elsif ($alg == 384) { $self->{sha} = $sha512;   $self->{H} = [@H0384] }
	elsif ($alg == 512) { $self->{sha} = $sha512;   $self->{H} = [@H0512] }
	elsif ($alg == 512224) { $self->{sha}=$sha512; $self->{H}=[@H0512224] }
	elsif ($alg == 512256) { $self->{sha}=$sha512; $self->{H}=[@H0512256] }
	push(@{$self->{H}}, 0) while scalar(@{$self->{H}}) < 8;
	$self;
}

sub _shaopen {
	my($alg) = @_;
	my($self);
	return unless grep { $alg == $_ } (1,224,256,384,512,512224,512256);
	return if ($alg >= 384 && !$uses64bit);
	$self->{alg} = $alg;
	_sharewind($self);
}

sub _shadirect {
	my($bitstr, $bitcnt, $self) = @_;
	my $savecnt = $bitcnt;
	my $offset = 0;
	my $blockbytes = $self->{blocksize} >> 3;
	while ($bitcnt >= $self->{blocksize}) {
		&{$self->{sha}}($self, substr($bitstr, $offset, $blockbytes));
		$offset += $blockbytes;
		$bitcnt -= $self->{blocksize};
	}
	if ($bitcnt > 0) {
		$self->{block} = substr($bitstr, $offset, _BYTECNT($bitcnt));
		$self->{blockcnt} = $bitcnt;
	}
	$savecnt;
}

sub _shabytes {
	my($bitstr, $bitcnt, $self) = @_;
	my($numbits);
	my $savecnt = $bitcnt;
	if ($self->{blockcnt} + $bitcnt >= $self->{blocksize}) {
		$numbits = $self->{blocksize} - $self->{blockcnt};
		$self->{block} .= substr($bitstr, 0, $numbits >> 3);
		$bitcnt -= $numbits;
		$bitstr = substr($bitstr, $numbits >> 3, _BYTECNT($bitcnt));
		&{$self->{sha}}($self, $self->{block});
		$self->{block} = "";
		$self->{blockcnt} = 0;
		_shadirect($bitstr, $bitcnt, $self);
	}
	else {
		$self->{block} .= substr($bitstr, 0, _BYTECNT($bitcnt));
		$self->{blockcnt} += $bitcnt;
	}
	$savecnt;
}

sub _shabits {
	my($bitstr, $bitcnt, $self) = @_;
	my($i, @buf);
	my $numbytes = _BYTECNT($bitcnt);
	my $savecnt = $bitcnt;
	my $gap = 8 - $self->{blockcnt} % 8;
	my @c = unpack("C*", $self->{block});
	my @b = unpack("C" . $numbytes, $bitstr);
	$c[$self->{blockcnt}>>3] &= (~0 << $gap);
	$c[$self->{blockcnt}>>3] |= $b[0] >> (8 - $gap);
	$self->{block} = pack("C*", @c);
	$self->{blockcnt} += ($bitcnt < $gap) ? $bitcnt : $gap;
	return($savecnt) if $bitcnt < $gap;
	if ($self->{blockcnt} == $self->{blocksize}) {
		&{$self->{sha}}($self, $self->{block});
		$self->{block} = "";
		$self->{blockcnt} = 0;
	}
	return($savecnt) if ($bitcnt -= $gap) == 0;
	for ($i = 0; $i < $numbytes - 1; $i++) {
		$buf[$i] = (($b[$i] << $gap) & 0xff) | ($b[$i+1] >> (8 - $gap));
	}
	$buf[$numbytes-1] = ($b[$numbytes-1] << $gap) & 0xff;
	_shabytes(pack("C*", @buf), $bitcnt, $self);
	$savecnt;
}

sub _shawrite {
	my($bitstr, $bitcnt, $self) = @_;
	return(0) unless $bitcnt > 0;
	no integer;
	my $TWO32 = 4294967296;
	if (($self->{lenll} += $bitcnt) >= $TWO32) {
		$self->{lenll} -= $TWO32;
		if (++$self->{lenlh} >= $TWO32) {
			$self->{lenlh} -= $TWO32;
			if (++$self->{lenhl} >= $TWO32) {
				$self->{lenhl} -= $TWO32;
				if (++$self->{lenhh} >= $TWO32) {
					$self->{lenhh} -= $TWO32;
				}
			}
		}
	}
	use integer;
	my $blockcnt = $self->{blockcnt};
	return(_shadirect($bitstr, $bitcnt, $self)) if $blockcnt == 0;
	return(_shabytes ($bitstr, $bitcnt, $self)) if $blockcnt % 8 == 0;
	return(_shabits  ($bitstr, $bitcnt, $self));
}

my $no_downgrade = 'sub utf8::downgrade { 1 }';

my $pp_downgrade = q {
	sub utf8::downgrade {

		# No need to downgrade if character and byte
		# semantics are equivalent.  But this might
		# leave the UTF-8 flag set, harmlessly.

		require bytes;
		return 1 if length($_[0]) == bytes::length($_[0]);

		use utf8;
		return 0 if $_[0] =~ /[^\x00-\xff]/;
		$_[0] = pack('C*', unpack('U*', $_[0]));
		return 1;
	}
};

{
	no integer;

	if    ($] < 5.006)	{ eval $no_downgrade }
	elsif ($] < 5.008)	{ eval $pp_downgrade }
}

my $WSE = 'Wide character in subroutine entry';
my $MWS = 16384;

sub _shaWrite {
	my($bytestr_r, $bytecnt, $self) = @_;
	return(0) unless $bytecnt > 0;
	croak $WSE unless utf8::downgrade($$bytestr_r, 1);
	return(_shawrite($$bytestr_r, $bytecnt<<3, $self)) if $bytecnt <= $MWS;
	my $offset = 0;
	while ($bytecnt > $MWS) {
		_shawrite(substr($$bytestr_r, $offset, $MWS), $MWS<<3, $self);
		$offset  += $MWS;
		$bytecnt -= $MWS;
	}
	_shawrite(substr($$bytestr_r, $offset, $bytecnt), $bytecnt<<3, $self);
}

sub _shafinish {
	my($self) = @_;
	my $LENPOS = $self->{alg} <= 256 ? 448 : 896;
	_SETBIT($self, $self->{blockcnt}++);
	while ($self->{blockcnt} > $LENPOS) {
		if ($self->{blockcnt} < $self->{blocksize}) {
			_CLRBIT($self, $self->{blockcnt}++);
		}
		else {
			&{$self->{sha}}($self, $self->{block});
			$self->{block} = "";
			$self->{blockcnt} = 0;
		}
	}
	while ($self->{blockcnt} < $LENPOS) {
		_CLRBIT($self, $self->{blockcnt}++);
	}
	if ($self->{blocksize} > 512) {
		$self->{block} .= pack("N", $self->{lenhh} & $MAX32);
		$self->{block} .= pack("N", $self->{lenhl} & $MAX32);
	}
	$self->{block} .= pack("N", $self->{lenlh} & $MAX32);
	$self->{block} .= pack("N", $self->{lenll} & $MAX32);
	&{$self->{sha}}($self, $self->{block});
}

sub _shadigest { my($self) = @_; _digcpy($self); $self->{digest} }

sub _shahex {
	my($self) = @_;
	_digcpy($self);
	join("", unpack("H*", $self->{digest}));
}

sub _shabase64 {
	my($self) = @_;
	_digcpy($self);
	my $b64 = pack("u", $self->{digest});
	$b64 =~ s/^.//mg;
	$b64 =~ s/\n//g;
	$b64 =~ tr|` -_|AA-Za-z0-9+/|;
	my $numpads = (3 - length($self->{digest}) % 3) % 3;
	$b64 =~ s/.{$numpads}$// if $numpads;
	$b64;
}

sub _shadsize { my($self) = @_; $self->{digestlen} }

sub _shacpy {
	my($to, $from) = @_;
	$to->{alg} = $from->{alg};
	$to->{sha} = $from->{sha};
	$to->{H} = [@{$from->{H}}];
	$to->{block} = $from->{block};
	$to->{blockcnt} = $from->{blockcnt};
	$to->{blocksize} = $from->{blocksize};
	for (qw(lenhh lenhl lenlh lenll)) { $to->{$_} = $from->{$_} }
	$to->{digestlen} = $from->{digestlen};
	$to;
}

sub _shadup { my($self) = @_; my($copy); _shacpy($copy, $self) }

sub _shadump {
	my $self = shift;
	for (qw(alg H block blockcnt lenhh lenhl lenlh lenll)) {
		return unless defined $self->{$_};
	}

	my @state = ();
	my $fmt = ($self->{alg} <= 256 ? "%08x" : "%016x");

	push(@state, "alg:" . $self->{alg});

	my @H = map { $self->{alg} <= 256 ? $_ & $MAX32 : $_ } @{$self->{H}};
	push(@state, "H:" . join(":", map { sprintf($fmt, $_) } @H));

	my @c = unpack("C*", $self->{block});
	push(@c, 0x00) while scalar(@c) < ($self->{blocksize} >> 3);
	push(@state, "block:" . join(":", map {sprintf("%02x", $_)} @c));
	push(@state, "blockcnt:" . $self->{blockcnt});

	push(@state, "lenhh:" . $self->{lenhh});
	push(@state, "lenhl:" . $self->{lenhl});
	push(@state, "lenlh:" . $self->{lenlh});
	push(@state, "lenll:" . $self->{lenll});
	join("\n", @state) . "\n";
}

sub _shaload {
	my $state = shift;

	my %s = ();
	for (split(/\n/, $state)) {
		s/^\s+//;
		s/\s+$//;
		next if (/^(#|$)/);
		my @f = split(/[:\s]+/);
		my $tag = shift(@f);
		$s{$tag} = join('', @f);
	}

	# H and block may contain arbitrary values, but check everything else
	grep { $_ == $s{alg} } (1,224,256,384,512,512224,512256) or return;
	length($s{H}) == ($s{alg} <= 256 ? 64 : 128) or return;
	length($s{block}) == ($s{alg} <= 256 ? 128 : 256) or return;
	{
		no integer;
		for (qw(blockcnt lenhh lenhl lenlh lenll)) {
			0 <= $s{$_} or return;
			$s{$_} <= 4294967295 or return;
		}
		$s{blockcnt} < ($s{alg} <= 256 ? 512 : 1024) or return;
	}

	my $self = _shaopen($s{alg}) or return;

	my @h = $s{H} =~ /(.{8})/g;
	for (@{$self->{H}}) {
		$_ = hex(shift @h);
		if ($self->{alg} > 256) {
			$_ = (($_ << 16) << 16) | hex(shift @h);
		}
	}

	$self->{blockcnt} = $s{blockcnt};
	$self->{block} = pack("H*", $s{block});
	$self->{block} = substr($self->{block},0,_BYTECNT($self->{blockcnt}));

	$self->{lenhh} = $s{lenhh};
	$self->{lenhl} = $s{lenhl};
	$self->{lenlh} = $s{lenlh};
	$self->{lenll} = $s{lenll};

	$self;
}

# ref. src/hmac.c from Digest::SHA

sub _hmacopen {
	my($alg, $key) = @_;
	my($self);
	$self->{isha} = _shaopen($alg) or return;
	$self->{osha} = _shaopen($alg) or return;
	croak $WSE unless utf8::downgrade($key, 1);
	if (length($key) > $self->{osha}->{blocksize} >> 3) {
		$self->{ksha} = _shaopen($alg) or return;
		_shawrite($key, length($key) << 3, $self->{ksha});
		_shafinish($self->{ksha});
		$key = _shadigest($self->{ksha});
	}
	$key .= chr(0x00)
		while length($key) < $self->{osha}->{blocksize} >> 3;
	my @k = unpack("C*", $key);
	for (@k) { $_ ^= 0x5c }
	_shawrite(pack("C*", @k), $self->{osha}->{blocksize}, $self->{osha});
	for (@k) { $_ ^= (0x5c ^ 0x36) }
	_shawrite(pack("C*", @k), $self->{isha}->{blocksize}, $self->{isha});
	$self;
}

sub _hmacWrite {
	my($bytestr_r, $bytecnt, $self) = @_;
	_shaWrite($bytestr_r, $bytecnt, $self->{isha});
}

sub _hmacfinish {
	my($self) = @_;
	_shafinish($self->{isha});
	_shawrite(_shadigest($self->{isha}),
			$self->{isha}->{digestlen} << 3, $self->{osha});
	_shafinish($self->{osha});
}

sub _hmacdigest { my($self) = @_; _shadigest($self->{osha}) }
sub _hmachex    { my($self) = @_; _shahex($self->{osha})    }
sub _hmacbase64 { my($self) = @_; _shabase64($self->{osha}) }

# SHA and HMAC-SHA functions

my @suffix_extern = ("", "_hex", "_base64");
my @suffix_intern = ("digest", "hex", "base64");

my($i, $alg);
for $alg (1, 224, 256, 384, 512, 512224, 512256) {
	for $i (0 .. 2) {
		my $fcn = 'sub sha' . $alg . $suffix_extern[$i] . ' {
			my $state = _shaopen(' . $alg . ') or return;
			for (@_) { _shaWrite(\$_, length($_), $state) }
			_shafinish($state);
			_sha' . $suffix_intern[$i] . '($state);
		}';
		eval($fcn);
		push(@EXPORT_OK, 'sha' . $alg . $suffix_extern[$i]);
		$fcn = 'sub hmac_sha' . $alg . $suffix_extern[$i] . ' {
			my $state = _hmacopen(' . $alg . ', pop(@_)) or return;
			for (@_) { _hmacWrite(\$_, length($_), $state) }
			_hmacfinish($state);
			_hmac' . $suffix_intern[$i] . '($state);
		}';
		eval($fcn);
		push(@EXPORT_OK, 'hmac_sha' . $alg . $suffix_extern[$i]);
	}
}

# OOP methods

sub hashsize  { my $self = shift; _shadsize($self) << 3 }
sub algorithm { my $self = shift; $self->{alg} }

sub add {
	my $self = shift;
	for (@_) { _shaWrite(\$_, length($_), $self) }
	$self;
}

sub digest {
	my $self = shift;
	_shafinish($self);
	my $rsp = _shadigest($self);
	_sharewind($self);
	$rsp;
}

sub hexdigest {
	my $self = shift;
	_shafinish($self);
	my $rsp = _shahex($self);
	_sharewind($self);
	$rsp;
}

sub b64digest {
	my $self = shift;
	_shafinish($self);
	my $rsp = _shabase64($self);
	_sharewind($self);
	$rsp;
}

sub new {
	my($class, $alg) = @_;
	$alg =~ s/\D+//g if defined $alg;
	if (ref($class)) {	# instance method
		if (!defined($alg) || ($alg == $class->algorithm)) {
			_sharewind($class);
			return($class);
		}
		my $self = _shaopen($alg) or return;
		return(_shacpy($class, $self));
	}
	$alg = 1 unless defined $alg;
	my $self = _shaopen($alg) or return;
	bless($self, $class);
	$self;
}

sub clone {
	my $self = shift;
	my $copy = _shadup($self) or return;
	bless($copy, ref($self));
}

BEGIN { *reset = \&new }

sub add_bits {
	my($self, $data, $nbits) = @_;
	unless (defined $nbits) {
		$nbits = length($data);
		$data = pack("B*", $data);
	}
	$nbits = length($data) * 8 if $nbits > length($data) * 8;
	_shawrite($data, $nbits, $self);
	return($self);
}

sub _bail {
	my $msg = shift;

	$msg .= ": $!";
	croak $msg;
}

sub _addfile {
	my ($self, $handle) = @_;

	my $n;
	my $buf = "";

	while (($n = read($handle, $buf, 4096))) {
		$self->add($buf);
	}
	_bail("Read failed") unless defined $n;

	$self;
}

{
	my $_can_T_filehandle;

	sub _istext {
		local *FH = shift;
		my $file = shift;

		if (! defined $_can_T_filehandle) {
			local $^W = 0;
			my $istext = eval { -T FH };
			$_can_T_filehandle = $@ ? 0 : 1;
			return $_can_T_filehandle ? $istext : -T $file;
		}
		return $_can_T_filehandle ? -T FH : -T $file;
	}
}

sub addfile {
	my ($self, $file, $mode) = @_;

	return(_addfile($self, $file)) unless ref(\$file) eq 'SCALAR';

	$mode = defined($mode) ? $mode : "";
	my ($binary, $UNIVERSAL, $BITS, $portable) =
		map { $_ eq $mode } ("b", "U", "0", "p");

		## Always interpret "-" to mean STDIN; otherwise use
		## sysopen to handle full range of POSIX file names

	local *FH;
	$file eq '-' and open(FH, '< -')
		or sysopen(FH, $file, O_RDONLY)
			or _bail('Open failed');

	if ($BITS) {
		my ($n, $buf) = (0, "");
		while (($n = read(FH, $buf, 4096))) {
			$buf =~ s/[^01]//g;
			$self->add_bits($buf);
		}
		_bail("Read failed") unless defined $n;
		close(FH);
		return($self);
	}

	binmode(FH) if $binary || $portable || $UNIVERSAL;
	if ($UNIVERSAL && _istext(*FH, $file)) {
		while (<FH>) {
			s/\015\012/\012/g;	# DOS/Windows
			s/\015/\012/g;		# early MacOS
			$self->add($_);
		}
	}
	elsif ($portable && _istext(*FH, $file)) {
		while (<FH>) {
			s/\015?\015\012/\012/g;
			s/\015/\012/g;
			$self->add($_);
		}
	}
	else { $self->_addfile(*FH) }
	close(FH);

	$self;
}

sub getstate {
	my $self = shift;

	return _shadump($self);
}

sub putstate {
	my $class = shift;
	my $state = shift;

	if (ref($class)) {	# instance method
		my $self = _shaload($state) or return;
		return(_shacpy($class, $self));
	}
	my $self = _shaload($state) or return;
	bless($self, $class);
	return($self);
}

sub dump {
	my $self = shift;
	my $file = shift;

	my $state = $self->getstate or return;
	$file = "-" if (!defined($file) || $file eq "");

	local *FH;
	open(FH, "> $file") or return;
	print FH $state;
	close(FH);

	return($self);
}

sub load {
	my $class = shift;
	my $file = shift;

	$file = "-" if (!defined($file) || $file eq "");
	
	local *FH;
	open(FH, "< $file") or return;
	my $str = join('', <FH>);
	close(FH);

	$class->putstate($str);
}

1;
1 core/conf/lib
conf.pl
58 core/conf/conf.pl
# Configuration variables.
# These can be specified as environment vars or overridden locally for specific
# operations.

our %conf_variables;
our %conf_defaults;

sub conf($) {
  die "ni: nonexistent configuration variable $_[0] (ni //ni/conf to list)"
    unless exists $conf_variables{$_[0]};
  dor $conf_variables{$_[0]}->(), $conf_defaults{$_[0]};
}

sub conf_set($$) {
  die "ni: nonexistent configuration variable $_[0] (ni //ni/conf to list)"
    unless exists $conf_variables{$_[0]};
  $conf_variables{$_[0]}->($_[1]);
}

defoperator conf_get => q{
  my ($name) = @_;
  sio();
  print conf $name, "\n";
};

sub defconf($$) {
  $conf_variables{$_[0]} = fn $_[1];
  defshort '/$' . $_[0], pmap qq{conf_get_op '$_[0]'}, pnone;
}

sub conf_env {
  my ($name, $v) = @_;
  $ENV{$name} = $v if @_ == 2;
  $ENV{$name};
}

sub defconfenv($$$) {
  my ($name, $env, $v) = @_;
  defconf $name, qq{conf_env '$env', \@_};
  $conf_defaults{$name} = $v;
}

defoperator configure => q{
  my ($vars, $f) = @_;
  conf_set $_, $$vars{$_} for keys %$vars;
  conf_set monitor => 0 unless exists $$vars{monitor};
  &$ni::main_operator(flatten_operators $f);
};

BEGIN {defparseralias config_map_key   => prx '[^=]+';
       defparseralias config_map_value => prc '.*[^}]+|'}
BEGIN {defparseralias config_map_kv    => pn [0, 2], config_map_key, pstr '=',
                                                     config_map_value}
BEGIN {defparseralias config_option_map
         => pmap q{my %h; $h{$$_[0]} = $$_[1] for @{$_[0]}; \%h},
            pn 0, prep(config_map_kv), prc '}'}

defshort '/^{', pmap q{configure_op @$_}, pseq config_option_map, _qfn;
6 core/stream/lib
fh.pl
procfh.pl
pipeline.pl
self.pl
ops.pl
main.pl
9 core/stream/fh.pl
# Filehandle functions.

use Fcntl qw/:DEFAULT/;

sub fh_nonblock($) {
  my ($fh) = @_;
  my $flags = fcntl $fh, F_GETFL, 0       or die "ni: fcntl get $fh: $!";
  fcntl $fh, F_SETFL, $flags | O_NONBLOCK or die "ni: fcntl set $fh: $!";
}
98 core/stream/procfh.pl
# Process + filehandle combination.
# We can't use Perl's process-aware FHs because they block-wait for the process
# on close. There are some situations where we care about the exit code and
# others where we don't, and this class supports both cases.

package ni::procfh;

use POSIX qw/:sys_wait_h/;

# Global child collector.
# Collect children regardless of whether anyone is listening for them. If we have
# an interested party, notify them.

our %child_owners;

sub await_children {
  local ($!, $?, $_);
  while (0 < ($_ = waitpid -1, WNOHANG)) {
    $child_owners{$_}->child_exited($?) if defined $child_owners{$_};
  }
  $SIG{CHLD} = \&await_children;
};
$SIG{CHLD} = \&await_children;

# Signal forwarding.
# Propagate termination signals to children and run finalizers. This makes it so
# that non-writing pipelines like `ni n100000000gzn` still die out without
# waiting for the SIGPIPE.

sub kill_children($) {kill $_[0], keys %child_owners}

# Proc-filehandle class.
# Overloading *{} makes it possible for this to act like a real filehandle in
# every sense: fileno() works, syswrite() works, etc. The constructor takes care
# of numeric fds by promoting them into Perl fh references.

use overload qw/*{} fh "" str/;
sub new($$$) {
  my ($class, $fd, $pid) = @_;
  my $result = bless {pid => $pid, status => undef}, $class;
  $child_owners{$pid} = $result;
  my $fh = ref($fd) ? $fd : undef;
  open $fh, "<&=$fd" or die "ni: procfh($fd, $pid) failed: $!"
    unless defined $fh;
  $$result{fh} = $fh;
  $result;
}

sub DESTROY {
  my ($self) = @_;
  close $$self{fh};
  delete $child_owners{$$self{pid}} unless defined $$self{status};
}

sub fh($)     {my ($self) = @_; $$self{fh}}
sub pid($)    {my ($self) = @_; $$self{pid}}
sub status($) {my ($self) = @_; $$self{status}}

sub kill($$) {
  my ($self, $sig) = @_;
  kill $sig, $$self{pid} unless defined $$self{status};
}

sub str($)
{ my ($self) = @_;
  sprintf "<fd %d, pid %d, status %s>",
          fileno $$self{fh}, $$self{pid}, $$self{status} || 'none' }

# Child await.
# We have to stop the SIGCHLD handler while we wait for the child in question.
# Otherwise we run the risk of waitpid() blocking forever or catching the wrong
# process. This ends up being fine because this process can't create more
# children while waitpid() is waiting, so we might have some resource delays but
# we won't have a leak.

# We also don't have to worry about multithreading: only one await() call can
# happen per process.

sub await($) {
  local ($?, $SIG{CHLD});
  my ($self) = @_;
  return $$self{status} if defined $$self{status};
  $SIG{CHLD} = 'DEFAULT';
  return $$self{status} if defined $$self{status};
  if (kill 'ZERO', $$self{pid}) {
    my $pid = waitpid $$self{pid}, 0;
    $self->child_exited($pid <= 0 ? "-1 [waitpid: $!]" : $?);
  } else {
    $self->child_exited("-1 [child already collected]");
  }
  $$self{status};
}

sub child_exited($$) {
  my ($self, $status) = @_;
  $$self{status} = $status;
  delete $child_owners{$$self{pid}};
}
235 core/stream/pipeline.pl
# Pipeline construction.
# A way to build a shell pipeline in-process by consing a transformation onto
# this process's standard input. This will cause a fork to happen, and the forked
# PID is returned.

# I define some system functions with a `c` prefix: these are checked system
# calls that will die with a helpful message if anything fails.

no warnings 'io';

use Errno qw/EINTR/;
use POSIX qw/dup2/;

sub cdup2 {defined dup2 $_[0], $_[1] or die "ni: dup2(@_) failed: $!"}
sub cpipe {pipe $_[0], $_[1] or die "ni: pipe failed: $!"}
sub cfork {my $pid = fork; die "ni: fork failed: $!" unless defined $pid; $pid}

sub sh($) {exec 'sh', '-c', $_[0]}

sub nuke_stdin() {
  open STDIN, '</dev/null';
  if (fileno STDIN) {
    cdup2 fileno STDIN, 0;
    open STDIN, '<&=0';
  }
}

# Safe reads/writes.
# This is required because older versions of Perl don't automatically retry
# interrupted reads/writes. We run the risk of interruption because we have a
# SIGCHLD handler. nfu lost data on older versions of Perl because it failed to
# handle this case properly.

sub saferead($$$;$) {
  my $n;
  do {
    return $n if defined($n = sysread $_[0], $_[1], $_[2], $_[3] || 0);
  } while $!{EINTR};
  return undef;
}

sub safewrite($$;$$) {
  my $n;
  do {
    return $n if defined($n = syswrite $_[0], $_[1], $_[2] || length $_[1], $_[3] || 0);
  } while $!{EINTR};
  return undef;
}

sub saferead_exactly($$$;$) {
  my ($r, $n) = (0, 0);
  while ($r < $_[2]) {
    return undef unless $n = saferead $_[0], $_[1], $_[2] - $r, ($_[3] || 0) + $r;
    $r += $n;
  }
  $r;
}

sub safewrite_exactly($$) {
  my ($w, $n) = (0, 0);
  while ($w < length $_[1]) {
    return undef unless $n = safewrite $_[0], $_[1], length($_[1]) - $w, $w;
    $w += $n;
  }
  $w;
}

# Process construction.
# A few functions, depending on what you want to do:

# | siproc(&): fork into block, return pipe FH to block's STDIN.
#   soproc(&): fork into block, return pipe FH from block's STDOUT.
#   sicons(&): fork into block, connect its STDOUT to our STDIN.
#   socons(&): fork into block, connect our STDOUT to its STDIN.

# NOTE: forkopen does something strange and noteworthy. You'll notice that it's
# reopening STDIN and STDOUT from FDs, which seems redundant. This is required
# because Perl filehandles aren't the same as OS-level file descriptors, and ni
# deals with both in different ways.

# In particular, ni closes STDIN (the filehandle) if the input comes from a
# terminal, since presumably the user doesn't intend to type their input in
# manually. This needs to happen before any exec() from a forked filter process.
# But this creates a problem: if we later reactivate fd 0, which we do by moving
# file descriptors from a pipe. We have to do this at the fd level so exec()
# works correctly (since exec doesn't know anything about Perl filehandles, just
# fds). Anyway, despite the fact that fd 0 is newly activated by an sicons {}
# operation, Perl's STDIN filehandle will think it's closed and return no data.

# So that's why we do these redundant open STDIN and STDOUT operations. At some
# point I might bypass Perl's IO layer altogether and use POSIX calls, but at the
# moment that seems like more trouble than it's worth.

sub forkopen {
  my ($fd, $f, @args) = @_;
  cpipe my $r, my $w;
  my ($ret, $child) = ($r, $w)[$fd ^ 1, $fd];
  my $pid;
  if ($pid = cfork) {
    close $child;
    return ni::procfh->new($ret, $pid);
  } else {
    close $ret;
    cdup2 fileno $child, $fd;
    close $child;
    open STDIN,  '<&=0' if $fd == 0;
    open STDOUT, '>&=1' if $fd == 1;
    &$f(@args);
    exit;
  }
}

sub sioproc(&@) {
  my ($f, @args) = @_;
  cpipe my $proc_in, my $w;
  cpipe my $r, my $proc_out;
  my $pid;
  if ($pid = cfork) {
    close $proc_in;
    close $proc_out;
    return ($w, ni::procfh->new($r, $pid));
  } else {
    close $w;
    close $r;
    cdup2 fileno $proc_in, 0;
    cdup2 fileno $proc_out, 1;
    close $proc_in;
    close $proc_out;
    open STDIN,  '<&=0';
    open STDOUT, '>&=1';
    &$f(@args);
    exit;
  }
}

sub siproc(&@) {forkopen 0, @_}
sub soproc(&@) {forkopen 1, @_}

sub sicons(&@) {
  my ($f, @args) = @_;
  my $fh = soproc {&$f(@args)};
  cdup2 fileno $fh, 0;
  close $fh;
  open STDIN, '<&=0';
  $fh;
}

sub socons(&@) {
  my ($f, @args) = @_;
  my $fh = siproc {&$f(@args)};
  cdup2 fileno $fh, 1;
  close $fh;
  open STDOUT, '>&=1';
  $fh;
}

# Stream functions.
# These are called by pipelines to simplify things. For example, a common
# operation is to append the output of some data-producing command:

# | $ ni . .              # lists current directory twice

# If you do this, ni will create a pipeline that uses stream wrappers to
# concatenate the second `ls` output (despite the fact that technically it's a
# shell pipe).

sub sforward($$) {local $_; safewrite_exactly $_[1], $_ while saferead $_[0], $_, 8192}
sub stee($$$)    {local $_; safewrite_exactly($_[1], $_), safewrite_exactly($_[2], $_) while saferead $_[0], $_, 8192}
sub sio()        {sforward \*STDIN, \*STDOUT}

sub srfile($) {open my $fh, '<', $_[0] or die "ni: srfile $_[0]: $!"; $fh}
sub swfile($) {mkdir_p dirname $_[0];
               open my $fh, '>', $_[0] or die "ni: swfile $_[0]: $!"; $fh}

# Compressed stream support.
# This provides a stdin filter you can use to read the contents of a compressed
# stream as though it weren't compressed. It's implemented as a filter process so
# we don't need to rely on file extensions.

# We detect the following file formats:

# | gzip:  1f 8b
#   bzip2: BZh[1-9]    (sometimes \0 instead of the digit)
#   lzo:   89 4c 5a 4f
#   lz4:   04 22 4d 18
#   xz:    fd 37 7a 58 5a

# Decoding works by reading enough to decode the magic, then forwarding data
# into the appropriate decoding process (or doing nothing if we don't know what
# the data is).

sub sdecode(;$) {
  local $_;
  return unless saferead \*STDIN, $_, 8192;

  my $decoder = /^\x1f\x8b/             ? "gzip -dc || cat"
              : /^BZh[1-9\0]/           ? "pbzip2 -dc || bzip2 -dc || cat"
              : /^\x89\x4c\x5a\x4f/     ? "lzop -dc || cat"
              : /^\x04\x22\x4d\x18/     ? "lz4 -dc || cat"
              : /^\xfd\x37\x7a\x58\x5a/ ? "xz -dc || cat" : undef;

  if (defined $decoder) {
    my $o = siproc {exec $decoder};
    safewrite_exactly $o, $_;
    sforward \*STDIN, $o;
    close $o;
    $o->await;
  } else {
    safewrite_exactly \*STDOUT, $_;
    sio;
  }
}

# File/directory cat.
# cat exists to turn filesystem objects into text. Files are emitted and
# directories are turned into readable listings. Files are automatically
# decompressed and globs are automatically deglobbed.

sub glob_expand($) {-e($_[0]) ? $_[0] : glob $_[0]}

sub scat {
  local $| = 1;
  for my $f (map glob_expand($_), @_) {
    if (-d $f) {
      opendir my $d, $f or die "ni_cat: failed to opendir $f: $!";
      print "$f/$_\n" for sort grep !/^\.\.?$/, readdir $d;
      closedir $d;
    } else {
      my $d = siproc {sdecode};
      sforward srfile $f, $d;
      close $d;
      $d->await;
    }
  }
}
101 core/stream/self.pl
# Self invocation.
# You can run ni and read from the resulting file descriptor; this gives you a
# way to evaluate lambda expressions (this is how checkpoints work, for example).
# If you do this, ni's standard input will come from a continuation of __DATA__.

use Errno qw/EINTR/;

our @quoted_resources;
our %non_propagated_env_vars;

sub defnonpropagatedenv {@non_propagated_env_vars{@_} = map 1, @_}

# TMPDIR is notoriously non-portable and shouldn't be forwarded at all.
defnonpropagatedenv 'TMPDIR';

sub quoted_resources()     {@quoted_resources}
sub add_quoted_resource($) {push @quoted_resources, $_[0]}

sub safereadbuf($$$;$) {
  my $n;
  do {
    return $n if defined($n = read $_[0], $_[1], $_[2], $_[3] || 0);
  } while $!{EINTR};
  return undef;
}

sub safereadbuf_exactly($$$;$) {
  my ($r, $n) = (0, 0);
  while ($r < $_[2]) {
    return undef unless $n = safereadbuf $_[0], $_[1], $_[2] - $r, ($_[3] || 0) + $r;
    $r += $n;
  }
  $r;
}

defclispecial '--internal/operate-quoted', q{
  my $parent_env = json_decode $ni::self{'quoted/env'};
  exists $ENV{$_} or $ENV{$_} = $$parent_env{$_} for keys %$parent_env;

  sforward_buf_unquoted $ni::data, resource_write($_)
    for @{json_decode $ni::self{'quoted/resources'}};

  $ni::is_toplevel = 0;
  my $fh = siproc {
    &$ni::main_operator(flatten_operators json_decode $ni::self{'quoted/op'});
  };
  safewrite $fh, $_ while safereadbuf $ni::data, $_, 8192;
  close $fh;
  $fh->await;
}, <<'_';
Internal option: causes ni to parse keys within its image and use those as the
list of operators to run. This is how all of ni's remoting is done; the
indirection prevents us from hitting any size limits on ARGV or ENV.
_

sub sforward_quoted($$) {
  my ($n, $b);
  safewrite $_[1], pack 'na*', $n, $b while $n = saferead $_[0], $b, 8192;
  safewrite $_[1], pack 'n', 0;
}

sub sforward_buf_unquoted($$) {
  my ($n, $nb, $b, $eof) = (0, '', '', 0);
  while (!$eof and safereadbuf_exactly $_[0], $nb, 2 and ($n) = unpack 'n', $nb) {
    $b = '';
    $eof ||= !safereadbuf $_[0], $b, $n - length($b), length $b
      until $eof or length($b) >= $n;
    safewrite $_[1], $b;
  }
}

sub ni_quoted_exec_args() {qw|perl - --internal/operate-quoted|}

sub ni_quoted_image($@) {
  my ($include_quoted_resources, @args) = @_;
  my @env_keys = grep !$non_propagated_env_vars{$_}, keys %ENV;
  my %reduced_env;
  @reduced_env{@env_keys} = @ENV{@env_keys};
  image_with
    'quoted/op'        => json_encode [@args],
    'quoted/env'       => json_encode {%reduced_env},
    'quoted/resources' => json_encode($include_quoted_resources
                                        ? [@quoted_resources]
                                        : []);
}

sub quote_ni_into($@) {
  my ($fh, @args) = @_;
  safewrite $fh, ni_quoted_image 1, @args;
  sforward_quoted resource_read($_), $fh for @quoted_resources;
  sforward \*STDIN, $fh;
  close $fh;
  $fh->await;
}

sub exec_ni(@) {
  my $ni = siproc {exec ni_quoted_exec_args};
  quote_ni_into $ni, @_;
}

sub sni(@) {soproc {nuke_stdin; exec_ni @_} @_}
312 core/stream/ops.pl
# Streaming data sources.
# Common ways to read data, most notably from files and directories. Also
# included are numeric generators, shell commands, etc.

BEGIN {
  defparseralias multiword    => pn 1, prx '\[',  prep(prc '[\s\S]*[^]]', 1), prx '\]';
  defparseralias multiword_ws => pn 1, prc '\[$', prep(pnx '\]$',         1), prx '\]$';

  defparser 'super_brackets', '', q{
    my ($self, @xs) = @_;
    return () unless $xs[0] =~ s/^(\^[^[]*)\[//;
    my $superness = $1;
    my @r;
    push @r, shift @xs while @xs && $xs[0] !~ s/^(\Q$superness\E)\]//;
    $1 eq $superness ? (\@r, @xs) : ();
  };
}
BEGIN {
  defparseralias shell_command => palt pmap(q{shell_quote @$_}, super_brackets),
                                       pmap(q{shell_quote @$_}, multiword_ws),
                                       pmap(q{shell_quote @$_}, multiword),
                                       prx '[^][]+';

  defparseralias shell_arg => palt pmap(q{shell_quote @$_}, super_brackets),
                                   pmap(q{shell_quote @$_}, multiword_ws),
                                   pmap(q{shell_quote @$_}, multiword),
                                   pmap q{shell_quote $_},  prx '[^][]+';

  defparseralias id_text => palt pmap(q{join "\t", @$_}, super_brackets),
                                 pmap(q{join "\t", @$_}, multiword_ws),
                                 pmap(q{join "\t", @$_}, multiword),
                                 prx '[^][]+';
}

defoperator echo => q{my ($x) = @_; sio; print "$x\n"};
defoperator sh   => q{my ($c) = @_; sh $c};

defshort '/e', pmap q{sh_op $_}, shell_command;

# Cat meta-operator.
# We don't want 'cat' to be a regular operator because of how shell wildcards
# work. If you say something like `ni *`, it's going to get a bunch of filenames,
# each of which will fork out to another ni process. Most of these ni processes
# will just be copying stdin to stdout, a huge waste if there are a lot of files.

# We get around this by making `cat` a meta-operator that merges adjacent cat
# operations into a single `cat_multi`.

defoperator cat_multi => q{sio; scat $_ for @_};

defmetaoperator cat => q{
  my ($args, $left, $right) = @_;
  my ($f) = @$args;
  my $i = -1;
  ++$i while $i+1 < @$right && $$right[$i+1][0] eq 'cat';
  ($left, [cat_multi_op($f, $i > -1 ? map $$_[1], @$right[0..$i] : ()),
           @$right[$i+1..$#{$right}]]);
};

docparser multiword => <<'_';
A bracketed list of arguments to exec(), interpreted verbatim (i.e. shell
metacharacters within the arguments won't be expanded). If you use this form,
no ARGV entry can end in a closing bracket; otherwise ni will assume you wanted
to close the list.
_

docparser multiword_ws => <<'_';
A bracketed list of arguments to exec(), interpreted verbatim (i.e. shell
metacharacters within the arguments won't be expanded). Whitespace is required
around both brackets.
_

docparser shell_command => q{A quoted or bracketed shell command};

docoperator cat  => q{Append contents of a file or resource};
docoperator echo => q{Append text verbatim};
docoperator sh   => q{Filter stream through a shell command};

# Note that we generate numbers internally rather than shelling out to `seq`
# (which is ~20x faster than Perl for the purpose, incidentally). This is
# deliberate: certain versions of `seq` generate floating-point numbers after a
# point, which can cause unexpected results and loss of precision.

defoperator n => q{
  my ($l, $u) = @_;
  sio; for (my $i = $l; $u < 0 || $i < $u; ++$i) {print "$i\n"};
};

docoperator n => q{Append consecutive integers within a range};

defshort '/n',  pmap q{n_op 1, defined $_ ? $_ + 1 : -1}, popt number;
defshort '/n0', pmap q{n_op 0, defined $_ ? $_ : -1}, popt number;
defshort '/i',  pmap q{echo_op $_}, id_text;

defshort '/1', pmap q{n_op 1, 2}, pnone;

deflong '/fs', pmap q{cat_op $_}, filename;

docshort '/n' => q{Append integers 1..N, or 1..infinity if N is unspecified};
docshort '/n0' => q{Append integers 0..N-1, or 0..infinity if N is unspecified};
docshort '/i' => q{Identity: append literal text};
docshort '/e' => q{Exec shell command as a filter for the current stream};

docshort '/1' => q{Alias for 'n1'};

doclong '/fs' => q{Append things that appear to be files};

# Stream mixing/forking.
# Append, prepend, divert.

defoperator append => q{my @xs = @_; sio; exec_ni @xs};
docoperator append => q{Append another ni stream to this one};

defoperator prepend => q{
  my @xs = @_;
  close(my $fh = siproc {exec_ni @xs});
  $fh->await;
  sio;
};
docoperator prepend => q{Prepend a ni stream to this one};

defoperator sink_null => q{1 while saferead \*STDIN, $_, 8192};
docoperator sink_null => q{Consume stream and produce nothing};

defoperator divert => q{
  my @xs = @_;
  my $fh = siproc {close STDOUT; exec_ni @xs, sink_null_op};
  stee \*STDIN, $fh, \*STDOUT;
  close $fh;
  $fh->await;
};
docoperator divert => q{Duplicate this stream into a ni pipeline, discarding that pipeline's output};

defshort '/+', pmap q{append_op    @$_}, _qfn;
defshort '/^', pmap q{prepend_op   @$_}, _qfn;
defshort '/=', pmap q{divert_op    @$_}, _qfn;

# Interleaving.
# Append/prepend will block one of the two data sources until the other
# completes. Sometimes, though, you want to stream both at once. Interleaving
# makes that possible, and you can optionally specify the mixture ratio, which is
# the number of interleaved rows per input row. (Negative numbers are interpreted
# as reciprocals, so -2 means two stdin rows for every interleaved.)

defoperator interleave => q{
  my ($ratio, $lambda) = @_;
  my $fh = soproc {close STDIN; exec_ni @$lambda};

  if ($ratio) {
    $ratio = 1/-$ratio if $ratio < 0;
    my ($n1, $n2) = (0, 0);
    while (1) {
      ++$n1, defined($_ = <STDIN>) || goto done, print while $n1 <= $n2 * $ratio;
      ++$n2, defined($_ = <$fh>)   || goto done, print while $n1 >= $n2 * $ratio;
    }
  } else {
    my $rmask;
    my ($stdin_ok,  $ni_ok) = (1, 1);
    my ($stdin_buf, $ni_buf);
    while ($stdin_ok || $ni_ok) {
      vec($rmask, fileno STDIN, 1) = $stdin_ok;
      vec($rmask, fileno $fh,   1) = $ni_ok;
      my $n = select my $rout = $rmask, undef, undef, 0.01;
      if (vec $rout, fileno STDIN, 1) {
        $stdin_ok = !!saferead \*STDIN, $stdin_buf, 1048576, length $stdin_buf;
        my $i = 1 + rindex $stdin_buf, "\n";
        if ($i) {
          safewrite \*STDOUT, substr $stdin_buf, 0, $i;
          $stdin_buf = substr $stdin_buf, $i;
        }
      }
      if (vec $rout, fileno $fh, 1) {
        $ni_ok = !!saferead $fh, $ni_buf, 1048576, length $ni_buf;
        my $i = 1 + rindex $ni_buf, "\n";
        if ($i) {
          safewrite \*STDOUT, substr $ni_buf, 0, $i;
          $ni_buf = substr $ni_buf, $i;
        }
      }
    }
  }

  done:
  close $fh;
  $fh->await;
};

defshort '/%', pmap q{interleave_op @$_}, pseq popt number, _qfn;

# Sinking.
# We can sink data into a file just as easily as we can read from it. This is
# done with the `>` operator, which is typically written as `\>`. The difference
# between this and the shell's > operator is that \> outputs the filename; this
# lets you invert the operation with the nullary \< operator.

defoperator file_read  => q{chomp, weval q{scat $_} while <STDIN>};
defoperator file_write => q{
  my ($file) = @_;
  $file = resource_tmp('file://') unless defined $file;
  sforward \*STDIN, swfile $file;
  print "$file\n";
};

defshort '/>', pmap q{file_write_op $_}, popt nefilename;
defshort '/<', pmap q{file_read_op},     pnone;

defoperator file_prepend_name_read => q{
  my $file;
  while (defined($file = <STDIN>))
  {
    chomp $file;
    my $fh = soproc {scat $file};
    print "$file\t$_" while <$fh>;
    close $fh;
    $fh->await;
  }
};

defshort '/W<', pmap q{file_prepend_name_read_op}, pnone;

defoperator file_prepend_name_write => q{
  my ($lambda) = @_;
  my $file     = undef;
  my $fh       = undef;

  while (<STDIN>)
  {
    my ($fname, $l) = /^([^\t\n]*)\t([\s\S]*)/;
    if (!defined $file or $fname ne $file)
    {
      close $fh, $fh->can('await') && $fh->await if defined $fh;
      $file = $fname;

      # NB: swfile has much lower startup overhead than exec_ni(), so use that
      # unless we have a lambda that requires slower operation.
      $fh = defined $lambda
        ? siproc {exec_ni(@$lambda, file_write_op $file)}
        : swfile $file;
    }
    print $fh $l;
  }

  close $fh, $fh->can('await') && $fh->await if defined $fh;
};

defshort '/W>', pmap q{file_prepend_name_write_op $_}, popt _qfn;

# Random-access sharding.
# Similar to prepended-name write, but splits data into a finite number of
# shards deterministically, i.e. we keep filehandles open.
#
# This may fail with "too many open files" if you have too many shards. If you
# have that problem, you can nest sharding operators by specifying intermediate
# partitions.

defoperator sharded_write => q{
  my ($lambda) = @_;
  my %fhs;

  while (<STDIN>)
  {
    my ($file, $l) = /^([^\t\n]*)\t([\s\S]*)/;
    my $fh = $fhs{$file} //= defined $lambda
      ? siproc {exec_ni(@$lambda, file_write_op $file)}
      : swfile $file;
    print $fh $l;
  }

  close $_ for values %fhs;
  $_->can('await') && $_->await for values %fhs;
};

defshort '/S>', pmap q{sharded_write_op $_}, popt _qfn;

# Resource stream encoding.
# This makes it possible to serialize a directory structure into a single stream.
# ni uses this format internally to store its k/v state.

defoperator encode_resource_stream => q{
  my @xs;
  while (<STDIN>) {
    chomp;
    my $s = rfc $_;
    my $line_count = @xs = split /\n/, "$s ";
    print "$line_count $_\n", $s, "\n";
  }
};

defshort '/>\'R', pmap q{encode_resource_stream_op}, pnone;

# Compression and decoding.
# Sometimes you want to emit compressed data, which you can do with the `Z`
# operator. It defaults to gzip, but you can also specify xz, lzo, lz4, or bzip2
# by adding a suffix. You can decode a stream in any of these formats using `ZD`
# (though in most cases ni will automatically decode compressed formats).

our %compressors = qw/ g gzip  x xz  o lzop  4 lz4  b bzip2 /;

BEGIN {defparseralias compressor_name => prx '[gxo4b]'}
BEGIN {
  defparseralias compressor_spec =>
    pmap q{my ($c, $level) = @$_;
           $c = $ni::compressors{$c || 'g'};
           defined $level ? sh_op "$c -$level" : sh_op $c},
    pseq popt compressor_name, popt integer;
}

defoperator decode => q{sdecode};

defshort '/z',  compressor_spec;
defshort '/zn', pk sink_null_op();
defshort '/zd', pk decode_op();
86 core/stream/main.pl
use POSIX ();

our $pager_fh;
our $handling_pipe;

defconfenv 'pager', NI_PAGER => 'less -u';

sub child_status_ok($) {
  $_[0] == 0                    # ok exit status
    or ($_[0] & 127) == 13      # killed by sigpipe
    or ($_[0] & 127) == 15      # killed by sigterm (probably from us)
}

$ni::main_operator = sub {
  my @children;

  # Awkward TMPDIR fix for mac OSX
  delete $ENV{TMPDIR} unless -d $ENV{TMPDIR} and -w $ENV{TMPDIR};

  if (-t STDIN) {
    nuke_stdin;
  } else {
    # Fix for bugs/2016.0918.replicated-garbage.md: forcibly flush the STDIN
    # buffer so no child process gets bogus data.
    cdup2 0, 3;
    close STDIN;
    cdup2 3, 0;
    POSIX::close 3;
    open STDIN, '<&=0' or die "ni: failed to reopen STDIN: $!";

    push @children, sicons {sdecode};
  }

  my @ops = apply_meta_operators @_;
  @$_ and push @children, sicons {operate @$_} for @ops;

  if (-t STDOUT) {
    $pager_fh = siproc {exec conf 'pager' or
                        exec 'less' or exec 'more' or sio};
    sforward \*STDIN, $pager_fh;
    close $pager_fh;
    $pager_fh->await;
    ni::procfh::kill_children 'TERM';
  } else {
    sio;
  }

  my $exit_status = 0;
  for (@children) {
    my $status = $_->await;
    next if child_status_ok $status;
    print STDERR "ni: nonzero exit status for child process $_\n";
    $exit_status = 1;
  }
  $handling_pipe ? 0 : $exit_status;
};

# Pagers and kill signals.
# `less` resets a number of terminal settings, including character buffering and
# no-echo. If we kill it directly with a signal, it will exit without restoring a
# shell-friendly terminal state, requiring the user to run `reset` to fix it. So
# in an interrupt context we try to give the pager a chance to exit gracefully by
# closing its input stream and having the user use `q` or similar.

$SIG{PIPE} = sub {
  $handling_pipe = 1;
  close $pager_fh if $pager_fh;
  ni::procfh::kill_children 'TERM';
  exit 0;
};

$SIG{TERM} =
$SIG{HUP}  = sub {
  close $pager_fh if $pager_fh;
  ni::procfh::kill_children 'TERM';
  exit 1;
};

$SIG{INT} = sub {
  if ($pager_fh) {
    close $pager_fh;
    $pager_fh->await;
  }
  ni::procfh::kill_children 'TERM';
  exit 1;
};
2 core/meta/lib
meta.pl
map.pl
77 core/meta/meta.pl
# Image-related data sources.
# Long options to access ni's internal state. Also the ability to instantiate ni
# within a shell process.

defoperator meta_image => q{sio; print image, "\n"};
defoperator meta_keys  => q{sio; print "$_\n" for sort keys %ni::self};
defoperator meta_key   => q{my @ks = @_; sio; print "$_\n" for @ni::self{@ks}};

defoperator meta_help => q{
  my ($topic) = @_;
  $topic = 'tutorial' unless length $topic;
  sio; print $ni::self{"doc/$topic.md"}, "\n";
};

defshort '///ni/',     pmap q{meta_key_op $_}, prc '[^][]+$';
defshort '///ni',      pmap q{meta_image_op},  pnone;
defshort '///ni/keys', pmap q{meta_keys_op},   pnone;

defoperator meta_eval_number => q{sio; print $ni::evals{$_[0] - 1}, "\n"};
defshort '///ni/eval/', pmap q{meta_eval_number_op $_}, integer;

# Documentation options.
# These are listed under the `//help` prefix. This isn't a toplevel option
# because it's more straightforward to model these as data sources.

sub meta_context_name($) {$_[0] || '<root>'}

defshort '///help', pmap q{meta_help_op $_}, popt prx '/(.*)';

defoperator meta_options => q{
  sio;
  for my $c (sort keys %ni::contexts) {
    printf "%s\tlong\t%s\t%s\n",  meta_context_name $c, $ni::long_names{$c}[$_], abbrev dev_inspect_nonl $ni::long_refs{$c}[$_],  40 for       0..$#{$ni::long_refs{$c}};
    printf "%s\tshort\t%s\t%s\n", meta_context_name $c, $_,                      abbrev dev_inspect_nonl $ni::short_refs{$c}{$_}, 40 for sort keys %{$ni::short_refs{$c}};
  }
};

defshort '///ni/options', pmap q{meta_options_op}, pnone;

defshort '///license', pmap q{meta_key_op 'license'}, pnone;
defshort '/--license', pmap q{meta_key_op 'license'}, pnone;

defoperator meta_conf => q{
  sio;
  print "$_\t" . conf($_) . "\t$ni::conf_variables{$_}\n" for sort keys %ni::conf_variables;
};

defshort '///ni/conf', pmap q{meta_conf_op}, pnone;

# Inspection.
# This lets you get details about specific operators or parsing contexts.

defoperator meta_op  => q{sio; print "sub {$ni::operators{$_[0]}}\n"};
defoperator meta_ops => q{sio; print "$_\n" for sort keys %ni::operators};
defshort '///ni/op/', pmap q{meta_op_op $_}, prc '.+';
defshort '///ni/ops', pmap q{meta_ops_op},   pnone;

defoperator meta_parser  => q{sio; print json_encode(parser $_[0]), "\n"};
defoperator meta_parsers => q{sio; print "$_\t" . json_encode(parser $_) . "\n" for sort keys %ni::parsers};
defshort '///ni/parser/', pmap q{meta_parser_op $_}, prc '.+';
defshort '///ni/parsers', pmap q{meta_parsers_op}, pnone;

# The backdoor.
# Motivated by `bugs/2016.0918-replicated-garbage`. Lets you eval arbitrary Perl
# code within this process, and behaves like a normal streaming operator.

defoperator dev_backdoor => q{ni::eval $_[0]};
defshort '/--dev/backdoor', pmap q{dev_backdoor_op $_}, prc '.*';

# Used for regression testing
defoperator dev_local_operate => q{
  my ($lambda) = @_;
  my $fh = siproc {exec ni_quoted_exec_args};
  quote_ni_into $fh, @$lambda;
};

defshort '/--dev/local-operate', pmap q{dev_local_operate_op $_}, _qfn;
24 core/meta/map.pl
# Syntax mapping.
# We can inspect the parser dispatch tables within various contexts to get a
# character-level map of prefixes and to indicate which characters are available
# for additional operators.

use constant qwerty_prefixes => 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789@%=$+_,.:';
use constant qwerty_effort =>   '02200011000021011000011212244222332222432332222334344444455544565565223';

defoperator meta_short_availability => q{
  sio;
  print "--------" . qwerty_prefixes . "\n";
  for my $c (sort keys %ni::contexts) {
    my $s = $ni::short_refs{$c};
    my %multi;
    ++$multi{substr $_, 0, 1} for grep 1 < length, keys %$s;

    print substr(meta_context_name $c, 0, 7) . "\t"
        . join('', map $multi{$_} ? '.' : $$s{$_} ? '|' : ' ',
                       split //, qwerty_prefixes)
        . "\n";
  }
};

defshort '///ni/map/short', pmap q{meta_short_availability_op}, pnone;
1 core/monitor/lib
monitor.pl
79 core/monitor/monitor.pl
# Pipeline monitoring.
# nfu provided a simple throughput/data count for each pipeline stage. ni can do
# much more, for instance determining the cause of a bottleneck and previewing
# data.

sub unit_bytes($) {
  return $_[0] >> 10, "K" if $_[0] >> 10 <= 99999;
  return $_[0] >> 20, "M" if $_[0] >> 20 <= 99999;
  return $_[0] >> 30, "G" if $_[0] >> 30 <= 99999;
  return $_[0] >> 40, "T" if $_[0] >> 40 <= 99999;
  return $_[0] >> 50, "P";
}

defconfenv 'monitor', NI_MONITOR => 'yes';

defmetaoperator stderr_monitor_transform => q{
  my ($args, $left) = @_;
  my ($interval) = @$args;
  [map {;$$left[$_], stderr_monitor_op($_, json_encode $$left[$_], $interval)}
        0..$#{$left}];
};

defoperator stderr_monitor => q{
  BEGIN {eval {require Time::HiRes; Time::HiRes->import('time')}}
  my ($monitor_id, $monitor_name, $update_rate) = (@_, 1);
  my ($itime, $otime, $bytes) = (0, 0, 0);
  my $last_update = 0;
  my $start_time  = 0;
  my ($stdin, $stdout) = (\*STDIN, \*STDOUT);
  while (1) {
    my $t1 = time; $bytes += my $n = saferead $stdin, $_, 65536;
                   last unless $n;
    my $t2 = time; safewrite_exactly $stdout, $_;
    my $t3 = time;

    # Start the clocks only once some data starts moving; we ignore the initial
    # read/write warmup
    if ($start_time)
    {
      $itime += $t2 - $t1;
      $otime += $t3 - $t2;
    }
    else
    {
      $start_time = $t2;
    }

    if ($t3 - $last_update > $update_rate && $t3 - $start_time > 2) {
      $last_update = $t3;
      my $runtime = $t3 - $start_time || 1;
      my $width   = $ENV{COLUMNS} || 80;
      my $preview;
      if ($t3 & 3 && /\n(.*)\n/) {
        ($preview = substr $1, 0, $width - 20) =~ s/\t/  /g;
        $preview =~ s/[[:cntrl:]]/./g;
        $preview = substr $preview, 0, $width - 20;
      } else {
        $preview = substr $monitor_name, 0, $width - 20;
      }

      my $factor_log = log(($otime || 1) / ($itime || 1)) / log 2;

      safewrite \*STDERR,
        sprintf "\033[%d;1H%d \r\033[K%5d%s %5d%s/s% 4d %s\n",
          $monitor_id + 1,
          int($t3),
          unit_bytes $bytes,
          unit_bytes $bytes / $runtime,
          $factor_log * 10,
          $preview;
    }
  }
};

my $original_main_operator = $ni::main_operator;
$ni::main_operator = sub {
  return &$original_main_operator(@_) if conf 'monitor' ne 'yes';
  &$original_main_operator(@_, stderr_monitor_transform_op(0.1));
};
1 core/uri/lib
uri.pl
111 core/uri/uri.pl
# Resources identified by URI.
# A way for ni to interface with URIs. URIs are self-appending like files; to
# quote them you should use the `\'` prefix or the `i` operator:

# | ni http://google.com          # prints contents of google.com
#   ni \'http://google.com        # prints "http://google.com"
#   ni ihttp://google.com         # prints "http://google.com"

# If you've got a lot of resources, you can use `\'` with a lambda to quote all
# of them:

# | ni \'[ http://foo.com http://bar.com ]

sub uri_scheme($) {my ($scheme) = $_[0] =~ /^([^:]+):/; $scheme}
sub uri_path($)   {my $s = uri_scheme $_[0]; sr $_[0], qr|^\Q$s://\E|, ''}

BEGIN {
  no strict 'refs';

  deflong '/resource', defdsp 'resourcealt', 'dispatch table for URI prefixes';

  for my $op (qw/read write exists tmp nuke/) {
    %{"ni::resource_$op"} = ();
    *{"ni::resource_$op"} = sub ($) {
      my ($r) = @_;
      my $scheme = uri_scheme $r;
      my $f = ${"ni::resource_$op"}{$scheme} or
        die "ni: $scheme resources don't support the $op operation";
      &$f($r, uri_path $r);
    };
  }
}

our %nuke_on_exit;
sub nuke_on_exit($) {$nuke_on_exit{$_[0]} = $$}

END {$nuke_on_exit{$_} eq $$ and resource_nuke $_ for keys %nuke_on_exit}

our %resource_read;
our %resource_write;
our %resource_exists;
our %resource_tmp;
our %resource_nuke;

defoperator resource_quote => q{sio; print "$_[0]\n"};
defoperator resource_append => q{
  sio;
  my $decoder = siproc {sdecode};
  sforward resource_read $_[0], $decoder;
  close $decoder;
  $decoder->await;
};

defoperator resource_quote_many => q{sio; print "$_\n" for @_};

defshort "/'", pmap q{resource_quote_many_op @$_},
  pn 1, prc qr/\[/, prep(prc '[^]].*'), prc qr/\]/;

sub defresource($%) {
  my ($scheme, %opts) = @_;
  defresourcealt("'$scheme://",
    pmap qq{resource_quote_op "$scheme://\$_"}, prx '.*');
  defresourcealt("$scheme://",
    pmap qq{resource_append_op "$scheme://\$_"}, prx '.*');

  $resource_read{$scheme}   = fn $opts{read}   if exists $opts{read};
  $resource_write{$scheme}  = fn $opts{write}  if exists $opts{write};
  $resource_exists{$scheme} = fn $opts{exists} if exists $opts{exists};
  $resource_tmp{$scheme}    = fn $opts{tmp}    if exists $opts{tmp};
  $resource_nuke{$scheme}   = fn $opts{nuke}   if exists $opts{nuke};
}

# Stream function extensions.
# Add resource support to srfile and swfile.

my $original_srfile = \&srfile;
my $original_swfile = \&swfile;
my $original_glob_expand = \&glob_expand;

sub is_uri($) {$_[0] =~ /^[^:\/]+:\/\//}

{
  no warnings 'redefine';
  *glob_expand = sub($) {
    return $_[0] if is_uri $_[0] or -e $_[0];
    glob $_[0];
  };

  *srfile = sub($) {
    return resource_read $_[0] if is_uri $_[0];
    &$original_srfile($_[0]);
  };

  *swfile = sub($) {
    return resource_write $_[0] if is_uri $_[0];
    &$original_swfile($_[0]);
  };
}

# Filesystem resources.
# Things that behave like files: local files, HDFS, S3, sftp, etc.

sub uri_temp_noise() {"ni." . getpwuid($<) . "." . noise_str 32}
defconfenv 'tmpdir', TMPDIR => '/tmp';

defresource 'file',
  read   => q{srfile $_[1]},
  write  => q{swfile $_[1]},
  exists => q{-e $_[1]},
  tmp    => q{"file://" . conf('tmpdir') . "/" . uri_temp_noise},
  nuke   => q{unlink $_[1]};
2 core/fn/lib
fn.pl
op-rewrite.pl
89 core/fn/fn.pl
# Operator->operator functions.
# This provides a mechanism for ni to implement aliases and other shorthands.
# Internally we do this by defining a "rewrite parser" that modifies the unparsed
# elements in front of it. Rewriting is namespaced: if you define a lambda in the
# root context, it won't apply in other contexts.

# Here's an example of a lambda that looks for manpages matching the given
# filename pattern:

# | defn ['/manpages', 'pattern'],
#        qw[e[find /usr/share/man -name $pattern*] \<];

# After this definition, ni will perform substitutions like the following:

# | $ ni manpages ls
#   # ni e[find /usr/share/man -name ls*] \<

# Other types of definitions.
# A parameter like 'pattern' will just consume a single unparsed argument, but
# sometimes you want to apply parsing structure to things. You can do that by
# type-tagging the parameters:

# | defexpander ['/manpages-matching', condition => plcode],
#               qw[e[find /usr/share/man -type f] rp$condition];

sub evaluate_fn_expansion(\%@) {
  local $_;
  my ($args, @expansion) = @_;
  return &{$expansion[0]}(%$args) if ref $expansion[0];

  return @expansion unless keys %$args;

  my @result;
  my $scalar_args = join '|', map qr/\$\Q$_\E/, keys %$args;
  $scalar_args = qr/$scalar_args/;
  my $array_args = join '|', map qr/@\Q$_\E/, keys %$args;
  $array_args = qr/$array_args/;

  for (@expansion) {
    if (/^($array_args)$/) {
      push @result, @$args{substr $1, 1};
    } else {
      my @pieces = split /($scalar_args)/;
      $_ & 1 and $pieces[$_] = $$args{substr $pieces[$_], 1}
        for 0..$#pieces;
      push @result, join '', @pieces;
    }
  }
  @result;
}

BEGIN {
  defparser fn_expander => '$$$$',
    q{
      my ($self, @xs) = @_;
      my (undef, $context, $formals, $positions, $expansion) = @$self;
      my ($parsed_formals, @rest) = parse pn(1, popt pempty, $formals), @xs;
      return () unless defined $parsed_formals;

      my %args;
      $args{$_} = $$parsed_formals[$$positions{$_}] for keys %$positions;
      parse parser "$context/op",
            evaluate_fn_expansion(%args, @$expansion), @rest;
    };
}

sub defexpander($@) {
  my ($fn, @expansion) = @_;
  my ($short_spec, @args) = ref $fn ? @$fn : ($fn);
  my ($context, $name) = split /\//, $short_spec, 2;

  my @arg_parsers;
  my %arg_positions;
  if (@args > 1 && ref $args[1]) {
    for (my $i = 0; $i < @args; $i += 2) {
      my ($k, $v) = @args[$i, $i + 1];
      $arg_positions{$k} = $i >> 1;
      push @arg_parsers, $v;
    }
  } elsif (@args) {
    $arg_positions{@args[0..$#args]} = 0..$#args;
    @arg_parsers = map prc '.*', @args;
  }

  defshort $short_spec,
    fn_expander $context, pseq(map pc $_, @arg_parsers),
                          \%arg_positions,
                          \@expansion;
}
50 core/fn/op-rewrite.pl
# Operator-level text substitution.
# WARNING: This is a hack, but possibly a useful one.

sub rewrite_atoms_in {
  my ($op, $fn) = @_;
  return $fn->($op) unless ref $op;
  return [map rewrite_atoms_in($_, $fn), @$op] if ref $op eq 'ARRAY';
  return {map rewrite_atoms_in($_, $fn), %$op} if ref $op eq 'HASH';
  die "rewrite_atoms_in: not sure how to rewrite $op of type " . ref($op);
}

defmetaoperator op_let => q{
  my ($args, $left, $right) = @_;
  my ($bindings, $ops) = @$args;
  my @keys = map $$_[0], @$bindings;
  my %replacements = map @$_, @$bindings;
  my $rewritten = rewrite_atoms_in $ops, sub {
    my $a = shift;
    $a =~ s/\Q$_\E/$replacements{$_}/g for @keys;
    $a;
  };
  ($left, [@$rewritten, @$right]);
};

defoperator op_fn => q{
  my ($bindings, $ops) = @_;
  while (<STDIN>) {
    chomp;
    my @vars = split /\t/;
    my %replacements;
    @replacements{@$bindings} = @vars;
    my $rewritten = rewrite_atoms_in $ops, sub {
      my $a = shift;
      $a =~ s/\Q$_\E/$replacements{$_}/g for @$bindings;
      $a;
    };
    close(my $fh = siproc {exec_ni @$rewritten});
    $fh->await;
  }
};

BEGIN {defparseralias fn_bindings => pn 0, prep(prc qr/[^:=]+/), prc qr/:/}
BEGIN {defparseralias let_binding => pn [0, 2], prx qr/[^:=]+/, pstr '=', prc '[\s\S]+'}
BEGIN {defparseralias let_bindings => pn 0, prep(let_binding), prc qr/:/}

defshort '/l[' => pmap q{op_let_op @$_},
                  pn [1, 2], popt pempty, let_bindings, '/series', pstr ']';

defshort '/f[' => pmap q{op_fn_op @$_},
                  pn [1, 2], popt pempty, fn_bindings, '/series', pstr ']';
2 core/closure/lib
closure.pl
file.pl
31 core/closure/closure.pl
# Data closures.
# Data closures are a way to ship data along with a process, for example over
# hadoop or SSH. The idea is to make your data as portable as ni is.

sub add_closure_key($$) {
  # TODO: use a lib for all data closures
  my ($k, $v) = @_;
  self_append_resource "transient/closure/$k", pack 'u', $v;
}

sub closure_keys()  {grep s/^transient\/closure\///, keys %ni::self}
sub closure_data($) {unpack 'u', $ni::self{"transient/closure/$_[0]"}}

defmetaoperator memory_data_closure => q{
  my ($name, $f) = @{$_[0]};
  my $data;
  my $fh = sni @$f;
  1 while saferead $fh, $data, 8192, length $data;
  close $fh;
  $fh->await;
  add_closure_key $name, $data;
  ();
};

defoperator memory_closure_append => q{sio; print closure_data $_[0]};

BEGIN {defparseralias closure_name => prx '[^][]+'}

defshort '///:', pmap q{memory_closure_append_op $_}, closure_name;
defshort '/::',  pmap q{memory_data_closure_op @$_},
                 pseq pc closure_name, _qfn;
43 core/closure/file.pl
# File-backed data closures.
# Sometimes you have data that's too large to store in-memory in the ni image,
# but you still want it to be forwarded automatically. To handle this case, you
# can use a file-backed data closure: the data is streamed after ni's image state
# and is written directly to disk, never stored in memory. (All that's stored in
# memory is the name of the file.)

# A point of subtlety about the way file closures are handled. I'm doing this
# through URIs because tempdirs might not be portable between machines: on a
# Linux machine all tempfiles might be in /tmp, but on Mac they might be
# somewhere else. So we make sure that the name of the tempfile is computed in
# the same place that it's written, minimizing the likelihood that we'll hit
# permission errors.

defresource 'file-closure',
  read  => q{resource_read closure_data $_[1]},
  write => q{my $tmp = resource_tmp 'file://';
             add_closure_key $_[1], $tmp;
             resource_write $tmp},
  nuke  => q{resource_nuke closure_data $_[1]};

defmetaoperator file_data_closure => q{
  my ($name, $f) = @{$_[0]};
  my $c    = "file-closure://$name";
  my $file = resource_write $c;
  my $fh   = sni @$f;
  sforward $fh, $file;
  close $file;
  close $fh;
  $fh->await;
  nuke_on_exit $c;
  add_quoted_resource $c;
  ();
};

defoperator file_closure_append => q{
  sio;
  sforward resource_read(closure_data $_[0]), \*STDOUT;
};

defshort '///@', pmap q{file_closure_append_op $_}, closure_name;
defshort '/:@',  pmap q{file_data_closure_op @$_},
                 pseq pc closure_name, _qfn;
1 core/destructure/lib
destructure.pl
54 core/destructure/destructure.pl
# Targeted extraction.
# Most data extraction workflows don't use every key of a rich data object like
# JSON or XML. ni allows you to avoid the overhead of fully decoding these
# objects by using targeted extraction, which compiles an optimized function to
# return just the values you need. Depending on what you're extracting, this can
# be up to 20-30x faster than doing a full decode.



# TODO: replace all of this

our %json_partial_unescapes = ("/" => "/", "\"" => "\"", b => "\b", r => "\r");

sub json_partial_unescape_one($) {$json_partial_unescapes{$_[0]} || chr hex substr $_[0], 1}
sub json_partial_unescape($) {
  my $x = substr $_[0], 1, -1;
  $x =~ s/\\(["\/bft]|u[0-9a-fA-F]{4})/json_partial_unescape_one $1/eg;
  $x;
}

use constant json_si_gen => gen q#
  (/"%k"\s*:\s*/g ? /\G("[^\\\\"]*")/            ? json_partial_unescape $1
                  : /\G("(?:[^\\\\"]+|\\\\.)*")/ ? json_partial_unescape $1
                  : /\G([^][{},]+)/              ? "" . $1
                  : undef
                  : undef) #;

sub json_extractor($) {
  my @pieces = split /\s*,\s*/, $_[0];
  die "ni: json_extractor is not really written yet"
    if grep !/^:\w+$/, @pieces;

  my $matchers = join "\n",
                 map '/^/g; push @result, ' . json_si_gen->(k => qr/\Q$_\E/) . ';',
                 map sr($_, qr/^:/, ''), @pieces;
  qq{
    my \@result;
    $matchers;
    print join("\\t", \@result) . "\\n";
  };
}

defoperator destructure => q{
  ni::eval gen(q{
    no warnings 'uninitialized';
    eval {binmode STDOUT, ":encoding(utf-8)"};
    print STDERR "ni: warning: your perl might not handle utf-8 correctly\n" if $@;
    while (<STDIN>) {
      %e;
    }
  })->(e => json_extractor $_[0]);
};

defshort '/D', pmap q{destructure_op $_}, generic_code;
1 core/checkpoint/lib
checkpoint.pl
32 core/checkpoint/checkpoint.pl
# Checkpoint files.
# You can break a long pipeline into a series of smaller files using
# checkpointing, whose operator is `:`. The idea is to cache intermediate
# results. A checkpoint specifies a file.

# Checkpoints are fully buffered before emitting output.

sub checkpoint_create($$) {
  my $name = "/";
  $name = "$_[0].part." . noise_str 8 while -e $name;
  my $fh = swfile $name;
  sforward sni(@{$_[1]}), $fh;
  rename $name, $_[0];
}

defoperator checkpoint => q{
  my ($file, $generator) = @_;
  sio;
  checkpoint_create $file, $generator unless -r $file;
  scat $file;
};

defmetaoperator inline_checkpoint => q{
  my ($args, $left, $right) = @_;
  my ($file) = @$args;
  ([], [checkpoint_op($file, $left), @$right]);
};

defoperator identity => q{sio};

defshort '/:', pmap q{$_ ? inline_checkpoint_op $_
                         : identity_op}, popt pc nefilename;
1 core/net/lib
net.pl
42 core/net/net.pl
# Networking stuff.
# SSH tunneling to other hosts. Allows you to run a ni lambda elsewhere. ni does
# not need to be installed on the remote system, nor does its filesystem need to
# be writable.

BEGIN {defparseralias ssh_host => prx '[^][/,]+'}
BEGIN {defparseralias ssh_host_full => palt pc pmap(q{[$_]}, ssh_host),
                                            pc multiword}

defoperator ssh => q{
  my ($host, $lambda) = @_;
  my $ssh_pipe = siproc {exec 'ssh', @$host, shell_quote ni_quoted_exec_args};
  quote_ni_into $ssh_pipe, @$lambda;
};

defshort '/s', pmap q{ssh_op @$_}, pseq ssh_host_full, _qfn;

# Network resources.

defresource 'http', read  => q{soproc {exec 'curl', '-sS', $_[0]} @_},
                    write => q{siproc {exec 'curl', '-sSd', '-', $_[0]} @_};

defresource 'https', read  => q{soproc {exec 'curl', '-sS', $_[0]} @_},
                     write => q{siproc {exec 'curl', '-sSd', '-', $_[0]} @_};

defresource 'sftp',
  read   => q{my ($host, $path) = $_[1] =~ m|^([^:/]+):?(.*)|;
              soproc {exec 'ssh', $host, 'cat', $path}};

defresource 's3cmd',
  read   => q{soproc {exec 's3cmd', '--no-progress', '--stop-on-error', 'get', "s3://$_[1]", '-'} @_},
  write  => q{siproc {exec 's3cmd', 'put', '-', "s3://$_[1]"} @_};
  # TODO

# Port forwarding
defoperator port_forward =>
q{
  my ($host, $port) = @_;
  exec 'ssh', '-L', "$port:localhost:$port", '-N', @$host;
};

defshort '/sF', pmap q{port_forward_op @$_}, pseq ssh_host_full, integer;
1 core/buffer/lib
buffer.pl
14 core/buffer/buffer.pl
# Buffering operators.
# Buffering a stream causes it to be forced in its entirety. Buffering does not
# imply, however, that the stream will be consumed at any particular rate; some
# buffers may be size-limited, at which point writes will block until there's
# space available.

# Null buffer.
# Forwards data 1:1, but ignores pipe signals on its output.

defoperator buffer_null => q{local $SIG{PIPE} = 'IGNORE'; sio};

defshort '/B',
  defdsp 'bufferalt', 'dispatch table for /B buffer operator',
    n => pmap q{buffer_null_op}, pnone;
1 core/script/lib
script.pl
35 core/script/script.pl
# Scripting support.
# This lets you define a library of scripts or other random utilities (possibly
# with dependent files) and gives you a way to invoke those scripts from a custom
# operator. See doc/script.md for details about how this works.

sub export_lib_to_path {
  local $_;
  my ($lib, $path) = @_;
  $path ||= uri_path resource_tmp 'file://';
  mkdir $path or die "ni: could not create $path/ for library export: $!";
  my @l     = lib_entries $lib, $ni::self{"$lib/lib"};
  my @files = map sr($_, qr|^\Q$lib/\E|, "$path/"), @l;
  wf "$path/ni", image;
  wf $files[$_], $ni::self{$l[$_]} for 0..$#l;
  chmod 0755, "$path/ni", @files;
  $path;
}

sub rm_rf($) {
  local $SIG{CHLD} = 'DEFAULT';
  system 'rm', '-rf', $_[0];
}

defoperator script => q{
  my ($lib, $cmd) = @_;
  my $tmpdir = export_lib_to_path $lib;
  my $runner = siproc {
    chdir $tmpdir;
    sh $cmd;
  };
  sforward \*STDIN, $runner;
  close $runner;
  $runner->await;
  rm_rf $tmpdir;
};
1 core/assert/lib
assert.pl
6 core/assert/assert.pl
# Assertions: die horribly unless something is true.
# Defines the `!` operator, which will deliberately nuke your entire process
# unless its condition is true.

defshort '/!',
  defdsp 'assertdsp', 'dispatch table for the ! assertion operator';
1 core/col/lib
col.pl
198 core/col/col.pl
# Column manipulation operators.
# In root context, ni interprets columns as being tab-delimited.

# Column selection.
# Normally perl is fast at text manipulation, but on most UNIX systems
# `/usr/bin/cut` is at least an order of magnitude faster. We can use it if the
# column access order is strictly ascending and has no duplicates.

sub col_cut {
  my ($floor, $rest, @fs) = @_;
  exec 'cut', '-f', join ',', $rest ? (@fs, "$floor-") : @fs;
}

use constant cols_gen =>
  gen q{@_ = split /\t/, $_, %limit; print join "\t", @_[%is]};

defoperator cols => q{
  my ($floor, @cs) = @_;
  my $asc = join('', @cs) eq join('', sort {$a <=> $b} @cs);
  my %dup; ++$dup{$_} for @cs;
  return col_cut $floor + 1, scalar(grep $_ == -1, @cs), map $_ + 1, @cs
    if $asc && !grep $_ > 1, values %dup;
  exec 'perl', '-lne',
       cols_gen->(limit => $floor + 1,
                  is    => join ',', map $_ == -1 ? "$floor..\$#_" : $_, @cs);
};

defshort '/f',
  defalt 'colalt', 'list of alternatives for /f field-select operator',
    pmap q{cols_op @$_}, colspec;

# Column swapping.
# This is such a common thing to do that it gets its own operator `x`. The idea
# is that you're swapping the specified column(s) into the first N position(s).

defoperator colswap => q{
  my ($floor, @cs) = @_;
  my %cs; ++$cs{$_} for @cs;
  die "ni colswap: . doesn't make sense"    if grep $_ == -1, @cs;
  die "ni colswap: can't duplicate columns" if grep $_ > 1, values %cs;
  my $n = 0;
  my @cols = 0..$floor-1;
  swap $cols[$n++], $cols[$_] for @cs;
  exec 'perl', '-lne', cols_gen->(limit => $floor + 1,
                                  is    => join ',', @cols, "$floor..\$#_");
};

defshort '/x', pmap q{ref $_ ? colswap_op @$_ : colswap_op 2, 1}, popt colspec;

# Column splitting.
# Adapters for input formats that don't have tab delimiters. Common ones are,
# with their split-spec mnemonics:

# | commas:       C
#   slashes:      D
#   "proper CSV": V
#   pipes:        P
#   whitespace:   S
#   non-words:    W

# You can also field-split on arbitrary regexes, or extend the splitalt dsp to
# add custom split operators.

defoperator split_chr   => q{exec 'perl', '-lnpe', $_[0] =~ /\// ? "y#$_[0]#\\t#" : "y/$_[0]/\\t/"};
defoperator split_regex => q{my $r = qr/$_[0]/; exec 'perl', '-lnpe', "s/$r/\$1\\t/g"};
defoperator scan_regex  => q{exec 'perl', '-lne',  'print join "\t", /' . "$_[0]/g"};

defoperator split_proper_csv => q{
  while (<STDIN>)
  {
    $_ = ",$_";
    $_ .= <STDIN> while 1 & (() = /"/g);
    chomp;
    print join("\t",
      map { s/^"|"$//g; s/\t/        /g; y/\n/\r/; s/""/\n/g; s/"//g; y/\n/"/; $_ }
          /\G,((?:"(?:[^"]+|"")*"|[^",]+)*)/g), "\n";
  }
};

defshort '/F',
  defdsp 'splitalt', 'dispatch table for /F split operator',
    'C' => pmap(q{split_chr_op   ','},               pnone),
    'D' => pmap(q{split_chr_op   '\/'},              pnone),
    'V' => pmap(q{split_proper_csv_op},              pnone),
    'P' => pmap(q{split_chr_op   '|'},               pnone),
    'S' => pmap(q{split_regex_op '\s+'},             pnone),
    'W' => pmap(q{split_regex_op '[^\w\n]+'},        pnone),
    '/' => pmap(q{split_regex_op $_},                regex),
    ':' => pmap(q{split_chr_op   $_},                prx '.'),
    'm' => pn(1, pstr '/', pmap q{scan_regex_op $_}, regex);

# Combining
defshort '/F^',
  defdsp 'combinealt', 'dispatch table for /F^ combine operator',
    'S' => pmap(q{sh_op 'tr "\t" " "'},      pnone),
    'C' => pmap(q{sh_op 'tr "\t" ,'},        pnone),
    'P' => pmap(q{sh_op 'tr "\t" "|"'},      pnone),
    ':' => pmap(q{sh_op 'tr "\t" "'.$_.'"'}, prx '.');

# Juxtaposition.
# You can juxtapose two data sources horizontally by using `w` for `with`.

defoperator with_right => q{
  my $fh = sni @_;
  my $l;
  while (<STDIN>) {
    chomp;
    return unless defined($l = <$fh>);
    print "$_\t$l";
  }
};

defoperator with_left => q{
  my $fh = sni @_;
  my $l;
  while (<STDIN>) {
    return unless defined($l = <$fh>);
    chomp $l;
    print "$l\t$_";
  }
};

defshort '/w', pmap q{with_right_op @$_}, _qfn;
defshort '/W', pmap q{with_left_op  @$_}, _qfn;

# Vertical transformation.
# This is useful when you want to apply a streaming transformation to a specific
# set of columns. For example, if you have five columns and want to lowercase the
# middle one:

# | ni vCplc              # lowercase column C

# WARNING: your process needs to output exactly one line per input. If the driver
# is forced to buffer too much memory it will hang waiting for the process to
# catch up.

# TODO: optimize this. Right now it's horrendously slow.

defoperator vertical_apply => q{
  my ($colspec, $lambda) = @_;
  my ($limit, @cols) = @$colspec;
  my ($i, $o) = sioproc {exec ni_quoted_exec_args};
  safewrite $i, ni_quoted_image 0, @$lambda;

  vec(my $rbits = '', fileno $o, 1) = 1;
  vec(my $wbits = '', fileno $i, 1) = 1;
  fh_nonblock $i;

  my $read_buf = '';
  my $write_buf = '';
  my @queued;
  my @awaiting_completion;
  my $stdin_ok = my $proc_ok = 1;
  while ($stdin_ok || $proc_ok) {
    my $l = sum map length, @queued;
    $_ = '';
    chomp, push @queued, $_ while ($l += length) <= 1048576
                              and $stdin_ok &&= defined($_ = <STDIN>);

    while (@queued && sum(map length, @awaiting_completion) < 1048576
                   && select undef, my $wout=$wbits, undef, 0) {
      my $n = 0;
      my @chopped;
      push @chopped, join "\t", (split /\t/, $queued[$n++], $limit)[@cols]
        while $n < @queued && 8192 > sum map 1 + length, @chopped;
      ++$n unless $n;
      push @awaiting_completion, @queued[0..$n-1];
      @queued = @queued[$n..$#queued];
      my $s  = $write_buf . join '', map "$_\n", @chopped;
      my $sn = safewrite $i, $s;
      $write_buf = substr $s, $sn;
    }

    close $i if !@queued && !$stdin_ok;

    $proc_ok &&= saferead $o, $read_buf, 8192, length $read_buf
      while $proc_ok && select my $rout=$rbits, undef, undef, 0;

    my @lines = split /\n/, $read_buf . " ";
    $proc_ok ? $read_buf = substr pop(@lines), 0, -1 : pop @lines;
    for (@lines) {
      die "ni: vertical apply's process emitted too many lines: $_"
        unless @awaiting_completion;
      my @fs = split /\t/, shift @awaiting_completion;
      @fs[@cols] = my @cs = split /\t/;
      print join("\t", @fs, @cs[@fs..$#cs]), "\n";
    }
  }

  die "ni: vertical apply's process ultimately lost "
    . scalar(@awaiting_completion) . " line(s)"
  if @awaiting_completion;

  close $o;
  $o->await;
};

defshort '/v', pmap q{vertical_apply_op @$_}, pseq colspec_fixed, _qfn;
4 core/row/lib
row.pl
scale.pl
join.pl
xargs.pl
219 core/row/row.pl
# Row-level operations.
# These reorder/drop/create entire rows without really looking at fields.

defoperator head => q{exec 'head', @_};
defoperator tail => q{exec 'tail', $_[0], join "", @_[1..$#_]};

defoperator safe_head => q{$. <= $_[0] && print while <STDIN>};

defconfenv 'row/seed', NI_ROW_SEED => 42;

defoperator row_every => q{($. - 1) % $_[0] || print while <STDIN>};
defoperator row_match => q{$\ = "\n"; chomp, /$_[0]/o && print while <STDIN>};
defoperator row_sample => q{
  srand conf 'row/seed';
  $. = 0;
  while (<STDIN>) {
    print, $. -= -log(1 - rand()) / $_[0] if $. >= 0;
  }
};

defoperator row_repeat => q{
  my $col = shift;
  while (defined (my $l = <STDIN>))
  {
    my $r = (split /\t/, $l, $col + 2)[$col];
    print $l for 1..$r;
  }
};

defoperator row_cols_defined => q{
  my ($floor, @cs) = @_;
  my @pieces = ('[^\t\n]*') x $floor;
  $pieces[$_] = '[^\t\n]+' for @cs;
  my $r = join '\t', @pieces;
  $r = qr/^$r/;
  /$r/ and print while <STDIN>;
};

defoperator row_include_or_exclude_exact => q{
  my ($include_mode, $col, $lambda) = @_;
  my %set;
  my $fh = sni @$lambda;
  chomp, ++$set{$_} while <$fh>;
  close $fh;
  $fh->await;
  while (<STDIN>) {
    chomp;
    my @fs = split /\t/, $_, $col + 2;
    print "$_\n" if !$include_mode == !$set{$fs[$col]};
  }
};

defshort '/r',
  defalt 'rowalt', 'alternatives for the /r row operator',
    pmap(q{tail_op '-n', '',  $_},       pn 1, prx '[+~]', integer),
    pmap(q{tail_op '-n', '+', ($_ + 1)}, pn 1, prx '-',    integer),
    pmap(q{safe_head_op  $_},            pn 1, prx 's',    number),
    pmap(q{row_every_op  $_},            pn 1, prx 'x',    number),
    pmap(q{row_repeat_op $_},            pn 1, prx 'x',    colspec1),
    pmap(q{row_match_op  $_},            pn 1, prx '/',    regex),
    pmap(q{row_sample_op $_},                  prx '\.\d+'),
    pmap(q{head_op '-n', 0 + $_},        integer),
    pmap(q{row_include_or_exclude_exact_op 1, @$_}, pn [1, 2], pstr 'i', colspec1, _qfn),
    pmap(q{row_include_or_exclude_exact_op 0, @$_}, pn [1, 2], pstr 'I', colspec1, _qfn),
    pmap(q{row_cols_defined_op @$_},     colspec_fixed);

# Sorting.
# ni has four sorting operators, each of which can take modifiers:

# | g     group: sort by byte ordering
#   G     groupuniq: sort + uniq by byte ordering
#   o     order: sort numeric ascending
#   O     rorder: sort numeric descending

# Modifiers follow the operator and dictate the column index and, optionally, the
# type of sort to perform on that column (though a lot of this is already
# specified by which sort operator you use). Columns are specified as A-Z, and
# modifiers, which are optional, are any of these:

# | g     general numeric sort (not available for all 'sort' versions)
#   n     numeric sort
#   -     reverse (I would use 'r', but it conflicts with the row operator)

BEGIN {defparseralias sortspec => prep pseq colspec1, popt prx '[-gn]+'}

sub sort_args {'-t', "\t",
               map {my $i = $$_[0] + 1;
                    (my $m = defined $$_[1] ? $$_[1] : '') =~ s/-/r/g;
                    ('-k', "$i$m,$i")} @_}

# Compatibility detection.
# GNU coreutils sort supports some useful options like `--buffer-size` and
# `--compress-program`. We should use these if they exist because they can make a
# huge difference when processing large datasets.

# Note that we localize compatibility detection down to the operator -- we don't
# do it system-wide or at parse time. The reason is that parameterized operators
# can be moved, potentially across machines; this really is the only way to do it
# reliably.

sub sort_supports(@) {
  my $args = shell_quote @_;
  my $p    = siproc {sh "sort $args >/dev/null 2>&1"};
  close $p;
  return !$p->await;
}

sub sort_extra_args(@) {
  my @r;
  sort_supports @r, $_ and push @r, $_ for @_;
  @r;
}

defconfenv 'row/sort-compress', NI_ROW_SORT_COMPRESS => '';
defconfenv 'row/sort-buffer',   NI_ROW_SORT_BUFFER   => '64M';
defconfenv 'row/sort-parallel', NI_ROW_SORT_PARALLEL => '4';

defoperator row_sort => q{
  exec 'sort', sort_extra_args(
    length(conf 'row/sort-compress')
      ? ('--compress-program=' . conf 'row/sort-compress') : (),
    '--buffer-size=' . conf 'row/sort-buffer',
    '--parallel='    . conf 'row/sort-parallel'), @_};

defoperator partial_sort => q{
  my $sort_size = shift;
  my @buff = ();
  while (<STDIN>) {
    push @buff, $_;
    if (@buff == $sort_size) {
      print sort(@buff);
      @buff = ();
    }
  }
  print sort(@buff) if @buff;
};

defshort '/g',
  defalt 'sortalt', 'alternatives for the /g row operator',
    pmap(q{partial_sort_op               $_}, pn 1, prx '_', integer),
    pmap(q{row_sort_op        sort_args @$_}, sortspec);
defshort '/o', pmap q{row_sort_op '-n',  sort_args @$_}, sortspec;
defshort '/O', pmap q{row_sort_op '-rn', sort_args @$_}, sortspec;

defoperator row_grouped_sort => q{
  my ($key_col, $sort_cols) = @_;
  my $key_expr = $key_col
    ? qq{(split /\\t/)[$key_col]}
    : qq{/^([^\\t\\n]*)/};

  my $sort_expr = join ' || ',
    map {my $sort_op = $$_[1] =~ /[gn]/ ? '<=>' : 'cmp';
         $$_[1] =~ /-/ ? qq{\$b[$$_[0]] $sort_op \$a[$$_[0]]}
                       : qq{\$a[$$_[0]] $sort_op \$b[$$_[0]]}} @$sort_cols;

  ni::eval gen(q{
    my $k;
    my @group;
    push @group, $_ = <STDIN>;
    ($k) = %key_expr;
    while (<STDIN>) {
      my ($rk) = %key_expr;
      if ($rk ne $k) {
        print sort {my @a = split /\t/, $a; my @b = split /\t/, $b; %sort_expr} @group;
        @group = $_;
        $k = $rk;
      } else {
        push @group, $_;
      }
    }
    print sort {my @a = split /\t/, $a; my @b = split /\t/, $b; %sort_expr} @group;
  })->(key_expr => $key_expr, sort_expr => $sort_expr);
};

defshort '/gg', pmap q{row_grouped_sort_op @$_}, pseq colspec1, sortspec;

# Counting.
# Sorted and unsorted streaming counts.

defoperator count => q{
  my ($n, $last) = (0, undef);
  while (<STDIN>) {
    if (!defined $last or $_ ne $last) {
      print "$n\t$last" if defined $last;
      $n = 0;
      $last = $_;
    }
    ++$n;
  }
  print "$n\t$last" if defined $last;
};

defoperator uniq => q{exec 'uniq'};

defshort '/c', pmap q{count_op}, pnone;
defshort '/u', pmap q{uniq_op},  pnone;

defoperator unordered_count => q{
  my %h;
  chomp, ++$h{$_} while <STDIN>;
  print "$h{$_}\t$_\n" for sort keys %h;
};

defshort '/U', pmap q{unordered_count_op}, pnone;

defoperator cleandos => q{exec shell_quote 'perl', '-npe', 's/\r\n/\n/g'};
defshort '/cleandos', pmap q{cleandos_op}, pnone; 

defoperator mdtable => q{
  my @lines;
  chomp, push @lines, $_ while <STDIN>;
  my $n_field_seps = $lines[0] =~ tr/\t//;
  my $n_fields = $n_field_seps + 1;
  my @output_lines = map {"|$_|"} map {local $_ = $_; $_ =~ s/\t/\|/g; $_} @lines;
  splice @output_lines, 1, 0, "|" . ":----:|" x $n_fields;
  print join "\n", @output_lines;
};

defshort '/mdtable', pmap q{mdtable_op}, pnone;
193 core/row/scale.pl
# Row-based process scaling.
# Allows you to bypass process bottlenecks by distributing rows across multiple
# workers.

BEGIN {defshort '/S', defalt 'scalealt', 'row scaling alternation list'}

# Fixed scaling.
# The simplest option: specify N workers and a lambda, and the lambda will be
# replicated that many times. Incoming data is broken into chunks of rows and
# written to any worker that's available.

# Implementation-wise here's how this works. We're distributing a single stream
# of data to potentially a lot of subprocesses, each of which might be quite
# fast. So we need to optimize this aggressively, which in this case consists of
# the following:

# | 1. We maintain an input queue for each worker for reasons described below.
#   2. We minimize the overhead involved in line-splitting blocks, avoiding it
#      entirely for most of the input data.
#   3. We keep writes to workers small enough that they won't block.

# Visually, here's what we're doing:

# | worker 1 <- [block 1] [block 2] [block 3] [block 4] [part of block 5]
#   worker 2 <- [rest of part 5] [block 6] [block 7] [block 8] [part of block 9]
#   worker 3 <- ...

# The key here is that we can avoid line-splitting for any two consecutive blocks
# we send to the same worker, so we want every queue-fill operation to consume a
# large number of blocks. This leads to a possibly counterintuitive heuristic: we
# deliberately let queues run low before refilling them.

# Reading from the workers' stdout is exactly the same: we enqueue a bunch of
# blocks and then line-merge once the queues are full enough.

# A note about blocking: the scale operator goes to some lengths to avoid
# blocking on the workers, but it's fine and expected for it to block on its own
# stdin and stdout. The only consideration there is that we try to interleave
# worker and stdin/stdout blocking; this increases the likelihood that we'll
# saturate source and/or sink processes.

# TODO: refactor this to make the pieces available elsewhere. Should probably end
# up with various "combine streams vertically/horizontally/etc" library
# functions.

defconfenv 'scale/ibuf', NI_SCALE_INPUT_BUFFER  => 32768;
defconfenv 'scale/obuf', NI_SCALE_OUTPUT_BUFFER => 32768;

defoperator row_fixed_scale => q{
  my $ibuf = conf 'scale/ibuf';
  my $obuf = conf 'scale/obuf';

  sub new_ref() {\(my $x = '')}

  my ($n, $f) = @_;
  conf_set monitor => 0;

  my ($iqueue, $oqueue) = (64, 64);

  my (@wi, @wo);
  my ($wb, $rb, $w, $r);
  my ($ib, $ob, $ibtmp, $obtmp);
  for (1..$n) {
    my ($i, $o) = sioproc {
      setpriority 0, 0, $n >> 2;
      &$ni::main_operator(flatten_operators $f);
      exit;
    };
    push @wi, $i;
    push @wo, $o;
    vec($wb, fileno $i, 1) = 1;
    vec($rb, fileno $o, 1) = 1;
  }

  vec($ib, fileno STDIN,  1) = 1;
  vec($ob, fileno STDOUT, 1) = 1;

  my $stdout_reader = siproc {
    my @bufs;
    my $buf_limit = $oqueue * $n;
    my @stdout = map [], @wo;
    my @outqueue;
    my $b;
    my $stdout = \*STDOUT;

    close $_ for @wi;

    while ($n) {
      until (@outqueue < $oqueue * $n) {
        safewrite $stdout, ${$b = shift @outqueue};
        push @bufs, $b unless @bufs >= $buf_limit;
      }

      select $r = $rb, undef, undef, undef;
      for my $i (0..$#wo) {
        next unless defined $wo[$i];
        next unless vec $r, fileno $wo[$i], 1;

        while (@outqueue and select undef, $obtmp = $ob, undef, 0) {
          safewrite $stdout, ${$b = shift @outqueue};
          push @bufs, $b unless @bufs >= $buf_limit;
        }
        my $so = $stdout[$i];
        if (saferead $wo[$i], ${$b = pop(@bufs) || new_ref}, $obuf) {
          push @$so, $b;
          my $np;
          if (@$so >= $oqueue and 0 <= ($np = rindex $$b, "\n")) {
            push @outqueue, @$so[0..$#{$so} - 1];
            push @outqueue, \(my $x = substr $$b, 0, $np + 1);
            $$b = substr $$b, $np + 1;
            @$so = ($b);
          }
        } else {
          --$n;
          vec($rb, fileno $wo[$i], 1) = 0;
          close $wo[$i];
          push @outqueue, @$so;
          $stdout[$i] = $wo[$i] = undef;
        }
      }
    }

    safewrite $stdout, $$_ for @outqueue;
  };

  close $stdout_reader;
  close $_ for @wo;

  {
    my @bufs;
    my $buf_limit = $iqueue * $n;
    my @stdin = map [], @wi;
    my @queue;
    my $eof;
    my $b;
    my $stdin = \*STDIN;

    until (!@queue && $eof) {
      select undef, $w = $wb, undef, undef;
      for my $i (0..$#wi) {
        next unless vec $w, fileno $wi[$i], 1;

        my $si = $stdin[$i];
        if (@$si * 4 < $iqueue) {
          # Commit to refilling this stdin queue, which means we need to write
          # exclusively to this one until we find a line break.
          push @$si, shift @queue while @$si < $iqueue and @queue;
          while (@queue or not $eof) {
            unless ($b = $queue[0]) {
              last if $eof ||= !saferead $stdin, ${$b = pop(@bufs) || new_ref}, $ibuf;
              push @queue, $b;
            }

            my $np;
            if (0 <= ($np = rindex $$b, "\n")) {
              push @$si, \(my $x = substr $$b, 0, $np + 1);
              $$b = substr $$b, $np + 1;
              last;
            } else {
              push @$si, shift @queue;
            }
          }
        }

        $eof ||= !saferead $stdin, ${$b = pop(@bufs) || new_ref}, $ibuf
        or push @queue, $b
          while @queue < $iqueue * $n and !$eof
            and select $ibtmp = $ib, undef, undef, 0;

        if (@$si) {
          safewrite $wi[$i], ${$b = shift @$si};
          push @bufs, $b unless @bufs >= $buf_limit;
        }

        $eof ||= !saferead $stdin, ${$b = pop(@bufs) || new_ref}, $ibuf
        or push @queue, $b
          while @queue < $iqueue * $n and !$eof
            and select $ibtmp = $ib, undef, undef, 0;
      }
    }

    # Run out the individual queues.
    for my $i (0..$#wi) {
      safewrite $wi[$i], $$_ for @{$stdin[$i]};
      close $wi[$i];
    }
  }

  $_->await for @wo;
  $stdout_reader->await;
};

defscalealt pmap q{row_fixed_scale_op @$_}, pseq integer, _qfn;
90 core/row/join.pl
# Streaming joins.
# The UNIX `join` command does this, but rearranges fields in the process. ni
# implements its own operators as a workaround.

defoperator join => q{
  my ($left_cols, $right_cols, $f) = @_;
  my $fh = sni @$f;
  my ($leof, $reof) = (0, 0);
  my ($llimit, @lcols) = @$left_cols;
  my ($rlimit, @rcols) = @$right_cols;
  my @rrows = ();
  my @lrows = ();

  chomp(my $lkey = join "\t", (split /\t/, my $lrow = <STDIN>, $llimit + 1)[@lcols]);
  chomp(my $rkey = join "\t", (split /\t/, my $rrow = <$fh>,   $rlimit + 1)[@rcols]);

  while (!$leof && !$reof) {
    if ($lkey lt $rkey) {
      chomp($lkey = join "\t", (split /\t/, $lrow = <STDIN>, $llimit + 1)[@lcols]);
      $leof ||= !defined $lrow;
    } elsif ($lkey gt $rkey) {
      chomp($rkey = join "\t", (split /\t/, $rrow = <$fh>,   $rlimit + 1)[@rcols]);
      $reof ||= !defined $rrow;
    } else {
      @rrows = $rrow;
      while(!$reof) {
        chomp(my $new_rkey = join "\t", (split /\t/, $rrow = <$fh>, $rlimit + 1)[@rcols]);
        $reof ||= !defined $rrow;
        if($new_rkey eq $rkey) {
          push @rrows, $rrow;
        } else {
          $rkey = $new_rkey;
          last;
        }
      }

      my @clean_rrows = ();
      my %delete_inds = map {$_ => 1} @rcols;
      for my $rrow(@rrows) {
        my @row_data = split /\t/, $rrow;
        push @clean_rrows, join "\t", @row_data[grep {not $delete_inds{$_}} 0..$#row_data];
      }
      # If we join on all the columns on the right
      # we'll need to append a newline;
      @clean_rrows = map {substr($_, -1) ne "\n" ? "$_\n" : $_ } @clean_rrows;

      while(!$leof) {
        chomp $lrow;
        print "$lrow\t$_" for @clean_rrows;
        chomp(my $new_lkey = join "\t", (split /\t/, $lrow = <STDIN>, $llimit + 1)[@lcols]);
        if ($new_lkey ne $lkey) { $lkey = $new_lkey; last;}
      }
    }
  }
  if (!$leof) {
    # We need to stream the entire left side
    # of the join to avoid breaking the pipe in
    # a Hadoop streaming context.
    1 while read STDIN, $_, 65536;
  }
};

defshort '/j', pmap q{join_op $$_[0] || [1, 0], $$_[0] || [1, 0], $$_[1]},
               pseq popt colspec, _qfn;

# In-memory joins
# This is an alternative to the usual build-a-dataclosure approach in perl.

defoperator memory_join =>
q{
  my ($col, $n, $f) = @_;
  my $default = "\t" x $n;
  my %lookup;
  my $fh = sni @$f;
  chomp, /^([^\t]+)\t(.*)/ and $lookup{$1} = $2 while <$fh>;
  close $fh;
  $fh->await;

  while (<STDIN>)
  {
    chomp;
    my $f = (split /\t/, $_, $col + 2)[$col];
    print exists $lookup{$f}
      ? "$_\t$lookup{$f}\n"
      : "$_$default\n";
  }
};

defshort '/J', pmap q{memory_join_op $$_[0] || 0, $$_[1] || 1, $$_[2]},
               pseq popt colspec1, popt integer, _qfn;
44 core/row/xargs.pl
# Row-based process scaling, powered by xargs.
# Similar to S8, but SX8 will use xargs -P8. xargs has every process write to
# the same output fd, so we have to redirect each output into a file in order to
# prevent rows from getting spliced.

# Overall usage looks like this:
#
#   ni indir SX4 {} z\>output/{}.gz [ ni commands to distribute ]
#
# {} and z\>output/{}.gz are both parsed as _strings_ -- i.e. as shell commands
# -- because they get passed straight through to xargs. The above is
# semantically equivalent to this:
#
#   ni indir e[ xargs -P4 -I{} /tmp/ni {} --internal/lambda z\>output/{}.gz ]
#
# We write our current state, closures and all, to a tempfile so the xargs
# indirection doesn't lose anything.

defconfenv 'xargs/arg', NI_XARGS_ARG => '{}';

defmetaoperator run_quoted_lambda => q{
  my ($args, $left, $right) = @_;
  my ($name) = @$args;
  my $ops = json_decode $ni::self{"quoted/$name"};
  ($left, [@$ops, @$right]);
};

defshort '/--internal/lambda' => pmap q{run_quoted_lambda_op $_}, prc '.*';

defoperator row_xargs_scale => q{
  my ($n, $inform, $outform, $lambda) = @_;
  my $arg = conf 'xargs/arg';
  my $tmp_ni = uri_path resource_tmp "file://";
  wf $tmp_ni, image_with "quoted/$$-lambda" => json_encode $lambda;
  chmod 0700, $tmp_ni;
  my $cmd = shell_quote "xargs", "-P$n", "-I$arg", "sh", "-c",
              "$tmp_ni $inform --internal/lambda$$-lambda $outform";
  system $cmd and die "ni SX$n: $cmd failed; temporary ni in $tmp_ni";
  unlink $tmp_ni;
};

defscalealt pmap q{row_xargs_scale_op @$_},
            pn 1, pstr"X",
                  pseq pc integer, pc shell_arg, pc shell_arg, _qfn;
15 core/pl/lib
util.pm
string.pm
file.pm
array.pm
json.pm
hash.pm
hadoop.pm
math.pm
stream.pm
reducers.pm
wkt.pl
time.pl
geohash.pl
pl.pl
url.pl
28 core/pl/util.pm
# Utility library functions.

use constant DEBUG_PRINT_CEVALS => 0;

sub ceval
{
  print STDERR "ceval: $_[0]\n" if DEBUG_PRINT_CEVALS;
  eval $_[0];
  die "error evaluating $_[0]: $@" if $@;
}

sub within {
  local $_;
  my ($lower, $upper, @xs) = @_;
  not grep $_ < $lower || $_ > $upper, @xs;
}

# Binary repacking
# It's common to pack(), then unpack() immediately; for instance, to parse WKB
# we'd pack hex and then unpack doubles. This transcoding can be more concisely
# represented using two functions, pu and up, each of which uses a colon to
# split the templates.
#
# For example, up("H*:Q*", 1, 2, 3) would give you a bunch of hex digits to
# encode the quadwords 1, 2, and 3.

sub pu { my ($p, $u) = split /:/, shift; pack $p, unpack $u, @_ }
sub up { my ($u, $p) = split /:/, shift; unpack $u, pack $p, @_ }
55 core/pl/string.pm
# String utilities

sub startswith($$) {
  $_[1] eq substr $_[0], 0, length $_[1];
}

sub endswith($$) {
  length($_[0]) >= length($_[1])
    and $_[1] eq substr $_[0], length($_[0]) - length($_[1]);
}

# Number to letter 1 => "A", 2 => "B", etc.
sub alph($) {chr($_[0] + 64)}

sub squo()    {"'"}
sub dquo()    {'"'}
sub squote($) {"'$_[0]'"}
sub dquote($) {"\"$_[0]\""}

sub restrict_hdfs_path ($$) {
  my ($path, $restriction) = @_;
  my ($zeroes) = ($restriction =~ /^1(0*)$/);
  if (endswith $path, "part-*") {
    $path =~ s/part-\*/part-$zeroes\*/;
  } else {
    $path = $path . "/part-$zeroes*"
  }
  $path;
}

# Syntactic sugar for join/split
BEGIN
{
  my %short_separators =
    ("c" => ",",
     "C" => ":",
     "n" => "\n",
     "p" => "|",
     "t" => "\t",
     "u" => "_",
     "w" => " ");

   for my $abbrev (keys %short_separators)
   {
     my $sep = $short_separators{$abbrev};
     ceval sprintf 'sub jj%s      {join "%s",      @_;}',
       $abbrev, $sep;
     ceval sprintf 'sub jj%s%s    {join "%s%s",    @_;}',
       $abbrev, $abbrev, $sep, $sep;
     ceval sprintf 'sub ss%s($)   {split /\Q%s\E/,   $_[0]}',
       $abbrev, $sep;
     ceval sprintf 'sub ss%s%s($) {split /\Q%s%s\E/, $_[0]}',
       $abbrev, $abbrev, $sep, $sep;
    }
}
39 core/pl/file.pm
# File Readers
sub rf  {open my $fh, "< $_[0]" or die "rf $_[0]: $!"; my $r = join '', <$fh>; close $fh; $r}
sub rfl {open my $fh, "< $_[0]" or die "rl $_[0]: $!"; my @r =          <$fh>; close $fh; @r}
sub rfc {chomp(my $r = rf @_); $r}

# ri(my $var, "< file"): read entire contents into
sub ri  {open my $fh, $_[1] or die "ri $_[1]: $!"; 1 while read $fh, $_[0], 65536, length $_[0]}

sub dirbase($)  {my @xs = $_[0] =~ /^(.*)\/+([^\/]+)\/*$/; @xs ? @xs : ('', $_[0])}
sub basename($) {(dirbase $_[0])[1]}
sub dirname($)  {(dirbase $_[0])[0]}

sub mkdir_p {-d $_[0] or !length $_[0] or mkdir_p(dirname $_[0]) && mkdir $_[0]}

sub wf {
  local $_;
  my $f = shift;
  my $fh;
  if ($f =~ /^\|/) {
    open $fh, $f or die "wf $f: $!";
  } else {
    mkdir_p dirname $f;
    open $fh, "> $f" or die "wf $f: $!";
  }
  print $fh /\n$/ ? $_ : "$_\n" for @_;
  close $fh;
  $f;
}

sub af {
  local $_;
  my $f = shift;
  mkdir_p dirname $f;
  open my $fh, ">> $f" or die "af $f: $!";
  print $fh /\n$/ ? $_ : "$_\n" for @_;
  close $fh;
  $f;
}

145 core/pl/array.pm
# Array processors
sub first  {$_[0]}
sub final  {$_[$#_]}   # `last` is reserved for breaking out of a loop
sub rando  {$_[int(rand($#_ + 1))]}
sub max    {local $_; my $m = pop @_; $m = defined && $_ >  $m ? $_ : $m for @_; $m}
sub min    {local $_; my $m = pop @_; $m = defined && $_ <  $m ? $_ : $m for @_; $m}
sub maxstr {local $_; my $m = pop @_; $m = defined && $_ gt $m ? $_ : $m for @_; $m}
sub minstr {local $_; my $m = pop @_; $m = defined && $_ lt $m ? $_ : $m for @_; $m}

sub any(&@) {local $_; my ($f, @xs) = @_; &$f($_) && return 1 for @xs; 0}
sub all(&@) {local $_; my ($f, @xs) = @_; &$f($_) || return 0 for @xs; 1}

sub uniq  {local $_; my(%seen, @xs); $seen{$_}++ or push @xs, $_ for @_; @xs}
sub freqs {local $_; my %fs; ++$fs{$_} for @_; \%fs}

sub reduce(&$@) {local $_; my ($f, $x, @xs) = @_; $x = &$f($x, $_) for @xs; $x}
sub reductions(&$@) {
  local $_;
  my ($f, $x, @xs, @ys) = @_;
  push @ys, $x = &$f($x, $_) for @xs;
  @ys;
}

sub deltas {local $_; return () unless @_ > 1; map $_[$_] - $_[$_ - 1], 1..$#_}
sub totals {local $_; my ($x, @xs) = 0; push @xs, $x += $_ for @_; @xs}

sub take($@) {my ($n, @xs) = @_; @xs[0..($n-1)]}
sub drop($@) {my ($n, @xs) = @_; @xs[$n..$#xs]}
sub take_last($@) {my ($n, @xs) = @_; @xs[($#xs-$n)..$#xs]}
sub drop_last($@) {my ($n, @xs) = @_; @xs[0..($#xs-$n-1)]}

sub take_while(&@) {
  local $_;
  my ($f, @xs) = @_; 
  my @out; 
  for (@xs) { if(&$f($_)) {push @out, $_} else {last} }
  @out;
}

sub drop_while(&@) {
  local $_;
  my ($f, @xs) = @_;
  my @out;
  my $count = 0;
  for (@xs) { if(!&$f($_)) {return drop $count, @xs} $count++;}
  ();
} 

sub take_every($$@) {
  my ($every, $start, @r) = @_;
  @r[grep { ($_ - $start) % $every == 0 } 0..$#r];
}

sub take_even(@) { take_every(2, 0, @_); }
sub take_odd(@) { take_every(2, 1, @_); }

sub argmax(&@) {
  local $_;
  my ($f, $m, @xs, $fx) = @_;
  my $fm = &$f($_ = $m);
  for (@xs) {
    ($m, $fm) = ($_, $fx) if ($fx = &$f($_)) > $fm;
  }
  $m;
}

sub argmin(&@) {
  local $_;
  my ($f, $m, @xs, $fx) = @_;
  my $fm = &$f($_ = $m);
  for (@xs) {
    ($m, $fm) = ($_, $fx) if ($fx = &$f($_)) < $fm;
  }
  $m;
}

# Index of Maximum Element
sub indmax(&@) {
  local $_;
  my ($f, @xs) = @_;
  my $im = 0;
  my $fm = &$f($xs[$im]);
  my $fx;
  for (1..$#xs) {
    ($im, $fm) = ($_, $fx) if ($fx = &$f($xs[$_])) > $fm;
  }
  $im;
}

# Index of Minimum Element
sub indmin(&@) {
  local $_;
  my ($f, @xs) = @_;
  my $im = 0;
  my $fm = &$f($xs[$im]);
  my $fx;
  for (1..$#xs) {
    ($im, $fm) = ($_, $fx) if ($fx = &$f($xs[$_])) < $fm;
  }
  $im;
}

sub most_common(@)
{
  local $_;
  my %freqs;
  ++$freqs{$_} for @_;
  my $most = max values %freqs;
  grep $freqs{$_} == $most, keys %freqs;
}

sub zip {
  my @rs = @_;
  my $min_length = min map {$#{$_}} @rs;
  my @r;
  for my $idx(0..$min_length) {
    push @r, ${$rs[$_]}[$idx] for 0..$#rs;
  }
  @r;
}

sub cart {
  use integer;
  local $_;
  return () unless @_;
  @$_ or return () for @_;
  return map [$_], @{$_[0]} if @_ == 1;
  my @ns = map scalar(@$_), @_;
  map {
    my ($i, $xs) = ($_ - 1, []);
    for (reverse 0..$#ns) {
      unshift @$xs, ${$_[$_]}[$i % $ns[$_]];
      $i /= $ns[$_];
    }
    $xs;
  } 1..prod(@ns);
}

sub clip {
  local $_;
  my ($lower, $upper, @xs) = @_;
  wantarray ? map min($upper, max $lower, $_), @xs
            : min $upper, max $lower, $xs[0];
}

56 core/pl/json.pm
# JSON utils 

# for extracting a small number of fields from
# complex JSON

sub get_array($$) {
  my @raw_data = $_[0] =~ /"$_[1]":\[([^]]+)/;
  return map {eval $_} map {split /,/, $_} @raw_data;
}

sub get_scalar($$) {
  my ($output_val,) = $_[0] =~ /"$_[1]":("[^"]*"|-?\d+.?\d*)/;
  return $output_val;
}

sub get_flat_hash($$) {
  my ($output_val,) = $_[0] =~ /"$_[1]":({[^}]*})/;
  return $output_val;
}

sub join_json_parts {
  if (substr($_[1], 0, 1) eq ",") {
    return join '', $_[0], substr($_[1], 1); 
  } elsif ($_[1] eq "}" and substr($_[0], -1) eq ",") {
    return join '', substr($_[0], 0, -1), $_[1];
  }  else {
    return join '', @_;
  }
}

sub delete_array {
  my @raw_data = $_[0] =~ /^(.*[{,])"$_[1]":\[[^]]+\]([},].*)$/;
  if(@raw_data) {
    return join_json_parts @raw_data;
  } else {
    return $_[0];
  }
}

sub delete_scalar {
  my @raw_data = $_[0] =~ /^(.*[{,])"$_[1]":(?:"[^"]*"|-?\d+.?\d*)([},].*)$/;
  if(@raw_data) {
    return join_json_parts @raw_data;
  } else {
    return $_[0];
  }
}

sub delete_flat_hash {
  my @raw_data = $_[0] =~ /^(.*[{,])"$_[1]":{[^}]*}([},].*)$/;
  if(@raw_data) {
    return join_json_parts @raw_data;
  } else {
    return $_[0];
  }
}
152 core/pl/hash.pm
# Hash utilities

# Key-By-Value ascending and descending
sub kbv_dsc { my %h = @_; sort { $h{$b} <=> $h{$a} } keys %h }
sub kbv_asc { my %h = @_; sort { $h{$a} <=> $h{$b} } keys %h }

sub dump_array {
  my $r = shift;
  my $indent = $_[0] ? $_[0] : 0;
  print "\t" x $indent, "[\n";
  for my $el (@$r) {
    if( ref $el eq "HASH" ) { 
        dump_hash( $el, $indent + 1 );
    } elsif( ref $el eq "ARRAY") {
        dump_array( $el, $indent + 1);
    } else { 
        print "\t" x ($indent + 1), "$el\n";
    } 
  } 
  print "\t" x $indent, "]\n";
}

sub dump_hash { 
  my $h = shift; 
  my $indent = $_[0] ? $_[0] : 0;
  foreach my $key (keys %$h) { 
    print "\t" x $indent, "$key\t=>";
    if( ref $h->{$key} eq "HASH" ) { 
      print "\n";
      dump_hash( $h->{$key}, $indent + 1);
    } elsif( ref $h->{$key} eq "ARRAY") {
      print "\n";
      dump_array( $h->{$key}, $indent + 1);
    } else { 
      print "\t", $h->{$key}, "\n";
    } 
  }   
}

sub dump_data {
  my $dumpme = pop @_;
  print join "\t", @_, "\n";
  if(ref($dumpme) eq "HASH") {
    dump_hash($dumpme);
  } elsif(ref($dumpme) eq "ARRAY") {
    dump_array($dumpme);
  } else {
    print "$dumpme\n";
  }
}

sub merge_hash_values($$) {
  my ($val1, $val2) = @_;
  return $val1 unless defined $val2;
  return $val2 unless defined $val1;

  my $ref1 = ref($val1);
  my $ref2 = ref($val2);
  my $output;
  if ($ref1 eq "" and $ref2 eq "") {
    $output = $val1 || $val2;
  } elsif($ref1 eq "ARRAY" and $ref2 eq "ARRAY") {
    my @output = @$val1;
    push @output, @$val2;
    $output = \@output;
  } elsif($ref1 eq "HASH" and $ref2 eq "HASH") {
    $output = merge_hashes($val1, $val2);
  } else {
    die "cannot merge different types of values value 1: $val1, value 2: $val2\n";
  }
  $output
}

sub sum_two_hashes($$);     # prevent prototype-check errors for recursion
sub sum_two_hashes($$) {
  my ($href1, $href2) = @_;
  for my $key(keys %{$href2}) {
    my $val = $href2->{$key};
    if(ref($val) eq "") {
       $href1->{$key} += $val;
    } elsif(ref($val) eq "HASH") {
      $href1->{$key} = %{$val} ? sum_two_hashes($href1->{$key}, $val ) 
                               : $href1->{$key} ? $href1->{$key} : {};
    } else { die "bad structure" }
  }
  $href1;
}

sub accumulate_two_hashes($$);
sub accumulate_two_hashes($$) {
  my ($href1, $href2) = @_;
  for my $key (keys %{$href2}) {
    $href1->{$key} = {} if not exists $href1->{$key};
    my $val = $href2->{$key};
    if(ref($val) eq "") {
      $href1->{$key}->{$val} += 1;
    } elsif(ref($val) eq "ARRAY") {
      for (@{$val}) {$href1->{$key}->{$_} += 1;}
    } elsif(ref($val) eq "HASH") {
      $href1->{$key} = accumulate_two_hashes($href1->{$key}, $val );
    } else {
      die "accumulating went bad";
    }
  }
  $href1;
}

sub merge_two_hashes($$) {
  my ($href1, $href2) = @_;
  my %h1 = %$href1;
  my %h2 = %$href2;
  my @keys = uniq keys %h1, keys %h2; 
  my %h;
  for my $key(@keys) {
    my $val1 = $h1{$key};
    my $val2 = $h2{$key};
    $h{$key} = merge_hash_values($val1, $val2); 
  }
  \%h;
}

sub sum_hashes {
  my $href = shift;
  for(@_) {
    $href = sum_two_hashes($href, $_);
  }
  $href;
}

sub merge_hashes {
  my $href = shift;
  for(@_) {
    $href = merge_two_hashes($href, $_);
  }
  $href;
}

sub accumulate_hashes {
  my $href = {};
  for(@_) {
    $href = accumulate_two_hashes($href, $_);
  }
  $href;
}

# JSON decoding is very slow; if you know that 
# your data has no shared (top-level) keys, 
# you can go from string json directly to string json.
sub string_merge_hashes {
  my @hash_vals = map {substr $_, 1, -1} @_;
  "{" . join(",", @hash_vals) . "}";
}
86 core/pl/hadoop.pm
# Helpers for interacting with Hadoop and YARN
sub extract_hdfs_path($) {
  my ($raw_path) = @_;
  my @input_path_parts = $raw_path =~ m([^/]+)mg;
  if(defined $input_path_parts[0] and 
    $input_path_parts[0] =~ /^hdfs[^:]*:/) {
    shift @input_path_parts;
  };
  if (defined $input_path_parts[-1] and
      $input_path_parts[-1] =~ /^(\*|part-)/) {
    pop @input_path_parts;
  }
 "/" . join "/", @input_path_parts;
}

sub extract_parent_path($) {
  my @path_parts = $_[0] =~ m([^/]+)mg;
  pop @path_parts;
  return "/" . join "/", @path_parts;
}

sub hdfs_du_h ($) {
  my $hdfs_path = extract_hdfs_path $_[0];
  `hadoop fs -du -h $hdfs_path`
}

sub hdfs_mkdir_p($) {
  my $hdfs_path = extract_hdfs_path $_[0];
  `hadoop fs -mkdir -p $_[0]`  
}

sub hdfs_rm_r($) {
  my $hdfs_path = extract_hdfs_path $_[0];
  `hadoop fs -rm -r $_[0]`
}

sub hdfs_put($$) {
  `hadoop fs -put -f $_[0] $_[1]`
}

sub hdfs_get($$) {
  my $hdfs_path = extract_hdfs_path $_[1];
  `hadoop fs -get $_[0] $hdfs_path`
}

sub hdfs_ls($) {
  my $hdfs_path = extract_hdfs_path $_[0];
  `hadoop fs -ls -h $hdfs_path`
}

sub hdfs_mv {
  my $raw_output_hdfs_path = pop @_;
  my @input_hdfs_paths  = map {extract_hdfs_path $_} @_;
  my $output_hdfs_folder = extract_hdfs_path($raw_output_hdfs_path);
  my $output_hdfs_parent_folder = extract_parent_path $output_hdfs_folder;
  my $pad = length (scalar @input_hdfs_paths - 1);
  my $pad_fmt_str = "/%0$pad" . "d";
  my @output_hdfs_paths = map {@input_hdfs_paths == 1 ? $output_hdfs_folder : $output_hdfs_folder . sprintf($pad_fmt_str, $_)} 0..$#input_hdfs_paths;
  if(@input_hdfs_paths == 1) {
    hdfs_mkdir_p $output_hdfs_parent_folder;
  } else {
    hdfs_mkdir_p $output_hdfs_folder;
  }
  `hadoop fs -mv $input_hdfs_paths[$_] $output_hdfs_paths[$_]` for 0..$#input_hdfs_paths;
  if(@input_hdfs_paths == 1) {
    return "hdfst://$output_hdfs_folder";
  } else {
    return "hdfst://$output_hdfs_folder/*/*";
  }
  
}

sub yarn_application_kill($) {
  `yarn application -kill $_[0]`
}

BEGIN {
  *hddu = \&hdfs_du_h;
  *hdmp = \&hdfs_mkdir_p;
  *hdrm = \&hdfs_rm_r;
  *hdpt = \&hdfs_put;
  *hdgt = \&hdfs_get;
  *hdls = \&hdfs_ls;
  *hdmv = \&hdfs_mv;
  *yak = \&yarn_application_kill;
}
158 core/pl/math.pm
# Math utility functions.
# Mostly geometric and statistical stuff.

use constant tau => 2 * 3.14159265358979323846264;
use constant tau2 => tau/2;
use constant tau4 => tau/4;

use constant LOG2  => log 2;
use constant LOG2R => 1 / LOG2;
use constant LOG10 => log 10;
use constant LOG10R=> 1 / LOG10;

BEGIN { eval "use constant E$_ => 1e$_" for 0..20 }

# Integer Functions
sub ceil($)  {$_[0] == int($_[0]) ? $_[0] : $_[0] > 0 ? int($_[0]) + 1 : int($_[0])}
sub floor($) {$_[0] == int($_[0]) ? $_[0] : $_[0] > 0 ? int($_[0]) : int($_[0]) -1 }

# Sums, Products, Medians
sub sum  {local $_; my $s = 0; $s += $_ for @_; $s}
sub prod {local $_; my $p = 1; $p *= $_ for @_; $p}
sub mean {scalar @_ && sum(@_) / @_;}
sub median {my $length = scalar @_; my @sorted = sort {$a <=> $b} @_; $sorted[int($length/2)];}
sub gmean {exp mean map {log $_} @_;}
sub hmean {scalar @_ && @_/sum(map {1/$_} @_) or 1;}

# Logarithmic
sub log2($) {LOG2R * log $_[0]}
sub log10($) {LOG10R * log $_[0]}

# Quantize and Interpolate
sub quant {my ($x, $q) = @_; $q ||= 1;
           my $s = $x < 0 ? -1 : 1; int(abs($x) / $q + 0.5) * $q * $s}

sub interp {
  my $f = shift;
  my @r;
  while (@_) {
    push @r, $_[0] * (1 - $f) + $_[1] * $f;
    shift; shift;
  }
  @r;
}

## Vector Functions
sub proj($$)
{ local $_; my ($a, $b) = @_;
  my $f = dot($a, $b) / dot($b, $b);
  map $f * $_, @$b }

sub orth($$)
{ local $_; my ($a, $b) = @_;
  my @proj = proj $a, $b;
  map $$a[$_] - $proj[$_], 0..$#{$a} }

sub cross($$)
{ my ($x1, $y1, $z1, $x2, $y2, $z2) = (@{$_[0]}, @{$_[1]});
  ($y1*$z2 - $z1*$y2, $z1*$x2 - $x1*$z2, $x1*$y2 - $y1*$x2) }


sub dot($$) {local $_; my ($u, $v) = @_;
             sum map $$u[$_] * $$v[$_], 0..min $#{$u}, $#{$v}}

sub l1norm {local $_; sum map abs($_), @_}
sub l2norm {local $_; sqrt sum map $_*$_, @_}

sub vec_sum($$) {
  local $_; my ($u, $v) = @_;
  map $$u[$_] + $$v[$_], 0..$#$u;
}

sub vec_diff($$) {
  local $_; my ($u, $v) = @_;
  map $$u[$_] - $$v[$_], 0..$#$u;
}

sub distance_to_line($$$) {
  local $_;
  my ($a, $l, $p) = @_;
  my @n = vec_diff($a, $l);
  my @d = vec_diff($a, $p);
  
  l2norm orth(\@d, \@n);
}


## Trig Functions
sub rdeg($) {$_[0] * 360 / tau}
sub drad($) {$_[0] / 360 * tau}

sub prec {($_[0] * sin drad $_[1], $_[0] * cos drad $_[1])}
sub rpol {(l2norm(@_), rdeg atan2($_[0], $_[1]))}

# Numpy synonyms and extensions
BEGIN
{
  *radians = \&drad;
  *degrees = \&rdeg;
}

sub linspace($$$) {
  my $n_spaces = $_[2] - 1;
  map {$_[0] + $_/$n_spaces *($_[1] - $_[0])} 0..$n_spaces;
}

sub arange($$$) {
  my $n_spaces = int abs ($_[1] - $_[0])/$_[2];
  linspace $_[0], $_[0] + $_[2]*$n_spaces, $n_spaces;
}

sub aspace($$$) {
  linspace $_[0], $_[1], 1 + abs int(($_[1] - $_[0])/$_[2]);
}

sub logspace($$$;$) {
  my @powers = linspace($_[0], $_[1], $_[2]);
  my $base = defined $_[3] ? $_[3] : 10;
  map {$base ** $_} @powers;
}

## Numpy stats synonyms
sub var {
  my $mean = mean @_;
  mean map {($_ - $mean)**2} @_;
}

sub std {
  sqrt(var(@_));
}

sub entropy {
  local $_;
  my $sum = sum @_;
  my $t = 0;
  $t += $_ / $sum * ($_ > 0 ? -log2($_ / $sum) : 0) for @_;
  $t;
}

# Random
sub randint {my ($low, $high) = @_; 
             ($high, $low) = $high ? ($high, $low) : ($low, 0);  
             int(rand($high - $low) + $low);
           }


# Sphere distance
BEGIN {
if (eval {require Math::Trig}) {
  Math::Trig->import('!sec');   # sec() conflicts with stream reducers
  sub haversine {
    local $_;
    my ($t1, $p1, $t2, $p2) = map drad $_, @_;
    my ($dt, $dp) = ($t2 - $t1, $p2 - $p1);
    my $a = clip 0, 1, sin($dp / 2)**2 + cos($p1) * cos($p2) * sin($dt / 2)**2;
    2 * atan2(sqrt($a), sqrt(1 - $a));
  }
}
}
119 core/pl/stream.pm
# Perl stream-related functions.
# Utilities to parse and emit streams of data. Handles the following use cases:

# | $ ni n10p'a + a'             # emit single value
#   $ ni n10p'a, a * a'          # emit multiple values vertically
#   $ ni n10p'r a, a * a'        # emit multiple values horizontally

# Lowercase letters followed by underscores are field-extractors that can take an
# array of lines and return an array of field values. These are useful in
# conjunction with the line-reading functions `rw`, `ru`, and `re`.

no warnings 'uninitialized';

our @q;
our @F;

sub rl(;$);
sub rl(;$) {return ($_, map rl(), 2..$_[0]) if @_;
            chomp($_ = @q ? shift @q : <STDIN>); @F = split /\t/; $_}
sub pl($)  {chomp, push @q, $_ until @q >= $_[0] || !defined($_ = <STDIN>); @q[0..$_[0]-1]}
sub F_(@)  {@_ ? @F[@_] : @F}
sub FM()   {$#F}
sub FR($)  {$_[0] > 0 ? @F[$_[0]..$#F] : @F[($#F + $_[0] + 1)..$#F]}
sub FT($)  {$_[0] > 0 ? @F[0..($_[0] - 1)] : @F[0..($#F + $_[0])]}
sub r(@)   {(my $l = join "\t", @_) =~ s/\n//g; print $l, "\n"; ()}
BEGIN {ceval sprintf 'sub %s():lvalue {$ni::pl::F[%d]}', $_, ord($_) - 97 for 'a'..'l';
       ceval sprintf 'sub %s_ {local $_;
                               die "coercing %s_() to a scalar is a mistake" unless wantarray;
                               map((split /\t/)[%d] || "", map split(/\n/), @_)}',
                     $_, $_, ord($_) - 97 for 'a'..'l'}
BEGIN {ceval sprintf 'sub %s__ {my @r;
                                die "coercing %s__() to a scalar is a mistake" unless wantarray;
                                foreach my $line(@_) 
                                { my @line_arr = split /\t/, $line; 
                                  my @short = @line_arr[%d..$#line_arr];
                                  push @r, @short } @r }', $_, $_, ord($_) - 97 for 'a'..'l'}

sub cols(@) {
  local $_;
  for my $i (0..min map $#{$_}, @_) {
    r map $_[$_][$i], 0..$#_;
  }
  ();
}

# Hash constructors.
# Pairs of letters you can use to index one column against another. For example,
# `%h = ab_ @lines` is the same as `@h{a_ @lines} = b_ @lines`.

BEGIN {for my $x ('a'..'l') {
         ceval sprintf 'sub %s%s_ {my %%r; @r{%s_ @_} = %s_ @_; %%r}',
                       $x, $_, $x, $_ for 'a'..'l'}}
BEGIN {for my $x ('a'..'l') {
        for my $y ('a'..'l') {
         ceval sprintf 'sub %s%sS {my %%r; my @key_arr = %s_ @_; my @val_arr = %s_ @_;
                                    $r{$key_arr[$_]} += $val_arr[$_] for 0..$#key_arr; %%r}',
                       $x, $y, $x, $y }}}
BEGIN {for my $x ('a'..'l') {
        for my $y ('a'..'l') {
         ceval sprintf 'sub %s%sSNN {my %%r; my @key_arr = %s_ @_; my @val_arr = %s_ @_;
                                    $r{$key_arr[$_]} += $val_arr[$_] for 0..$#key_arr;
                                    my %%r_output; my @filtered_keys = grep {$_ ne ""} keys %%r;
                                    @r_output{@filtered_keys} = @r{@filtered_keys}; %%r_output}',
                       $x, $y, $x, $y }}}

## Seeking functions.
# It's possible to read downwards (i.e. future lines), which returns an array and
# sends the after-rejected line into the lookahead queue to be used by the next
# iteration. Mnemonics:

# | rw: read while condition
#   ru: read until condition
#   re: read while equal

# These functions all read things into memory. If you want to stream stuff, you
# can do it in two ways. One is to use control flow with the 'rl' (read line)
# function:

# | do_stuff until rl =~ /<\//;           # iterate until closing XML tag
#   push @q, $_;                          # important: stash rejected line

sub r1()  {my @r = ($_); push @r, $_ while  defined rl; push @q, $_ if defined $_;  @r}
sub rw(&) {my @r = ($_); push @r, $_ while  defined rl && &{$_[0]}; push @q, $_ if defined $_; @r}
sub ru(&) {my @r = ($_); push @r, $_ until !defined rl || &{$_[0]}; push @q, $_ if defined $_; @r}
sub re(&) {my ($f, $i) = ($_[0], &{$_[0]}); rw {&$f eq $i}}
sub rea() {re {a}}
sub reA() {re {a}}
BEGIN {ceval sprintf '
       our $warned_about_lowercase_reX = 0;
       sub re%s() {
         warn "WARNING: the lowercase re<col> functions are deprecated "
            . "because ref conflicts with the perl ref() builtin; you "
            . "should use re%s instead" unless $warned_about_lowercase_reX++;
         re {join "\t", @ni::pl::F[0..%d]}}',
       $_, uc, ord($_) - 97 for 'b'..'l'}

BEGIN {ceval sprintf 'sub re%s() {re {join "\t", @ni::pl::F[0..%d]}}',
       $_, ord($_) - 65 for 'B'..'Z'}

# Streaming aggregations.
# These functions are like the ones above, but designed to work in constant
# space:

# | se<column>: streaming reduce while everything up to column is equal
#   sr: streaming reduce all data

sub se(&$@) {my ($f, $e, @xs) = @_; my $k = &$e;
             @xs = &$f(@xs), rl while defined and &$e eq $k;
             push @q, $_ if defined; @xs}
BEGIN {ceval sprintf 'sub se%s(&$@) {
                        my ($f, @xs) = @_;
                        se {&$f(@_)} sub {join "\t", @ni::pl::F[0..%d]}, @xs;
                      }', $_, ord($_) - 97 for 'a'..'l'}
BEGIN {ceval sprintf 'sub se%s(&$@) {
                        my ($f, @xs) = @_;
                        se {&$f(@_)} sub {join "\t", @ni::pl::F[0..%d]}, @xs;
                      }', $_, ord($_) - 65 for 'A'..'Z'}

sub sr(&@) {my ($f, @xs) = @_; @xs = &$f(@xs), rl while defined; @xs}
67 core/pl/reducers.pm
# Compound reductions.
# Suppose you want to calculate, in parallel, the sum of one column and the mean
# of another. You can't use two separate `sr` calls since the first one will
# force the whole stream. Instead, you need a way to build a single compound
# function that maintains the two separate state elements. That's what `rc`
# (reduce compound) is all about.

# In fast languages we could probably get away with some nice combinatory stuff
# here, but this is performance-critical and Perl isn't fast. So I'm making some
# epic use of codegen and `eval` to help Perl be all it can be. We end up
# compiling into a single function body for a `cr` call, which is then mapped
# through a finalizer to eliminate intermediate states.

sub rsum($)  {+{reduce => gen "%1 + ($_[0])",
                init   => [0],
                end    => gen '%1'}}

sub rmean($) {+{reduce => gen "%1 + ($_[0]), %2 + 1",
                init   => [0, 0],
                end    => gen '%1 / (%2 || 1)'}}

sub rmin($)  {+{reduce => gen "defined %1 ? min %1, ($_[0]) : ($_[0])",
                init   => [undef],
                end    => gen '%1'}}

sub rmax($)  {+{reduce => gen "defined %1 ? max %1, ($_[0]) : ($_[0])",
                init   => [undef],
                end    => gen '%1'}}

sub rarr($)  {+{reduce => gen "[\@{%1}, ($_[0])]",
                init   => [[]],
                end    => gen '%1'}}

sub rfn($$)  {+{reduce => gen $_[0],
                init   => [@_[1..$#_]],
                end    => gen join ', ', map "%$_", 1..$#_}}

sub compound_reducer(@) {
  local $_;
  my $slots = 0;
  my @indexes = map {my $n = @{$$_{init}}; $slots += $n; $slots - $n} @_;
  my @mapping = map {my $i = $_;
                     [map {;$_ => sprintf "\$_[%d]", $indexes[$i] + $_ - 1}
                          1..@{$_[$i]{init}}]} 0..$#_;
  (init   => [map @{$$_{init}}, @_],
   reduce => join(', ', map $_[$_]{reduce}->(@{$mapping[$_]}), 0..$#_),
   end    => join(', ', map $_[$_]{end}->(@{$mapping[$_]}),    0..$#_));
}

# Reduce compound function.
# Executes a compound reduction using the specified stream reducer function.
# Typical usage would be like this:

# | ($sum, $mean) = rc \&sea, fsum A, fmean B;

sub rc {
  my ($f, @rs) = @_;
  my %c        = compound_reducer @rs;
  my $reduce   = eval "sub{\n($c{reduce})\n}" or die "sc: '$c{reduce}': $@";
  my $end      = eval "sub{\n($c{end})\n}"    or die "sc: '$c{end}': $@";
  &$end(&$f($reduce, @{$c{init}}));
}

# Just like for `se` functions, we define shorthands such as `rca ...` = `rc
# \&sea, ...`.

BEGIN {ceval sprintf 'sub rc%s {rc \&se%s, @_}', $_, $_ for 'a'..'q'}
89 core/pl/wkt.pl
# WKT and polygons (ported from nfu)

sub line_opposite
{
  # Returns true if two points are on opposite sides of the line starting at
  # (x0, y0) and whose direction is (dx, dy).
  my ($x0, $y0, $dx, $dy, $x1, $y1, $x2, $y2) = @_;
  return (($x1 - $x0) * $dy - ($y1 - $y0) * $dx)
       * (($x2 - $x0) * $dy - ($y2 - $y0) * $dx) < 0;
}

sub evens(@) {local $_; @_[map $_ * 2,     0 .. $#_ >> 1]}
sub odds(@)  {local $_; @_[map $_ * 2 + 1, 0 .. $#_ >> 1]}

sub parse_rings
{
  +{
    rings  => [map [map $_ + 0, @$_], @_],
    ylimit => 1 + max(map max(@$_), @_),
    bounds => [min(map evens(@$_), @_), max(map evens(@$_), @_),
               min(map odds(@$_),  @_), max(map odds(@$_),  @_)],
  }
}

sub parse_wkt
{
  parse_rings map [/([-+eE0-9.]+)\s+([-+eE0-9.]+)/g],
              split /\)\s*,\s*\(/, shift;
}

sub parse_wkb
{
  # Parses either hex or binary. The first byte of WKB is an endianness
  # indicator, so if we see a hex digit we know to decode.
  my $wkb   = $_[0] =~ /^[0-9a-fA-F]/ ? pack "H*", shift : shift;
  my $float = $wkb =~ /^\x01/ ? 'd<' : 'd>';
  my $long  = $wkb =~ /^\x01/ ? 'V'  : 'N';

  my $type     = unpack "x $long", $wkb;
  my $has_srid = $type & 0x20000000;
  my $prefix   = $has_srid ? 9 : 5;
  $type &= 0xff;

  # Parse linestrings, polygons, multilinestrings, and multipolygons. Assume
  # constant endianness throughout the WKB; anything else would be insane.
  my $template =
      $type == 2 || $type == 3 ? "x$prefix $long/(   $long/($long X4 $long/($float$float)))"
    : $type == 5 || $type == 6 ? "x$prefix $long/(x5 $long/($long X4 $long/($float$float)))"
    :                            die "parse_wkb: unknown type $type in $_[0]";

  my @pts = unpack $template, $wkb;

  # Now @pts contains length-prefixed float pairs. We need to convert those to
  # array refs.
  my @rings;
  my $n;
  for (my $i = 0; $i < @pts - 2; $i += $n*2)
  {
    $n = $pts[$i];
    push @rings, [@pts[$i + 1 .. $i + $n*2]];
  }

  parse_rings @rings;
}

sub in_poly
{
  # Returns true if a point resides in the given parsed polygon.
  my ($x, $y, $parsed) = @_;
  my $ylimit = $parsed->{ylimit};
  my @bounds = @{$parsed->{bounds}};
  return 0 if $x < $bounds[0] || $x > $bounds[1]
           || $y < $bounds[2] || $y > $bounds[3];

  my $hits = 0;
  for my $r (@{$parsed->{rings}}) {
    my ($lx, $ly) = @$r[0, 1];
    for (my $i = 2; $i < @$r; $i += 2) {
      my $cx = $$r[$i];
      my $cy = $$r[$i + 1];
      ++$hits if $lx <= $x && $x < $cx || $lx >= $x && $x > $cx
             and line_opposite $lx, $ly, $cx - $lx, $cy - $ly,
                               $x, $y, $x, $ylimit;
      $lx = $cx;
      $ly = $cy;
    }
  }
  $hits & 1;
}
235 core/pl/time.pl
# Time conversion functions.
# Dependency-free functions that do various time-conversion tasks for you in a
# standardized way. They include:

# | @parts = tep($elements, $epoch): convert an epoch to specified pieces
#   $epoch = tpe($elements, @values): convert values to an epoch

# Everything always happens in UTC. If you want a different timezone, you'll need
# to shift your epochs by some multiple of 3600.

use POSIX ();
BEGIN {eval {require Time::HiRes; Time::HiRes->import('time')}}

use constant time_pieces => 'SMHdmYwjDN';

our $mktime_error = 0;          # bugfix for OSX

sub time_element_indexes($) {map index(time_pieces, $_), split //, $_[0]}

sub time_epoch_pieces($;$) {
  no warnings;
  local $_;
  my ($es, $t) = $_[0] =~ /^[SMHdmYwjDN]+$/ ? @_ : ('YmdHMS', @_);
  my @pieces = gmtime $t;
  push @pieces, int(1_000_000_000 * ($t - int $t));
  $pieces[5] += 1900;
  $pieces[4]++;
  @pieces[time_element_indexes $es];
}

sub time_epoch_formatted($;$)
{
  my ($es, $t) = $_[0] =~ /^\D+$/ ? @_ : ('Y-m-d H:M:S', @_);
  my $pieces = join"", $es =~ /[SMHdmYjDN]/g;
  (my $format = $es) =~ s/([a-zA-Z])/$1 eq "Y" ? "%04d" : "%02d"/eg;
  sprintf $format, time_epoch_pieces $pieces, $t;
}

sub time_pieces_epoch {
  no warnings;
  local $_;
  my ($es, @ps) = $_[0] =~ /^[SMHdmYwjDN]+$/ ? @_ : ('YmdHMS', @_);
  my @tvs = (0, 0, 0, 1, 1, 1970, 0, 0, -1, 0);
  @tvs[time_element_indexes $es] = @ps;
  $tvs[5] -= 1900;
  $tvs[4]--;
  POSIX::mktime(@tvs[0..5]) + $tvs[9] / 1_000_000_000 - $mktime_error;
}

# Day of Week and Hour of Day.
# These methods are for converting timestamps in GMT; if you have data from another location on the globe (and you probably do), you'll need to use a timezone shift as described above.

our @days = qw(Thu Fri Sat Sun Mon Tue Wed);
sub day_of_week($) {
  my $ts = $_[0];
  my $weekday = int(($ts % 604800)/86400);
  $days[$weekday];
}

sub hour_of_day($) {
  my $ts = $_[0];
  int(($ts %86400)/3600);
}

sub hour_of_week($) {
  my $ts = $_[0];
  my $dow = day_of_week($ts);
  my $hod = sprintf "%02d", hour_of_day($ts);
  $dow . "_" . $hod;
}

sub year_month($) {
  my @year_month = tep('Ym', $_[0]);
  my $year = $year_month[0];
  my $month = sprintf "%02d", $year_month[1];
  $year . "-" . $month;
}

sub year_month_day($) {
  my @year_month = tep('Ymd', $_[0]);
  my $year = $year_month[0];
  my $month = sprintf "%02d", $year_month[1];
  my $day = sprintf "%02d", $year_month[2];
  join "-", $year, $month, $day;
}

# Round to day/hour/quarter-hour/minute.

BEGIN {my %duration_in_seconds = ('day' => 86400, 
                                  'hour' => 3600,
                                  'quarter_hour' => 900, 
                                  'minute' => 60,
                                  'week' => 7*86400);
        for my $time_period (keys %duration_in_seconds) {
         my $seconds = $duration_in_seconds{$time_period};
         eval sprintf 'sub truncate_to_%s($) {my $ts = $_[0]; %d * int($ts/%d)}',
                      $time_period, $seconds, $seconds}}

# Approximate timezone shifts by lat/lng.
# Uses the Bilow-Steinmetz approximation to quickly calculate a timezone offset
# (in seconds, which can be added to a GMT epoch) for a given latitude/longitude.
# It may be off by a few hours but is generally unbiased.

sub timezone_seconds {
  my ($lat, $lng) = @_;
  240 * int($lng + 7);
}

sub gh60_localtime($$) {
  my ($ts, $gh) = @_;
  my ($lat, $lng) = ghd $gh, 60;
  $ts + timezone_seconds($lat, $lng);
}

sub gh_localtime($$) {
  my ($ts, $gh) = @_;
  my ($lat, $lng) = ghd $gh;
  $ts + timezone_seconds($lat, $lng);
}

{
  my $t = time;
  $mktime_error = int time_pieces_epoch(time_epoch_pieces $t) - $t;
}


# ISO 8601 is a standard format for time data; it looks like: 
# 2017-06-24T07:58:59+00:00 or 2017-06-24T07:58:59Z
# There's also a form with no colons or dashes that's supported:
# 20170624T075859Z
# And also a form with a space between the time and the date:
# 2017-06-24 07:58:59.729
# The added or subtracted amount at the end corresponds to the
# local timezone.

sub iso_8601_epoch {
  my $iso_time = $_[0];
  my ($date_part, $time_part) = split /[\sT]/, $iso_time;
  my ($y, $m, $d);
  if ($date_part !~ /^\d{4}-/) {
    ($y, $m, $d) = /^(\d{4})(\d{2})(\d{2})/;
  } else {
    ($y, $m, $d) = split /-/, $date_part;
  }

  return time_pieces_epoch($y, $m, $d) unless $time_part;

  my ($h, $min, $s, $tz_part) = ($time_part =~ /^(\d{2}):?(\d{2}):?([0-9.]{2,})([Z+-].*)?$/);
  my $raw_ts = time_pieces_epoch($y, $m, $d, $h, $min, $s);
  return $raw_ts unless defined $tz_part;
  return $raw_ts if $tz_part eq "Z";

  my ($offset_type, $offset_hr, $offset_min) = ($tz_part =~ /([+-])(\d{2}):?(\d{2})?/);

  my $offset_amt = $offset_type eq "-" ? 1 : -1; 
  my $offset = $offset_amt * (3600 * $offset_hr + 60 * $offset_min); 
  $raw_ts + $offset;
}

# Converts an epoch timestamp to the corresponding 
# time zone; gives local time when a second argument
# corresponding to the local timezone is given.

sub make_tz_str($) {
  my $tz_raw = shift;
  my $epoch_offset;
  my $tz_str;
  if ($tz_raw =~ /^-?\d+\.?\d*$/) {
    die("badly formatted ISO timezone: $tz_raw\n") if abs $tz_raw > 12;
    $epoch_offset = $tz_raw*3600;
    my $tz_hr = int($tz_raw);
    my $tz_min = abs int(($tz_raw - $tz_hr)*60);
    my $tz_sign = $tz_raw < 0 ? "-" : "+";
    $tz_str = sprintf "%s%02d:%02d", $tz_sign, abs $tz_hr, $tz_min;
  } elsif ($tz_raw =~ /^[+-]\d{1,2}:?(\d{2})?$/) {
    my $tz_sign = substr($tz_raw, 0, 1);
    my ($tz_hr, $tz_min) = ($tz_raw =~ /^[+-](\d{1,2}):?(\d{2})?$/);
    $tz_str = sprintf "%s%02d:%02d", $tz_sign, $tz_hr, $tz_min || 0;
    my $offset_amt = 3600 * $tz_hr + 60 * ($tz_min || 0);
    $epoch_offset = $tz_sign eq "+"? $offset_amt : -$offset_amt;
  } elsif ($tz_raw eq "Z") {
    $epoch_offset = 0;
    $tz_str = $tz_raw;
  } else {
    die("badly formatted ISO 8601 timestamp: $tz_raw");
  }
  $tz_str, $epoch_offset;
}

sub epoch_iso_8601($;$) {
  my ($epoch, $tz_raw) = $#_ == 2 ? @_ : (@_ , "Z");
  my ($tz_str, $epoch_offset) = make_tz_str($tz_raw);
  $epoch += $epoch_offset;
  my ($y, $m, $d, $h, $min, $s) = time_epoch_pieces($epoch);
  my $iso_time = sprintf "%d-%02d-%02dT%02d:%02d:%02d%s", $y, $m, $d, $h, $min, $s, $tz_str;
  $iso_time;
}

sub time_parts_iso_8601 {
  my ($y, $m, $d, $h, $min, $s, $tz_raw) = @_;
  my ($tz_str, $epoch_offset) = make_tz_str($tz_raw);
  my $iso_time = sprintf "%d-%02d-%02dT%02d:%02d:%02d%s", $y, $m, $d, $h, $min, $s, $tz_str;
  $iso_time;
}

sub mdy_epoch {
  my ($m, $d, $y, $h, $min, $s) = split m#[/:\s]+#, $_[0];
  $y = $y < 100 ? $y + 2000 : $y;
  time_pieces_epoch($y, $m, $d, $h, $min, $s);
}


BEGIN {
  *tep  = \&time_epoch_pieces;
  *tef  = \&time_epoch_formatted;
  *tpe  = \&time_pieces_epoch;
  *tsec = \&timezone_seconds;
  *ghl = \&gh_localtime;
  *gh6l = \&gh60_localtime;
  *dow = \&day_of_week;
  *hod = \&hour_of_day;
  *how = \&hour_of_week;
  *ym = \&year_month;
  *ymd = \&year_month_day;
  *ttw = \&truncate_to_week;
  *ttd = \&truncate_to_day;
  *tth = \&truncate_to_hour;
  *tt15 = \&truncate_to_quarter_hour;
  *ttm = \&truncate_to_minute;
  *i2e = \&iso_8601_epoch;
  *e2i = \&epoch_iso_8601;
  *tpi = \&time_parts_iso_8601;
  *usfe = \&mdy_epoch
}

250 core/pl/geohash.pl
# Fast, portable geohash encoder... AND MORE!
# A port of https://www.factual.com/blog/how-geohashes-work. 
# I'm assuming 64-bit int support.

no warnings 'portable';

our @geohash_alphabet = split //, '0123456789bcdefghjkmnpqrstuvwxyz';
our %geohash_decode   = map(($geohash_alphabet[$_], $_), 0..$#geohash_alphabet);

sub gh58($)
{
  my $gh30 = shift;
  $gh30 = ($gh30 & 0x3fff8000) << 9 | $gh30 & 0x7fff;
  $gh30      &   0x1f00001f
    | ($gh30 &  0x3e00003e0) << 3
    | ($gh30 & 0x7c00007c00) << 6;
}

sub gh85($)
{
  my $g = shift;
  $g = ($g &     0x1f00001f)
     | ($g &   0x1f00001f00) >> 3
     | ($g & 0x1f00001f0000) >> 6;
  ($g & 0x7fff000000) >> 9 | $g & 0x7fff;
}

sub geohash_binary_to_base32($$)
{
  my ($gh, $p) = @_;
  my $s;
  if ($p <= 20)
  {
    $s = pack "N", gh58 $gh << 20 - $p;
  }
  elsif ($p <= 40)
  {
    $gh <<= 40 - $p;
    my $w1 = gh58 $gh;
    my $w2 = gh58 $gh >> 30;
    $s = pack "N2", $w1 >> 32 & 0xffff | $w2 << 16 & 0xffff0000,
                    $w1 & 0xffffffff;
  }
  else
  {
    $gh <<= 60 - $p;
    my $w1 = gh58 $gh;
    my $w2 = gh58 $gh >> 30;
    $s = pack "N3", $w2 >> 16,
                    $w1 >> 32 & 0xffff | $w2 << 16 & 0xffff0000,
                    $w1 & 0xffffffff;
  }

  $s =~ y/\x00-\x1f/0123456789bcdefghjkmnpqrstuvwxyz/;
  substr $s, 0, int(($p + 4) / 5);
}

sub geohash_base32_to_binary($)
{
  (my $gh = lc shift) =~ y/0123456789bcdefghjkmnpqrstuvwxyz/\x00-\x1f/;
  my $bits = 5 * length $gh;

  if ($bits <= 20)
  {
    gh85(unpack "N", "$gh\0\0\0\0") >> 20 - $bits;
  }
  elsif ($bits <= 40)
  {
    my ($n1, $n2) = unpack "N2", "$gh\0\0\0\0";
    my $n = gh85($n1) << 20 | gh85($n2 || 0);
    $n >> 40 - $bits;
  }
  else
  {
    my ($n1, $n2, $n3) = unpack "N3", "$gh\0\0\0\0";
    my $n = gh85($n1) << 40 | gh85($n2 || 0) << 20 | gh85($n3 || 0);
    $n >> 60 - $bits;
  }
}

sub morton_gap($) {
  my ($x) = @_;
  $x |= $x << 16; $x &= 0x0000ffff0000ffff;
  $x |= $x << 8;  $x &= 0x00ff00ff00ff00ff;
  $x |= $x << 4;  $x &= 0x0f0f0f0f0f0f0f0f;
  $x |= $x << 2;  $x &= 0x3333333333333333;
  return ($x | $x << 1) & 0x5555555555555555;
}

sub morton_ungap($) {
  my ($x) = @_;  $x &= 0x5555555555555555;
  $x ^= $x >> 1; $x &= 0x3333333333333333;
  $x ^= $x >> 2; $x &= 0x0f0f0f0f0f0f0f0f;
  $x ^= $x >> 4; $x &= 0x00ff00ff00ff00ff;
  $x ^= $x >> 8; $x &= 0x0000ffff0000ffff;
  return ($x ^ $x >> 16) & 0x00000000ffffffff;
}

sub geohash_encode {
  my ($lat, $lng, $precision) = @_;
  $precision ||= 12;
  my $bits = $precision > 0 ? $precision * 5 : -$precision;
  my $gh   = (morton_gap(int(($lat +  90) / 180 * 0x40000000)) |
              morton_gap(int(($lng + 180) / 360 * 0x40000000)) << 1)
             >> 60 - $bits;

  $precision > 0 ? geohash_binary_to_base32 $gh, $bits : $gh;
}

sub geohash_tagged_precision {
  my $gh = 0x3fff_ffff_ffff_ffff & shift;
  my $bits = 0;
  for (my $b = 32; $b; $b >>= 1) {
    $bits |= $b if ($gh & ~(-1 << ($bits | $b))) != $gh;
  }
  $bits;
}

sub geohash_decode_tagged {
  my $gh = 0x3fff_ffff_ffff_ffff & shift;
  my $tag_bit_index = geohash_tagged_precision($gh);
  geohash_decode($gh & ~(-1 << $tag_bit_index), $tag_bit_index);
}

sub geohash_decode
{
  my ($gh, $bits) = @_;
  unless (defined $bits)
  {
    return geohash_decode_tagged($gh) if $gh =~ /^\d{19}/ && $gh & 1 << 62;
    $bits = 5 * length $gh;
    $gh   = geohash_base32_to_binary $gh;
  }
  $gh <<= 60 - $bits;
  return (morton_ungap($gh)      / 0x40000000 * 180 -  90,
          morton_ungap($gh >> 1) / 0x40000000 * 360 - 180);
}

sub to_radians {
  3.1415926535897943284626 * $_[0]/180.0;
}

our %earth_radius_in_units = ("km" => 6371,   "mi" => 3959, 
                              "m" =>  6371E3, "ft" => 3959 * 5280);

sub lat_lon_dist {
  my $units = @_ == 4 ? "km" : pop || "km";
  my ($lat1, $lon1, $lat2, $lon2) = @_;
  my $earth_radius = $earth_radius_in_units{$units};
  my $phi1 = to_radians $lat1;
  my $phi2 = to_radians $lat2;
  my $d_phi = $phi1 - $phi2;
  my $d_lambda = to_radians ($lon1 - $lon2);
  my $a = sin($d_phi/2)**2 + cos($phi1)*cos($phi2)*(sin($d_lambda/2)**2);
  my $c = 2 * atan2(sqrt($a), sqrt(1-$a));
  $earth_radius * $c
}

sub gh_dist_exact {
  my ($gh1, $gh2, $precision, $unit) = @_;
  $unit = $precision if exists $earth_radius_in_units{$precision}; 
  $precision = undef if exists $earth_radius_in_units{$precision};
  lat_lon_dist gll($gh1, $precision), gll($gh2, $precision), $unit;
}

sub geohash_box($;$) {
  my $gh = shift;
  my $northeast_corner = substr($gh . "z" x 12, 0, 12);
  my $southwest_corner = substr($gh . "0" x 12, 0, 12);
  my ($north, $east) = gll($northeast_corner);
  my ($south, $west) = gll($southwest_corner);
  ($north, $south, $east, $west);
}

sub geohash_cardinal_direction {
  my ($gh1, $gh2, $precision) = @_;
  my $n = ($gh2 & 0x5555_5555_5555_5555) > ($gh1 & 0x5555_5555_5555_5555);
  my $s = ($gh1 & 0x5555_5555_5555_5555) > ($gh2 & 0x5555_5555_5555_5555);
  my $e = ($gh2 & 0xaaaa_aaaa_aaaa_aaaa) > ($gh1 & 0xaaaa_aaaa_aaaa_aaaa);
  my $w = ($gh1 & 0xaaaa_aaaa_aaaa_aaaa) > ($gh2 & 0xaaaa_aaaa_aaaa_aaaa);
  $n - $s, $e - $w;
}

sub most_significant_even_bit_index {
  my $x = shift;
  my $index = 2;
  ($x & 0xffff_ffff_0000_0000) && ($index += 32) && ($x >>= 32);
  ($x & 0xffff_0000)           && ($index += 16) && ($x >>= 16);
  ($x & 0xff00)                && ($index += 8)  && ($x >>= 8 );
  ($x & 0xf0)                  && ($index += 4)  && ($x >>= 4 );
  ($x & 0xc)                   && ($index += 2);
  $index;
}


sub morton_generate($$) {
  my ($n_bits, $offset) = @_;
  map {morton_ungap $_ >> $offset} 0..(2**$n_bits - 1);
}

our $MORTON_PRECISION = 10;
our @morton_eastings  = morton_generate($MORTON_PRECISION, 0);
our @morton_northings = morton_generate($MORTON_PRECISION, 1);
our $latitude_meters  = $earth_radius_in_units{"m"} * to_radians(1);
our @longitude_meters = map {$latitude_meters * cos(to_radians($_ * 90/16))} 0..16; 
our @morton_longitude_lengths = map {$longitude_meters[abs $_ - 16] } @morton_northings;


sub gh_dist_approx {
  # Compute approximate distance along the earth
  # without branching, map, or inverse trig functions
  # BIT HACKS BIT HACKS BIT HACKS
#  printf "%s\n", join "\t", @morton_northings;
  my ($gh1, $gh2, $precision) = @_;
  my $diff = ($gh1 ^ $gh2) << (60 - $precision);
  # need to be in the same 10-bit geohash
  return gh_dist_exact(geohash_binary_to_base32($gh1, $precision),
                       geohash_binary_to_base32($gh2, $precision)) if $diff & 0x0ffc_0000_0000_0000;
  my $diff_msb_index = most_significant_even_bit_index $diff;
#  printf "%s: %d\n", "Most significant difference at position:", $diff_msb_index - $precision;
  my $ms_diff = $diff  >> max 0, $diff_msb_index - $MORTON_PRECISION;
#  printf "%s %d %b\n", "most significant gh diff @ position:", $diff_msb_index, $ms_diff;
  my $northing = $morton_northings[$ms_diff]; 
  my $easting  = $morton_eastings[$ms_diff];
#  print("Northing/Easting: $northing\t$easting\n");
  my $north_degrees = $northing * 180 * 2**(($diff_msb_index - $MORTON_PRECISION - 60)/2);
  my $east_degrees  = $easting  * 360 * 2**(($diff_msb_index - $MORTON_PRECISION - 60)/2);
#  print("North/East Degrees: $north_degrees\t$east_degrees\n");
  # longitude is a different length at different latitudes 
  my $longitude_meters = $morton_longitude_lengths[$gh1 >> ($precision - $MORTON_PRECISION)];

#  print("Longitude Length: $longitude_meters\n");
  my $dist = sqrt (($north_degrees * $latitude_meters)**2 + ($east_degrees * $longitude_meters)**2);
  $dist;
}



BEGIN
{
  *ghe = \&geohash_encode;
  *llg = \&geohash_encode;
  *ghd = \&geohash_decode;
  *gll = \&geohash_decode;
  *g3b = \&geohash_base32_to_binary;
  *gb3 = \&geohash_binary_to_base32;
  *ghb = \&geohash_box;
  *gh_dist_a = \&gh_dist_approx;
  *gh_dist = \&gh_dist_exact;
}
203 core/pl/pl.pl
# Perl parse element.
# A way to figure out where some Perl code ends, in most cases. This works
# because appending closing brackets to valid Perl code will always make it
# invalid. The same property holds across most code-to-code functions. This is
# how ni figures out whether a closing bracket is a lambda-terminator or a part
# of some row mapping code.

use POSIX ();

sub syntax_check($$) {
  my ($check_cmd, $code) = @_;
  my $fh = siproc {sh "$check_cmd >/dev/null 2>&1"};
  safewrite $fh, $code;
  close $fh;
  $fh->await;
}

# We need to explicitly disable any BEGIN{} blocks to avoid executing side
# effects. We can guarantee that nothing will run (beyond `use` statements, which
# we assume are safe) by removing any occurrences of the string `BEGIN` and
# replacing them with something syntactically equivalent but less volatile -- in
# this case, `END`.

BEGIN {
defparser 'plcode', '$', q{
  my ($self, $code, @xs) = @_;
  die <<EOF if $code =~ /\\\r?\n/;
ni: you have a trailing backslash in the perl code "$code", which perl will
    interpret as a reference operator and things will go horribly wrong. If,
    for some reason, you really do want a trailing backslash, you can bypass
    this error by putting a space or a comment after it.

    # this is why you're seeing this message (you don't want the backslash):
    p'foo \\\\
      bar'

    # this is the correct way to write it:
    p'foo
      bar'
EOF

  return $_[1], '', @_[2..$#_] unless $code =~ /\]$/;
  my $safecode      = $code;
  my $begin_warning = $safecode =~ s/BEGIN/ END /g;
  my $codegen       = $$self[1];
  my $status        = 0;
  my $x             = '';
  $x .= ']' while $status = syntax_check 'perl -c -', &$codegen($safecode)
                  and ($safecode =~ s/\]$//, $code =~ s/\]$//);

  die <<EOF if $status;
ni: failed to get closing bracket count for perl code "$code$x", possibly
    because BEGIN-block metaprogramming is disabled when ni tries to figure
    this out. To avoid this, make sure the shell argument containing your code
    ends with something that isn't a closing bracket; e.g:

    p'[[some code]]'            # this may fail due to bracket inference
    p'[[some code]] '           # this works by bypassing it
    [p'[some code] ' ]          # this works for ni lambdas
EOF

  ($code, $x, @xs);
};
}

# Perl wrapper.
# Defines the `p` operator, which can be modified in a few different ways to do
# different things. By default it functions as a one-in, many-out row
# transformer.

use constant perl_mapgen => gen q{
  package ni::pl;
  use strict;
  use warnings;
  %prefix
#line 1 "perl context dataclosures"
  %closures
#line 7 "perl_mapgen template"
  close STDIN;
  open STDIN, '<&=3' or die "ni: failed to open fd 3: $!";
  sub row {
    no strict;
#line 1 "perl code context"
    %body
  }
  while (defined rl) {
#line 1 "perl_mapgen each snippet"
    %each
  }
};

our @perl_prefix_keys = qw| core/pl/util.pm
                            core/pl/array.pm
                            core/pl/file.pm
                            core/pl/string.pm
                            core/pl/json.pm
                            core/pl/hadoop.pm
                            core/pl/hash.pm
                            core/pl/math.pm
                            core/pl/stream.pm
                            core/pl/wkt.pl
                            core/pl/geohash.pl
                            core/pl/time.pl
                            core/pl/url.pl
                            core/cell/murmurhash.pl
                            core/bloom/bloomfilter.pl
                            core/bloom/minhash.pl
                            core/gen/gen.pl
                            core/json/json.pl
                            core/pl/reducers.pm |;

defoperator perl_prefix => q{ sio; print join"\n", @ni::perl_prefix_keys };
defshort '///ni/perl_prefix' => pmap q{perl_prefix_op}, pnone;

sub defperlprefix($) {push @perl_prefix_keys, $_[0]}

sub perl_prefix() { join "\n", map "BEGIN{\n# line 1 \"//ni/$_\"\n$ni::self{$_}\n}",
                                   @perl_prefix_keys }

sub perl_quote($)    {pack u => $_[0]}
sub perl_closure($$) {"use constant $_[0] => unpack u => q|" . perl_quote($_[1]) . "|;"}
sub perl_closures()
{join "\n", map perl_closure($_, closure_data $_), closure_keys}

sub perl_expand_begin($) {sr $_[0], qr/^\^/, 'BEGIN'}

sub stdin_to_perl($) {
  eval {cdup2 0, 3; POSIX::close 0};
  die "ni: perl driver failed to move FD 0 to 3 ($!)\n"
    . "    this usually means you're running in a context with no STDIN"
  if $@;
  safewrite siproc {exec 'perl', '-'}, $_[0];
}

sub perl_code($$) {perl_mapgen->(prefix   => perl_prefix,
                                 closures => perl_closures,
                                 body     => $_[0],
                                 each     => $_[1])}

sub perl_mapper($)   {perl_code perl_expand_begin $_[0], 'CORE::ref $_ eq "ARRAY" ? r(@$_) : length && print $_, "\n" for row'}
sub perl_grepper($)  {perl_code perl_expand_begin $_[0], 'print $_, "\n" if row'}
sub perl_asserter($) {perl_code perl_expand_begin $_[0], q(
  print $_, "\n";
  unless (row) {
    sleep 1;
    die "\r\033[KASSERTION " . q#) . $_[0] . q(# . " FAILED at line $.: $_";
  }
)}

defoperator perl_mapper  => q{stdin_to_perl perl_mapper   $_[0]};
defoperator perl_grepper => q{stdin_to_perl perl_grepper  $_[0]};
defoperator perl_assert  => q{stdin_to_perl perl_asserter $_[0]};

defoperator perl_cell_transformer => q{
  my ($colspec, $code) = @_;
  my ($limit, @cols) = @$colspec;
  my $gen = gen q{
    for my $fi (%cols) {
      $_ = $F[$fi];
      $F[$fi] = row;
    }
    r @F;
  };
  stdin_to_perl perl_mapgen->(
    prefix   => perl_prefix,
    closures => perl_closures,
    body     => perl_expand_begin $code,
    each     => $gen->(cols => @cols ? join ',', @cols : '0..$#F'));
};

defmetaoperator perl_require => q{
  my ($args, $left, $right) = @_;
  (my $filename = json_encode $args) =~ s/[\\\"]//g;
  my $code_fh = sni @$args;
  my $code    = "BEGIN{\n#line 1 \"$filename\"\n" . join('', <$code_fh>) . "\n}";
  my $key     = "core/pl/require/" . gensym;
  self_append_resource $key, $code;
  self_append_resource "$key-prepend.pl",
    qq{ push \@ni::perl_prefix_keys, q{$key} };
  push @ni::perl_prefix_keys, $key;
  ($left, $right);
};

BEGIN {
  defparseralias perl_mapper_code         => plcode \&perl_mapper;
  defparseralias perl_grepper_code        => plcode \&perl_grepper;
  defparseralias perl_asserter_code       => plcode \&perl_asserter;
  defparseralias perl_cell_transform_code => plcode \&perl_mapper;      # [sic]
}

defshort '/p',
  defalt 'perlalt', 'alternatives for /p perl operator',
    pmap q{perl_mapper_op $_}, perl_mapper_code;

defshort '/pR', pmap q{perl_require_op @$_}, _qfn;

defrowalt pmap q{perl_grepper_op $_},
          pn 1, pstr 'p', perl_grepper_code;

defassertdsp 'p', pmap q{perl_assert_op $_}, perl_asserter_code;

defshort 'cell/p', pmap q{perl_cell_transformer_op @$_},
                   pseq colspec, perl_cell_transform_code;
15 core/pl/url.pl
# Credit to S. Vertigan from this post:
# http://code.activestate.com/recipes/577450-perl-url-encode-and-decode/#c6

sub url_encode($) {
  my ($rv) = @_;
  $rv =~ s/([^A-Za-z0-9])/sprintf("%%%2.2X", ord($1))/ge;
  return $rv;
}

sub url_decode($) {
  my ($rv) = @_;
  $rv =~ s/\+/ /g;
  $rv =~ s/%(..)/pack("c",hex($1))/ge;
  return $rv;
}
3 core/bloom/lib
bloomfilter.pl
minhash.pl
bloom.pl
92 core/bloom/bloomfilter.pl
# Bloom filter library.
# A simple pure-Perl implementation of Bloom filters.

eval {require Digest::MD5; Digest::MD5->import('md5')};

# Swiped from https://hur.st/bloomfilter
sub bloom_args($$) {
  my ($n, $p) = @_;
  my $m = int 1 + $n * -log($p) / log(2 ** log 2);
  my $k = int 0.5 + log(2) * $m / $n;
  ($m, $k);
}

sub bloom_new($$) {
  my ($m, $k) = @_;
  ($m, $k) = bloom_args($m, $k) if $k < 1;
  pack("QQ", $m, $k) . "\0" x ($m + 7 >> 3);
}

sub bloom_from_hex($) {
  pack 'H*', $_[0];
}

sub multihash($$) {
  my @hs;
  push @hs, unpack "QQ", md5($_[0] . scalar @hs) until @hs >= $_[1];
  @hs[0..$_[1]-1];
}

# Destructively adds an element to the filter and returns the filter.
sub bloom_add($$) {
  my ($m, $k) = unpack "QQ", $_[0];
  vec($_[0], $_ % $m + 128, 1) = 1 for multihash $_[1], $k;
  $_[0];
}

sub bloom_contains($$) {
  my ($m, $k) = unpack "QQ", $_[0];
  vec($_[0], $_ % $m + 128, 1) || return 0 for multihash $_[1], $k;
  1;
}

# Prehashing variants
# prehash($m, $k, $element) -> "prehash_string"
# bloom_add_prehashed($filter, "prehash_string")
sub bloom_prehash($$$) {
  my ($m, $k) = @_;
  join ",", map $_ % $m, multihash $_[2], $k;
}

sub bloom_add_prehashed($$) {
  vec($_[0], $_ + 128, 1) = 1 for split /,/, $_[1];
  $_[0];
}

sub bloom_contains_prehashed($$) {
  vec($_[0], $_ + 128, 1) || return 0 for split /,/, $_[1];
  1;
}

# Set operations
sub bloom_intersect {
  local $_;
  my ($n, $k, $filter) = unpack "QQa*", shift;
  for (@_) {
    my ($rn, $rk) = unpack "QQ", $_;
    die "cannot intersect two bloomfilters of differing parameters "
      . "($n, $k) vs ($rn, $rk)"
      unless $n == $rn && $k == $rk;
    $filter &= unpack "x16 a*", $_;
  }
  pack("QQ", $n, $k) . $filter;
}

sub bloom_union {
  local $_;
  my ($n, $k, $filter) = unpack "QQa*", shift;
  for (@_) {
    my ($rn, $rk) = unpack "QQ", $_;
    die "cannot union two bloomfilters of differing parameters "
      . "($n, $k) vs ($rn, $rk)"
      unless $n == $rn && $k == $rk;
    $filter |= unpack "x16 a*", $_;
  }
  pack("QQ", $n, $k) . $filter;
}

sub bloom_count($) {
  my ($m, $k, $bits) = unpack "QQ %64b*", $_[0];
  return -1 if $bits >= $m;     # overflow case (> if %32b runs past end maybe)
  $m * -log(1 - $bits/$m) / $k;
}
47 core/bloom/minhash.pl
# minhash sets
# These are mutable arrays of 32-bit slices of MD5s.

BEGIN {eval {require Digest::MD5}}

sub minhash_new($) { [map 0xffffffff, 1..$_[0]] }
sub minhash_add
{
  my $minhash = shift;
  if (@_ > 1)
  {
    my %m;
    ++$m{$_} for @$minhash, grep $_ < $$minhash[-1],
                            map unpack('N', Digest::MD5::md5($_)), @_;
    @$minhash = (sort {$a <=> $b} keys %m) [0..$#$minhash];
  }
  else
  {
    # Optimized single-add: don't allocate a hash
    my $h = unpack 'N', Digest::MD5::md5($_[0]);
    return $minhash if $h >= $$minhash[-1];
    $_ == $h and return $minhash for @$minhash;
    @$minhash = (sort {$a <=> $b} @$minhash, $h)[0..$#$minhash];
  }
  $minhash;
}

sub minhash_count($)
{
  my ($minhash) = @_;
  my $i = $#$minhash;
  --$i while $i && $$minhash[$i] == 0xffffffff;
  return -1 if $$minhash[$i] == 0;
  0xffffffff * ($i + 1) / $$minhash[$i];
}

sub minhash_union { [(sort {$a <=> $b} map @$_, @_)[0..$#{$_[0]}]] }
sub minhash_intersect
{
  my %m;
  for my $i (0..$#_) { $m{$_} |= 1 << $i for @{$_[$i]} }
  my $all = (1 << @_) - 1;
  my @i   = grep $m{$_} == $all, keys %m;
  return minhash_new @{$_[0]} unless @i;
  push @i, (0xffffffff) x (@{$_[0]} - @i) if @{$_[0]} > @i;
  [(sort {$a <=> $b} @i)[0..$#{$_[0]}]];
}
53 core/bloom/bloom.pl
# Bloom filter operators.
# Operators to construct and query bloom filters. The bloom constructor is a
# sub-operator of `z` (compress), and querying is done using `rb`.
#
# Notation is two digits: power of ten #elements, and power of ten
# false-positive probability. So `zB74` means "create a filter designed to
# store 10^7 (== 10M) elements with a 10^-4 likelihood of false positives."

BEGIN {
  defparseralias bloom_size_spec => pmap q{10 **  $_}, prx qr/\d(?:\.\d)?/;
  defparseralias bloom_fp_spec   => pmap q{10 ** -$_}, prx qr/\d(?:\.\d)?/;
}

defoperator bloomify => q{
  my ($n, $p) = @_;
  my $f = bloom_new $n, $p;
  chomp, bloom_add $f, $_ while <STDIN>;
  print $f;
};

defoperator bloomify_hex => q{
  my ($n, $p) = @_;
  my $f = bloom_new $n, $p;
  chomp, bloom_add $f, $_ while <STDIN>;
  print unpack("H*", $f), "\n";
};

defoperator bloomify_prehashed => q{
  my ($n, $p) = @_;
  my $f = bloom_new $n, $p;
  chomp, bloom_add_prehashed $f, $_ while <STDIN>;
  print $f;
};

defshort '/zB',  pmap q{bloomify_op @$_},           pseq bloom_size_spec, bloom_fp_spec;
defshort '/zBH', pmap q{bloomify_hex_op @$_},       pseq bloom_size_spec, bloom_fp_spec;
defshort '/zBP', pmap q{bloomify_prehashed_op @$_}, pseq bloom_size_spec, bloom_fp_spec;

defoperator bloom_rows => q{
  use bytes;
  my ($include_mode, $col, $bloom_lambda) = @_;
  my $bloom;
  my $r = sni @$bloom_lambda;
  1 while read $r, $bloom, 65536, length $bloom;
  $r->await;
  while (<STDIN>) {
    chomp(my @cols = split /\t/, $_, $col + 2);
    print if !$include_mode == !bloom_contains $bloom, $cols[$col];
  }
};

defrowalt pmap q{bloom_rows_op 1, @$_}, pn [1, 2], pstr 'b', pc colspec1, _qfn;
defrowalt pmap q{bloom_rows_op 0, @$_}, pn [1, 2], pstr '^b', pc colspec1, _qfn;
2 core/cell/lib
murmurhash.pl
cell.pl
28 core/cell/murmurhash.pl
# Pure-Perl MurmurHash3_32 implementation.
# This is used by some intification operators and based on the Wikipedia
# implementation. It's limited to 32 bits because otherwise ni will fail on 32-bit
# machines.

use constant murmur_c1 => 0xcc9e2d51;
use constant murmur_c2 => 0x1b873593;
use constant murmur_n  => 0xe6546b64;

sub murmurhash3($;$) {
  use integer;
  local $_;
  my $h = $_[1] || 0;

  for (unpack 'L*', $_[0]) {
    $_ *= murmur_c1;
    $h ^= ($_ << 15 | $_ >> 17 & 0x7fff) * murmur_c2 & 0xffffffff;
    $h  = ($h << 13 | $h >> 19 & 0x1fff) * 5 + murmur_n;
  }

  my ($r) = unpack 'V', substr($_[0], ~3 & length $_[0]) . "\0\0\0\0";
  $r *= murmur_c1;
  $h ^= ($r << 15 | $r >> 17 & 0x7fff) * murmur_c2 & 0xffffffff ^ length $_[0];
  $h &= 0xffffffff;
  $h  = ($h ^ $h >> 16) * 0x85ebca6b & 0xffffffff;
  $h  = ($h ^ $h >> 13) * 0xc2b2ae35 & 0xffffffff;
  return $h ^ $h >> 16;
}
251 core/cell/cell.pl
# Cell-level operators.
# Cell-specific transformations that are often much shorter than the equivalent
# Perl code. They're also optimized for performance.

defcontext 'cell', q{cell operator context};
defshort '/,', parser 'cell/qfn';

BEGIN {
  defparseralias cellspec       => pmap q{$_ || [1, 0]}, popt colspec;
  defparseralias cellspec_fixed => pmap q{$_ || [1, 0]}, popt colspec_fixed;
}

# Codegen.
# Most of these have exactly the same format and take a column spec.

use constant cell_op_gen => gen q{
  BEGIN {eval {require Digest::MD5; Digest::MD5->import(qw/md5 md5_hex/)}}
  my ($cs, %args) = @_;
  my ($floor, @cols) = @$cs;
  my $limit = $floor + 1;
  %begin;
  while (<STDIN>) {
    chomp;
    my @xs = split /\t/, $_, $limit;
    %each_line
    %each for @cols;
    print join("\t", @xs) . "\n";
  }
  %end
};

sub cell_eval($@) {
  my ($h, @args) = @_;
  fn(cell_op_gen->(%$h))->(@args);
}

# Intification.
# Strategies to turn each distinct entry into a number. Particularly useful in a
# plotting context.

defoperator intify_compact => q{
  cell_eval {args  => 'undef',
             begin => 'my %ids; my $n = 0',
             each  => '$xs[$_] = ($ids{$xs[$_]} ||= ++$n) - 1'}, @_;
};

defoperator intify_hash => q{
  cell_eval {args  => '$seed',
             begin => '$seed ||= 0',
             each  => '$xs[$_] = unpack "N", md5 $xs[$_] . $seed'}, @_;
};

defoperator real_hash => q{
  cell_eval {args  => '$seed',
             begin => '$seed ||= 0',
             each  => '$xs[$_] = unpack("N", md5 $xs[$_] . $seed) / (1<<32)'}, @_;
};

defoperator md5 => q{
  cell_eval {args  => 'undef',
             begin => '',
             each  => '$xs[$_] = md5_hex $xs[$_]'}, @_;
};

defshort 'cell/z', pmap q{intify_compact_op $_},  cellspec_fixed;
defshort 'cell/h', pmap q{intify_hash_op    @$_}, pseq cellspec_fixed, popt integer;
defshort 'cell/H', pmap q{real_hash_op      @$_}, pseq cellspec_fixed, popt integer;

defshort 'cell/m', pmap q{md5_op $_}, cellspec_fixed;

defoperator bloom_prehash => q{
  cell_eval {args  => '$m, $k',
             begin => '($m, $k) = bloom_args $m, $k',
             each  => '$xs[$_] = bloom_prehash $m, $k, $xs[$_]'}, @_;
};

defshort 'cell/BP', pmap q{bloom_prehash_op @$_},
  pseq cellspec_fixed, bloom_size_spec, bloom_fp_spec;

# Numerical transformations.
# Trivial stuff that applies to each cell individually.

BEGIN {
  defparseralias quant_spec  => pmap q{$_ || 1}, popt number;
  defparseralias log_base    => pmap q{$_ || exp 1}, popt number;
  defparseralias jitter_bias => pmap q{dor $_, 0}, popt number;
  defparseralias jitter_mag  => pmap q{$_ || 1},   palt pmap(q{0.9}, prx ','),
                                                        popt number;
}

defoperator cell_log => q{
  my ($cs, $base) = @_;
  my $lb = 1 / log $base;
  cell_eval {args => 'undef', each => "\$xs[\$_] = log(max 1e-16, \$xs[\$_]) * $lb"}, $cs;
};

defoperator cell_exp => q{
  my ($cs, $base) = @_;
  my $eb = log $base;
  cell_eval {args => 'undef', each => "\$xs[\$_] = exp $eb * \$xs[\$_]"}, $cs;
};

defshort 'cell/l', pmap q{cell_log_op @$_}, pseq cellspec_fixed, log_base;
defshort 'cell/e', pmap q{cell_exp_op @$_}, pseq cellspec_fixed, log_base;

# Log-progression that preserves sign of the values. Everything is shifted
# upwards by one in log-space, so signed_log(0) == log(1) == 0.
defoperator cell_signed_log => q{
  my ($cs, $base) = @_;
  my $lb = 1 / log $base;
  cell_eval {
    args => 'undef',
    each => "\$xs[\$_] = (\$xs[\$_] > 0 ? $lb : -$lb) * log(1 + abs \$xs[\$_])"}, $cs;
};

defshort 'cell/L', pmap q{cell_signed_log_op @$_}, pseq cellspec_fixed, log_base;

defoperator jitter_uniform => q{
  my ($cs, $mag, $bias) = @_;
  my $adjust = $bias - $mag / 2;
  cell_eval {args => 'undef', each => "\$xs[\$_] += rand() * $mag + $adjust"}, $cs;
};

defshort 'cell/j', pmap q{jitter_uniform_op @$_},
                   pseq cellspec_fixed, jitter_mag, jitter_bias;


defoperator quantize => q{
  my ($cs, $q) = @_;
  my $iq = 1 / $q;
  cell_eval {args => 'undef',
             each => "\$xs[\$_] = $q * int(0.5 + $iq * \$xs[\$_])"}, $cs;
};

defshort 'cell/q', pmap q{quantize_op @$_}, pseq cellspec_fixed, quant_spec;

# Cellular quantization (for visualization): quantize axes to cell centers, then
# uniformly jitter them by 0.9 * that amount. This will produce visually
# distinct but uniformly shaded cells.
defshort 'cell/Q',
  pmap q{ my ($cellspec, $quantum) = @$_;
          [quantize_op($cellspec, $quantum),
           jitter_uniform_op($cellspec, $quantum * 0.9)] },
  pseq cellspec_fixed, quant_spec;


# Random value attenuation (for visualization): attenuate by 1-rand()**n, where
# you can specify n. This results in values casting a shadow downwards.
BEGIN
{ defparseralias attenuate_spec => pmap q{$_ || 4}, popt number }

defoperator attenuate => q{
  my ($cs, $power) = @_;
  my $rand_code = $power == int $power
    ? join"*", ("rand()") x $power
    : "rand() ** $power";
  cell_eval {args => 'undef',
             each => "\$xs[\$_] *= (1 - $rand_code)"}, $cs;
};

defshort 'cell/A',
  pmap q{attenuate_op @$_},
  pseq cellspec_fixed, attenuate_spec;


# Streaming numeric transformations.
# Sum, delta, average, variance, entropy, etc. Arguably these are column operators and
# not cell operators, but in practice you tend to use them in the same context as
# things like log scaling.

defoperator col_sum => q{
  cell_eval {args  => 'undef',
             begin => 'my @ns = map 0, @cols',
             each  => '$xs[$_] = $ns[$_] += $xs[$_]'}, @_;
};

defoperator col_delta => q{
  cell_eval {args  => 'undef',
             begin => 'my @ns = map 0, @cols',
             each  => '$xs[$_] -= $ns[$_], $ns[$_] += $xs[$_]'}, @_;
};

defoperator col_average => q{
  cell_eval {args  => 'undef',
             begin => 'my @ns = map 0, @cols; $. = 0',
             each  => '$xs[$_] = ($ns[$_] += $xs[$_]) / $.'}, @_;
};

defshort 'cell/a', pmap q{col_average_op $_}, cellspec_fixed;
defshort 'cell/s', pmap q{col_sum_op     $_}, cellspec_fixed;
defshort 'cell/d', pmap q{col_delta_op   $_}, cellspec_fixed;


# Grouped sum/average.
# This is to save you the indignity of writing something like
# "p'r a, sum b_ rea'", which is a common and keystroke-heavy thing to do.
# Instead, you can write the much-suaver ",sgA": sum values grouped ending with
# column A (so the values are in col B). The same goes for averaging.
#
# We're overloading the syntax against "g", the geohash encoding operator,
# which you would never use immediately after a non-colspec ,s or ,a -- so this
# will never collide in practice.

defshort 'cell/ag', pmap
  q{
    my $col  = $_;
    my $fs   = "0..$col";
    my $se   = "se" . ("A".."Z")[$col];
    my $next = ("a".."z")[$col + 1];
    perl_mapper_op "
      my \@fs = F_($fs);
      my (\$t, \$n) = $se { (\$_[0] + $next, \$_[1] + 1) } 0, 0;
      r \@fs, \$t / (\$n || 1)";
  }, colspec1;

defshort 'cell/sg', pmap
  q{
    my $col  = $_;
    my $fs   = "0..$col";
    my $se   = "se" . ("A".."Z")[$col];
    my $next = ("a".."z")[$col + 1];
    perl_mapper_op "r F_($fs), $se { \$_[0] + $next } 0";
  }, colspec1;


# Time conversions.

defoperator epoch_to_formatted => q{
  cell_eval {args => 'undef',
             each => q{$xs[$_] = sprintf "%04d-%02d-%02dT%02d:%02d:%02dZ",
                                         time_epoch_pieces $xs[$_]}}, @_;
};

defshort 'cell/t', pmap q{epoch_to_formatted_op $_}, cellspec_fixed;

# Geohash conversions.
# These can be parameterized by a precision spec, which takes the same form as
# the one you normally use with `ghe` and `ghd`.

defoperator geohash_encode => q{
  cell_eval {args => '@precision',
             each => q{$xs[$_] = geohash_encode split(/,/, $xs[$_]), @precision}}, @_;
};

defoperator geohash_decode => q{
  cell_eval {args => '@precision',
             each => q{$xs[$_] = join",", geohash_decode $xs[$_], @precision}}, @_;
};

defshort 'cell/g', pmap q{geohash_encode_op @$_}, pseq cellspec_fixed, palt integer, pk 12;
defshort 'cell/G', pmap q{geohash_decode_op @$_}, pseq cellspec_fixed, popt integer;
1 core/c/lib
c.pl
39 core/c/c.pl
# C language interfacing
# This allows you to use C99 as a compilation target, rather than executing all
# operators in perl.

defconfenv cc      => 'CC',      'c99';
defconfenv cc_opts => 'CC_OPTS', '';

# exec_c99($c_source, @argv...) -> doesn't return
sub exec_c99
{
  local $SIG{CHLD} = 'DEFAULT';

  # First write a tempfile for the c99 compiler. It's important that we put
  # this into a directory that already exists, since all the program should do
  # is unlink itself as a binary.
  my $source_tmp = conf('tmpdir') . "/ni-$ENV{USER}-" . noise_str(16) . ".c";
  {
    open my $source, '>', $source_tmp or die "ni exec_c99: can't write source: $!";
    print $source shift;
    close $source;
  }

  my $compiler      = conf 'cc';
  my $compiler_opts = conf 'cc_opts';
  (my $binary = $source_tmp) =~ s/\.c$//;
  system "$compiler $compiler_opts -o '$binary' '$source_tmp' >/dev/null && rm -f '$source_tmp'"
     and die "ni exec_c99: failed to compile code";

  exec $binary, @_;
  die "ni exec_c99: failed to run compiled binary: $!";
}

# C RMI
# You can seamlessly call functions that are written in C. The function
# signature should refer to input/output data structs 
sub c_rmi
{
  # TODO
}
1 core/git/lib
git.pl
81 core/git/git.pl
# Git interop
# Allows you to use git repositories as data sources for ni

sub git_dir($) { -d "$_[0]/.git" ? "$_[0]/.git" : $_[0] }

# Main entry point: repo -> branches/tags
# git:///path/to/repo
defresource 'git',
  read => q{
    my $path = git_dir $_[1];
    (my $outpath = $path) =~ s/\/\.git$//;
    soproc {
      my $format = "--format=gitcommit://$outpath:%(refname)\t%(objectname)";
      sh shell_quote(git => "--git-dir=$path", "for-each-ref", $format)};
  };

# Commits: emit options
defresource 'gitcommit',
  read => q{
    my $pathref = $_[1];
    soproc {
      print join("\t", map "$_://$pathref",
                 qw/ gitcommitmeta githistory gitdiff gittree /), "\n";
    };
  };

defresource 'gitcommitmeta',
  read => q{
    my ($path, $ref) = $_[1] =~ /(.*):([^:]+)$/;
    $path = git_dir $path;
    soproc {sh shell_quote
      git => "--git-dir=$path", "cat-file", "commit", $ref};
  };

defresource 'githistory',
  read => q{
    my ($path, $ref) = $_[1] =~ /(.*):([^:]+)$/;
    $path = git_dir $path;
    (my $outpath = $path) =~ s/\/\.git$//;
    soproc {sh shell_quote
      git => "--git-dir=$path", "log",
             "--format=gitcommit://$outpath:%H\t%an\t%at\t%s", $ref};
  };

defresource 'gitdiff',
  read => q{
    my ($path, $refs) = $_[1] =~ /(.*):([^:]+)$/;
    my @refs          = split /\.\./, $refs, 2;
    $path = git_dir $path;
    if (@refs < 2)
    {
      my $parent_cmd = shell_quote git => "--git-dir=$path",
                         "show", "--format=%P", "-s", $refs[0];
      my @parents = grep length, split /\s+/, `$parent_cmd`;
      unshift @refs, $parents[0];
    }
    soproc {sh shell_quote git => "--git-dir=$path", "diff", @refs};
  };

# Tree/blob objects: behave just like directories/files normally
defresource 'gittree',
  read => q{
    my ($path, $ref) = $_[1] =~ /(.*):([^:]+)$/;
    $path = git_dir $path;
    (my $outpath = $path) =~ s/\/\.git$//;
    soproc {
      for (`git --git-dir='$path' ls-tree '$ref'`)
      {
        chomp(my ($mode, $type, $id, $name) = split /\h/, $_, 4);
        print "git$type://$outpath:$id\t$mode\t$name\n";
      }
    };
  };

defresource 'gitblob',
  read => q{
    my ($path, $ref) = $_[1] =~ /(.*):([^:]+)$/;
    $path = git_dir $path;
    (my $outpath = $path) =~ s/\/\.git$//;
    soproc {sh shell_quote git => "--git-dir=$path", 'cat-file', 'blob', $ref};
  };
4 core/archive/lib
zip.pl
7z.pl
tar.pl
xlsx.pl
30 core/archive/zip.pl
# Zip archive support (requires the "unzip" command-line tool)

sub zip_listing_fh($)
{
  my $f = shift;
  soproc { sh shell_quote(unzip => '-l', '-qq', $f)
            . " | cut -c31- " };
}

sub zip_file_fh($$)
{
  my ($zipf, $entry) = @_;
  soproc { sh shell_quote(unzip => '-p', $zipf, $entry) };
}

# Zip file listing: zip:///path/to/zipfile
defresource 'zip',
  read => q{
    my $filename = $_[1];
    soproc {
      my $fh = zip_listing_fh $filename;
      print "zipentry://$filename:$_" while <$fh> };
  };

# Single-entry unpacking: zipentry:///path/to/file.zip:subfilename
defresource 'zipentry',
  read => q{
    my ($zipfile, $fname) = split /:/, $_[1], 2;
    zip_file_fh $zipfile, $fname;
  };
40 core/archive/7z.pl
# 7zip archive support (requires the "7z" tool or one of its variants)

sub which_7zip()
{
    !system("7z > /dev/null")  ? '7z'
  : !system("7za > /dev/null") ? '7za'
  : !system("7zr > /dev/null") ? '7zr'
  : 'p7zip';
}

sub sevenzip_listing_fh($)
{
  my $f = shift;
  soproc { sh shell_quote(which_7zip, 'l', '-slt', $f)
                . " | grep '^Path = '"
                . " | tail -n+2"
                . " | cut -c8-" };
}

sub sevenzip_file_fh($$)
{
  my ($f, $entry) = @_;
  soproc { sh shell_quote(which_7zip, 'x', '-so', $f, $entry) };
}

# 7z file listing: 7z:///path/to/7zfile
defresource '7z',
  read => q{
    my $filename = $_[1];
    soproc {
      my $fh = sevenzip_listing_fh $filename;
      print "7zentry://$filename:$_" while <$fh> };
  };

# Single-entry unpacking: 7zentry:///path/to/file.7z:subfilename
defresource '7zentry',
  read => q{
    my ($zipfile, $fname) = split /:/, $_[1], 2;
    sevenzip_file_fh $zipfile, $fname;
  };
36 core/archive/tar.pl
# tar unpacking (file version)
# These functions auto-decompress using sdecode, so you won't need to worry
# about knowing which algorithm was used. You also get automatic speedups from
# things like pbzip2 if they're installed.

sub tar_listing_fh($)
{
  my $tarfile = shift;
  soproc {
    sforward soproc {scat($tarfile)},
             siproc {sh shell_quote(tar => '-t')} };
}

sub tar_file_fh($$)
{
  my ($tarfile, $entry) = @_;
  soproc {
    sforward soproc {scat($tarfile)},
             siproc {sh shell_quote(tar => '-x', '-O', $entry)} };
}

# Entry point: tar:///path/to/tarfile.tar
defresource 'tar',
  read => q{
    my $tarfile = $_[1];
    soproc {
      my $fh = tar_listing_fh $tarfile;
      print "tarentry://$tarfile:$_" while <$fh> };
  };

# Single-file extraction: tarentry:///path/to/tarfile.tar:filename
defresource 'tarentry',
  read => q{
    my ($tarfile, $entry) = split /:/, $_[1], 2;
    tar_file_fh $tarfile, $entry;
  };
69 core/archive/xlsx.pl
# xlsx parsing
# This backs into the zip archive handler, adding some shorthands for working
# with xlsx worksheets.
#
# NB: this is a good resource: https://stackoverflow.com/questions/18334314/what-do-excel-xml-cell-attribute-values-mean

# List all worksheets: xlsx:///path/to/file.xlsx
defresource 'xlsx',
  read => q{
    my $file = $_[1];
    soproc {
      my $fh = zip_listing_fh $file;
      /^xl\/worksheets\/sheet(\d+)\.xml/ && print "xlsxsheet://$file:$1\n"
        while <$fh> };
  };

sub worksheet_col_to_offset($)
{
  # Takes a column ID like "AZ" and converts it to the zero-based offset it
  # represents; that is, the offset of A = 0.
  my $i = 0;
  $i = $i * 26 + (1 + ord() - ord"A") for split //, shift;
  $i - 1;
}

sub workbook_shared_strings($)
{
  # Takes a workbook filename and returns an array of shared strings. This will
  # fail if any strings are multiline (TODO)
  my $fh = zip_file_fh shift, "xl/sharedStrings.xml";
  my @r;
  /<t>(.*)<\/t>/ and push @r, $1 while <$fh>;
  @r;
}

# Decode a worksheet: xlsxsheet:///path/to/file.xlsx:<sheet-number>
defresource 'xlsxsheet',
  read => q{
    my ($file, $sheet_id) = split /:/, $_[1], 2;
    soproc {
      my $fh = zip_file_fh $file, "xl/worksheets/sheet$sheet_id.xml";
      my @ss = workbook_shared_strings $file;
      my @row;
      my $i;                  # next col index to assign
      my $is_shared = 0;      # true if <v> node is a shared string index
      while (<$fh>)
      {
        chomp;
        if (/<\/row>/)
        {
          print join("\t", @row), "\n";
          @row = ();
        }

        if (/<c /)
        {
          # We need to know the data type of the cell. If it's a shared string,
          # type it as such so we know how to interpret the <v> node.
          $i         = worksheet_col_to_offset $1 if /r="([A-Z]+)/;
          $is_shared = /t="s"/;
        }

        if (/<[vt]>([^<]+)<\/[vt]>/)
        {
          push @row, "" until $#row >= $i;
          $row[$i] = $is_shared ? $ss[$1] : $1;
        }
      } };
  };
2 core/rb/lib
prefix.rb
rb.pl
96 core/rb/prefix.rb
# ni ruby driver prefix
# This is loaded prior to the short codegen segment in rb.pl.sdoc.

$have_json = true
begin
  require 'json'
rescue ScriptError
  $have_json = false
end

# Portability stuff.
# Old versions of Ruby have "a"[0] == 97, new versions have "a"[0] == "a". This
# makes it always safe to say "a"[0].ord.
class Numeric
  def ord; self; end
end

# Add to_proc conversion to symbols, which makes it possible to write
# map(&:foo).
class Symbol
  def to_proc
    x = self
    proc {|v| v.send(x)}
  end
end

class Line
  attr_reader :fields

  def initialize s
    @fields = s.split /\t/
  end

  def [] *x
    fields[*x]
  end

  def to_s
    fields.join "\t"
  end
end

# Some metaprogramming to get letter accessors
Line.class_eval do
  ('a'..'q').each do |l|
    index = l[0].ord - 97
    define_method    l   .to_sym, proc {fields[index]}
    define_method "#{l}s".to_sym, proc {fields[index].to_s}
    define_method "#{l}i".to_sym, proc {fields[index].to_i}
    define_method "#{l}f".to_sym, proc {fields[index].to_f}
  end
end

Enumerable.class_eval do
  ('a'..'q').each do |l|
    index = l[0].ord - 97
    define_method    l   .to_sym, proc {map {|x| x.fields[index]}}
    define_method "#{l}s".to_sym, proc {map {|x| fields[index].to_s}}
    define_method "#{l}i".to_sym, proc {map {|x| fields[index].to_i}}
    define_method "#{l}f".to_sym, proc {map {|x| fields[index].to_f}}
  end
end

def r *xs
  xs.join("\t")
end

# Readahead support
$q = []
$l = nil

def next_line
  return $q.shift unless $q.empty?
  Line.new($in.readline.chomp!) rescue nil
end

def rw
  r = [$l]
  l = nil
  r << l while l = next_line and yield l
  $q << l if l
  r
end

def ru
  r = [$l]
  l = nil
  r << l until !(l = next_line) or yield l
  $q << l if l
  r
end

def re &f
  v = f.call $l
  rw {|l| f.call(l) == v}
end
75 core/rb/rb.pl
# Ruby code element.
# This works just like the Perl code parser but is slightly less involved because
# there's no `BEGIN/END` substitution. We also don't need to take a code
# transform because no amount of wrapping will change whether an expression can
# be parsed.

use POSIX ();

BEGIN {
defparser 'rbcode', '', q{
  return $_[1], '', @_[2..$#_] unless $_[1] =~ /\]$/;
  my ($self, $code, @xs) = @_;
  my ($x, $status) = ('', 0);
  $x .= ']' while $status = syntax_check 'ruby -c -', $code and $code =~ s/\]$//;
  die <<EOF if $status;
ni: failed to get closing bracket count for ruby code "$code$x"; this means
    your code has a syntax error.
EOF
  ($code, $x, @xs);
};
}

# Ruby wrapper.

use constant ruby_mapgen => gen q{
  %prefix
  STDIN.close
  $in = IO.new(3)
  class Line
    def row
      %body
    end
  end

  def map_mode! x
    if x.is_a? Enumerable
      x.each do |v|
        v = r *v if v.is_a? Enumerable
        puts v
      end
    elsif !x.nil?
      puts x
    end
  end

  while $l = next_line
    x = $l.row
    %each
  end
  exit 0
};

use constant ruby_prefix => join "\n", @ni::self{qw| core/rb/prefix.rb |};

sub stdin_to_ruby($) {
  cdup2 0, 3;
  POSIX::close 0;
  safewrite siproc {exec 'ruby', '-'}, $_[0];
}

sub ruby_code($$) {ruby_mapgen->(prefix => ruby_prefix,
                                 body   => $_[0],
                                 each   => $_[1])}

sub ruby_mapper($)  {ruby_code $_[0], 'map_mode! x'}
sub ruby_grepper($) {ruby_code $_[0], 'puts $l if x'}

defoperator ruby_mapper  => q{stdin_to_ruby ruby_mapper  $_[0]};
defoperator ruby_grepper => q{stdin_to_ruby ruby_grepper $_[0]};

defshort '/m',
  defalt 'rubyalt', 'alternatives for the /m ruby operator',
    pmap q{ruby_mapper_op $_}, rbcode;

defrowalt pmap q{ruby_grepper_op $_}, pn 1, pstr 'm', rbcode;
2 core/lisp/lib
prefix.lisp
lisp.pl
166 core/lisp/prefix.lisp
;;;;;;;;
;; NB: don't delete the line of semicolons above; SBCL throws away the first few
;; bytes on CentOS.
(declaim (optimize (speed 3) (safety 0)))
(setf *read-default-float-format* 'double-float)

;;; utility functions from wu-sugar

(defun str (&rest values)
  (with-output-to-string (s)
    (dolist (val values)
      (princ val s))))

(defun join (separator &rest strings)
  "Concatenates STRINGS, joining them by SEPARATOR."
  (when (characterp separator)
    (setf separator (string separator)))
  (if strings
      (reduce (lambda (a b) (str a separator b)) strings)
      ""))

(defun split (string &rest delimiter-chars)
  "Splits STRING by one or more delimiter characters, returning a list."
  (let ((current-pos 0)
	result)
    (loop
       (push (subseq string 
		     current-pos 
		     (setf current-pos (position-if (lambda (c) (member c delimiter-chars)) 
						    string 
						    :start current-pos)))
	     result)
       (unless current-pos (return))
       (incf current-pos))
    (nreverse result)))

(defun starts-with-p (seq subseq)
  (let ((subseq-len (length subseq))) 
    (if (<= subseq-len (length seq)) 
	(search subseq seq :end2 subseq-len)
	nil)))

(defun ends-with-p (seq subseq)
  (let ((seq-len (length seq))
	(subseq-len (length subseq))) 
    (if (<= (length subseq) (length seq)) 
	(search subseq seq :from-end t :start2 (- seq-len subseq-len))
	nil)))

(defun partial (function &rest args)
  (lambda (&rest more-args)
    (apply function (append args more-args))))


(defvar *l*)
(defvar *cols*)

(defun read-col (text)
  (when text
    (let* ((*read-eval* nil)
           (r (read-from-string text)))
      (etypecase r
        (symbol text)
        (number r)))))

(defun %r (&rest values)
  (apply #'join #\Tab values))

(defmacro r (&rest values)
  `(multiple-value-call #'%r ,@values))

(defvar *line-q* (make-array 10 :adjustable t :fill-pointer 0))

(declaim (inline next-line))
(defun next-line ()
  (or (when (plusp (length *line-q*))
        (vector-pop *line-q*))
      (read-line *standard-input* nil)))

(defun %sr (&rest reducefn_inputfn_current)
  (loop for l = (next-line) while l do
       (let ((*cols* (split l #\Tab)))
         (loop for (reducefn inputfn current) in reducefn_inputfn_current
              for ric in reducefn_inputfn_current do
              (setf (third ric)
                    (funcall reducefn current (funcall inputfn))))))
  (apply #'values (mapcar #'third reducefn_inputfn_current)))

(defmacro sr (&rest reducer_input_initial)
  `(let* ((bindings (list ,@(loop for (reducer input initial) in reducer_input_initial append
                                 (list reducer `(lambda () ,input) initial))))
          (fixed-bindings (loop for (reducefn inputfn initial) on bindings by #'cdddr collect
                               (list reducefn inputfn (if initial                                                          
                                                          (funcall reducefn initial (funcall inputfn))
                                                          (funcall inputfn))))))
     (apply #'%sr fixed-bindings)))

(defun %se (reducefn inputfn continuefn current)
  (loop for l = (next-line) while l do
       (let ((*cols* (split l #\Tab)))
         (if (funcall continuefn)
             (setf current (funcall reducefn current (funcall inputfn)))
             (progn
               (vector-push-extend l *line-q*)
               (return)))))
  current)

(defmacro se (reducer input partition &optional (initial nil initial-supplied-p))
  `(let* ((inputfn (lambda () ,input))
          (partfn (lambda () ,partition))
          (first-partfn-result (funcall partfn))
          (continuefn (lambda () (equal first-partfn-result (funcall partfn))))
          (reducefn ,reducer))
     (%se reducefn inputfn continuefn ,(if initial-supplied-p               
                                          `(funcall reducefn ,initial (funcall inputfn))
                                          `(funcall inputfn)))))

(defun %rw (continue-fn)
  (let ((result (list *l*)))
    (loop for *l* = (next-line) while *l* do
         (let ((*cols* (split *l* #\Tab)))
           (if (funcall continue-fn)
               (push *l* result)
               (progn
                 (vector-push-extend *l* *line-q*)
                 (return)))))
    (apply #'values (nreverse result))))

(defmacro rw (condition)
  `(let ((continue-fn (lambda () ,condition)))
     (%rw continue-fn)))

(defmacro ru (condition)
  `(let ((continue-fn (lambda () (not ,condition))))
     (%rw continue-fn)))

;; TODO: convert row strings to numbers
;; (defun %mean (&rest values)
;;   (/ (apply #'+ values)
;;      (length values)))

;; (defmacro mean (form)
;;   `(multiple-value-call #'%mean ,form))

(defun output-rows (&rest rows)
  (dolist (row rows)
    (princ row)
    (terpri)))

(defmacro with-ni-env (filter-p &body body)
  (let ((l-var '*l* ;;(gensym "L")
         ))
    `(let ((*standard-input* (sb-sys:make-fd-stream 3)))
       (symbol-macrolet ,(loop for colname in '(a b c d e f g h i j k l m n o p q)
                            for index from 0
                            collect (list colname `(read-col (nth ,index *cols*))))     
         (loop for ,l-var = (next-line) while ,l-var do
              (let ((*cols* (split ,l-var #\Tab)))
                ,(if filter-p
                     `(when (progn ,@body)
                        (write-string ,l-var)
                        (terpri))
                     `(progn
                        ,@(loop for form in body collect
                               `(multiple-value-call #'output-rows ,form)
                        )))))))))
53 core/lisp/lisp.pl
# Lisp backend.
# A super simple SBCL operator. The first thing we want to do is to define the
# code template that we send to Lisp via stdin (using a heredoc). So ni ends up
# generating a pipeline element like this:

# | ... | sbcl --noinform --script 3<&0 <<'EOF' | ...
#         (prefix lisp code)
#         (line mapping code)
#         EOF

use POSIX ();

use constant lisp_mapgen => gen q{
  %prefix
  (with-ni-env nil
    %body)
};

use constant lisp_grepgen => gen q{
  %prefix
  (with-ni-env t
    %body)
};

# Now we specify which files get loaded into the prefix. File paths become keys
# in the %self hash.

sub lisp_prefix() {join "\n", @ni::self{qw| core/lisp/prefix.lisp |}}

# Finally we define the toplevel operator. 'root' is the operator context, 'L' is
# the operator name, and pmap {...} mrc '...' is the parsing expression that
# consumes the operator's arguments (in this case a single argument of just some
# Lisp code) and returns a shell command. (See src/sh.pl.sdoc for details about
# how shell commands are represented.)

BEGIN {defparseralias lispcode => prc '.*[^]]+'}

defoperator lisp_code => q{
  my ($code) = @_;
  cdup2 0, 3;
  POSIX::close 0;
  safewrite siproc {exec qw| sbcl --noinform --noprint --eval |,
                         '(load *standard-input* :verbose nil :print nil)'},
            $code;
};

defshort '/l', pmap q{lisp_code_op lisp_mapgen->(prefix => lisp_prefix,
                                                 body   => $_)},
               lispcode;

defrowalt pmap q{lisp_code_op lisp_grepgen->(prefix => lisp_prefix,
                                             body   => $_)},
          pn 1, pstr 'l', lispcode;
1 core/sql/lib
sql.pl
129 core/sql/sql.pl
# SQL parsing context.
# Translates ni CLI grammar to a SELECT query. This is a little interesting
# because SQL has a weird structure to it; to help with this I've also got a
# 'sqlgen' abstraction that figures out when we need to drop into a subquery.

sub sqlgen($) {bless {from => $_[0]}, 'ni::sqlgen'}

sub ni::sqlgen::render {
  local $_;
  my ($self) = @_;
  return $$self{from} if 1 == keys %$self;

  my $select = ni::dor $$self{select}, '*';
  my @others;

  for (qw/from where order_by group_by limit union intersect except
          inner_join left_join right_join full_join natural_join/) {
    next unless exists $$self{$_};
    (my $k = $_) =~ y/a-z_/A-Z /;
    push @others, "$k $$self{$_}";
  }

  ni::gen('SELECT %distinct %stuff %others')
       ->(stuff    => $select,
          distinct => $$self{uniq} ? 'DISTINCT' : '',
          others   => join ' ', @others);
}

sub ni::sqlgen::modify_where {join ' AND ', @_}

sub ni::sqlgen::modify {
  my ($self, %kvs) = @_;
  while (my ($k, $v) = each %kvs) {
    if (exists $$self{$k}) {
      if (exists ${'ni::sqlgen::'}{"modify_$k"}) {
        $v = &{"ni::sqlgen::modify_$k"}($$self{$k}, $v);
      } else {
        $self = ni::sqlgen "($self->render)";
      }
    }
    $$self{$k} = $v;
  }
  $self;
}

sub ni::sqlgen::map        {$_[0]->modify(select => $_[1])}
sub ni::sqlgen::filter     {$_[0]->modify(where =>  $_[1])}
sub ni::sqlgen::take       {$_[0]->modify(limit =>  $_[1])}
sub ni::sqlgen::sample     {$_[0]->modify(where =>  "random() < $_[1]")}

sub ni::sqlgen::ijoin      {$_[0]->modify(join => 1, inner_join   => $_[1])}
sub ni::sqlgen::ljoin      {$_[0]->modify(join => 1, left_join    => $_[1])}
sub ni::sqlgen::rjoin      {$_[0]->modify(join => 1, right_join   => $_[1])}
sub ni::sqlgen::njoin      {$_[0]->modify(join => 1, natural_join => $_[1])}

sub ni::sqlgen::order_by   {$_[0]->modify(order_by => $_[1])}

sub ni::sqlgen::uniq       {${$_[0]}{uniq} = 1; $_[0]}

sub ni::sqlgen::union      {$_[0]->modify(setop => 1, union     => $_[1])}
sub ni::sqlgen::intersect  {$_[0]->modify(setop => 1, intersect => $_[1])}
sub ni::sqlgen::difference {$_[0]->modify(setop => 1, except    => $_[1])}

# SQL code parse element.
# Counts brackets outside quoted strings.

BEGIN {defparseralias sqlcode => generic_code}

# Code compilation.
# Parser elements can generate one of two things: [method, @args] or
# {%modifications}. Compiling code is just starting with a SQL context and
# left-reducing method calls.

sub sql_compile {
  local $_;
  my ($g, @ms) = @_;
  for (@ms) {
    if (ref($_) eq 'ARRAY') {
      my ($m, @args) = @$_;
      $g = $g->$m(@args);
    } else {
      $g = $g->modify(%$_);
    }
  }
  $g->render;
}

# SQL operator mapping.
# For the most part we model SQL operations the same way that we address Spark
# RDDs, though the mnemonics are a mix of ni and SQL abbreviations.

BEGIN {defcontext 'sql', q{SQL generator context}}
BEGIN {defparseralias sql_table => pmap q{sqlgen $_}, prc '^[^][]*'}
BEGIN {defparseralias sql_query => pmap q{sql_compile $$_[0], @{$$_[1]}},
                                   pseq sql_table, popt parser 'sql/qfn'}

defshort 'sql/m', pmap q{['map', $_]}, sqlcode;
defshort 'sql/u', pk ['uniq'];

defshort 'sql/r',
  defalt 'sqlrowalt', 'alternatives for sql/r row operator',
    pmap(q{['take',   $_]}, integer),
    pmap(q{['filter', $_]}, sqlcode);

defshort 'sql/j',
  defalt 'sqljoinalt', 'alternatives for sql/j join operator',
    pmap(q{['ljoin', $_]}, pn 1, pstr 'L', sql_query),
    pmap(q{['rjoin', $_]}, pn 1, pstr 'R', sql_query),
    pmap(q{['njoin', $_]}, pn 1, pstr 'N', sql_query),
    pmap(q{['ijoin', $_]}, sql_query);

defshort 'sql/g', pmap q{['order_by', $_]},        sqlcode;
defshort 'sql/o', pmap q{['order_by', "$_ ASC"]},  sqlcode;
defshort 'sql/O', pmap q{['order_by', "$_ DESC"]}, sqlcode;

defshort 'sql/+', pmap q{['union',      $_]}, sql_query;
defshort 'sql/*', pmap q{['intersect',  $_]}, sql_query;
defshort 'sql/-', pmap q{['difference', $_]}, sql_query;

# Global operator.
# SQL stuff is accessed using Q, which delegates to a sub-parser that handles
# configuration/connections. The dev/compile delegate is provided so you can see
# the SQL code being generated.

defoperator sql_preview => q{sio; print "$_[0]\n"};

defshort '/Q',
  defdsp 'sqlprofile', 'dispatch for SQL profiles',
    'dev/compile' => pmap q{sql_preview_op($_[0])}, sql_query;
1 core/python/lib
python.pl
41 core/python/python.pl
# Python stuff.
# A context for processing stuff in Python, as well as various functions to
# handle the peculiarities of Python code.

# Indentation fixing.
# This is useful in any context where code is artificially indented, e.g. when
# you've got a multiline quotation and the first line appears outdented because
# the quote opener has taken up space:

# | my $python_code = q{import numpy as np
#                       print np};
#   # -----------------| <- this indentation is misleading

# In this case, we want to have the second line indented at zero, not at the
# apparent indentation. The pydent function does this transformation for you, and
# correctly handles Python block constructs:

# | my $python_code = pydent q{if True:
#                                print "well that's good"};

sub pydent($) {
  my @lines   = split /\n/, $_[0];
  my @indents = map length(sr $_, qr/\S.*$/, ''), @lines;
  my $indent  = @lines > 1 ? $indents[1] - $indents[0] : 0;

  $indent = min $indent - 1, @indents[2..$#indents]
    if $lines[0] =~ /:\s*(#.*)?$/ && @lines >= 2;

  my $spaces = ' ' x $indent;
  $lines[$_] =~ s/^$spaces// for 1..$#lines;
  join "\n", @lines;
}

sub pyquote($) {"'" . sgr(sgr($_[0], qr/\\/, '\\\\'), qr/'/, '\\\'') . "'"}

# Python code parse element.
# Counts brackets, excluding those inside quoted strings. This is more efficient
# and less accurate than Ruby/Perl, but the upside is that errors are not
# particularly common.

defparseralias pycode => pmap q{pydent $_}, generic_code;
4 core/binary/lib
bytestream.pm
bytewriter.pm
search.pm
binary.pl
29 core/binary/bytestream.pm
# Binary byte stream driver.
# Functions that read data in blocks. The lookahead is 8192 bytes by default, but
# you can peek further using the 'pb' function.

our $stdin_ok = 1;
our $offset = 0;
our $binary = '';

sub bi() {$offset}

sub pb($) {
  use bytes;
  $stdin_ok &&= sysread STDIN, $binary, $_[0], length $binary
    while $stdin_ok && length($binary) < $_[0];
  substr $binary, 0, $_[0];
}

sub available() {length pb 1}

# TODO: optimize
sub rb($) {
  use bytes;
  my $r = pb $_[0];
  $binary = substr $binary, $_[0];
  $offset += $_[0];
  $r;
}

sub rp($) {unpack $_[0], rb length pack $_[0], unpack $_[0], $binary}
7 core/binary/bytewriter.pm
# Byte writer.
# Convenience functions that make it easier to write binary data to standard out.
# This library gets added to the perl prefix, so these functions are available in
# perl mappers.

sub ws($)  {print $_[0]; ()}
sub wp($@) {ws pack $_[0], @_[1..$#_]}
34 core/binary/search.pm
# Binary searching functions, esp for packed values
#
# These functions are useful when you don't have space for a hashtable but want
# associative lookups anyway.

# bsf(packed-string, unpack-template, reclength, target-value) -> recindex
sub bsf
{
  my $packed = \shift;
  my ($unpacker, $reclength, $target) = @_;
  my $upper = length($$packed) / $reclength;
  die "bsf: total length " . length($$packed) . " isn't evenly divided "
    . "by record length $reclength" unless $upper == int $upper;

  for (my ($lower, $mid) = (0, 0);
       $mid = $upper + $lower >> 1, $upper > 1 + $lower;)
  {
    my $midval = unpack $unpacker,
                 substr $$packed, $mid * $reclength, $reclength;
    return $mid   if $target == $midval;
    $upper = $mid if $target <  $midval;
    $lower = $mid if $target >  $midval;
  }
  $upper - 1;
}

# bsflookup(packed, unpacker, reclength, target, valunpacker) -> val...
sub bsflookup
{
  my $index = bsf @_[0..3];
  my $record = substr $_[0], $index * $_[2], $_[2];
  my $key    = unpack $_[1], $record;
  $key == $_[3] ? unpack $_[4], $record : undef;
}
53 core/binary/binary.pl
# Binary import operator.
# An operator that reads data in terms of bytes rather than lines. This is done
# in a Perl context with functions that manage a queue of data in `$_`.

use constant binary_perlgen => gen q{
  %prefix
  close STDIN;
  open STDIN, '<&=3';
  while (available) {
    %body
  }
};

defperlprefix 'core/binary/bytewriter.pm';
defperlprefix 'core/binary/search.pm';

our @binary_perl_prefix_keys = qw| core/binary/bytestream.pm |;

sub binary_perl_prefix() {join "\n", perl_prefix,
                                     @ni::self{@binary_perl_prefix_keys}}

sub defbinaryperlprefix($) {push @binary_perl_prefix_keys, $_[0]}

sub binary_perl_mapper($) {binary_perlgen->(prefix => binary_perl_prefix,
                                            body   => perl_expand_begin $_[0])}

defoperator binary_perl => q{stdin_to_perl binary_perl_mapper $_[0]};

defoperator binary_fixed => q{
  use bytes;
  my ($pack_template) = @_;
  my $length = length pack $pack_template, unpack $pack_template, "\0" x 65536;
  die "ni: binary_fixed template consumes no data" unless $length;
  my $bufsize = $length;
  $bufsize <<= 1 until $bufsize >= 65536;
  my $buf = '';
  while (1)
  {
    read STDIN, $buf, $bufsize - length($buf), length($buf) or return
      until length($buf) >= $length;
    my $o = 0;
    for (; $o + $length <= length($buf); $o += $length)
    {
      print join("\t", unpack $pack_template, substr $buf, $o, $length), "\n";
    }
    $buf = substr $buf, $o;
  }
};

defshort '/b',
  defdsp 'binaryalt', 'dispatch table for the /b binary operator',
    f => pmap(q{binary_fixed_op $_}, generic_code),
    p => pmap q{binary_perl_op $_}, plcode \&binary_perl_mapper;
1 core/matrix/lib
matrix.pl
198 core/matrix/matrix.pl
# Matrix conversions.
# Dense to sparse creates a (row, column, value) stream from your data. Sparse to
# dense inverts that. You can specify where the matrix data begins using a column
# identifier; this is useful when your matrices are prefixed with keys.

sub matrix_cell_combine($$) {
  return $_[0] = $_[1] unless defined $_[0];
  $_[0] += $_[1];
}

defoperator dense_to_sparse => q{
  my ($col) = @_;
  $col ||= 0;
  my @q;
  my $n = 0;
  while (defined($_ = @q ? shift @q : <STDIN>)) {
    chomp(my @fs = split /\t/);
    if ($col) {
      $n = 0;
      my $k  = join "\t", @fs[0..$col-1];
      my $kr = qr/\Q$k\E/;
      print join("\t", $k, $n, $_ - $col, $fs[$_]), "\n" for $col..$#fs;
      my $l;
      while (defined($l = <STDIN>) && $l =~ /^$kr\t/) {
        ++$n;
        chomp(@fs = split /\t/, $l);
        print join("\t", $k, $n, $_ - $col, $fs[$_]), "\n" for $col..$#fs;
      }
      push @q, $l if defined $l;
    } else {
      print join("\t", $n, $_, $fs[$_]), "\n" for 0..$#fs;
      ++$n;
    }
  }
};

defoperator sparse_to_dense => q{
  my ($col) = @_;
  $col ||= 0;
  my $n = 0;
  my @q;
  my $row = -1;
  while (defined($_ = @q ? shift @q : <STDIN>)) {
    ++$row;
    chomp;
    my @r = split /\t/, $_, $col + 3;
    my $k = join "\t", @r[0..$col];
    my $kr = qr/\Q$k\E/;
    my @fs = $col ? @r[0..$col-1] : ();
    if ($col < @r) {
      no warnings 'numeric';
      ++$row, print "\n" until $row >= $r[$col];
    }
    matrix_cell_combine $fs[$col + $r[$col+1]], $r[$col+2];
    matrix_cell_combine $fs[$col + $1], $2
      while defined($_ = <STDIN>) && /^$kr\t([^\t]+)\t(.*)/;
    push @q, $_ if defined;
    print join("\t", map defined() ? $_ : '', @fs), "\n";
  }
};

defoperator pivot_table => q{
  my $row_id = 0;
  my $col_id = 0;
  my %row_ids;
  my %col_ids;
  my @cells;
  my @row_labels;
  my @col_labels;

  while (<STDIN>)
  {
    chomp;
    my ($row, $col, $v) = split /\t/;
    my $x = ($col_ids{$col} ||= ++$col_id) - 1;
    my $y = ($row_ids{$row} ||= ++$row_id) - 1;
    $row_labels[$y] = $row;
    $col_labels[$x] = $col;
    ${$cells[$y] ||= []}[$x] += $v;
  }

  print join("\t", "", @col_labels), "\n";
  for my $i (0..$#cells)
  {
    print join("\t", $row_labels[$i], @{$cells[$i] || []}), "\n";
  }
};

defoperator unflatten => q{
  my ($n_cols) = @_;
  my @row = ();
  while(<STDIN>) {
    chomp;
    push @row, split /\t/, $_;
    while(@row >= $n_cols) {
      my @emit_vals = splice(@row, 0, $n_cols);
      print(join("\t", @emit_vals). "\n"); 
      }
    }
  if (@row > 0) {
    while(@row > 0) {
      my @emit_vals = splice(@row, 0, $n_cols);
      print(join("\t", @emit_vals). "\n");
    }
  }
};

defoperator partial_transpose =>
q{
  my ($col) = @_;
  while (<STDIN>)
  {
    chomp;
    my @fs   = split /\t/;
    my $base = join "", map "$_\t", @fs[0..$col-1];
    print "$base$fs[$_]\n" for $col..$#fs;
  }
};

defshort '/X',  pmap q{sparse_to_dense_op $_}, popt colspec1;
defshort '/XP', pmap q{pivot_table_op}, pnone;

defshort '/Y', pmap q{dense_to_sparse_op $_}, popt colspec1;
defshort '/Z', palt pmap(q{unflatten_op 0 + $_}, integer),
                    pmap(q{partial_transpose_op $_}, colspec1);

# NumPy interop.
# Partitioned by the first row value and sent in as dense matrices.

use constant numpy_gen => gen pydent q{
  from numpy import *
  from sys   import stdin, stdout, stderr
  try:
    stdin = stdin.buffer
    stdout = stdout.buffer
  except:
    pass
  while True:
    try:
      dimensions = fromstring(stdin.read(8), dtype=">u4", count=2)
    except:
      exit()
    x = fromstring(stdin.read(8*dimensions[0]*dimensions[1]),
                   dtype="d",
                   count=dimensions[0]*dimensions[1]) \
        .reshape(dimensions)
  %body
    if type(x) != ndarray: x = array(x)
    if len(x.shape) != 2: x = reshape(x, (-1, 1))
    stdout.write(array(x.shape).astype(">u4").tostring())
    stdout.write(x.astype("d").tostring())
    stdout.flush()};

defoperator numpy_dense => q{
  my ($col, $f) = @_;
  $col ||= 0;
  my ($i, $o) = sioproc {
    exec 'python', '-c', numpy_gen->(body => indent $f, 2)
      or die "ni: failed to execute python: $!"};

  my @q;
  my ($rows, $cols);
  while (defined($_ = @q ? shift @q : <STDIN>)) {
    chomp;
    my @r = split /\t/;
    my $k = $col ? join("\t", @r[0..$col-1]) : '';
    $rows = 1;
    my @m = [@r[$col..$#r]];
    my $kr = qr/\Q$k\E/;
    ++$rows, push @m, [split /\t/, $col ? substr $_, length $1 : $_]
      while defined($_ = <STDIN>) and !$col || /^($kr\t)/;
    push @q, $_ if defined;

    $cols = max map scalar(@$_), @m;
    safewrite $i, pack "NNF*", $rows, $cols,
      map $_ || 0,
      map {(@$_, (0) x ($cols - @$_))} @m;

    saferead $o, $_, 8;
    ($rows, $cols) = unpack "NN", $_;

    $_ = '';
    saferead $o, $_, $rows*$cols*8 - length(), length
      until length == $rows*$cols*8;

    # TODO: optimize this. Right now it's horrifically slow and for no purpose
    # (everything's getting read into memory either way).
    for my $r (0..$rows-1) {
      print join("\t", $col ? ($k) : (), unpack "F$cols", substr $_, $r*$cols*8), "\n";
    }
  }

  close $i;
  close $o;
  $o->await;
};

defshort '/N', pmap q{numpy_dense_op @$_}, pseq popt colspec1, pycode;
1 core/gnuplot/lib
gnuplot.pl
121 core/gnuplot/gnuplot.pl
# Gnuplot interop.
# An operator that sends output to a gnuplot process.

use Scalar::Util qw/looks_like_number/;

BEGIN {defdsp gnuplot_code_prefixalt => 'prefixes for gnuplot code';
       defparseralias gnuplot_colspec => palt colspec1, pmap q{undef}, pstr ':'}
BEGIN {defparseralias gnuplot_code =>
         pmap q{join "", map ref($_) ? @$_ : $_, @$_},
              pseq prep('dsp/gnuplot_code_prefixalt'),
                   popt generic_code}

defoperator stream_to_gnuplot => q{
  my ($col, $command) = @_;
  exec 'gnuplot', '-e', $command unless defined $col;
  my ($k, $fh) = (undef, undef);
  while (<STDIN>) {
    chomp;
    my @fs = split /\t/, $_, $col + 2;
    my $rk = join "\t", @fs[0..$col];
    if (!defined $k or $k ne $rk) {
      if (defined $fh) {
        close $fh;
        $fh->await;
      }
      $k  = $rk;
      $fh = siproc {exec 'gnuplot', '-e', "KEY='$k';$command"};
    }
    print $fh join("\t", @fs[$col+1..$#fs]) . "\n";
  }
};

defshort '/G', pmap q{stream_to_gnuplot_op @$_},
               pseq gnuplot_colspec, gnuplot_code;

# Some convenient shorthands for gnuplot -- things like interactive plotting,
# setting up JPEG export, etc.

BEGIN {defparseralias gnuplot_terminal_size =>
         pmap q{defined $_ ? "size " . join ',', @$_ : ""},
         popt pn [0, 2], integer, prx('[x,]'), integer}

defgnuplot_code_prefixalt J  => pmap q{"set terminal jpeg $_;"}, gnuplot_terminal_size;
defgnuplot_code_prefixalt PC => pmap q{"set terminal pngcairo $_;"}, gnuplot_terminal_size;
defgnuplot_code_prefixalt P  => pmap q{"set terminal png $_;"}, gnuplot_terminal_size;

defgnuplot_code_prefixalt X => pmap q{"set terminal x11 persist;"}, popt pstr 'P';
defgnuplot_code_prefixalt Q => pmap q{"set terminal qt persist;"}, popt pstr 'P';
defgnuplot_code_prefixalt W => pmap q{"set terminal wx persist;"}, popt pstr 'P';

defgnuplot_code_prefixalt '%l' => pk 'plot "-" with lines ';
defgnuplot_code_prefixalt '%d' => pk 'plot "-" with dots ';
defgnuplot_code_prefixalt '%i' => pk 'plot "-" with impulses ';
defgnuplot_code_prefixalt '%v' => pk 'plot "-" with vectors ';

defgnuplot_code_prefixalt '%t' => pmap q{"title '$_'"}, generic_code;
defgnuplot_code_prefixalt '%u' => pmap q{"using $_"},   generic_code;

# FFMPEG movie assembly.
# You can use the companion operator `GF` to take a stream of jpeg images from a
# partitioned gnuplot process and assemble a movie. `GF` accepts shell arguments
# for ffmpeg to follow `-f image2pipe -i -`.
#
# GF^ inverts GF, outputting PNG images from a video specified on stdin.

defshort '/GF',  pmap q{sh_op "ffmpeg -f image2pipe -i - $_"}, shell_command;
defshort '/GF^', pmap q{sh_op "ffmpeg -i - $_ -f image2pipe -c:v png -"},
                      shell_command;

# Auto-multiplotting
# If you have a TSV containing multiple columns, we can put them all into a
# single plot.
#
# Getting the data into gnuplot isn't quite trivial. We need to transpose the
# stream column-wise, which involves buffering everything up front.

defoperator gnuplot_all =>
q{
  my $code_prefix = shift || "set terminal wx persist";
  my @col_vectors;
  my @col_titles;

  chomp(my $l = <STDIN>);
  my @fs = split /\t/, $l;
  if (grep !looks_like_number($_), @fs)
  {
    # First line is a header
    @col_titles = @fs[1..$#fs];
  }
  else
  {
    # First line is data
    @col_titles  = ("A".."Z")[1..$#fs];
    @col_vectors = map [$_], @fs;
  }

  while (<STDIN>)
  {
    chomp;
    my @fs = split /\t/;
    push @{$col_vectors[$_] ||= []}, 0+$fs[$_] for 0..$#fs;
  }

  # NB: col A is implicitly the shared X coordinate
  my $code = $code_prefix
    . ";plot "
    . join",", map "\"-\" with lines title \"$_\"", @col_titles;

  my $xs = shift @col_vectors;
  my $fh = siproc {exec 'gnuplot', '-e', $code};
  for my $v (@col_vectors)
  {
    print $fh "$$xs[$_]\t$$v[$_]\n" for 0..$#$v;
    print $fh "e\n";
  }
  close $fh;
  $fh->await;
};

# NB: using G* instead of G% because it has better keyboard ergonomics on QWERTY
defshort '/G*', pmap q{gnuplot_all_op $_}, gnuplot_code;
1 core/image/lib
image.pl
129 core/image/image.pl
# Image compositing and processing
# Operators that loop over concatenated PNG images within a stream. This is
# useful for compositing workflows in a streaming context, e.g. between a
# gnuplot loop and ffmpeg.

# Image traversal functions
# simage() will read a single image from stdin, copying it to stdout, then
# return. This allows you to perform a distinct action for each of a series of
# images concatenated into a stream.
#
# OK .... so this is a lot more complicated than it should be, for all kinds of
# fun reasons. Here's what's up.
#
# For PNG it's simple: there are multiple sections, each length-prefixed
# because its designers were sober, well-adjusted individuals. This includes
# the zero-length IEND marker. So we can do small reads to get the length+type,
# then do custom-sized reads to skip sections.
#
# Contrarily, JFIF/JPEG exemplifies the ambiguity between malice and
# incompetence. JFIF sections are tagged with lengths, but the image data
# itself is a binary format with the equivalent of backslash-escapes around the
# ff byte. The idea is that because each ff in the image is replaced with ff00,
# you can safely identify the image size by looking for the ffd9 EOI marker.
# But that's a bit of a wrench for this use case because it means we need to
# push bytes back into the data stream.
#
# So ... what do we do? We have `simage` maintain a "leftovers" buffer so we
# can still do big-ish block reads and keep track of unconsumed data.
#
# TODO: for now only PNG and BMP are supported.

sub simage_png {
  my ($into) = @_;
  return undef unless saferead_exactly \*STDIN, $_, 6;
  safewrite_exactly $into, $_;

  my ($l, $t) = (0, '');
  while ($t ne 'IEND') {
    ($l, $t) = unpack 'Na4', $_ if saferead_exactly \*STDIN, $_, 8;
    saferead_exactly \*STDIN, $_, $l + 4, 8;
    safewrite_exactly $into, $_;
  }
  close $into;
  $into->await;
}

sub simage_bmp {
  my ($into) = @_;
  return undef unless saferead_exactly \*STDIN, $_, 4;
  safewrite_exactly $into, $_;

  # Super easy: bytes 2-6 store the total size as a little-endian int.
  saferead_exactly \*STDIN, $_, unpack('V', $_) - 2;
  safewrite_exactly $into, $_;
  close $into;
  $into->await;
}

sub simage_jfif {
  die "ni simage jfif: TODO: this is complicated and unimplemented at the moment";
}

sub simage_into(&) {
  # Reads exactly one image from stdin, outputting to the stdin of the
  # specified forked function if an image can be read. Returns the fork's exit
  # code on success, sets $! and returns undef on failure. Dies if you're
  # working with an unsupported type of image.
  my ($fn) = @_;
  local $_;
  my $n;
  return undef unless $n = saferead_exactly \*STDIN, $_, 2;
  my $into = siproc {&$fn};
  safewrite_exactly $into, $_;
  return simage_png  $into if /^\x89P$/;
  return simage_jfif $into if /^\xff\xd8$/;
  return simage_bmp  $into if /^BM$/;
  die "ni simage: unsupported image type (unrecognized magic in $_)";
}

# Image splitting operators
# The simplest of these executes a pipeline separately for each of a series of
# images.

defoperator each_image => q{
  my ($lambda) = @_;
  $ENV{KEY} = 0;
  1 while ++$ENV{KEY} && defined simage_into {exec_ni @$lambda};
};

defshort '/I' => pmap q{each_image_op $_}, _qfn;

# Streaming compositing pipelines
# ImageMagick's "convert" command lets you composite images and select regions.
# This isn't an especially cheap strategy and it involves a lot of disk IO, but
# it ends up being a very flexible way to implement a multi-frame compositing
# setup.

BEGIN {defparseralias image_command => palt pmap(q{''}, pstr ':'), shell_command}

defconfenv image_command => 'NI_IMAGE_COMMAND', 'convert';

sub image_sync_sh($) {
  my $fh = siproc {close STDIN; sh $_[0]} $_[0];
  close $fh;
  $fh->await;
}

defoperator composite_images => q{
  my ($init, $reducer, $emitter) = @_;
  my $ic = conf 'image_command';
  my $reduced_image = substr(resource_tmp 'file://', 7) . '.png';
  my $temp_image    = substr(resource_tmp 'file://', 7) . '.png';

  my $reduced_q = shell_quote $reduced_image;
  my $temp_q    = shell_quote $temp_image;

  if (defined simage_into {sh "$ic - $init $reduced_q"}) {
    image_sync_sh "$ic $reduced_q $emitter png:-";
    image_sync_sh "$ic $reduced_q $emitter png:-"
      while defined simage_into {sh "$ic $reduced_q $reducer $temp_q; mv $temp_q $reduced_q"};
  }

  unlink $reduced_image;
};

defshort '/IC' => pmap q{composite_images_op @$_},
                  pseq pc image_command, pc image_command, pc image_command;

defshort '/IJ' => pmap q{each_image_op [sh_op "convert - jpg:-"]}, pnone;
2 core/http/lib
ws.pm
http.pl
41 core/http/ws.pm
# WebSocket encoding functions.
# We just encode text messages; no binary or other protocols are defined yet.

BEGIN {
  eval 'use Digest::SHA qw/sha1_base64/';
  load 'core/deps/sha1.pm',
    Digest::SHA::PurePerl->import(qw/sha1_base64/) if $@;

  eval 'use Encode qw/encode/';
  if ($@) {
    warn 'ni: websockets will fail for utf-8 data on this machine '
       . '(no Encode module)';
    *encode = sub {$_[1]};
  }
}

use constant ws_guid => '258EAFA5-E914-47DA-95CA-C5AB0DC85B11';

sub ws_header($) {
  my ($client_key) = $_[0] =~ /Sec-WebSocket-Key:\s*(\S+)/i;
  my ($protocol)   = $_[0] =~ /Sec-WebSocket-Protocol:\s*(\S+)/i;
  my $hash = sha1_base64 $client_key . ws_guid;
  join "\n", "HTTP/1.1 101 Switching Protocols",
             "Upgrade: websocket",
             "Connection: upgrade",
             "Sec-WebSocket-Accept: $hash=",
             "Sec-WebSocket-Protocol: $protocol",
             '', '';
}

sub ws_length_encode($) {
  my ($n) = @_;
  return pack 'C',        $n if $n < 126;
  return pack 'Cn',  126, $n if $n < 65536;
  return pack 'CNN', 127, $n >> 32, $n;
}

sub ws_encode($) {
  my $e = encode 'utf8', $_[0];
  "\x81" . ws_length_encode(length $e) . $e;
}
65 core/http/http.pl
# HTTP server.
# A very simple HTTP server that can be used to serve a stream's contents. This is used
# by other libraries to serve things like JSPlot.

use Socket;
use Errno qw/EINTR/;

sub http_reply($$$%) {
  my ($fh, $code, $body, %headers) = @_;
  $fh->print(join "\n", "HTTP/1.1 $code NI",
                        map("$_: $headers{$_}", sort keys %headers),
                        "Content-Length: " . length($body),
                        '',
                        $body);
}

sub uri_decode(@) {(my $u = $_[0]) =~ s/%([0-9A-Fa-f]{2})/chr hex $1/eg; $u}

sub safeaccept($$) {
  my $r;
  1 until $r = accept $_[0], $_[1] or !$!{EINTR};
  $r;
}

sub http($$) {
  my (undef, $f) = @_;
  my ($server, $client);
  $f = fn $f;

  socket $server, PF_INET, SOCK_STREAM, getprotobyname 'tcp'
    or die "ni http: socket() failed: $!";
  setsockopt $server, SOL_SOCKET, SO_REUSEADDR, pack 'l', 1
    or die "ni http: setsockopt() failed: $!";

  ++$_[0] > 65535 && die "ni http: bind() failed: $!"
    until bind $server, sockaddr_in $_[0], INADDR_LOOPBACK;

  listen $server, SOMAXCONN or die "ni http: listen() failed: $!";

  &$f;
  for (; $_ = '', safeaccept $client, $server; close $client) {
    next if cfork;
    my $n = 1;
    close $server;
    $n = saferead $client, $_, 8192, length until /\r?\n\r?\n/ || !$n;
    &$f(uri_decode(/^GET (.*) HTTP\//), $_, $client);
    exit;
  }
}

# Websocket operators.
# This is used to stream a data source to the browser. See `core/jsplot` for details.

defoperator http_websocket_encode => q{
  load 'core/http/ws.pm';
  safewrite \*STDOUT, ws_encode($_) while <STDIN>;
};

defoperator http_websocket_encode_batch => q{
  load 'core/http/ws.pm';
  safewrite \*STDOUT, ws_encode($_) while saferead \*STDIN, $_, $_[0] || 8192;
};

defshort '/--http/wse',       pmap q{http_websocket_encode_op}, pnone;
defshort '/--http/wse-batch', pmap q{http_websocket_encode_batch_op $_}, popt integer;
3 core/caterwaul/lib
caterwaul.min.js
caterwaul.std.min.js
caterwaul.ui.min.js
138 core/caterwaul/caterwaul.min.js
(function(f){return f(f)})(function(initializer,key,undefined){(function(f){return f(f)})(function(initializer){var calls_init=function(){var f=function(){return f.init.apply(f,arguments)
};return f},original_global=typeof caterwaul==="undefined"?undefined:caterwaul,caterwaul_global=calls_init();caterwaul_global.deglobalize=function(){caterwaul=original_global;
return caterwaul_global};caterwaul_global.core_initializer=initializer;caterwaul_global.context=this;caterwaul_global.merge=(function(o){for(var k in o){if(o.hasOwnProperty(k)){return true
}}})({toString:true})?function(o){for(var i=1,l=arguments.length,_;i<l;++i){if(_=arguments[i]){for(var k in _){if(Object.prototype.hasOwnProperty.call(_,k)){o[k]=_[k]
}}}}return o}:function(o){for(var i=1,l=arguments.length,_;i<l;++i){if(_=arguments[i]){for(var k in _){if(Object.prototype.hasOwnProperty.call(_,k)){o[k]=_[k]}}if(_.toString&&!/\[native code\]/.test(_.toString.toString())){o.toString=_.toString
}}}return o},caterwaul_global.modules=[];caterwaul_global.module=function(name,transform,f){if(arguments.length===1){return caterwaul_global[name+"_initializer"]
}name+"_initializer" in caterwaul_global||caterwaul_global.modules.push(name);f||(f=transform,transform=null);(caterwaul_global[name+"_initializer"]=transform?caterwaul_global(transform)(f):f)(caterwaul_global);
return caterwaul_global};return caterwaul=caterwaul_global});var qw=function(x){return x.split(/\s+/)},se=function(x,f){return f&&f.call(x,x)||x},fail=function(m){throw new Error(m)
},unique=key||(function(){for(var xs=[],d="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789$_",i=21,n;i>=0;--i){xs.push(d.charAt(Math.random()*64>>>0))
}return xs.join("")})(),gensym=(function(c){return function(name){return[name||"",(++c).toString(36),unique].join("_")}})(0),is_gensym=function(s){return s.substr(s.length-22)===unique
},bind=function(f,t){return function(){return f.apply(t,arguments)}},map=function(f,xs){for(var i=0,ys=[],l=xs.length;i<l;++i){ys.push(f(xs[i],i))}return ys},rmap=function(f,xs){return map(function(x){return x instanceof Array?rmap(f,x):f(x)
})},hash=function(s){for(var i=0,xs=qw(s),o={},l=xs.length;i<l;++i){o[xs[i]]=true}return annotate_keys(o)},max_length_key=gensym("hash"),annotate_keys=function(o){var max=0;
for(var k in o){own.call(o,k)&&(max=k.length>max?k.length:max)}o[max_length_key]=max;return o},has=function(o,p){return p!=null&&!(p.length>o[max_length_key])&&own.call(o,p)
},own=Object.prototype.hasOwnProperty,caterwaul_global=caterwaul.merge(caterwaul,{map:map,rmap:rmap,gensym:gensym,is_gensym:is_gensym,gensym_entropy:function(){return unique
}}),lex_op=hash(". new ++ -- u++ u-- u+ u- typeof void u~ u! ! * / % + - << >> >>> < > <= >= instanceof in == != === !== & ^ | && || ? = += -= *= /= %= &= |= ^= <<= >>= >>>= : , return throw case var const break continue else u; ;"),lex_table=function(s){for(var i=0,xs=[false];
i<8;++i){xs.push.apply(xs,xs)}for(var i=0,l=s.length;i<l;++i){xs[s.charCodeAt(i)]=true}return xs},lex_float=lex_table(".0123456789"),lex_decimal=lex_table("0123456789"),lex_integer=lex_table("0123456789abcdefABCDEFx"),lex_exp=lex_table("eE"),lex_space=lex_table(" \n\r\t"),lex_bracket=lex_table("()[]{}?:"),lex_opener=lex_table("([{?:"),lex_punct=lex_table("+-*/%&|^!~=<>?:;.,"),lex_eol=lex_table("\n\r"),lex_regexp_suffix=lex_table("gims"),lex_quote=lex_table("'\"/"),lex_slash="/".charCodeAt(0),lex_zero="0".charCodeAt(0),lex_postfix_unary=hash("++ --"),lex_ident=lex_table("@$_abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"),lex_star="*".charCodeAt(0),lex_back="\\".charCodeAt(0),lex_x="x".charCodeAt(0),lex_dot=".".charCodeAt(0),lex_hash="#".charCodeAt(0),parse_reduce_order=map(hash,["function","( [ . [] ()","new delete void","u++ u-- ++ -- typeof u~ u! u+ u-","* / %","+ -","<< >> >>>","< > <= >= instanceof in","== != === !==","::",":::","&","^","|","&&","||","-> =>","case","? = += -= *= /= %= &= |= ^= <<= >>= >>>= &&= ||=",":",",","return throw break continue","var const","if else try catch finally for switch with while do",";"]),parse_associates_right=hash("= += -= *= /= %= &= ^= |= <<= >>= >>>= &&= ||= :: ::: -> => ~ ! new typeof void u+ u- -- ++ u-- u++ ? if else function try catch finally for switch case with while do"),parse_inverse_order=(function(xs){for(var o={},i=0,l=xs.length;
i<l;++i){for(var k in xs[i]){has(xs[i],k)&&(o[k]=i)}}return annotate_keys(o)})(parse_reduce_order),parse_index_forward=(function(rs){for(var xs=[],i=0,l=rs.length,_=null;
_=rs[i],xs[i]=true,i<l;++i){for(var k in _){if(has(_,k)&&(xs[i]=xs[i]&&!has(parse_associates_right,k))){break}}}return xs})(parse_reduce_order),parse_lr=hash("[] . () * / % + - << >> >>> < > <= >= instanceof in == != === !== & ^ | && || -> => = += -= *= /= %= &= |= ^= <<= >>= >>>= &&= ||= , : ;"),parse_r_until_block=annotate_keys({"function":2,"if":1,"do":1,"catch":1,"try":1,"for":1,"while":1,"with":1,"switch":1}),parse_accepts=annotate_keys({"if":"else","do":"while","catch":"finally","try":"catch"}),parse_invocation=hash("[] ()"),parse_r_optional=hash("return throw break continue else"),parse_r=hash("u+ u- u! u~ u++ u-- new typeof finally case var const void delete"),parse_block=hash("; {"),parse_invisible=hash("i;"),parse_l=hash("++ --"),parse_group=annotate_keys({"(":")","[":"]","{":"}","?":":"}),parse_ambiguous_group=hash("[ ("),parse_ternary=hash("?"),parse_not_a_value=hash("function if for while with catch void delete new typeof in instanceof"),parse_also_expression=hash("function"),parse_misleading_postfix=hash(":"),syntax_common=caterwaul_global.syntax_common={_replace:function(n){return(n.l=this.l)&&(this.l.r=n),(n.r=this.r)&&(this.r.l=n),this
},_append_to:function(n){return n&&n._append(this),this},_reparent:function(n){return this.p&&this.p[0]===this&&(this.p[0]=n),this},_fold_l:function(n){return this._append(this.l&&this.l._unlink(this)||empty)
},_append:function(n){return(this[this.length++]=n)&&(n.p=this),this},_fold_r:function(n){return this._append(this.r&&this.r._unlink(this)||empty)},_sibling:function(n){return n.p=this.p,(this.r=n).l=this
},_fold_lr:function(){return this._fold_l()._fold_r()},_fold_rr:function(){return this._fold_r()._fold_r()},_wrap:function(n){return n.p=this._replace(n).p,this._reparent(n),delete this.l,delete this.r,this._append_to(n)
},_unlink:function(n){return this.l&&(this.l.r=this.r),this.r&&(this.r.l=this.l),delete this.l,delete this.r,this._reparent(n)},pop:function(){return --this.length,this
},push:function(x){return this[this.length++]=caterwaul_global.syntax.promote(x||empty),this},id:function(){var id=gensym("id");return(this.id=function(){return id
})()},is_caterwaul_syntax:true,each:function(f){for(var i=0,l=this.length;i<l;++i){f(this[i],i)}return this},map:function(f){for(var n=new this.constructor(this),i=0,l=this.length;
i<l;++i){n.push(f(this[i],i)||this[i])}return n},reach:function(f){f(this);for(var i=0,l=this.length;i<l;++i){this[i].reach(f)}return this},rmap:function(f){var r=f(this);
return !r||r===this?this.map(function(n){return n.rmap(f)}):r===true?this:r.rmap===undefined?new this.constructor(r):r},peach:function(f){for(var i=0,l=this.length;
i<l;++i){this[i].peach(f)}f(this);return this},pmap:function(f){var t=this.map(function(n){return n.pmap(f)});return f(t)},clone:function(){return this.rmap(function(){return false
})},collect:function(p){var ns=[];this.reach(function(n){p(n)&&ns.push(n)});return ns},replace:function(rs){var r;return own.call(rs,this.data)&&(r=rs[this.data])?r.constructor===String?se(this.map(function(n){return n.replace(rs)
}),function(){this.data=r}):r:this.map(function(n){return n.replace(rs)})},thin_clone:function(){return this.map(function(){return false})},repopulated_with:function(xs){return new this.constructor(this.data,xs)
},with_data:function(d){return new this.constructor(d,Array.prototype.slice.call(this))},change:function(i,x){return se(new this.constructor(this.data,Array.prototype.slice.call(this)),function(n){n[i]=x
})},compose_single:function(i,f){return this.change(i,f(this[i]))},slice:function(x1,x2){return new this.constructor(this.data,Array.prototype.slice.call(this,x1,x2))
},traverse:function(f){f({entering:this});f({exiting:this.each(function(n){n.traverse(f)})});return this},flatten:function(d){d=d||this.data;return d!==this.data?this.as(d):!(has(parse_lr,d)&&this.length)?this:has(parse_associates_right,d)?se(new this.constructor(d),bind(function(n){for(var i=this;
i&&i.data===d;i=i[1]){n.push(i[0])}n.push(i)},this)):se(new this.constructor(d),bind(function(n){for(var i=this,ns=[];i.data===d;i=i[0]){i[1]&&ns.push(i[1])}ns.push(i);
for(i=ns.length-1;i>=0;--i){n.push(ns[i])}},this))},unflatten:function(){var t=this,right=has(parse_associates_right,this.data);return this.length<=2?this:se(new this.constructor(this.data),function(n){if(right){for(var i=0,l=t.length-1;
i<l;++i){n=n.push(t[i]).push(i<l-2?t.data:t[i])[1]}}else{for(var i=t.length-1;i>=1;--i){n=n.push(i>1?t.data:t[0]).push(t[i])[0]}}})},as:function(d){return this.data===d?this:new caterwaul_global.syntax(d).push(this)
},bindings:function(hash){var result=hash||{};this.reach(function(n){n.add_bindings_to(result)});return result},expressions:function(hash){var result=hash||{};this.reach(function(n){n.add_expressions_to(result)
});return result},add_bindings_to:function(hash){},add_expressions_to:function(hash){},resolve:function(){return this},reduce:function(){return this},prefix:function(d){return this.prefixes().push(d),this
},prefixes:function(){return this.prefix_data||(this.prefix_data=[])},infix:function(d){return this.infixes().push(d),this},infixes:function(){return this.infix_data||(this.infix_data=[])
},suffix:function(d){return this.suffixes().push(d),this},suffixes:function(){return this.suffix_data||(this.suffix_data=[])},contains:function(f){var result=f(this);
if(result){return result}for(var i=0,l=this.length;i<l;++i){if(result=this[i].contains(f)){return result}}},match:function(target,variables){target=target.constructor===String?caterwaul_global.parse(target):target;
variables||(variables={_:target});if(this.is_wildcard()&&(!this.leaf_nodes_only()||!this.length)){return variables[this.without_metadata()]=target,variables}else{if(this.length===target.length&&this.data===target.data){for(var i=0,l=this.length;
i<l;++i){if(!this[i].match(target[i],variables)){return null}}return variables}}},toString:function(depth){var xs=[""];this.serialize(xs,depth||-1);return xs.join("")
},structure:function(){if(this.length){return"("+['"'+this.data+'"'].concat(map(function(x){return x.structure()},this)).join(" ")+")"}else{return this.data}}};caterwaul_global.syntax_subclasses=[];
caterwaul_global.syntax_subclass=function(ctor){var extensions=Array.prototype.slice.call(arguments,1),proxy=function(){return ctor.apply(this,arguments)};caterwaul_global.merge.apply(this,[proxy.prototype,syntax_common].concat(extensions));
caterwaul_global.syntax_subclasses.push(proxy);proxy.prototype.constructor=proxy;return proxy};caterwaul_global.syntax_extend=function(){for(var i=0,l=caterwaul_global.syntax_subclasses.length,es=Array.prototype.slice.call(arguments);
i<l;++i){caterwaul_global.merge.apply(this,[caterwaul_global.syntax_subclasses[i].prototype].concat(es))}caterwaul_global.merge.apply(this,[syntax_common].concat(es));
return caterwaul_global};var parse_hex=caterwaul_global.parse_hex=function(digits){for(var result=0,i=0,l=digits.length,d;i<l;++i){result*=16,result+=(d=digits.charCodeAt(i))<=58?d-48:(d&95)-55
}return result},parse_octal=caterwaul_global.parse_octal=function(digits){for(var result=0,i=0,l=digits.length;i<l;++i){result*=8,result+=digits.charCodeAt(i)-48
}return result},unescape_string=caterwaul_global.unescape_string=function(s){for(var i=0,c,l=s.length,result=[],is_escaped=false;i<l;++i){if(is_escaped){is_escaped=false,result.push((c=s.charAt(i))==="\\"?"\\":c==="n"?"\n":c==="r"?"\r":c==="b"?"\b":c==="f"?"\f":c==="0"?"\u0000":c==="t"?"\t":c==="v"?"\v":c==='"'||c==="'"?c:c==="x"?String.fromCharCode(parse_hex(s.substring(i,++i+1))):c==="u"?String.fromCharCode(parse_hex(s.substring(i,(i+=3)+1))):String.fromCharCode(parse_octal(s.substring(i,(i+=2)+1))))
}else{if((c=s.charAt(i))==="\\"){is_escaped=true}else{result.push(c)}}}return result.join("")};caterwaul_global.javascript_tree_type_methods={is_string:function(){return/['"]/.test(this.data.charAt(0))
},as_escaped_string:function(){return this.data.substr(1,this.data.length-2)},is_number:function(){return/^-?(0x|\d|\.\d+)/.test(this.data)},as_number:function(){return Number(this.data)
},is_boolean:function(){return this.data==="true"||this.data==="false"},as_boolean:function(){return this.data==="true"},is_regexp:function(){return/^\/./.test(this.data)
},as_escaped_regexp:function(){return this.data.substring(1,this.data.lastIndexOf("/"))},is_array:function(){return this.data==="["},as_unescaped_string:function(){return unescape_string(this.as_escaped_string())
},could_be_identifier:function(){return/^[A-Za-z_$@][A-Za-z0-9$_@]*$/.test(this.data)},is_identifier:function(){return this.length===0&&this.could_be_identifier()&&!this.is_boolean()&&!this.is_null_or_undefined()&&!has(lex_op,this.data)
},has_grouped_block:function(){return has(parse_r_until_block,this.data)},is_block:function(){return has(parse_block,this.data)},is_blockless_keyword:function(){return has(parse_r_optional,this.data)
},is_null_or_undefined:function(){return this.data==="null"||this.data==="undefined"},is_constant:function(){return this.is_number()||this.is_string()||this.is_boolean()||this.is_regexp()||this.is_null_or_undefined()
},left_is_lvalue:function(){return/=$/.test(this.data)||/\+\+$/.test(this.data)||/--$/.test(this.data)},is_empty:function(){return !this.length},has_parameter_list:function(){return this.data==="function"||this.data==="catch"
},has_lvalue_list:function(){return this.data==="var"||this.data==="const"},is_dereference:function(){return this.data==="."||this.data==="[]"},is_invocation:function(){return this.data==="()"
},is_contextualized_invocation:function(){return this.is_invocation()&&this[0].is_dereference()},is_invisible:function(){return has(parse_invisible,this.data)},is_binary_operator:function(){return has(parse_lr,this.data)
},is_prefix_unary_operator:function(){return has(parse_r,this.data)},is_postfix_unary_operator:function(){return has(parse_l,this.data)},is_unary_operator:function(){return this.is_prefix_unary_operator()||this.is_postfix_unary_operator()
},precedence:function(){return parse_inverse_order[this.data]},is_right_associative:function(){return has(parse_associates_right,this.data)},is_associative:function(){return/^[,;]$/.test(this.data)
},is_group:function(){return/^[(\[{][)\]]?$/.test(this.data)},accepts:function(e){return has(parse_accepts,this.data)&&parse_accepts[this.data]===(e.data||e)}};caterwaul_global.javascript_tree_metadata_methods={could_have_metadata:function(){return this.could_be_identifier()
},without_metadata:function(){return this.data.replace(/@.*$/g,"")},is_wildcard:function(){return this.data.charCodeAt(0)===95},leaf_nodes_only:function(){return/@0/.test(this.data)
},is_opaque:function(){return this.data.charCodeAt(0)===64}};caterwaul_global.javascript_tree_serialization_methods={ends_with_block:function(){var block=this[this.length-1];
if(block&&block.data===parse_accepts[this.data]){block=block[0]}return this.data==="{"||has(parse_r_until_block,this.data)&&(this.data!=="function"||this.length===3)&&block&&block.ends_with_block()
},never_guarded:function(){return this.is_group()||this.precedence()>parse_inverse_order[","]},guarded:function(p){var this_p=this.never_guarded()?undefined:this.precedence(),associative=this.is_associative(),right=this.is_right_associative(),result=this.map(function(x,i){return x.guarded(this_p-(!associative&&!right&&!!i))
});return this_p>p?result.as("("):result},serialize:function(xs,depth){var ep=function(x){e(p||x&&lex_ident[xs[xs.length-1].charCodeAt(0)]===lex_ident[x.charCodeAt(0)]?" ":""),x&&e(x)
},e=function(x){x&&xs.push(x)},p=this.prefix_data&&this.prefix_data.join(""),l=this.length,d=this.data,d1=depth-1,i=this.infix_data&&this.infix_data.join(""),s=this.suffix_data&&this.suffix_data.join("");
if(depth===0&&(l||d.length>32)){return e("...")}switch(l){case 0:if(has(parse_r_optional,d)){return ep(d.replace(/^u/,"")),e(s)}else{if(has(parse_group,d)){return ep(d),e(i),e(parse_group[d]),e(s)
}else{return ep(d),e(s)}}case 1:if(has(parse_r,d)||has(parse_r_optional,d)){return ep(d.replace(/^u/,"")),this[0].serialize(xs,d1),e(s)}else{if(has(parse_misleading_postfix,d)){return this[0].serialize(xs,d1),ep(d),e(s)
}else{if(has(parse_group,d)){return ep(d),this[0].serialize(xs,d1),e(i),e(parse_group[d]),e(s)}else{if(has(parse_lr,d)){return ep(),this[0].serialize(xs,d1),e(s)
}else{return this[0].serialize(xs,d1),ep(d),e(s)}}}}case 2:if(has(parse_invocation,d)){return this[0].serialize(xs,d1),ep(d.charAt(0)),this[1].serialize(xs,d1),e(i),e(d.charAt(1)),e(s)
}else{if(has(parse_r_until_block,d)){return ep(d),this[0].serialize(xs,d1),this[1].serialize(xs,d1),e(s)}else{if(has(parse_invisible,d)){return this[0].serialize(xs,d1),this[1].serialize(xs,d1),e(s)
}else{return this[0].serialize(xs,d1),ep(d),this[1].serialize(xs,d1),e(s)}}}default:if(has(parse_ternary,d)){return this[0].serialize(xs,d1),ep(d),this[1].precedence()>this.precedence()?(this[1].as("(").serialize(xs,d1),e(i),e(":"),this[2].serialize(xs,d1),e(s)):(this[1].serialize(xs,d1),e(i),e(":"),this[2].serialize(xs,d1),e(s))
}else{if(has(parse_r_until_block,d)){return this.accepts(this[2])&&!this[1].ends_with_block()?(ep(d),this[0].serialize(xs,d1),this[1].serialize(xs,d1),e(";"),this[2].serialize(xs,d1),e(s)):(ep(d),this[0].serialize(xs,d1),this[1].serialize(xs,d1),this[2].serialize(xs,d1),e(s))
}else{return ep(),this.unflatten().serialize(xs,d1),e(s)}}}}};caterwaul_global.ref_common=caterwaul_global.merge({},caterwaul_global.javascript_tree_type_methods,caterwaul_global.javascript_tree_metadata_methods,caterwaul_global.javascript_tree_serialization_methods,{replace:function(replacements){var r;
return own.call(replacements,this.data)&&(r=replacements[this.data])?r.constructor===String?se(new this.constructor(this.value),function(){this.data=r}):r:this},length:0});
caterwaul_global.ref=caterwaul_global.syntax_subclass(function(value,name){if(value instanceof this.constructor){this.value=value.value,this.data=value.data}else{this.value=value,this.data=gensym(name&&name.constructor===String?name:"ref")
}},caterwaul_global.ref_common,{add_bindings_to:function(hash){hash[this.data]=this.value}});caterwaul_global.expression_ref=caterwaul_global.syntax_subclass(function(e,name){if(e instanceof this.constructor){this.e=e.e,this.data=e.data
}else{this.e=e,this.data=gensym(name&&name.constructor===String?name:"e")}},caterwaul_global.ref_common,{add_expressions_to:function(hash){hash[this.data]=this.e
}});caterwaul_global.metadata_node=caterwaul_global.syntax_subclass(function(d,name){if(d instanceof this.constructor){this.metadata=d.metadata,this.data=d.data}else{this.metadata=d,this.data="@"+(name||"")
}},caterwaul_global.ref_common);caterwaul_global.opaque_tree=caterwaul_global.syntax_subclass(function(code,expression_refs){if(code instanceof this.constructor){this.data=code.data,this.expression_refs=code.expression_refs
}else{this.data=code.toString(),this.expression_refs=expression_refs||code.caterwaul_expression_ref_table}var rs=this.expression_refs;for(var k in rs){own.call(rs,k)&&rs[k].constructor===String&&(rs[k]=new caterwaul_global.opaque_tree(rs[k]))
}},{resolve:function(){return this.expression_refs?caterwaul_global.late_bound_tree(new this.constructor(this.data),this.expression_refs):this},reduce:function(){return this.expression_refs?caterwaul_global.late_bound_tree(this.parse(),this.expression_refs):this.parse()
},guarded:function(){return this},serialize:function(xs){return xs.push(this.data),xs},parse:function(){return caterwaul_global.parse(this.data)}});caterwaul_global.syntax=se(caterwaul_global.syntax_subclass(function(data){if(data instanceof this.constructor){this.data=data.data,this.length=0,this.prefix_data=data.prefix_data,this.infix_data=data.infix_data,this.suffix_data=data.suffix_data
}else{this.data=data&&data.toString();this.length=0;for(var i=1,l=arguments.length,_;_=arguments[i],i<l;++i){for(var j=0,lj=_.length,it,c;_ instanceof Array?(it=_[j],j<lj):(it=_,!j);
++j){this._append(caterwaul_global.syntax.promote(it))}}}},caterwaul_global.javascript_tree_type_methods,caterwaul_global.javascript_tree_metadata_methods,caterwaul_global.javascript_tree_serialization_methods),function(){this.from_string=function(s){return new caterwaul_global.syntax('"'+s.replace(/\\/g,"\\\\").replace(/"/g,'\\"').replace(/\n/g,"\\n")+'"')
};this.from_array=function(xs){for(var i=0,c=new caterwaul_global.syntax(","),l=xs.length;i<l;++i){c.push(xs[i])}return new caterwaul_global.syntax("[",c.length?c.unflatten():[])
};this.from_object=function(o){var comma=new caterwaul_global.syntax(",");for(var k in o){if(own.call(o,k)){comma.push(new caterwaul_global.syntax(":",/^[$_A-Za-z][A-Za-z0-9$_]*$/.test(k)?k:caterwaul_global.syntax.from_string(k),o[k].as("(")))
}}return new caterwaul_global.syntax("{",comma.length?comma.unflatten():[])}});caterwaul_global.syntax.promote=function(v){var c=v.constructor;return c===String||c===Number||c===Boolean?new caterwaul_global.syntax(v):v
};var empty=caterwaul_global.empty=new caterwaul_global.syntax("");caterwaul_global.parse=function(input){if(input==null){return input}if(input.constructor===caterwaul_global.syntax){return input
}var s=input.toString().replace(/^\s*|\s*$/g,""),mark=0,c=0,re=true,esc=false,dot=false,exp=false,close=0,t="",i=0,l=s.length,cs=function(i){return s.charCodeAt(i)
},grouping_stack=[],gs_top=null,head=null,parent=null,indexes=map(function(){return[]},parse_reduce_order),invocation_nodes=[],all_nodes=[empty],new_node=function(n){return all_nodes.push(n),n
},push=function(n){return head?head._sibling(head=n):(head=n._append_to(parent)),new_node(n)},syntax_node=this.syntax,groups=[],ternaries=[],prefix=[],shift_prefix=function(){var k=prefix;
prefix=[];return k},prefixed_node=function(n){n.prefix_data=shift_prefix();return new_node(n)};if(l===0){return empty}while((mark=i)<l){esc=exp=dot=t=0;if(lex_space[c=cs(i)]){while(++i<l&&lex_space[cs(i)]){}}else{if(lex_bracket[c]){++i,t=1,re=lex_opener[c]
}else{if(c===lex_slash&&cs(i+1)===lex_star&&(i+=2)){while(++i<=l&&(cs(i-1)!==lex_slash||cs(i-2)!==lex_star)){}}else{if(c===lex_slash&&cs(i+1)===lex_slash){while(++i<=l&&!lex_eol[cs(i-1)]){}}else{if(c===lex_hash){while(++i<=l&&!lex_eol[cs(i-1)]){}}else{if(lex_quote[c]&&(close=c)&&re&&!(re=!(t=s.charAt(i)))){while(++i<l&&(c=cs(i))!==close||esc){esc=!esc&&c===lex_back
}while(++i<l&&lex_regexp_suffix[cs(i)]){}t=1}else{if(c===lex_zero&&lex_integer[cs(i+1)]){while(++i<l&&lex_integer[cs(i)]){}re=!(t=1)}else{if(lex_float[c]&&(c!==lex_dot||lex_decimal[cs(i+1)])){while(++i<l&&(lex_decimal[c=cs(i)]||dot^(dot|=c===lex_dot)||exp^(exp|=lex_exp[c]&&++i))){}while(i<l&&lex_decimal[cs(i)]){++i
}re=!(t=1)}else{if(lex_punct[c]&&(t=re?"u":"",re=true)){while(i<l&&lex_punct[cs(i)]&&has(lex_op,t+s.charAt(i))){t+=s.charAt(i++)}re=!has(lex_postfix_unary,t)}else{while(++i<l&&(lex_ident[c=cs(i)]||c>127)){}re=has(lex_op,t=s.substring(mark,i))
}}}}}}}}}if(i===mark){throw new Error('Caterwaul lex error at "'+s.substr(mark,80)+'" with leading context "'+s.substr(mark-80,80)+'" (probably a Caterwaul bug)')
}if(t===0){prefix.push(s.substring(mark,i));continue}t=t===1?s.substring(mark,i):t==="u;"?";":t;t===gs_top?(grouping_stack.pop(),gs_top=grouping_stack[grouping_stack.length-1],(head||parent).infix_data=shift_prefix(),head=head?head.p:parent,parent=null):(has(parse_group,t)?(grouping_stack.push(gs_top=parse_group[t]),parent=push(prefixed_node(new syntax_node(t))),groups.push(parent),head=null):push(prefixed_node(new syntax_node(t))),has(parse_inverse_order,t)&&indexes[parse_inverse_order[t]].push(head||parent));
re|=t===")"&&head.l&&has(parse_r_until_block,head.l.data)}for(var i=0,l=indexes.length,forward,_;_=indexes[i],forward=parse_index_forward[i],i<l;++i){for(var j=forward?0:_.length-1,lj=_.length,inc=forward?1:-1,node,data,ll;
forward?j<lj:j>=0;j+=inc){if(has(parse_lr,data=(node=_[j]).data)){if(data===":"&&parse_inverse_order[node.r.data]>i){node._fold_l()}else{node._fold_lr()}}else{if(has(parse_ambiguous_group,data)&&node.l&&!((ll=node.l.l)&&has(parse_r_until_block,ll.data))&&(node.l.data==="."||(node.l.data==="function"&&node.l.length===2)||!(has(lex_op,node.l.data)||has(parse_not_a_value,node.l.data)))){invocation_nodes.push(node.l._wrap(new_node(new syntax_node(data+parse_group[data]))).p._fold_r())
}else{if(has(parse_l,data)){node._fold_l()}else{if(has(parse_r,data)){node._fold_r()}else{if(has(parse_ternary,data)){node._fold_lr(),ternaries.push(node)}else{if(has(parse_r_until_block,data)&&node.r&&node.r.data!==":"){for(var count=0,limit=parse_r_until_block[data];
count<limit&&node.r&&!has(parse_block,node.r.data);++count){node._fold_r()}node.r&&(node.r.data===";"?node.push(empty):node._fold_r());if(has(parse_accepts,data)&&parse_accepts[data]===(node.r&&node.r.r&&node.r.r.data)){node._fold_r().pop()._fold_r()
}else{if(has(parse_accepts,data)&&parse_accepts[data]===(node.r&&node.r.data)){node._fold_r()}}}else{if(has(parse_r_optional,data)){node.r&&node.r.data!==";"&&node._fold_r()
}}}}}}}}}for(var i=all_nodes.length-1,_;i>=0;--i){(_=all_nodes[i]).r&&_._wrap(new_node(new syntax_node("i;"))).p._fold_r()}for(var i=0,l=invocation_nodes.length,_,child;
i<l;++i){(child=(_=invocation_nodes[i])[1]=_[1][0]||empty)&&(child.p=_)}for(var i=0,l=groups.length,_;i<l;++i){(_=groups[i]).length||_.push(empty)}for(var i=0,l=ternaries.length,_,n,temp;
i<l;++i){n=(_=ternaries[i]).length,temp=_[0],_[0]=_[n-2],_[1]=temp,_[2]=_[n-1],_.length=3}while(head.p){head=head.p}for(var i=all_nodes.length-1,_;i>=0;--i){delete (_=all_nodes[i]).p,delete _.l,delete _.r
}head.suffix_data=prefix;return head};var bound_expression_template=caterwaul_global.parse("var _bindings; return(_expression)"),binding_template=caterwaul_global.parse("_variable = _base._variable"),undefined_binding=caterwaul_global.parse("undefined = void(0)"),late_bound_template=caterwaul_global.parse("(function (_bindings) {var _result=(_body);_result_init;return(_result)}).call(this, _expressions)"),late_bound_ref_table_template=caterwaul_global.parse("_result.caterwaul_expression_ref_table = _expression_ref_table");
caterwaul_global.compile=function(tree,environment,options){options=caterwaul_global.merge({gensym_renaming:true,transparent_errors:false,unbound_closure:false,guard:true},options);
tree=caterwaul_global.late_bound_tree(tree,null,options);if(options.guard){tree=tree.guarded()}var bindings=caterwaul_global.merge({},this._environment,environment,tree.bindings()),variables=[undefined_binding],s=gensym("base");
for(var k in bindings){if(own.call(bindings,k)&&k!=="this"){variables.push(binding_template.replace({_variable:k,_base:s}))}}var variable_definitions=new this.syntax(",",variables).unflatten(),function_body=bound_expression_template.replace({_bindings:variable_definitions,_expression:tree});
if(options.gensym_renaming){var renaming_table=this.gensym_rename_table(function_body);for(var k in bindings){own.call(bindings,k)&&(bindings[renaming_table[k]||k]=bindings[k])
}function_body=function_body.replace(renaming_table);s=renaming_table[s]}var code=function_body.toString(),closure=(function(){if(options.transparent_errors){return new Function(s,code)
}else{try{return new Function(s,code)}catch(e){throw new Error((e.message||e)+" while compiling "+code)}}})();return options.unbound_closure?closure:closure.call(bindings["this"],bindings)
};var trivial_node_template=caterwaul_global.parse("new caterwaul.syntax(_data)"),nontrivial_node_template=caterwaul_global.parse("new caterwaul.syntax(_data, _xs)"),node_prefix_template=caterwaul_global.parse("_x.prefix(_y)"),node_infix_template=caterwaul_global.parse("_x.infix(_y)"),node_suffix_template=caterwaul_global.parse("_x.suffix(_y)");
caterwaul_global.node_padding_annotations=function(node,node_expression){for(var xs=node.prefixes(),i=0,l=xs.length;i<l;++i){node_expression=node_prefix_template.replace({_x:node_expression,_y:caterwaul_global.syntax.from_string(xs[i])})
}for(var xs=node.infixes(),i=0,l=xs.length;i<l;++i){node_expression=node_infix_template.replace({_x:node_expression,_y:caterwaul_global.syntax.from_string(xs[i])})
}for(var xs=node.suffixes(),i=0,l=xs.length;i<l;++i){node_expression=node_suffix_template.replace({_x:node_expression,_y:caterwaul_global.syntax.from_string(xs[i])})
}return node_expression};caterwaul_global.syntax_to_expression=function(tree){if(tree.length){for(var comma=new caterwaul_global.syntax(","),i=0,l=tree.length;i<l;
++i){comma.push(caterwaul_global.syntax_to_expression(tree[i]))}return caterwaul_global.node_padding_annotations(tree,nontrivial_node_template.replace({_data:caterwaul_global.syntax.from_string(tree.data),_xs:comma.unflatten()}))
}else{return caterwaul_global.node_padding_annotations(tree,trivial_node_template.replace({_data:caterwaul_global.syntax.from_string(tree.data)}))}};caterwaul_global.late_bound_tree=function(tree,environment,options){options=caterwaul_global.merge({expression_ref_table:true},options);
tree=tree.rmap(function(node){return node.resolve()});var bindings=caterwaul_global.merge({},environment,tree.expressions()),variables=new caterwaul_global.syntax(","),expressions=new caterwaul_global.syntax(","),table={};
for(var k in bindings){if(own.call(bindings,k)){variables.push(new caterwaul_global.syntax(k)),expressions.push(bindings[k]),table[k]=caterwaul_global.syntax.from_string(bindings[k].toString())
}}var result_gensym=caterwaul_global.gensym("result"),result_initializer=options.expression_ref_table?late_bound_ref_table_template.replace({_result:result_gensym,_expression_ref_table:caterwaul_global.syntax.from_object(table)}):caterwaul_global.empty;
return variables.length?late_bound_template.replace({_bindings:variables.unflatten(),_expressions:expressions.unflatten(),_result:result_gensym,_result_init:result_initializer,_body:tree}):tree
};caterwaul_global.gensym_rename_table=function(tree){var names={},gensyms=[];tree.reach(function(node){var d=node.data;if(is_gensym(d)){names[d]||gensyms.push(d)
}names[d]=d.replace(/^(.*)_[a-z0-9]+_.{22}$/,"$1")||"anon"});var unseen_count={},next_unseen=function(name){if(!(name in names)){return name}var n=unseen_count[name]||0;
while(names[name+(++n).toString(36)]){}return name+(unseen_count[name]=n).toString(36)};for(var renamed={},i=0,l=gensyms.length,g;i<l;++i){renamed[g=gensyms[i]]||(names[renamed[g]=next_unseen(names[g])]=true)
}return renamed};var invoke_caterwaul_methods=function(methods){/^:/.test(methods)&&(methods=caterwaul_global[methods.substr(1)]);methods.constructor===String&&(methods=methods.split(/\s+/));
for(var i=1,l=methods.length,r=caterwaul_global[methods[0]]();i<l;++i){r=caterwaul_global[methods[i]](r)}return r};caterwaul_global.init=function(macroexpander){macroexpander||(macroexpander=function(x){return true
});return macroexpander.constructor===Function?se((function(){var result=function(f,environment,options){return typeof f==="function"||f.constructor===String?caterwaul_global.compile(result.call(result,caterwaul_global.parse(f)),environment,options):f.rmap(function(node){return macroexpander.call(result,node,environment,options)
})};return result})(),function(){this.global=caterwaul_global,this.macroexpander=macroexpander}):invoke_caterwaul_methods(macroexpander)};caterwaul_global.initializer=initializer;
caterwaul_global.clone=function(){return se(initializer(initializer,unique).deglobalize(),function(){for(var k in caterwaul_global){this[k]||(this[k]=caterwaul_global[k])
}})};var w_template=caterwaul_global.parse("(function (f) {return f(f)})(_x)"),module_template=caterwaul_global.parse("module(_name, _f)");caterwaul_global.replicator=function(options){if(options&&options.minimal_core_only){return w_template.replace({_x:new this.opaque_tree(this.core_initializer)})
}if(options&&options.core_only){return w_template.replace({_x:new this.opaque_tree(this.initializer)})}for(var i=0,ms=options&&options.modules||this.modules,c=[],l=ms.length;
i<l;++i){c.push(module_template.replace({_name:this.syntax.from_string(ms[i]),_f:new this.opaque_tree(this.module(ms[i]))}))}for(var i=0,l=c.length,result=new this.syntax(".",w_template.replace({_x:new this.opaque_tree(this.initializer)}));
i<l;++i){result.push(c[i])}return this.late_bound_tree(result.unflatten())};return caterwaul});
79 core/caterwaul/caterwaul.std.min.js
caterwaul.module("std.all-bundle",function($){$.all=[]});caterwaul.module("std.macro",function($){var syntax_manipulator=function(base_case){var result=function(x){if(x.constructor===Array){for(var i=0,l=x.length,ys=[];
i<l;++i){ys.push(result(x[i]))}return function(tree){for(var i=ys.length-1,r;i>=0;--i){if(r=ys[i].call(this,tree)){return r}}}}else{return x.constructor===String?result($.parse(x)):x.constructor===$.syntax?base_case.call(this,x):x
}};return result};$.pattern=syntax_manipulator(function(pattern){return function(tree){return pattern.match(tree)}});$.expander=syntax_manipulator(function(expander){return function(match){return expander.replace(match)
}});$.alternatives=syntax_manipulator(function(alternative){throw new Error("must use replacer functions with caterwaul.alternatives()")});$.reexpander=function(expander){var e=$.expander(expander);
return function(match){var r=e.call(this,match);return r&&this(r)}};var composer=function(expander_base_case){return function(pattern,expander){var new_pattern=$.pattern(pattern),new_expander=expander_base_case(expander);
return function(tree){var match=new_pattern.call(this,tree);return match&&new_expander.call(this,match)}}};$.replacer=composer($.expander);$.rereplacer=composer($.reexpander);
$.macroexpand=function(tree){return $($.alternatives(Array.prototype.slice.call(arguments,1)))(tree)}});caterwaul.module("std.anon",function($){$.anonymizer=function(){var xs=arguments;
return(function(){var table=(function(o){for(var r={},i=0,l=o.length,x;i<l;++i){x=o[i],r[x[0]]=x[1]}return r}).call(this,((function(xs){var x,x0,xi,xl,xr;for(var xr=new xs.constructor(),xi=0,xl=xs.length;
xi<xl;++xi){x=xs[xi],xr.push(([x,$.gensym(x)]))}return xr}).call(this,(function(xs){var x,x0,xi,xl,xr;for(var xr=new xs.constructor(),xi=0,xl=xs.length;xi<xl;++xi){x=xs[xi],xr.push.apply(xr,Array.prototype.slice.call((x.constructor===Array?x:x.split(" "))))
}return xr}).call(this,Array.prototype.slice.call((xs))))));return function(_){return(($).parse(_)).replace(table)}}).call(this)}});caterwaul.module("std.js",(function(qs,qs1,qs2,qs3,qs4,qs5,qs6,qs7,qs8,qs9,qsa,qsb,qsc,qsd,qse,qsf,qsg,qsh,qsi,qsj,qsk,qsl,qsm,qsn){var result1=(function($){$.js=function(macroexpander){var string_interpolator=function(node){var s=node.data,q=s.charAt(0),syntax=$.syntax;
if(q!=="'"&&q!=='"'||!/#\{[^\}]+\}/.test(s)){return false}for(var pieces=[],is_code=[],i=1,l=s.length-1,brace_depth=0,got_hash=false,start=1,c;i<l;++i){if(brace_depth){if((c=s.charAt(i))==="}"){--brace_depth||(pieces.push(s.substring(start,i)),is_code.push(true))&&(start=i+1),got_hash=false
}else{brace_depth+=c==="{"}}else{if((c=s.charAt(i))==="#"){got_hash=true}else{if(c==="{"&&got_hash){pieces.push(s.substring(start,i-1)),is_code.push(false),start=i+1,++brace_depth
}else{got_hash=false}}}}pieces.push(s.substring(start,l)),is_code.push(false);for(var quoted=new RegExp("\\\\"+q,"g"),i=0,l=pieces.length;i<l;++i){pieces[i]=is_code[i]?this($.parse(pieces[i].replace(quoted,q)).as("(")):new syntax(q+pieces[i]+q)
}return new syntax("+",pieces).unflatten().as("(")};var function_local_template=qs,function_bind_pattern=qs1,function_result_pattern=qs2,function_with_afters=qs3,function_without_afters=qs4,function_assignment_template=qs5,function_is_result=function(n){return n.is_empty()&&n.data==="result"
},function_destructure=$.rereplacer(qs6,function(match){for(var formals=[],befores=[],afters=[],ps=match._xs.flatten(","),i=0,l=ps.length,p;i<l;++i){p=this(ps[i]),(afters.length||p.contains(function_is_result)?afters:befores.length||p.length?befores:formals).push(p)
}for(var contains_locals=[befores,afters],i=0,l=contains_locals.length;i<l;++i){for(var xs=contains_locals[i],j=0,lj=xs.length,m;j<lj;++j){xs[j]=(m=function_bind_pattern.match(xs[j]))&&m._x.is_empty()?function_local_template.replace(m):xs[j].as("(")
}}var new_formals=formals.length?new $.syntax(",",formals).unflatten():$.empty,new_befores=befores.length?new $.syntax(";",befores).unflatten():$.empty,new_afters=afters.length?new $.syntax(";",afters).unflatten():$.empty,template=function_assignment_template.replace({_f:match._f,_x:afters.length?function_with_afters:function_without_afters});
return template.replace({_formals:new_formals,_befores:new_befores,_afters:new_afters,_result:match._y})});var tuple_template=qs7,tuple_constructor=qs8,tuple_assignment=qs9,tuple_destructure=$.rereplacer(qsa,function(match){for(var formals=match._xs.flatten(","),assignments=new $.syntax(";"),i=0,l=formals.length;
i<l;++i){assignments.push(tuple_assignment.replace({_name:formals[i]}))}return tuple_template.replace({_f:match._f,_g:$.gensym("tuple_ctor"),_ctor:tuple_constructor.replace({_formals:formals,_assignments:assignments.unflatten()}),_prototype:match._y})
});var infix_function=function(node){var d=node.data,left,fn;if((d==="/"||d==="|")&&(left=node[0]).data===d&&left[1]&&left[1].data==="u-"&&(fn=left[1][0])){return new $.syntax("()",fn,this(left[0]).flatten(d).push(this(node[1])).with_data(",").unflatten())
}};var infix_method=function(node){var d=node.data,left,fn;if((d==="/"||d==="|")&&(left=node[0]).data===d&&left[1]&&left[1].data==="u~"&&(fn=left[1][0])){var xs=[].slice.call(this(node[0][0]).flatten(d)),object=xs.shift();
return new $.syntax("()",new $.syntax(".",new $.syntax("(",object),fn),new $.syntax(",",xs,this(node[1])).unflatten())}};var postfix_function_template=qsb,postfix_function=$.rereplacer(qsc,function(match){return postfix_function_template.replace({_f:match._f,_x:this(match._x).flatten("/").with_data(",").unflatten()})
});var modified_literal_form=$.pattern(qsd),lookup_literal_modifier=function(caterwaul,type,modifier){var hash=caterwaul.literal_modifiers[type];return hash.hasOwnProperty(modifier)&&hash[modifier]
},literal_modifier=function(node){var modified_literal=modified_literal_form.call(this,node),literal,expander;if(modified_literal&&(literal=modified_literal._literal)&&(expander=literal.is_identifier()?lookup_literal_modifier(this,"identifier",modified_literal._modifier.data):literal.is_array()?lookup_literal_modifier(this,"array",modified_literal._modifier.data):literal.is_regexp()?lookup_literal_modifier(this,"regexp",modified_literal._modifier.data):literal.is_number()?lookup_literal_modifier(this,"number",modified_literal._modifier.data):literal.is_string()?lookup_literal_modifier(this,"string",modified_literal._modifier.data):null)){return expander.call(this,literal)
}};var bracket_modifier_form=$.pattern(qse),slash_modifier_form=$.pattern(qsf),minus_modifier_form=$.pattern(qsg),in_modifier_form=$.pattern(qsh),pipe_modifier_form=$.pattern(qsi),comma_modifier_form=$.pattern(qsj),dot_parameters=$.pattern(qsk),bracket_parameters=$.pattern(qsl),parameterized_wickets=$.pattern(qsm),parameterized_minus=$.pattern(qsn),modifier=function(node){var modifier,parameterized_match=parameterized_wickets.call(this,node)||parameterized_minus.call(this,node);
if(parameterized_match&&this.parameterized_modifiers.hasOwnProperty(modifier=parameterized_match._modifier.data)){var r=this.parameterized_modifiers[modifier].call(this,parameterized_match);
if(r){return r}}var regular_match=bracket_modifier_form.call(this,node)||slash_modifier_form.call(this,node)||minus_modifier_form.call(this,node)||in_modifier_form.call(this,node)||pipe_modifier_form.call(this,node)||comma_modifier_form.call(this,node);
if(regular_match){var parameter_match=dot_parameters.call(this,regular_match._modifier)||bracket_parameters.call(this,regular_match._modifier);if(parameter_match){regular_match._modifier=parameter_match._modifier;
regular_match._parameters=parameter_match._parameters;return this.parameterized_modifiers.hasOwnProperty(modifier=regular_match._modifier.data)&&this.parameterized_modifiers[modifier].call(this,regular_match)
}else{return this.modifiers.hasOwnProperty(modifier=regular_match._modifier.data)&&this.modifiers[modifier].call(this,regular_match)}}};var each_node=function(node){if(node.prefixes){var p=(function(xs1){var x,x0,xi,xl,xr;
for(var x,xi=0,xl=xs1.length,x1;xi<xl;++xi){x=xs1[xi];if(x1=(/^#/.test(x))){return x1}}return false}).call(this,node.prefixes()),i=(function(xs1){var x,x0,xi,xl,xr;
for(var x,xi=0,xl=xs1.length,x1;xi<xl;++xi){x=xs1[xi];if(x1=(/^#/.test(x))){return x1}}return false}).call(this,node.infixes()),s=(function(xs1){var x,x0,xi,xl,xr;
for(var x,xi=0,xl=xs1.length,x1;xi<xl;++xi){x=xs1[xi];if(x1=(/^#/.test(x))){return x1}}return false}).call(this,node.suffixes());(p||i||s)&&(node=node.thin_clone()),p&&(node.prefix_data=(function(xs1){var x,x0,xi,xl,xr;
for(var xr=new xs1.constructor(),xi=0,xl=xs1.length;xi<xl;++xi){x=xs1[xi],(/^#/.test(x))||xr.push(x)}return xr}).call(this,node.prefix_data)),i&&(node.infix_data=(function(xs1){var x,x0,xi,xl,xr;
for(var xr=new xs1.constructor(),xi=0,xl=xs1.length;xi<xl;++xi){x=xs1[xi],(/^#/.test(x))||xr.push(x)}return xr}).call(this,node.infix_data)),s&&(node.suffix_data=(function(xs1){var x,x0,xi,xl,xr;
for(var xr=new xs1.constructor(),xi=0,xl=xs1.length;xi<xl;++xi){x=xs1[xi],(/^#/.test(x))||xr.push(x)}return xr}).call(this,node.suffix_data))}return string_interpolator.call(this,node)||literal_modifier.call(this,node)||node.length&&(modifier.call(this,node)||function_destructure.call(this,node)||tuple_destructure.call(this,node)||infix_function.call(this,node)||infix_method.call(this,node)||postfix_function.call(this,node))
},result=macroexpander?$(function(node){return macroexpander.call(this,node)||each_node.call(this,node)}):$(each_node);result.modifiers={};result.parameterized_modifiers={};
result.literal_modifiers={regexp:{},array:{},string:{},number:{},identifier:{}};return result}});result1.caterwaul_expression_ref_table={qs:('new caterwaul.syntax( "var" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "_y") .prefix( " ")) .prefix( " "))'),qs1:('new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") ,new caterwaul.syntax( "_y") .prefix( " ")) .prefix( " ")'),qs2:('new caterwaul.syntax( "result")'),qs3:('new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_formals")) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "_befores") ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "result") .prefix( " ") ,new caterwaul.syntax( "_result") .prefix( " ")) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "_afters") .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "result") .prefix( " ")) .prefix( " "))) .prefix( " "))'),qs4:('new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_formals")) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "_befores") ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_result") .prefix( " ")) .prefix( " "))) .prefix( " "))'),qs5:('new caterwaul.syntax( "=" ,new caterwaul.syntax( "_f") ,new caterwaul.syntax( "_x") .prefix( " ")) .prefix( " ")'),qs6:('new caterwaul.syntax( "=" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "_f") ,new caterwaul.syntax( "_xs")) ,new caterwaul.syntax( "_y") .prefix( " ")) .prefix( " ")'),qs7:('new caterwaul.syntax( "=" ,new caterwaul.syntax( "_f") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "")) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_g") .prefix( " ") ,new caterwaul.syntax( "_ctor") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_g") .prefix( " ") ,new caterwaul.syntax( "prototype")) ,new caterwaul.syntax( "_prototype") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_g") .prefix( " ") ,new caterwaul.syntax( "prototype")) ,new caterwaul.syntax( "constructor")) ,new caterwaul.syntax( "_g") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_g") .prefix( " ")) .prefix( " "))) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "this"))) .prefix( " ")'),qs8:('new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_formals")) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( "_assignments")) .prefix( " "))'),qs9:('new caterwaul.syntax( "=" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "this") ,new caterwaul.syntax( "_name")) ,new caterwaul.syntax( "_name") .prefix( " ")) .prefix( " ")'),qsa:('new caterwaul.syntax( "*=" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "_f") ,new caterwaul.syntax( "_xs")) ,new caterwaul.syntax( "_y") .prefix( " ")) .prefix( " ")'),qsb:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "_f") ,new caterwaul.syntax( "_x"))'),qsc:('new caterwaul.syntax( "/" ,new caterwaul.syntax( "_x") ,new caterwaul.syntax( "u!" ,new caterwaul.syntax( "_f"))) .prefix( " ")'),qsd:('new caterwaul.syntax( "." ,new caterwaul.syntax( "_literal") ,new caterwaul.syntax( "_modifier"))'),qse:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_modifier") ,new caterwaul.syntax( "_expression"))'),qsf:('new caterwaul.syntax( "/" ,new caterwaul.syntax( "_expression") ,new caterwaul.syntax( "_modifier")) .prefix( " ")'),qsg:('new caterwaul.syntax( "-" ,new caterwaul.syntax( "_expression") ,new caterwaul.syntax( "_modifier")) .prefix( " ")'),qsh:('new caterwaul.syntax( "in" ,new caterwaul.syntax( "_modifier") ,new caterwaul.syntax( "_expression") .prefix( " ")) .prefix( " ")'),qsi:('new caterwaul.syntax( "|" ,new caterwaul.syntax( "_expression") ,new caterwaul.syntax( "_modifier")) .prefix( " ")'),qsj:('new caterwaul.syntax( "," ,new caterwaul.syntax( "_expression") ,new caterwaul.syntax( "_modifier") .prefix( " "))'),qsk:('new caterwaul.syntax( "." ,new caterwaul.syntax( "_modifier") ,new caterwaul.syntax( "_parameters"))'),qsl:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_modifier") ,new caterwaul.syntax( "_parameters"))'),qsm:('new caterwaul.syntax( ">" ,new caterwaul.syntax( "<" ,new caterwaul.syntax( "_expression") ,new caterwaul.syntax( "_modifier")) .prefix( " ") ,new caterwaul.syntax( "_parameters") .prefix( " "))'),qsn:('new caterwaul.syntax( "-" ,new caterwaul.syntax( "-" ,new caterwaul.syntax( "_expression") ,new caterwaul.syntax( "_modifier")) .prefix( " ") ,new caterwaul.syntax( "_parameters") .prefix( " "))')};
return(result1)}).call(this,new caterwaul.syntax("var",(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),(new caterwaul.syntax("_y")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",new caterwaul.syntax("_x"),(new caterwaul.syntax("_y")).prefix(" "))).prefix(" "),new caterwaul.syntax("result"),new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax("_formals"))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("_befores"),(new caterwaul.syntax("var",(new caterwaul.syntax("=",(new caterwaul.syntax("result")).prefix(" "),(new caterwaul.syntax("_result")).prefix(" "))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("_afters")).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("result")).prefix(" "))).prefix(" ")))).prefix(" ")),new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax("_formals"))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax(";",new caterwaul.syntax("_befores"),(new caterwaul.syntax("return",(new caterwaul.syntax("_result")).prefix(" "))).prefix(" ")))).prefix(" ")),(new caterwaul.syntax("=",new caterwaul.syntax("_f"),(new caterwaul.syntax("_x")).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",new caterwaul.syntax("()",new caterwaul.syntax("_f"),new caterwaul.syntax("_xs")),(new caterwaul.syntax("_y")).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",new caterwaul.syntax("_f"),new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("(",new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax(""))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",(new caterwaul.syntax("=",(new caterwaul.syntax("_g")).prefix(" "),(new caterwaul.syntax("_ctor")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",new caterwaul.syntax(".",(new caterwaul.syntax("_g")).prefix(" "),new caterwaul.syntax("prototype")),(new caterwaul.syntax("_prototype")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",new caterwaul.syntax(".",new caterwaul.syntax(".",(new caterwaul.syntax("_g")).prefix(" "),new caterwaul.syntax("prototype")),new caterwaul.syntax("constructor")),(new caterwaul.syntax("_g")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("_g")).prefix(" "))).prefix(" ")))).prefix(" ")))).prefix(" "),new caterwaul.syntax("call")),new caterwaul.syntax("this")))).prefix(" "),new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax("_formals"))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax("_assignments"))).prefix(" ")),(new caterwaul.syntax("=",new caterwaul.syntax(".",new caterwaul.syntax("this"),new caterwaul.syntax("_name")),(new caterwaul.syntax("_name")).prefix(" "))).prefix(" "),(new caterwaul.syntax("*=",new caterwaul.syntax("()",new caterwaul.syntax("_f"),new caterwaul.syntax("_xs")),(new caterwaul.syntax("_y")).prefix(" "))).prefix(" "),new caterwaul.syntax("()",new caterwaul.syntax("_f"),new caterwaul.syntax("_x")),(new caterwaul.syntax("/",new caterwaul.syntax("_x"),new caterwaul.syntax("u!",new caterwaul.syntax("_f")))).prefix(" "),new caterwaul.syntax(".",new caterwaul.syntax("_literal"),new caterwaul.syntax("_modifier")),new caterwaul.syntax("[]",new caterwaul.syntax("_modifier"),new caterwaul.syntax("_expression")),(new caterwaul.syntax("/",new caterwaul.syntax("_expression"),new caterwaul.syntax("_modifier"))).prefix(" "),(new caterwaul.syntax("-",new caterwaul.syntax("_expression"),new caterwaul.syntax("_modifier"))).prefix(" "),(new caterwaul.syntax("in",new caterwaul.syntax("_modifier"),(new caterwaul.syntax("_expression")).prefix(" "))).prefix(" "),(new caterwaul.syntax("|",new caterwaul.syntax("_expression"),new caterwaul.syntax("_modifier"))).prefix(" "),new caterwaul.syntax(",",new caterwaul.syntax("_expression"),(new caterwaul.syntax("_modifier")).prefix(" ")),new caterwaul.syntax(".",new caterwaul.syntax("_modifier"),new caterwaul.syntax("_parameters")),new caterwaul.syntax("[]",new caterwaul.syntax("_modifier"),new caterwaul.syntax("_parameters")),new caterwaul.syntax(">",(new caterwaul.syntax("<",new caterwaul.syntax("_expression"),new caterwaul.syntax("_modifier"))).prefix(" "),(new caterwaul.syntax("_parameters")).prefix(" ")),new caterwaul.syntax("-",(new caterwaul.syntax("-",new caterwaul.syntax("_expression"),new caterwaul.syntax("_modifier"))).prefix(" "),(new caterwaul.syntax("_parameters")).prefix(" "))));
caterwaul.module("std.js-literals",(function(qs1,qs2){var result=(function($){$.js_literals=function(caterwaul_function){var function_template=qs1;(function(r){r.x=$.reexpander(function(node){return node.with_data(node.data.replace(/\s+/g,""))
});var call_exec_template=qs2;r.qf=function(node){return function_template.replace({_body:call_exec_template.replace({_regexp:node})})}})(caterwaul_function.literal_modifiers.regexp);
(function(s){s.qw=$.reexpander(function(node){for(var array_node=new $.syntax("["),comma=new $.syntax(","),delimiter=node.data.charAt(0),pieces=node.as_escaped_string().split(/\s+/),i=0,l=pieces.length;
i<l;++i){comma.push(new $.syntax(delimiter+pieces[i]+delimiter))}return array_node.push(comma.unflatten())});s.qh=$.reexpander(function(node){for(var hash_node=new $.syntax("{"),comma=new $.syntax(","),delimiter=node.data.charAt(0),pieces=node.as_escaped_string().split(/\s+/),i=0,l=pieces.length;
i<l;i+=2){comma.push(new $.syntax(":",new $.syntax(delimiter+pieces[i]+delimiter),new $.syntax(delimiter+pieces[i+1]+delimiter)))}return hash_node.push(comma.unflatten())
});s.qr=$.reexpander(function(node){return node.with_data("/"+node.as_escaped_string().replace(/\//g,"\\/")+"/")});s.qs=function(node){return new $.expression_ref($.syntax_to_expression($.parse(node.as_unescaped_string())),"qs")
};s.qse=function(node){return new $.expression_ref($.syntax_to_expression(this.call(this,$.parse(node.as_unescaped_string()))),"qse")};s.qf=$.reexpander(function(node){return function_template.replace({_body:$.parse(node.as_unescaped_string())})
})})(caterwaul_function.literal_modifiers.string);return caterwaul_function}});result.caterwaul_expression_ref_table={qs1:('new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_")) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_body") .prefix( " "))) .prefix( " "))'),qs2:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_regexp") ,new caterwaul.syntax( "exec")) ,new caterwaul.syntax( "_"))')};
return(result)}).call(this,new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax("_"))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax("return",(new caterwaul.syntax("_body")).prefix(" ")))).prefix(" ")),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("_regexp"),new caterwaul.syntax("exec")),new caterwaul.syntax("_"))));
caterwaul.module("std.words",(function(qs1,qs2,qs3,qs4,qs5,qs6,qs7,qs8,qs9,qsa,qsb,qsc,qsd,qsf,qsg,qsh,qsi,qsj){var result=(function($){(function(){var scope_template=qs1;
return $.words=function(caterwaul_function){return($.merge(caterwaul_function.modifiers,$.words.modifiers),$.merge(caterwaul_function.parameterized_modifiers,$.words.parameterized_modifiers),caterwaul_function)
},$.words.modifiers={qs:function(match){return new $.expression_ref($.syntax_to_expression(match._expression),"qs")},qse:function(match){return new $.expression_ref($.syntax_to_expression(this(match._expression)),"qse")
},qc:function(match){return $.compile(this(match._expression))},qce:function(match){return this($.compile(this(match._expression)))},reexpand:function(match){return this(this(match._expression))
},noexpand:function(match){return match._expression},raise:$.reexpander(qs2),eval:function(match){return new $.ref($.compile(this(match._expression)),"eval")},ahead:function(match){return new $.expression_ref(this(match._expression),"ahead")
},capture:function(match){for(var comma=new $.syntax(","),bindings=match._expression.flatten(","),i=0,l=bindings.length;i<l;++i){comma.push(this(bindings[i]).with_data(":"))
}return new $.syntax("{",comma.unflatten())},wcapture:function(match){for(var e=this(match._expression),comma=new $.syntax(","),bindings=e.flatten(","),node,i=0,l=bindings.length;
i<l;++i){(node=this(bindings[i]))[1]=node[0],comma.push(node.with_data(":"))}return scope_template.replace({_variables:e,_expression:new $.syntax("{",comma.unflatten())})
}},$.words.parameterized_modifiers={given:$.reexpander(qs3),bgiven:$.reexpander(qs4),rescue:$.reexpander(qs5),se:$.reexpander(qs6),re:$.reexpander(qs7),then:$.reexpander(qs8),eq:$.reexpander(qs9),ocq:$.reexpander(qsa),dcq:$.reexpander(qsb),acq:$.reexpander(qsc),ncq:$.reexpander(qsd),where:$.reexpander(qsf),using:$.reexpander(function(match){var m=this(match._parameters),o=$.compile(m),comma=new $.syntax(","),expression_ref=new $.expression_ref(m);
for(var k in o){Object.prototype.hasOwnProperty.call(o,k)&&/^[_$a-zA-Z][_$0-9a-zA-Z]*$/.test(k)&&!this.modifiers.hasOwnProperty(k)&&!this.parameterized_modifiers.hasOwnProperty(k)&&comma.push(new $.syntax("=",k,new $.syntax(".",expression_ref,k)))
}return scope_template.replace({_variables:comma.unflatten(),_expression:match._expression})}),when:$.reexpander(qsg),and:$.reexpander(qsh),unless:$.reexpander(qsi),or:$.reexpander(qsj)}
}).call(this)});result.caterwaul_expression_ref_table={qs1:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "")) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "_variables") .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_expression") .prefix( " ")) .prefix( " "))) .prefix( " "))) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "this"))'),qs2:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "")) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( "throw" ,new caterwaul.syntax( "_expression") .prefix( " "))) .prefix( " "))) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "this"))'),qs3:('new caterwaul.syntax( "(" ,new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_parameters")) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_expression") .prefix( " "))) .prefix( " ")))'),qs4:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "t") ,new caterwaul.syntax( "f") .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "")) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "f") .prefix( " ") ,new caterwaul.syntax( "apply")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "t") ,new caterwaul.syntax( "arguments") .prefix( " "))))) .prefix( " ")) .prefix( " "))) .prefix( " "))) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "this") ,new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_parameters")) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_expression") .prefix( " "))) .prefix( " ")) .prefix( " ")))'),qs5:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "")) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( "try" ,new caterwaul.syntax( "{" ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_expression") .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "catch" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "e")) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_parameters") .prefix( " "))) .prefix( " ")) .prefix( " "))) .prefix( " "))) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "this"))'),qs6:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "it")) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_parameters") .prefix( " ") ,new caterwaul.syntax( "it") .prefix( " ")))) .prefix( " "))) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "this") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_expression")) .prefix( " ")))'),qs7:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "it")) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_parameters") .prefix( " "))) .prefix( " "))) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "this") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_expression")) .prefix( " ")))'),qs8:('new caterwaul.syntax( "(" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_expression") ,new caterwaul.syntax( "_parameters") .prefix( " ")))'),qs9:('new caterwaul.syntax( "=" ,new caterwaul.syntax( "_expression") ,new caterwaul.syntax( "_parameters") .prefix( " ")) .prefix( " ")'),qsa:('new caterwaul.syntax( "?" ,new caterwaul.syntax( "_expression") ,new caterwaul.syntax( "_expression") .prefix( " ") .infix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_expression") .prefix( " ") ,new caterwaul.syntax( "_parameters") .prefix( " ")) .prefix( " ")) .prefix( " ")'),qsb:('new caterwaul.syntax( "?" ,new caterwaul.syntax( "!==" ,new caterwaul.syntax( "_expression") ,new caterwaul.syntax( "void" ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "_expression") .prefix( " ") .infix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_expression") .prefix( " ") ,new caterwaul.syntax( "_parameters") .prefix( " ")) .prefix( " ")) .prefix( " ")'),qsc:('new caterwaul.syntax( "?" ,new caterwaul.syntax( "u!" ,new caterwaul.syntax( "_expression")) ,new caterwaul.syntax( "_expression") .prefix( " ") .infix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_expression") .prefix( " ") ,new caterwaul.syntax( "_parameters") .prefix( " ")) .prefix( " ")) .prefix( " ")'),qsd:('new caterwaul.syntax( "?" ,new caterwaul.syntax( "!=" ,new caterwaul.syntax( "_expression") ,new caterwaul.syntax( "void" ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( "  ")) .prefix( " ") ,new caterwaul.syntax( "_expression") .prefix( " ") .infix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_expression") .prefix( " ") ,new caterwaul.syntax( "_parameters") .prefix( " ")) .prefix( " ")) .prefix( " ")'),qsf:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "")) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "_parameters") .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_expression") .prefix( " ")) .prefix( " "))) .prefix( " "))) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "this"))'),qsg:('new caterwaul.syntax( "&&" ,new caterwaul.syntax( "_parameters") ,new caterwaul.syntax( "_expression") .prefix( " ")) .prefix( " ")'),qsh:('new caterwaul.syntax( "&&" ,new caterwaul.syntax( "_expression") ,new caterwaul.syntax( "_parameters") .prefix( " ")) .prefix( " ")'),qsi:('new caterwaul.syntax( "&&" ,new caterwaul.syntax( "u!" ,new caterwaul.syntax( "_parameters") .prefix( " ")) ,new caterwaul.syntax( "_expression") .prefix( " ")) .prefix( " ")'),qsj:('new caterwaul.syntax( "||" ,new caterwaul.syntax( "_expression") ,new caterwaul.syntax( "_parameters") .prefix( " ")) .prefix( " ")')};
return(result)}).call(this,new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("(",new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax(""))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax(";",new caterwaul.syntax("var",(new caterwaul.syntax("_variables")).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("_expression")).prefix(" "))).prefix(" ")))).prefix(" "))),new caterwaul.syntax("call")),new caterwaul.syntax("this")),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("(",new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax(""))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax("throw",(new caterwaul.syntax("_expression")).prefix(" ")))).prefix(" "))),new caterwaul.syntax("call")),new caterwaul.syntax("this")),new caterwaul.syntax("(",new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax("_parameters"))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax("return",(new caterwaul.syntax("_expression")).prefix(" ")))).prefix(" "))),new caterwaul.syntax("()",new caterwaul.syntax("(",new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax(",",new caterwaul.syntax("t"),(new caterwaul.syntax("f")).prefix(" ")))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax("return",(new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax(""))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax("return",new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("f")).prefix(" "),new caterwaul.syntax("apply")),new caterwaul.syntax(",",new caterwaul.syntax("t"),(new caterwaul.syntax("arguments")).prefix(" ")))))).prefix(" "))).prefix(" ")))).prefix(" "))),new caterwaul.syntax(",",new caterwaul.syntax("this"),(new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax("_parameters"))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax("return",(new caterwaul.syntax("_expression")).prefix(" ")))).prefix(" "))).prefix(" "))),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("(",new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax(""))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax("try",(new caterwaul.syntax("{",new caterwaul.syntax("return",(new caterwaul.syntax("_expression")).prefix(" ")))).prefix(" "),(new caterwaul.syntax("catch",(new caterwaul.syntax("(",new caterwaul.syntax("e"))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax("return",(new caterwaul.syntax("_parameters")).prefix(" ")))).prefix(" "))).prefix(" ")))).prefix(" "))),new caterwaul.syntax("call")),new caterwaul.syntax("this")),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("(",new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax("it"))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax("return",new caterwaul.syntax(",",(new caterwaul.syntax("_parameters")).prefix(" "),(new caterwaul.syntax("it")).prefix(" "))))).prefix(" "))),new caterwaul.syntax("call")),new caterwaul.syntax(",",new caterwaul.syntax("this"),(new caterwaul.syntax("(",new caterwaul.syntax("_expression"))).prefix(" "))),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("(",new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax("it"))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax("return",(new caterwaul.syntax("_parameters")).prefix(" ")))).prefix(" "))),new caterwaul.syntax("call")),new caterwaul.syntax(",",new caterwaul.syntax("this"),(new caterwaul.syntax("(",new caterwaul.syntax("_expression"))).prefix(" "))),new caterwaul.syntax("(",new caterwaul.syntax(",",new caterwaul.syntax("_expression"),(new caterwaul.syntax("_parameters")).prefix(" "))),(new caterwaul.syntax("=",new caterwaul.syntax("_expression"),(new caterwaul.syntax("_parameters")).prefix(" "))).prefix(" "),(new caterwaul.syntax("?",new caterwaul.syntax("_expression"),(new caterwaul.syntax("_expression")).prefix(" ").infix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_expression")).prefix(" "),(new caterwaul.syntax("_parameters")).prefix(" "))).prefix(" "))).prefix(" "),(new caterwaul.syntax("?",(new caterwaul.syntax("!==",new caterwaul.syntax("_expression"),(new caterwaul.syntax("void",(new caterwaul.syntax("0")).prefix(" "))).prefix(" "))).prefix(" "),(new caterwaul.syntax("_expression")).prefix(" ").infix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_expression")).prefix(" "),(new caterwaul.syntax("_parameters")).prefix(" "))).prefix(" "))).prefix(" "),(new caterwaul.syntax("?",new caterwaul.syntax("u!",new caterwaul.syntax("_expression")),(new caterwaul.syntax("_expression")).prefix(" ").infix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_expression")).prefix(" "),(new caterwaul.syntax("_parameters")).prefix(" "))).prefix(" "))).prefix(" "),(new caterwaul.syntax("?",(new caterwaul.syntax("!=",new caterwaul.syntax("_expression"),(new caterwaul.syntax("void",(new caterwaul.syntax("0")).prefix(" "))).prefix("  "))).prefix(" "),(new caterwaul.syntax("_expression")).prefix(" ").infix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_expression")).prefix(" "),(new caterwaul.syntax("_parameters")).prefix(" "))).prefix(" "))).prefix(" "),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("(",new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax(""))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax(";",new caterwaul.syntax("var",(new caterwaul.syntax("_parameters")).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("_expression")).prefix(" "))).prefix(" ")))).prefix(" "))),new caterwaul.syntax("call")),new caterwaul.syntax("this")),(new caterwaul.syntax("&&",new caterwaul.syntax("_parameters"),(new caterwaul.syntax("_expression")).prefix(" "))).prefix(" "),(new caterwaul.syntax("&&",new caterwaul.syntax("_expression"),(new caterwaul.syntax("_parameters")).prefix(" "))).prefix(" "),(new caterwaul.syntax("&&",new caterwaul.syntax("u!",(new caterwaul.syntax("_parameters")).prefix(" ")),(new caterwaul.syntax("_expression")).prefix(" "))).prefix(" "),(new caterwaul.syntax("||",new caterwaul.syntax("_expression"),(new caterwaul.syntax("_parameters")).prefix(" "))).prefix(" ")));
caterwaul.module("std.grammar",(function(qs){var result=(function($){$.grammar=function(anonymous_symbols,options,rule_cc){return(function(){var default_options={fix:true,descend:true,initial:qs},settings=$.merge({},default_options,options),anon=$.anonymizer(anonymous_symbols),anon_pattern=anon(settings.initial),rule=function(p,e){return $[settings.fix?"rereplacer":"replacer"](anon(p),e.constructor===$.syntax?anon(e):e)
},expand=(function(it){return settings.descend?$(it):it}).call(this,($.alternatives(rule_cc(rule,anon))));return function(_){return(function(it){return this.constructor===Function?it&&this(it):it
}).call(this,(expand.call(expand,(anon_pattern).replace(_))))}}).call(this)}});result.caterwaul_expression_ref_table={qs:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_expression"))')};
return(result)}).call(this,new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_expression"))));caterwaul.module("std.seq",(function(qs,qs1,qs2,qs3,qs4,qs5,qs6,qs7,qs8,qs9,qsa,qsb,qsc,qsd,qse,qsf,qsg,qsh,qsi,qsj,qsk,qsl,qsm,qsn,qso,qsp,qsq,qsr,qss,qst,qsu,qsv,qsw,qsx,qsy,qsz,qs10,qs11,qs12,qs13,qs14,qs15,qs16,qs17,qs18,qs19,qs1a,qs1b,qs1c,qs1d,qs1e,qs1f,qs1g,qs1h,qs1i,qs1j,qs1k,qs1l,qs1m,qs1n,qs1o,qs1p,qs1q,qs1r,qs1s,qs1t,qs1u,qs1v,qs1w,qs1x,qs1y,qs1z,qs20,qs21,qs22,qs23,qs24,qs25,qs26,qs27,qs28,qs29,qs2a,qs2b,qs2c,qs2d,qs2e,qs2f,qs2g,qs2h,qs2i,qs2j,qs2k,qs2l,qs2m,qs2n,qs2o,qs2p){var result=(function($){$.seq=function(caterwaul_function){return(function(it){return it.modifiers.seq=$.grammar("S",{initial:qs},(function(rule,anon){return(function(){var operator_macros=(function(){var loop_anon=$.anonymizer("x","y","i","j","l","lj","r","o","k"),scope=anon(qs1),scoped=function(t){return(scope).replace({_body:t})
},form=function(x){return(function(it){return it.uses_x0=/_x0\s*=/.test(x.toString()),it}).call(this,(loop_anon(scoped(anon(x)))))},map=form(qs2),each=form(qs3),flatmap=form(qs4),iterate=form(qs5),filter=form(qs6),filter_not=form(qs7),map_filter=form(qs8),imap_filter=form(qs9),foldl=form(qsa),foldr=form(qsb),unfold=form(qsc),ifoldl=form(qsd),ifoldr=form(qse),iunfold=form(qsf),exists=form(qsg),not_exists=form(qsh),r_exists=form(qsi),iexists=form(qsj),ir_exists=form(qsk),concat=anon(qsl),kmap=form(qsm),keach=form(qsn),kfilter=form(qso),kfilter_not=form(qsp),kmap_filter=form(qsq),vmap=form(qsr),veach=form(qss),vfilter=form(qst),vfilter_not=form(qsu),vmap_filter=form(qsv);
return(function(){var operator_case=function(forms){return function(match){return(function(){var use=function(form,iform){return function(body){return render_form(match._xs,body,form,iform)
}};return parse_modifiers(match._thing,use(forms.normal,forms.inormal),use(forms.bang,forms.ibang),use(forms.tbang,forms.itbang))}).call(this)}},map_forms=operator_case({normal:map,bang:each,tbang:flatmap,itbang:iterate}),filter_forms=operator_case({normal:filter,bang:filter_not,tbang:map_filter,itbang:imap_filter}),fold_forms=operator_case({normal:foldl,bang:foldr,tbang:unfold,inormal:ifoldl,ibang:ifoldr,itbang:iunfold}),kmap_forms=operator_case({normal:kmap,bang:keach}),kfilter_forms=operator_case({normal:kfilter,bang:kfilter_not,tbang:kmap_filter}),vmap_forms=operator_case({normal:vmap,bang:veach}),vfilter_forms=operator_case({normal:vfilter,bang:vfilter_not,tbang:vmap_filter}),exists_forms=operator_case({normal:exists,bang:not_exists,tbang:r_exists,inormal:iexists,itbang:ir_exists}),parse_modifiers=function(tree,n,b,tb){return(function(){var r=null;
return((r=qsw.match(tree))?tb(r._x):(r=qsx.match(tree))?b(r._x):n(tree))}).call(this)},render_form=function(xs,body,form,iform){return(function(){var r=null,use=function(f,match){return f.replace($.merge({_f:match._x,_init:match._init,_s:xs},names_for(match._var)))
},promote=function(f,body){return((f).replace({_f:(f.uses_x0?qsy:qsz).replace($.merge({_f:body},gensym_names)),_s:xs})).replace(gensym_names)};return((r=qs10.match(body)||qs11.match(body))?use(iform,r):(r=qs12.match(body)||qs13.match(body))?use(form,r):promote(form,body))
}).call(this)},names_for=function(p){return p?{_x:p,_x0:(""+(p)+"0"),_xi:(""+(p)+"i"),_xl:(""+(p)+"l"),_xs:(""+(p)+"s"),_xr:(""+(p)+"r")}:{_x:"x",_x0:"x0",_xi:"xi",_xl:"xl",_xs:"xs",_xr:"xr"}
},gensym_names=(function(xs1){var x1,x0,xi,xl,xr;var xr=new xs1.constructor();for(var k in xs1){if(Object.prototype.hasOwnProperty.call(xs1,k)){x1=xs1[k],xr[k]=($.gensym(x1))
}}return xr}).call(this,names_for(null));return[rule(qs14,qs15),rule(qs16,concat),rule(qs17,qs18),rule(qs19,qs1a),rule(qs1b,qs1c),rule(qs1d,qs1e),rule(qs1f,qs1g),rule(qs1h,qs1i),rule(qs1j,qs1k),rule(qs1l,qs1m),rule(qs1n,qs1o),rule(qs1p,qs1q),rule(qs1r,qs1s),rule(qs1t,qs1u),rule(qs1v,filter_forms),rule(qs1w,map_forms),rule(qs1x,fold_forms),rule(qs1y,exists_forms),rule(qs1z,kmap_forms),rule(qs20,vmap_forms),rule(qs21,kfilter_forms),rule(qs22,vfilter_forms)]
}).call(this)}).call(this),word_macros=(function(){var n=function(match){return n_pattern.replace($.merge({_l:"0",_step:"1"},match))},ni=function(match){return ni_pattern.replace($.merge({_l:"0",_step:"1"},match))
},scope=anon(qs23),scoped=function(t){return scope.replace({_body:t})},form=function(p){return(function(){var tree=scoped(anon(p));return function(_){return tree.replace(_)
}}).call(this)},n_pattern=anon(qs24),ni_pattern=anon(qs25),keys=form(qs26),values=form(qs27),pairs=form(qs28),object=form(qs29),mobject=form(qs2a);return[rule(qs2b,n),rule(qs2c,ni),rule(qs2d,n),rule(qs2e,ni),rule(qs2f,n),rule(qs2g,ni),rule(qs2h,keys),rule(qs2i,object),rule(qs2j,mobject),rule(qs2k,values),rule(qs2l,object),rule(qs2m,mobject),rule(qs2n,pairs),rule(qs2o,object),rule(qs2p,mobject)]
}).call(this);return(operator_macros).concat(word_macros)}).call(this)})),it}).call(this,(caterwaul_function))}});result.caterwaul_expression_ref_table={qs:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_expression"))'),qs1:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_xs")) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "_x0") .prefix( " ")) ,new caterwaul.syntax( "_xi") .prefix( " ")) ,new caterwaul.syntax( "_xl") .prefix( " ")) ,new caterwaul.syntax( "_xr") .prefix( " "))) ,new caterwaul.syntax( "_body") .prefix( " "))) .prefix( " "))) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "this") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") .prefix( " ") ,new caterwaul.syntax( "_s"))))'),qs2:('new caterwaul.syntax( ";" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "new" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "constructor")) ,new caterwaul.syntax( ""))) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "length"))) .prefix( " "))) ,new caterwaul.syntax( "<" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "_xl") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u++" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_xi"))) .prefix( " ") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "push")) ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f"))))) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xr") .prefix( " ")) .prefix( "                                        "))'),qs3:('new caterwaul.syntax( ";" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( "                              ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "length"))) .prefix( " "))) ,new caterwaul.syntax( "<" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "_xl") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u++" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_xi"))) .prefix( " ") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( " "))) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xs") .prefix( " ")) .prefix( "                                                  "))'),qs4:('new caterwaul.syntax( ";" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "new" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "constructor")) ,new caterwaul.syntax( ""))) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "length"))) .prefix( " "))) ,new caterwaul.syntax( "<" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "_xl") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u++" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_xi"))) .prefix( " ") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "push")) ,new caterwaul.syntax( "apply")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_xr") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "Array") .prefix( " ") ,new caterwaul.syntax( "prototype")) ,new caterwaul.syntax( "slice")) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f"))))))) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xr") .prefix( " ")) .prefix( " "))'),qs5:('new caterwaul.syntax( ";" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "_xs") .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "_x0") .prefix( " ")) ,new caterwaul.syntax( "_xl") .prefix( " "))) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x0") .prefix( " ") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_init")) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u++" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_x") .prefix( " ")) .prefix( " "))'),qs6:('new caterwaul.syntax( ";" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "new" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "constructor")) ,new caterwaul.syntax( ""))) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "length"))) .prefix( " "))) ,new caterwaul.syntax( "<" ,new caterwaul.syntax( "_xi") .prefix( "    ") ,new caterwaul.syntax( "_xl") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u++" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_xi"))) .prefix( " ") ,new caterwaul.syntax( "&&" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( " ") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "push")) ,new caterwaul.syntax( "_x"))) .prefix( " "))) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xr") .prefix( " ")) .prefix( "      "))'),qs7:('new caterwaul.syntax( ";" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "new" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "constructor")) ,new caterwaul.syntax( ""))) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "length"))) .prefix( " "))) ,new caterwaul.syntax( "<" ,new caterwaul.syntax( "_xi") .prefix( "    ") ,new caterwaul.syntax( "_xl") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u++" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_xi"))) .prefix( " ") ,new caterwaul.syntax( "||" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( " ") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "push")) ,new caterwaul.syntax( "_x"))) .prefix( " "))) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xr") .prefix( " ")) .prefix( "      "))'),qs8:('new caterwaul.syntax( ";" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "new" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "constructor")) ,new caterwaul.syntax( ""))) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "length"))) .prefix( " ")) ,new caterwaul.syntax( "y") .prefix( " "))) ,new caterwaul.syntax( "<" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "_xl") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u++" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_xi"))) .prefix( " ") ,new caterwaul.syntax( "&&" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "y") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( " ")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "push")) ,new caterwaul.syntax( "y"))) .prefix( " "))) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xr") .prefix( " ")) .prefix( " "))'),qs9:('new caterwaul.syntax( ";" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "new" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "constructor")) ,new caterwaul.syntax( ""))) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "length"))) .prefix( " ")) ,new caterwaul.syntax( "_x0") .prefix( " "))) ,new caterwaul.syntax( "<" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "_xl") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u++" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_xi"))) .prefix( " ") ,new caterwaul.syntax( "&&" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x0") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_init")) .prefix( " ")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "push")) ,new caterwaul.syntax( "_f"))) .prefix( " "))) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xr") .prefix( " ")) .prefix( " "))'),qsa:('new caterwaul.syntax( ";" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x0") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "0"))) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "1") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "length"))) .prefix( " "))) ,new caterwaul.syntax( "<" ,new caterwaul.syntax( "_xi") .prefix( "            ") ,new caterwaul.syntax( "_xl") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u++" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_xi"))) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x0") .prefix( " ") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( " ")) .prefix( " "))) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_x0") .prefix( " ")) .prefix( " "))'),qsb:('new caterwaul.syntax( ";" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "length"))) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "-" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "2") .prefix( " ")) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x0") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "-" ,new caterwaul.syntax( "_xl") ,new caterwaul.syntax( "1") .prefix( " ")) .prefix( " "))) .prefix( " "))) ,new caterwaul.syntax( ">=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u--" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_xi"))) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x0") .prefix( " ") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( " ")) .prefix( " "))) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_x0") .prefix( " ")) .prefix( " "))'),qsc:('new caterwaul.syntax( ";" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "_xs") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " "))) ,new caterwaul.syntax( "!==" ,new caterwaul.syntax( "_x") .prefix( "                      ") ,new caterwaul.syntax( "null") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u++" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "push")) ,new caterwaul.syntax( "_x")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( " ")) .prefix( " "))) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xr") .prefix( " ")) .prefix( "   "))'),qsd:('new caterwaul.syntax( ";" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x0") .prefix( " ") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_init")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "length"))) .prefix( " "))) ,new caterwaul.syntax( "<" ,new caterwaul.syntax( "_xi") .prefix( "      ") ,new caterwaul.syntax( "_xl") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u++" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_xi"))) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x0") .prefix( " ") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( " ")) .prefix( " "))) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_x0") .prefix( " ")) .prefix( "      "))'),qse:('new caterwaul.syntax( ";" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "-" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "length")) ,new caterwaul.syntax( "1") .prefix( " ")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "_xl") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x0") .prefix( " ") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_init")) .prefix( " ")) .prefix( " "))) ,new caterwaul.syntax( ">=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u--" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_xi"))) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x0") .prefix( " ") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( " ")) .prefix( " "))) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_x0") .prefix( " ")) .prefix( "      "))'),qsf:('new caterwaul.syntax( ";" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "_xs") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "_x0") .prefix( " "))) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x0") .prefix( "          ") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_init")) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u++" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "push")) ,new caterwaul.syntax( "_x")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( " ")) .prefix( " "))) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xr") .prefix( " ")) .prefix( "        "))'),qsg:('new caterwaul.syntax( "i;" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "length"))) .prefix( " ")) ,new caterwaul.syntax( "x") .prefix( " "))) ,new caterwaul.syntax( "<" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "_xl") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u++" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_xi"))) .prefix( " ") ,new caterwaul.syntax( "if" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( " ")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "x") .prefix( " ")) .prefix( " ")) .prefix( " "))) .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "false") .prefix( " ")) .prefix( " "))'),qsh:('new caterwaul.syntax( "i;" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "length"))) .prefix( " ")) ,new caterwaul.syntax( "x") .prefix( " "))) ,new caterwaul.syntax( "<" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "_xl") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u++" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_xi"))) .prefix( " ") ,new caterwaul.syntax( "if" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( " ")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "false") .prefix( " ")) .prefix( " ")) .prefix( " "))) .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "true") .prefix( " ")) .prefix( " "))'),qsi:('new caterwaul.syntax( "i;" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "length"))) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "-" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "1") .prefix( " ")) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "_x") .prefix( " ")) ,new caterwaul.syntax( "x") .prefix( " "))) ,new caterwaul.syntax( ">=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u--" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_xi"))) .prefix( " ") ,new caterwaul.syntax( "if" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( " ")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "x") .prefix( " ")) .prefix( " ")) .prefix( " "))) .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "false") .prefix( " ")) .prefix( " "))'),qsj:('new caterwaul.syntax( "i;" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "length"))) .prefix( " ")) ,new caterwaul.syntax( "x") .prefix( " "))) ,new caterwaul.syntax( "<" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "_xl") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u++" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_xi"))) .prefix( " ") ,new caterwaul.syntax( "if" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x0") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_init")) .prefix( " ")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_f") .prefix( " ")) .prefix( " ")) .prefix( " "))) .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "false") .prefix( " ")) .prefix( " "))'),qsk:('new caterwaul.syntax( "i;" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "length"))) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "-" ,new caterwaul.syntax( "_xl") .prefix( " ") ,new caterwaul.syntax( "1") .prefix( " ")) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "_x") .prefix( " ")) ,new caterwaul.syntax( "x") .prefix( " "))) ,new caterwaul.syntax( ">=" ,new caterwaul.syntax( "_xi") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u--" ,new caterwaul.syntax( "_xi")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_xi"))) .prefix( " ") ,new caterwaul.syntax( "if" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x0") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_init")) .prefix( " ")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_f") .prefix( " ")) .prefix( " ")) .prefix( " "))) .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "false") .prefix( " ")) .prefix( " "))'),qsl:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_xs"))) ,new caterwaul.syntax( "concat")) ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_ys"))))'),qsm:('new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "new" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "constructor")) ,new caterwaul.syntax( ""))) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "in" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "_xs") .prefix( " ")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "if" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "Object") ,new caterwaul.syntax( "prototype")) ,new caterwaul.syntax( "hasOwnProperty")) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "_x") .prefix( " ")))) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "_f")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_x"))) .prefix( " ")) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xr") .prefix( " ")) .prefix( " "))'),qsn:('new caterwaul.syntax( ";" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "in" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "_xs") .prefix( " ")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "if" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "Object") ,new caterwaul.syntax( "prototype")) ,new caterwaul.syntax( "hasOwnProperty")) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "_x") .prefix( " ")))) .prefix( " ") ,new caterwaul.syntax( "_f") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xs") .prefix( " ")) .prefix( "                "))'),qso:('new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "new" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "constructor")) ,new caterwaul.syntax( ""))) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "in" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "_xs") .prefix( " ")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "if" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "&&" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "Object") ,new caterwaul.syntax( "prototype")) ,new caterwaul.syntax( "hasOwnProperty")) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "_x") .prefix( " "))) ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( "      ")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xr") .prefix( "  ") ,new caterwaul.syntax( "_x")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_x"))) .prefix( " ")) .prefix( " ")) .prefix( "    ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xr") .prefix( " ")) .prefix( " "))'),qsp:('new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "new" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "constructor")) ,new caterwaul.syntax( ""))) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "in" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "_xs") .prefix( " ")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "if" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "&&" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "Object") ,new caterwaul.syntax( "prototype")) ,new caterwaul.syntax( "hasOwnProperty")) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "_x") .prefix( " "))) ,new caterwaul.syntax( "u!" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( " ")) .prefix( "    ")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xr") .prefix( "  ") ,new caterwaul.syntax( "_x")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_x"))) .prefix( " ")) .prefix( " ")) .prefix( "    ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xr") .prefix( " ")) .prefix( " "))'),qsq:('new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "new" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "constructor")) ,new caterwaul.syntax( ""))) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "x") .prefix( " "))) ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "in" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "_xs") .prefix( " ")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "if" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "&&" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "Object") ,new caterwaul.syntax( "prototype")) ,new caterwaul.syntax( "hasOwnProperty")) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "_x") .prefix( " "))) ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( " ")) .prefix( " ")) .prefix( " ")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "x")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "_x"))) .prefix( "  ")) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xr") .prefix( " ")) .prefix( " "))'),qsr:('new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "new" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "constructor")) ,new caterwaul.syntax( ""))) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "in" ,new caterwaul.syntax( "k") .prefix( "  ") ,new caterwaul.syntax( "_xs") .prefix( " ")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "if" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "Object") ,new caterwaul.syntax( "prototype")) ,new caterwaul.syntax( "hasOwnProperty")) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "k") .prefix( " ")))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "k"))) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "k")) ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( " ")) .prefix( " "))) .prefix( " ")) .prefix( "    ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xr") .prefix( " ")) .prefix( " "))'),qss:('new caterwaul.syntax( ";" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "in" ,new caterwaul.syntax( "k") .prefix( "  ") ,new caterwaul.syntax( "_xs") .prefix( " ")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "if" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "Object") ,new caterwaul.syntax( "prototype")) ,new caterwaul.syntax( "hasOwnProperty")) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "k") .prefix( " ")))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "k"))) .prefix( " ") ,new caterwaul.syntax( "_f") .prefix( " "))) .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xs") .prefix( " ")) .prefix( "            "))'),qst:('new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "new" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "constructor")) ,new caterwaul.syntax( ""))) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "in" ,new caterwaul.syntax( "k") .prefix( "  ") ,new caterwaul.syntax( "_xs") .prefix( " ")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "if" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "Object") ,new caterwaul.syntax( "prototype")) ,new caterwaul.syntax( "hasOwnProperty")) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "k") .prefix( " ")))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "k"))) .prefix( " ") ,new caterwaul.syntax( "&&" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( "        ") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xr") ,new caterwaul.syntax( "k")) ,new caterwaul.syntax( "_x") .prefix( " ")) .prefix( " ")) .prefix( " ")) .prefix( " "))) .prefix( " ")) .prefix( "    ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xr") .prefix( " ")) .prefix( " "))'),qsu:('new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "new" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "constructor")) ,new caterwaul.syntax( ""))) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "in" ,new caterwaul.syntax( "k") .prefix( "  ") ,new caterwaul.syntax( "_xs") .prefix( " ")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "if" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "Object") ,new caterwaul.syntax( "prototype")) ,new caterwaul.syntax( "hasOwnProperty")) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "k") .prefix( " ")))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "k"))) .prefix( " ") ,new caterwaul.syntax( "||" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( "        ") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xr") ,new caterwaul.syntax( "k")) ,new caterwaul.syntax( "_x") .prefix( " ")) .prefix( " ")) .prefix( " ")) .prefix( " "))) .prefix( " ")) .prefix( "    ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xr") .prefix( " ")) .prefix( " "))'),qsv:('new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_xr") .prefix( " ") ,new caterwaul.syntax( "new" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "constructor")) ,new caterwaul.syntax( ""))) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "x") .prefix( " "))) ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "in" ,new caterwaul.syntax( "k") .prefix( "  ") ,new caterwaul.syntax( "_xs") .prefix( " ")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "if" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "Object") ,new caterwaul.syntax( "prototype")) ,new caterwaul.syntax( "hasOwnProperty")) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "k") .prefix( " ")))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_x") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xs") .prefix( " ") ,new caterwaul.syntax( "k"))) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "x") .prefix( " ") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_f")) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "&&" ,new caterwaul.syntax( "x") .prefix( " ") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_xr") ,new caterwaul.syntax( "k")) ,new caterwaul.syntax( "x") .prefix( "  ")) .prefix( " ")) .prefix( " ")) .prefix( " "))) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_xr") .prefix( " ")) .prefix( " "))'),qsw:('new caterwaul.syntax( "u~" ,new caterwaul.syntax( "u!" ,new caterwaul.syntax( "_x")))'),qsx:('new caterwaul.syntax( "u!" ,new caterwaul.syntax( "_x"))'),qsy:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "_f") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_x") ,new caterwaul.syntax( "_x0")))'),qsz:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "_f") ,new caterwaul.syntax( "_x"))'),qs10:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_var@0") ,new caterwaul.syntax( "_init")) ,new caterwaul.syntax( "_x"))'),qs11:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "_init")) ,new caterwaul.syntax( "_x"))'),qs12:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_var@0") ,new caterwaul.syntax( "_x"))'),qs13:('new caterwaul.syntax( "[" ,new caterwaul.syntax( "_x"))'),qs14:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_x"))'),qs15:('new caterwaul.syntax( "_x")'),qs16:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "+" ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "_ys") .prefix( " ")) .prefix( " "))'),qs17:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_x")))'),qs18:('new caterwaul.syntax( "(" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_x")))'),qs19:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_x") ,new caterwaul.syntax( "_y")))'),qs1a:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_x")) ,new caterwaul.syntax( "_y"))'),qs1b:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "_ys")))'),qs1c:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_xs")) ,new caterwaul.syntax( "_ys"))'),qs1d:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "_x")))'),qs1e:('new caterwaul.syntax( "[" ,new caterwaul.syntax( "_x"))'),qs1f:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_x") ,new caterwaul.syntax( "_y") .prefix( " ")))'),qs1g:('new caterwaul.syntax( "," ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_x")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") .prefix( " ") ,new caterwaul.syntax( "_y")))'),qs1h:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "_p")))'),qs1i:('new caterwaul.syntax( "." ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_xs")) ,new caterwaul.syntax( "_p"))'),qs1j:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "u~" ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "_x"))))'),qs1k:('new caterwaul.syntax( "[" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_x")))'),qs1l:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "u~" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "_ys"))))'),qs1m:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_xs")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_ys")))'),qs1n:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "?" ,new caterwaul.syntax( "_x") ,new caterwaul.syntax( "_y") .prefix( " ") .infix( " ") ,new caterwaul.syntax( "_z") .prefix( " ")) .prefix( " "))'),qs1o:('new caterwaul.syntax( "?" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_x"))) ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_y"))) .prefix( " ") .infix( " ") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_z"))) .prefix( " ")) .prefix( " ")'),qs1p:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "&&" ,new caterwaul.syntax( "_x") ,new caterwaul.syntax( "_y") .prefix( " ")) .prefix( " "))'),qs1q:('new caterwaul.syntax( "&&" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_x"))) ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_y"))) .prefix( " ")) .prefix( " ")'),qs1r:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "||" ,new caterwaul.syntax( "_x") ,new caterwaul.syntax( "_y") .prefix( " ")) .prefix( " "))'),qs1s:('new caterwaul.syntax( "||" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_x"))) ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_y"))) .prefix( " ")) .prefix( " ")'),qs1t:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "u+" ,new caterwaul.syntax( "_xs")))'),qs1u:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "Array") ,new caterwaul.syntax( "prototype")) ,new caterwaul.syntax( "slice")) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_xs"))))'),qs1v:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "%" ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "_thing")) .prefix( " "))'),qs1w:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "*" ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "_thing")) .prefix( " "))'),qs1x:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "/" ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "_thing")) .prefix( " "))'),qs1y:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "|" ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "_thing")) .prefix( " "))'),qs1z:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "*" ,new caterwaul.syntax( "%" ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "k")) .prefix( " ") ,new caterwaul.syntax( "_thing")))'),qs20:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "*" ,new caterwaul.syntax( "%" ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "v")) .prefix( " ") ,new caterwaul.syntax( "_thing")))'),qs21:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "%" ,new caterwaul.syntax( "%" ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "k")) .prefix( " ") ,new caterwaul.syntax( "_thing")))'),qs22:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "%" ,new caterwaul.syntax( "%" ,new caterwaul.syntax( "_xs") ,new caterwaul.syntax( "v")) .prefix( " ") ,new caterwaul.syntax( "_thing")))'),qs23:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "o")) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( "_body")) .prefix( " "))) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "this") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_o"))) .prefix( " ")))'),qs24:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "i") ,new caterwaul.syntax( "u") .prefix( " ")) ,new caterwaul.syntax( "s") .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "if" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "<=" ,new caterwaul.syntax( "*" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "-" ,new caterwaul.syntax( "u") ,new caterwaul.syntax( "i") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "s") .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "")) .prefix( " ")) .prefix( "      ")) ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "r") .prefix( " ") ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "d") .prefix( " ") ,new caterwaul.syntax( "-" ,new caterwaul.syntax( "u") .prefix( " ") ,new caterwaul.syntax( "i") .prefix( " ")) .prefix( " ")) .prefix( " "))) ,new caterwaul.syntax( "?" ,new caterwaul.syntax( ">=" ,new caterwaul.syntax( "d") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "<" ,new caterwaul.syntax( "i") .prefix( " ") ,new caterwaul.syntax( "u") .prefix( "  ") .infix( " ")) .prefix( " ") ,new caterwaul.syntax( ">" ,new caterwaul.syntax( "i") .prefix( " ") ,new caterwaul.syntax( "u") .prefix( "  ")) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "+=" ,new caterwaul.syntax( "i") .prefix( " ") ,new caterwaul.syntax( "s") .prefix( " ")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "r") .prefix( " ") ,new caterwaul.syntax( "push")) ,new caterwaul.syntax( "i"))) .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "r") .prefix( " ")) .prefix( " "))) .prefix( " "))) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_l")) ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_u")) .prefix( " ")) ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_step")) .prefix( " ")))'),qs25:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "i") ,new caterwaul.syntax( "u") .prefix( " ")) ,new caterwaul.syntax( "s") .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "if" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "||" ,new caterwaul.syntax( "<" ,new caterwaul.syntax( "*" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "-" ,new caterwaul.syntax( "u") ,new caterwaul.syntax( "i") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "s") .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "u!" ,new caterwaul.syntax( "s")) .prefix( " ")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "")) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "r") .prefix( " ") ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "d") .prefix( " ") ,new caterwaul.syntax( "-" ,new caterwaul.syntax( "u") .prefix( " ") ,new caterwaul.syntax( "i") .prefix( " ")) .prefix( " ")) .prefix( " "))) ,new caterwaul.syntax( "?" ,new caterwaul.syntax( ">=" ,new caterwaul.syntax( "d") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "<=" ,new caterwaul.syntax( "i") .prefix( " ") ,new caterwaul.syntax( "u") .prefix( " ") .infix( " ")) .prefix( " ") ,new caterwaul.syntax( ">=" ,new caterwaul.syntax( "i") .prefix( " ") ,new caterwaul.syntax( "u") .prefix( " ")) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "+=" ,new caterwaul.syntax( "i") .prefix( " ") ,new caterwaul.syntax( "s") .prefix( " ")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "r") .prefix( " ") ,new caterwaul.syntax( "push")) ,new caterwaul.syntax( "i"))) .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "r") .prefix( " ")) .prefix( " "))) .prefix( " "))) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_l")) ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_u")) .prefix( " ")) ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_step")) .prefix( " ")))'),qs26:('new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "ks") .prefix( " ") ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "")) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "in" ,new caterwaul.syntax( "k") .prefix( " ") ,new caterwaul.syntax( "o") .prefix( " ")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "&&" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "Object") .prefix( " ") ,new caterwaul.syntax( "prototype")) ,new caterwaul.syntax( "hasOwnProperty")) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "o") ,new caterwaul.syntax( "k") .prefix( " "))) ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "ks") .prefix( " ") ,new caterwaul.syntax( "push")) ,new caterwaul.syntax( "k"))) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "ks") .prefix( " ")) .prefix( " "))'),qs27:('new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "vs") .prefix( " ") ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "")) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "in" ,new caterwaul.syntax( "k") .prefix( " ") ,new caterwaul.syntax( "o") .prefix( " ")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "&&" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "Object") .prefix( " ") ,new caterwaul.syntax( "prototype")) ,new caterwaul.syntax( "hasOwnProperty")) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "o") ,new caterwaul.syntax( "k") .prefix( " "))) ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "vs") .prefix( " ") ,new caterwaul.syntax( "push")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "o") ,new caterwaul.syntax( "k")))) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "vs") .prefix( " ")) .prefix( " "))'),qs28:('new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "ps") .prefix( " ") ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "")) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "in" ,new caterwaul.syntax( "k") .prefix( " ") ,new caterwaul.syntax( "o") .prefix( " ")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "&&" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "." ,new caterwaul.syntax( "Object") .prefix( " ") ,new caterwaul.syntax( "prototype")) ,new caterwaul.syntax( "hasOwnProperty")) ,new caterwaul.syntax( "call")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "o") ,new caterwaul.syntax( "k") .prefix( " "))) ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "ps") .prefix( " ") ,new caterwaul.syntax( "push")) ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "k") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "o") .prefix( " ") ,new caterwaul.syntax( "k")))))) .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "ps") .prefix( " ")) .prefix( " "))'),qs29:('new caterwaul.syntax( ";" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "r") .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( "")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "i") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "l") .prefix( " ") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "o") .prefix( " ") ,new caterwaul.syntax( "length"))) .prefix( " ")) ,new caterwaul.syntax( "x") .prefix( " "))) ,new caterwaul.syntax( "<" ,new caterwaul.syntax( "i") .prefix( " ") ,new caterwaul.syntax( "l") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u++" ,new caterwaul.syntax( "i")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "x") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "o") .prefix( " ") ,new caterwaul.syntax( "i"))) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "r") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "0"))) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "x") .prefix( " ") ,new caterwaul.syntax( "1"))) .prefix( " "))) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "r") .prefix( " ")) .prefix( " "))'),qs2a:('new caterwaul.syntax( ";" ,new caterwaul.syntax( "for" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( ";" ,new caterwaul.syntax( "var" ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "r") .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( "")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "i") .prefix( " ") ,new caterwaul.syntax( "0") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "l") .prefix( " ") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "o") .prefix( " ") ,new caterwaul.syntax( "length"))) .prefix( " ")) ,new caterwaul.syntax( "x") .prefix( " "))) ,new caterwaul.syntax( "<" ,new caterwaul.syntax( "i") .prefix( " ") ,new caterwaul.syntax( "l") .prefix( " ")) .prefix( " ")) ,new caterwaul.syntax( "u++" ,new caterwaul.syntax( "i")) .prefix( " "))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "x") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "o") .prefix( " ") ,new caterwaul.syntax( "i"))) .prefix( " ") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "||" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "r") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "0"))) ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "r") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "0"))) ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "")) .prefix( " ")) .prefix( " ")) .prefix( " ")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "push")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "1"))))) ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "r") .prefix( " ")) .prefix( " "))'),qs2b:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "n") ,new caterwaul.syntax( "_u")))'),qs2c:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "ni") ,new caterwaul.syntax( "_u")))'),qs2d:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "n") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_l") ,new caterwaul.syntax( "_u") .prefix( " "))))'),qs2e:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "ni") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_l") ,new caterwaul.syntax( "_u") .prefix( " "))))'),qs2f:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "n") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_l") ,new caterwaul.syntax( "_u") .prefix( " ")) ,new caterwaul.syntax( "_step") .prefix( " "))))'),qs2g:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "ni") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_l") ,new caterwaul.syntax( "_u") .prefix( " ")) ,new caterwaul.syntax( "_step") .prefix( " "))))'),qs2h:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "/" ,new caterwaul.syntax( "_o") ,new caterwaul.syntax( "keys")) .prefix( " "))'),qs2i:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "|" ,new caterwaul.syntax( "_o") ,new caterwaul.syntax( "object")) .prefix( " "))'),qs2j:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "/" ,new caterwaul.syntax( "_o") ,new caterwaul.syntax( "mobject")) .prefix( " "))'),qs2k:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "/" ,new caterwaul.syntax( "_o") ,new caterwaul.syntax( "values")) .prefix( " "))'),qs2l:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "-" ,new caterwaul.syntax( "_o") ,new caterwaul.syntax( "object")) .prefix( " "))'),qs2m:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "-" ,new caterwaul.syntax( "_o") ,new caterwaul.syntax( "mobject")) .prefix( " "))'),qs2n:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "/" ,new caterwaul.syntax( "_o") ,new caterwaul.syntax( "pairs")) .prefix( " "))'),qs2o:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "/" ,new caterwaul.syntax( "_o") ,new caterwaul.syntax( "object")) .prefix( " "))'),qs2p:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "|" ,new caterwaul.syntax( "_o") ,new caterwaul.syntax( "mobject")) .prefix( " "))')};
return(result)}).call(this,new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_expression")),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("(",new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax("_xs"))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("_x")).prefix(" "),(new caterwaul.syntax("_x0")).prefix(" ")),(new caterwaul.syntax("_xi")).prefix(" ")),(new caterwaul.syntax("_xl")).prefix(" ")),(new caterwaul.syntax("_xr")).prefix(" "))),(new caterwaul.syntax("_body")).prefix(" ")))).prefix(" "))),new caterwaul.syntax("call")),new caterwaul.syntax(",",new caterwaul.syntax("this"),new caterwaul.syntax("[]",(new caterwaul.syntax("S")).prefix(" "),new caterwaul.syntax("_s")))),new caterwaul.syntax(";",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_xr")).prefix(" "),(new caterwaul.syntax("new",new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("constructor")),new caterwaul.syntax("")))).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",(new caterwaul.syntax("_xl")).prefix(" "),new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("length")))).prefix(" "))),(new caterwaul.syntax("<",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("_xl")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u++",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_xi")))).prefix(" "),new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xr")).prefix(" "),new caterwaul.syntax("push")),new caterwaul.syntax("(",new caterwaul.syntax("_f"))))),(new caterwaul.syntax("return",(new caterwaul.syntax("_xr")).prefix(" "))).prefix("                                        ")),new caterwaul.syntax(";",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix("                              "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_xl")).prefix(" "),new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("length")))).prefix(" "))),(new caterwaul.syntax("<",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("_xl")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u++",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_xi")))).prefix(" "),(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix(" "))),(new caterwaul.syntax("return",(new caterwaul.syntax("_xs")).prefix(" "))).prefix("                                                  ")),new caterwaul.syntax(";",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_xr")).prefix(" "),(new caterwaul.syntax("new",new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("constructor")),new caterwaul.syntax("")))).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",(new caterwaul.syntax("_xl")).prefix(" "),new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("length")))).prefix(" "))),(new caterwaul.syntax("<",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("_xl")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u++",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_xi")))).prefix(" "),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax(".",(new caterwaul.syntax("_xr")).prefix(" "),new caterwaul.syntax("push")),new caterwaul.syntax("apply")),new caterwaul.syntax(",",new caterwaul.syntax("_xr"),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax(".",(new caterwaul.syntax("Array")).prefix(" "),new caterwaul.syntax("prototype")),new caterwaul.syntax("slice")),new caterwaul.syntax("call")),new caterwaul.syntax("(",new caterwaul.syntax("_f"))))))),(new caterwaul.syntax("return",(new caterwaul.syntax("_xr")).prefix(" "))).prefix(" ")),new caterwaul.syntax(";",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),(new caterwaul.syntax("_xs")).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("_x0")).prefix(" ")),(new caterwaul.syntax("_xl")).prefix(" "))),(new caterwaul.syntax("=",(new caterwaul.syntax("_x0")).prefix(" "),(new caterwaul.syntax("(",new caterwaul.syntax("_init"))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u++",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("_x")).prefix(" "))).prefix(" ")),new caterwaul.syntax(";",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_xr")).prefix(" "),(new caterwaul.syntax("new",new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("constructor")),new caterwaul.syntax("")))).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",(new caterwaul.syntax("_xl")).prefix(" "),new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("length")))).prefix(" "))),(new caterwaul.syntax("<",(new caterwaul.syntax("_xi")).prefix("    "),(new caterwaul.syntax("_xl")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u++",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_xi")))).prefix(" "),(new caterwaul.syntax("&&",(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix(" "),new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xr")).prefix(" "),new caterwaul.syntax("push")),new caterwaul.syntax("_x")))).prefix(" "))),(new caterwaul.syntax("return",(new caterwaul.syntax("_xr")).prefix(" "))).prefix("      ")),new caterwaul.syntax(";",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_xr")).prefix(" "),(new caterwaul.syntax("new",new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("constructor")),new caterwaul.syntax("")))).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",(new caterwaul.syntax("_xl")).prefix(" "),new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("length")))).prefix(" "))),(new caterwaul.syntax("<",(new caterwaul.syntax("_xi")).prefix("    "),(new caterwaul.syntax("_xl")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u++",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_xi")))).prefix(" "),(new caterwaul.syntax("||",(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix(" "),new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xr")).prefix(" "),new caterwaul.syntax("push")),new caterwaul.syntax("_x")))).prefix(" "))),(new caterwaul.syntax("return",(new caterwaul.syntax("_xr")).prefix(" "))).prefix("      ")),new caterwaul.syntax(";",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_xr")).prefix(" "),(new caterwaul.syntax("new",new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("constructor")),new caterwaul.syntax("")))).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",(new caterwaul.syntax("_xl")).prefix(" "),new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("length")))).prefix(" ")),(new caterwaul.syntax("y")).prefix(" "))),(new caterwaul.syntax("<",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("_xl")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u++",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_xi")))).prefix(" "),(new caterwaul.syntax("&&",(new caterwaul.syntax("(",(new caterwaul.syntax("=",new caterwaul.syntax("y"),(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix(" "))).prefix(" "))).prefix(" "),new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xr")).prefix(" "),new caterwaul.syntax("push")),new caterwaul.syntax("y")))).prefix(" "))),(new caterwaul.syntax("return",(new caterwaul.syntax("_xr")).prefix(" "))).prefix(" ")),new caterwaul.syntax(";",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_xr")).prefix(" "),(new caterwaul.syntax("new",new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("constructor")),new caterwaul.syntax("")))).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",(new caterwaul.syntax("_xl")).prefix(" "),new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("length")))).prefix(" ")),(new caterwaul.syntax("_x0")).prefix(" "))),(new caterwaul.syntax("<",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("_xl")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u++",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_xi")))).prefix(" "),(new caterwaul.syntax("&&",(new caterwaul.syntax("(",(new caterwaul.syntax("=",new caterwaul.syntax("_x0"),(new caterwaul.syntax("(",new caterwaul.syntax("_init"))).prefix(" "))).prefix(" "))).prefix(" "),new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xr")).prefix(" "),new caterwaul.syntax("push")),new caterwaul.syntax("_f")))).prefix(" "))),(new caterwaul.syntax("return",(new caterwaul.syntax("_xr")).prefix(" "))).prefix(" ")),new caterwaul.syntax(";",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x0")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("0")))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("1")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",(new caterwaul.syntax("_xl")).prefix(" "),new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("length")))).prefix(" "))),(new caterwaul.syntax("<",(new caterwaul.syntax("_xi")).prefix("            "),(new caterwaul.syntax("_xl")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u++",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_xi")))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_x0")).prefix(" "),(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix(" "))).prefix(" "))),(new caterwaul.syntax("return",(new caterwaul.syntax("_x0")).prefix(" "))).prefix(" ")),new caterwaul.syntax(";",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_xl")).prefix(" "),new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("length")))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("-",(new caterwaul.syntax("_xl")).prefix(" "),(new caterwaul.syntax("2")).prefix(" "))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",(new caterwaul.syntax("_x0")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),(new caterwaul.syntax("-",new caterwaul.syntax("_xl"),(new caterwaul.syntax("1")).prefix(" "))).prefix(" ")))).prefix(" "))),(new caterwaul.syntax(">=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u--",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_xi")))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_x0")).prefix(" "),(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix(" "))).prefix(" "))),(new caterwaul.syntax("return",(new caterwaul.syntax("_x0")).prefix(" "))).prefix(" ")),new caterwaul.syntax(";",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_xr")).prefix(" "),(new caterwaul.syntax("[",new caterwaul.syntax(""))).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),(new caterwaul.syntax("_xs")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" "))),(new caterwaul.syntax("!==",(new caterwaul.syntax("_x")).prefix("                      "),(new caterwaul.syntax("null")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u++",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),new caterwaul.syntax(",",new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xr")).prefix(" "),new caterwaul.syntax("push")),new caterwaul.syntax("_x")),(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix(" "))).prefix(" "))),(new caterwaul.syntax("return",(new caterwaul.syntax("_xr")).prefix(" "))).prefix("   ")),new caterwaul.syntax(";",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x0")).prefix(" "),(new caterwaul.syntax("(",new caterwaul.syntax("_init"))).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",(new caterwaul.syntax("_xl")).prefix(" "),new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("length")))).prefix(" "))),(new caterwaul.syntax("<",(new caterwaul.syntax("_xi")).prefix("      "),(new caterwaul.syntax("_xl")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u++",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_xi")))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_x0")).prefix(" "),(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix(" "))).prefix(" "))),(new caterwaul.syntax("return",(new caterwaul.syntax("_x0")).prefix(" "))).prefix("      ")),new caterwaul.syntax(";",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_xl")).prefix(" "),(new caterwaul.syntax("-",new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("length")),(new caterwaul.syntax("1")).prefix(" "))).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("_xl")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",(new caterwaul.syntax("_x0")).prefix(" "),(new caterwaul.syntax("(",new caterwaul.syntax("_init"))).prefix(" "))).prefix(" "))),(new caterwaul.syntax(">=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u--",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_xi")))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_x0")).prefix(" "),(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix(" "))).prefix(" "))),(new caterwaul.syntax("return",(new caterwaul.syntax("_x0")).prefix(" "))).prefix("      ")),new caterwaul.syntax(";",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_xr")).prefix(" "),(new caterwaul.syntax("[",new caterwaul.syntax(""))).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),(new caterwaul.syntax("_xs")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("_x0")).prefix(" "))),(new caterwaul.syntax("=",(new caterwaul.syntax("_x0")).prefix("          "),(new caterwaul.syntax("(",new caterwaul.syntax("_init"))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u++",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),new caterwaul.syntax(",",new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xr")).prefix(" "),new caterwaul.syntax("push")),new caterwaul.syntax("_x")),(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix(" "))).prefix(" "))),(new caterwaul.syntax("return",(new caterwaul.syntax("_xr")).prefix(" "))).prefix("        ")),new caterwaul.syntax("i;",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("_x")).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",(new caterwaul.syntax("_xl")).prefix(" "),new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("length")))).prefix(" ")),(new caterwaul.syntax("x")).prefix(" "))),(new caterwaul.syntax("<",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("_xl")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u++",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax(";",(new caterwaul.syntax("=",new caterwaul.syntax("_x"),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_xi")))).prefix(" "),(new caterwaul.syntax("if",(new caterwaul.syntax("(",(new caterwaul.syntax("=",new caterwaul.syntax("x"),(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix(" "))).prefix(" "))).prefix(" "),(new caterwaul.syntax("return",(new caterwaul.syntax("x")).prefix(" "))).prefix(" "))).prefix(" ")))).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("false")).prefix(" "))).prefix(" ")),new caterwaul.syntax("i;",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("_x")).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",(new caterwaul.syntax("_xl")).prefix(" "),new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("length")))).prefix(" ")),(new caterwaul.syntax("x")).prefix(" "))),(new caterwaul.syntax("<",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("_xl")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u++",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax(";",(new caterwaul.syntax("=",new caterwaul.syntax("_x"),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_xi")))).prefix(" "),(new caterwaul.syntax("if",(new caterwaul.syntax("(",(new caterwaul.syntax("=",new caterwaul.syntax("x"),(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix(" "))).prefix(" "))).prefix(" "),(new caterwaul.syntax("return",(new caterwaul.syntax("false")).prefix(" "))).prefix(" "))).prefix(" ")))).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("true")).prefix(" "))).prefix(" ")),new caterwaul.syntax("i;",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_xl")).prefix(" "),new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("length")))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("-",(new caterwaul.syntax("_xl")).prefix(" "),(new caterwaul.syntax("1")).prefix(" "))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("_x")).prefix(" ")),(new caterwaul.syntax("x")).prefix(" "))),(new caterwaul.syntax(">=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u--",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax(";",(new caterwaul.syntax("=",new caterwaul.syntax("_x"),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_xi")))).prefix(" "),(new caterwaul.syntax("if",(new caterwaul.syntax("(",(new caterwaul.syntax("=",new caterwaul.syntax("x"),(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix(" "))).prefix(" "))).prefix(" "),(new caterwaul.syntax("return",(new caterwaul.syntax("x")).prefix(" "))).prefix(" "))).prefix(" ")))).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("false")).prefix(" "))).prefix(" ")),new caterwaul.syntax("i;",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("_x")).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",(new caterwaul.syntax("_xl")).prefix(" "),new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("length")))).prefix(" ")),(new caterwaul.syntax("x")).prefix(" "))),(new caterwaul.syntax("<",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("_xl")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u++",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax(";",(new caterwaul.syntax("=",new caterwaul.syntax("_x"),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_xi")))).prefix(" "),(new caterwaul.syntax("if",(new caterwaul.syntax("(",(new caterwaul.syntax("=",new caterwaul.syntax("_x0"),(new caterwaul.syntax("(",new caterwaul.syntax("_init"))).prefix(" "))).prefix(" "))).prefix(" "),(new caterwaul.syntax("return",(new caterwaul.syntax("_f")).prefix(" "))).prefix(" "))).prefix(" ")))).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("false")).prefix(" "))).prefix(" ")),new caterwaul.syntax("i;",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_xl")).prefix(" "),new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("length")))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("-",(new caterwaul.syntax("_xl")).prefix(" "),(new caterwaul.syntax("1")).prefix(" "))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("_x")).prefix(" ")),(new caterwaul.syntax("x")).prefix(" "))),(new caterwaul.syntax(">=",(new caterwaul.syntax("_xi")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u--",new caterwaul.syntax("_xi"))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax(";",(new caterwaul.syntax("=",new caterwaul.syntax("_x"),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_xi")))).prefix(" "),(new caterwaul.syntax("if",(new caterwaul.syntax("(",(new caterwaul.syntax("=",new caterwaul.syntax("_x0"),(new caterwaul.syntax("(",new caterwaul.syntax("_init"))).prefix(" "))).prefix(" "))).prefix(" "),(new caterwaul.syntax("return",(new caterwaul.syntax("_f")).prefix(" "))).prefix(" "))).prefix(" ")))).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("false")).prefix(" "))).prefix(" ")),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("(",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_xs"))),new caterwaul.syntax("concat")),new caterwaul.syntax("(",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_ys")))),new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",(new caterwaul.syntax("=",(new caterwaul.syntax("_xr")).prefix(" "),(new caterwaul.syntax("new",new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("constructor")),new caterwaul.syntax("")))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax("var",(new caterwaul.syntax("in",(new caterwaul.syntax("_x")).prefix(" "),(new caterwaul.syntax("_xs")).prefix(" "))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("if",(new caterwaul.syntax("(",new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax("Object"),new caterwaul.syntax("prototype")),new caterwaul.syntax("hasOwnProperty")),new caterwaul.syntax("call")),new caterwaul.syntax(",",new caterwaul.syntax("_xs"),(new caterwaul.syntax("_x")).prefix(" "))))).prefix(" "),(new caterwaul.syntax("=",new caterwaul.syntax("[]",(new caterwaul.syntax("_xr")).prefix(" "),new caterwaul.syntax("_f")),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_x")))).prefix(" "))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("_xr")).prefix(" "))).prefix(" ")),new caterwaul.syntax(";",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax("var",(new caterwaul.syntax("in",(new caterwaul.syntax("_x")).prefix(" "),(new caterwaul.syntax("_xs")).prefix(" "))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("if",(new caterwaul.syntax("(",new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax("Object"),new caterwaul.syntax("prototype")),new caterwaul.syntax("hasOwnProperty")),new caterwaul.syntax("call")),new caterwaul.syntax(",",new caterwaul.syntax("_xs"),(new caterwaul.syntax("_x")).prefix(" "))))).prefix(" "),(new caterwaul.syntax("_f")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("_xs")).prefix(" "))).prefix("                ")),new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",(new caterwaul.syntax("=",(new caterwaul.syntax("_xr")).prefix(" "),(new caterwaul.syntax("new",new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("constructor")),new caterwaul.syntax("")))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax("var",(new caterwaul.syntax("in",(new caterwaul.syntax("_x")).prefix(" "),(new caterwaul.syntax("_xs")).prefix(" "))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("if",(new caterwaul.syntax("(",(new caterwaul.syntax("&&",new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax("Object"),new caterwaul.syntax("prototype")),new caterwaul.syntax("hasOwnProperty")),new caterwaul.syntax("call")),new caterwaul.syntax(",",new caterwaul.syntax("_xs"),(new caterwaul.syntax("_x")).prefix(" "))),(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix("      "))).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",new caterwaul.syntax("[]",(new caterwaul.syntax("_xr")).prefix("  "),new caterwaul.syntax("_x")),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_x")))).prefix(" "))).prefix(" "))).prefix("    ")),(new caterwaul.syntax("return",(new caterwaul.syntax("_xr")).prefix(" "))).prefix(" ")),new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",(new caterwaul.syntax("=",(new caterwaul.syntax("_xr")).prefix(" "),(new caterwaul.syntax("new",new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("constructor")),new caterwaul.syntax("")))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax("var",(new caterwaul.syntax("in",(new caterwaul.syntax("_x")).prefix(" "),(new caterwaul.syntax("_xs")).prefix(" "))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("if",(new caterwaul.syntax("(",(new caterwaul.syntax("&&",new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax("Object"),new caterwaul.syntax("prototype")),new caterwaul.syntax("hasOwnProperty")),new caterwaul.syntax("call")),new caterwaul.syntax(",",new caterwaul.syntax("_xs"),(new caterwaul.syntax("_x")).prefix(" "))),(new caterwaul.syntax("u!",(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix(" "))).prefix("    "))).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",new caterwaul.syntax("[]",(new caterwaul.syntax("_xr")).prefix("  "),new caterwaul.syntax("_x")),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_x")))).prefix(" "))).prefix(" "))).prefix("    ")),(new caterwaul.syntax("return",(new caterwaul.syntax("_xr")).prefix(" "))).prefix(" ")),new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_xr")).prefix(" "),(new caterwaul.syntax("new",new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("constructor")),new caterwaul.syntax("")))).prefix(" "))).prefix(" "),(new caterwaul.syntax("x")).prefix(" "))),(new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax("var",(new caterwaul.syntax("in",(new caterwaul.syntax("_x")).prefix(" "),(new caterwaul.syntax("_xs")).prefix(" "))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("if",(new caterwaul.syntax("(",(new caterwaul.syntax("&&",new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax("Object"),new caterwaul.syntax("prototype")),new caterwaul.syntax("hasOwnProperty")),new caterwaul.syntax("call")),new caterwaul.syntax(",",new caterwaul.syntax("_xs"),(new caterwaul.syntax("_x")).prefix(" "))),(new caterwaul.syntax("(",(new caterwaul.syntax("=",new caterwaul.syntax("x"),(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix(" "))).prefix(" "))).prefix(" "))).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",new caterwaul.syntax("[]",(new caterwaul.syntax("_xr")).prefix(" "),new caterwaul.syntax("x")),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("_x")))).prefix("  "))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("_xr")).prefix(" "))).prefix(" ")),new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",(new caterwaul.syntax("=",(new caterwaul.syntax("_xr")).prefix(" "),(new caterwaul.syntax("new",new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("constructor")),new caterwaul.syntax("")))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax("var",(new caterwaul.syntax("in",(new caterwaul.syntax("k")).prefix("  "),(new caterwaul.syntax("_xs")).prefix(" "))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("if",(new caterwaul.syntax("(",new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax("Object"),new caterwaul.syntax("prototype")),new caterwaul.syntax("hasOwnProperty")),new caterwaul.syntax("call")),new caterwaul.syntax(",",new caterwaul.syntax("_xs"),(new caterwaul.syntax("k")).prefix(" "))))).prefix(" "),new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("k")))).prefix(" "),(new caterwaul.syntax("=",new caterwaul.syntax("[]",(new caterwaul.syntax("_xr")).prefix(" "),new caterwaul.syntax("k")),(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix(" "))).prefix(" ")))).prefix(" "))).prefix("    ")),(new caterwaul.syntax("return",(new caterwaul.syntax("_xr")).prefix(" "))).prefix(" ")),new caterwaul.syntax(";",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax("var",(new caterwaul.syntax("in",(new caterwaul.syntax("k")).prefix("  "),(new caterwaul.syntax("_xs")).prefix(" "))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("if",(new caterwaul.syntax("(",new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax("Object"),new caterwaul.syntax("prototype")),new caterwaul.syntax("hasOwnProperty")),new caterwaul.syntax("call")),new caterwaul.syntax(",",new caterwaul.syntax("_xs"),(new caterwaul.syntax("k")).prefix(" "))))).prefix(" "),new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("k")))).prefix(" "),(new caterwaul.syntax("_f")).prefix(" ")))).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("_xs")).prefix(" "))).prefix("            ")),new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",(new caterwaul.syntax("=",(new caterwaul.syntax("_xr")).prefix(" "),(new caterwaul.syntax("new",new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("constructor")),new caterwaul.syntax("")))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax("var",(new caterwaul.syntax("in",(new caterwaul.syntax("k")).prefix("  "),(new caterwaul.syntax("_xs")).prefix(" "))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("if",(new caterwaul.syntax("(",new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax("Object"),new caterwaul.syntax("prototype")),new caterwaul.syntax("hasOwnProperty")),new caterwaul.syntax("call")),new caterwaul.syntax(",",new caterwaul.syntax("_xs"),(new caterwaul.syntax("k")).prefix(" "))))).prefix(" "),new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("k")))).prefix(" "),(new caterwaul.syntax("&&",(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix("        "),(new caterwaul.syntax("(",(new caterwaul.syntax("=",new caterwaul.syntax("[]",new caterwaul.syntax("_xr"),new caterwaul.syntax("k")),(new caterwaul.syntax("_x")).prefix(" "))).prefix(" "))).prefix(" "))).prefix(" ")))).prefix(" "))).prefix("    ")),(new caterwaul.syntax("return",(new caterwaul.syntax("_xr")).prefix(" "))).prefix(" ")),new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",(new caterwaul.syntax("=",(new caterwaul.syntax("_xr")).prefix(" "),(new caterwaul.syntax("new",new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("constructor")),new caterwaul.syntax("")))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax("var",(new caterwaul.syntax("in",(new caterwaul.syntax("k")).prefix("  "),(new caterwaul.syntax("_xs")).prefix(" "))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("if",(new caterwaul.syntax("(",new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax("Object"),new caterwaul.syntax("prototype")),new caterwaul.syntax("hasOwnProperty")),new caterwaul.syntax("call")),new caterwaul.syntax(",",new caterwaul.syntax("_xs"),(new caterwaul.syntax("k")).prefix(" "))))).prefix(" "),new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("k")))).prefix(" "),(new caterwaul.syntax("||",(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix("        "),(new caterwaul.syntax("(",(new caterwaul.syntax("=",new caterwaul.syntax("[]",new caterwaul.syntax("_xr"),new caterwaul.syntax("k")),(new caterwaul.syntax("_x")).prefix(" "))).prefix(" "))).prefix(" "))).prefix(" ")))).prefix(" "))).prefix("    ")),(new caterwaul.syntax("return",(new caterwaul.syntax("_xr")).prefix(" "))).prefix(" ")),new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_xr")).prefix(" "),(new caterwaul.syntax("new",new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("constructor")),new caterwaul.syntax("")))).prefix(" "))).prefix(" "),(new caterwaul.syntax("x")).prefix(" "))),(new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax("var",(new caterwaul.syntax("in",(new caterwaul.syntax("k")).prefix("  "),(new caterwaul.syntax("_xs")).prefix(" "))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("if",(new caterwaul.syntax("(",new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax("Object"),new caterwaul.syntax("prototype")),new caterwaul.syntax("hasOwnProperty")),new caterwaul.syntax("call")),new caterwaul.syntax(",",new caterwaul.syntax("_xs"),(new caterwaul.syntax("k")).prefix(" "))))).prefix(" "),new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("_x")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("_xs")).prefix(" "),new caterwaul.syntax("k")))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("x")).prefix(" "),(new caterwaul.syntax("(",new caterwaul.syntax("_f"))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("&&",(new caterwaul.syntax("x")).prefix(" "),(new caterwaul.syntax("(",(new caterwaul.syntax("=",new caterwaul.syntax("[]",new caterwaul.syntax("_xr"),new caterwaul.syntax("k")),(new caterwaul.syntax("x")).prefix("  "))).prefix(" "))).prefix(" "))).prefix(" ")))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("_xr")).prefix(" "))).prefix(" ")),new caterwaul.syntax("u~",new caterwaul.syntax("u!",new caterwaul.syntax("_x"))),new caterwaul.syntax("u!",new caterwaul.syntax("_x")),new caterwaul.syntax("()",new caterwaul.syntax("_f"),new caterwaul.syntax(",",new caterwaul.syntax("_x"),new caterwaul.syntax("_x0"))),new caterwaul.syntax("()",new caterwaul.syntax("_f"),new caterwaul.syntax("_x")),new caterwaul.syntax("[]",new caterwaul.syntax("[]",new caterwaul.syntax("_var@0"),new caterwaul.syntax("_init")),new caterwaul.syntax("_x")),new caterwaul.syntax("[]",new caterwaul.syntax("[",new caterwaul.syntax("_init")),new caterwaul.syntax("_x")),new caterwaul.syntax("[]",new caterwaul.syntax("_var@0"),new caterwaul.syntax("_x")),new caterwaul.syntax("[",new caterwaul.syntax("_x")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_x")),new caterwaul.syntax("_x"),new caterwaul.syntax("[]",new caterwaul.syntax("S"),(new caterwaul.syntax("+",new caterwaul.syntax("_xs"),(new caterwaul.syntax("_ys")).prefix(" "))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("(",new caterwaul.syntax("_x"))),new caterwaul.syntax("(",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_x"))),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("[]",new caterwaul.syntax("_x"),new caterwaul.syntax("_y"))),new caterwaul.syntax("[]",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_x")),new caterwaul.syntax("_y")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("()",new caterwaul.syntax("_xs"),new caterwaul.syntax("_ys"))),new caterwaul.syntax("()",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_xs")),new caterwaul.syntax("_ys")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("[",new caterwaul.syntax("_x"))),new caterwaul.syntax("[",new caterwaul.syntax("_x")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax(",",new caterwaul.syntax("_x"),(new caterwaul.syntax("_y")).prefix(" "))),new caterwaul.syntax(",",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_x")),new caterwaul.syntax("[]",(new caterwaul.syntax("S")).prefix(" "),new caterwaul.syntax("_y"))),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax(".",new caterwaul.syntax("_xs"),new caterwaul.syntax("_p"))),new caterwaul.syntax(".",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_xs")),new caterwaul.syntax("_p")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("u~",new caterwaul.syntax("[",new caterwaul.syntax("_x")))),new caterwaul.syntax("[",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_x"))),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("u~",new caterwaul.syntax("()",new caterwaul.syntax("_xs"),new caterwaul.syntax("_ys")))),new caterwaul.syntax("()",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_xs")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_ys"))),new caterwaul.syntax("[]",new caterwaul.syntax("S"),(new caterwaul.syntax("?",new caterwaul.syntax("_x"),(new caterwaul.syntax("_y")).prefix(" ").infix(" "),(new caterwaul.syntax("_z")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("?",new caterwaul.syntax("(",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_x"))),(new caterwaul.syntax("(",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_y")))).prefix(" ").infix(" "),(new caterwaul.syntax("(",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_z")))).prefix(" "))).prefix(" "),new caterwaul.syntax("[]",new caterwaul.syntax("S"),(new caterwaul.syntax("&&",new caterwaul.syntax("_x"),(new caterwaul.syntax("_y")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("&&",new caterwaul.syntax("(",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_x"))),(new caterwaul.syntax("(",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_y")))).prefix(" "))).prefix(" "),new caterwaul.syntax("[]",new caterwaul.syntax("S"),(new caterwaul.syntax("||",new caterwaul.syntax("_x"),(new caterwaul.syntax("_y")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("||",new caterwaul.syntax("(",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_x"))),(new caterwaul.syntax("(",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_y")))).prefix(" "))).prefix(" "),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("u+",new caterwaul.syntax("_xs"))),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax("Array"),new caterwaul.syntax("prototype")),new caterwaul.syntax("slice")),new caterwaul.syntax("call")),new caterwaul.syntax("(",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_xs")))),new caterwaul.syntax("[]",new caterwaul.syntax("S"),(new caterwaul.syntax("%",new caterwaul.syntax("_xs"),new caterwaul.syntax("_thing"))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),(new caterwaul.syntax("*",new caterwaul.syntax("_xs"),new caterwaul.syntax("_thing"))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),(new caterwaul.syntax("/",new caterwaul.syntax("_xs"),new caterwaul.syntax("_thing"))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),(new caterwaul.syntax("|",new caterwaul.syntax("_xs"),new caterwaul.syntax("_thing"))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("*",(new caterwaul.syntax("%",new caterwaul.syntax("_xs"),new caterwaul.syntax("k"))).prefix(" "),new caterwaul.syntax("_thing"))),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("*",(new caterwaul.syntax("%",new caterwaul.syntax("_xs"),new caterwaul.syntax("v"))).prefix(" "),new caterwaul.syntax("_thing"))),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("%",(new caterwaul.syntax("%",new caterwaul.syntax("_xs"),new caterwaul.syntax("k"))).prefix(" "),new caterwaul.syntax("_thing"))),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("%",(new caterwaul.syntax("%",new caterwaul.syntax("_xs"),new caterwaul.syntax("v"))).prefix(" "),new caterwaul.syntax("_thing"))),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("(",new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax("o"))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax("_body"))).prefix(" "))),new caterwaul.syntax("call")),new caterwaul.syntax(",",new caterwaul.syntax("this"),(new caterwaul.syntax("(",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_o")))).prefix(" "))),new caterwaul.syntax("()",new caterwaul.syntax("(",new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax("i"),(new caterwaul.syntax("u")).prefix(" ")),(new caterwaul.syntax("s")).prefix(" ")))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("if",(new caterwaul.syntax("(",(new caterwaul.syntax("<=",(new caterwaul.syntax("*",new caterwaul.syntax("(",(new caterwaul.syntax("-",new caterwaul.syntax("u"),(new caterwaul.syntax("i")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("s")).prefix(" "))).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" "))).prefix(" "),(new caterwaul.syntax("return",(new caterwaul.syntax("[",new caterwaul.syntax(""))).prefix(" "))).prefix("      ")),(new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("r")).prefix(" "),(new caterwaul.syntax("[",new caterwaul.syntax(""))).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("d")).prefix(" "),(new caterwaul.syntax("-",(new caterwaul.syntax("u")).prefix(" "),(new caterwaul.syntax("i")).prefix(" "))).prefix(" "))).prefix(" "))),(new caterwaul.syntax("?",(new caterwaul.syntax(">=",(new caterwaul.syntax("d")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" "),(new caterwaul.syntax("<",(new caterwaul.syntax("i")).prefix(" "),(new caterwaul.syntax("u")).prefix("  ").infix(" "))).prefix(" "),(new caterwaul.syntax(">",(new caterwaul.syntax("i")).prefix(" "),(new caterwaul.syntax("u")).prefix("  "))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("+=",(new caterwaul.syntax("i")).prefix(" "),(new caterwaul.syntax("s")).prefix(" "))).prefix(" ")))).prefix(" "),new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("r")).prefix(" "),new caterwaul.syntax("push")),new caterwaul.syntax("i")))).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("r")).prefix(" "))).prefix(" ")))).prefix(" "))),new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax("(",new caterwaul.syntax("_l")),(new caterwaul.syntax("(",new caterwaul.syntax("_u"))).prefix(" ")),(new caterwaul.syntax("(",new caterwaul.syntax("_step"))).prefix(" "))),new caterwaul.syntax("()",new caterwaul.syntax("(",new caterwaul.syntax("function",(new caterwaul.syntax("(",new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax("i"),(new caterwaul.syntax("u")).prefix(" ")),(new caterwaul.syntax("s")).prefix(" ")))).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("if",(new caterwaul.syntax("(",(new caterwaul.syntax("||",(new caterwaul.syntax("<",(new caterwaul.syntax("*",new caterwaul.syntax("(",(new caterwaul.syntax("-",new caterwaul.syntax("u"),(new caterwaul.syntax("i")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("s")).prefix(" "))).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" "),(new caterwaul.syntax("u!",new caterwaul.syntax("s"))).prefix(" "))).prefix(" "))).prefix(" "),(new caterwaul.syntax("return",(new caterwaul.syntax("[",new caterwaul.syntax(""))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("r")).prefix(" "),(new caterwaul.syntax("[",new caterwaul.syntax(""))).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("d")).prefix(" "),(new caterwaul.syntax("-",(new caterwaul.syntax("u")).prefix(" "),(new caterwaul.syntax("i")).prefix(" "))).prefix(" "))).prefix(" "))),(new caterwaul.syntax("?",(new caterwaul.syntax(">=",(new caterwaul.syntax("d")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" "),(new caterwaul.syntax("<=",(new caterwaul.syntax("i")).prefix(" "),(new caterwaul.syntax("u")).prefix(" ").infix(" "))).prefix(" "),(new caterwaul.syntax(">=",(new caterwaul.syntax("i")).prefix(" "),(new caterwaul.syntax("u")).prefix(" "))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("+=",(new caterwaul.syntax("i")).prefix(" "),(new caterwaul.syntax("s")).prefix(" "))).prefix(" ")))).prefix(" "),new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("r")).prefix(" "),new caterwaul.syntax("push")),new caterwaul.syntax("i")))).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("r")).prefix(" "))).prefix(" ")))).prefix(" "))),new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax("(",new caterwaul.syntax("_l")),(new caterwaul.syntax("(",new caterwaul.syntax("_u"))).prefix(" ")),(new caterwaul.syntax("(",new caterwaul.syntax("_step"))).prefix(" "))),new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",(new caterwaul.syntax("=",(new caterwaul.syntax("ks")).prefix(" "),(new caterwaul.syntax("[",new caterwaul.syntax(""))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax("var",(new caterwaul.syntax("in",(new caterwaul.syntax("k")).prefix(" "),(new caterwaul.syntax("o")).prefix(" "))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("&&",new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax(".",(new caterwaul.syntax("Object")).prefix(" "),new caterwaul.syntax("prototype")),new caterwaul.syntax("hasOwnProperty")),new caterwaul.syntax("call")),new caterwaul.syntax(",",new caterwaul.syntax("o"),(new caterwaul.syntax("k")).prefix(" "))),new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("ks")).prefix(" "),new caterwaul.syntax("push")),new caterwaul.syntax("k")))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("ks")).prefix(" "))).prefix(" ")),new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",(new caterwaul.syntax("=",(new caterwaul.syntax("vs")).prefix(" "),(new caterwaul.syntax("[",new caterwaul.syntax(""))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax("var",(new caterwaul.syntax("in",(new caterwaul.syntax("k")).prefix(" "),(new caterwaul.syntax("o")).prefix(" "))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("&&",new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax(".",(new caterwaul.syntax("Object")).prefix(" "),new caterwaul.syntax("prototype")),new caterwaul.syntax("hasOwnProperty")),new caterwaul.syntax("call")),new caterwaul.syntax(",",new caterwaul.syntax("o"),(new caterwaul.syntax("k")).prefix(" "))),new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("vs")).prefix(" "),new caterwaul.syntax("push")),new caterwaul.syntax("[]",new caterwaul.syntax("o"),new caterwaul.syntax("k"))))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("vs")).prefix(" "))).prefix(" ")),new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",(new caterwaul.syntax("=",(new caterwaul.syntax("ps")).prefix(" "),(new caterwaul.syntax("[",new caterwaul.syntax(""))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax("var",(new caterwaul.syntax("in",(new caterwaul.syntax("k")).prefix(" "),(new caterwaul.syntax("o")).prefix(" "))).prefix(" ")))).prefix(" "),(new caterwaul.syntax("&&",new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax(".",new caterwaul.syntax(".",(new caterwaul.syntax("Object")).prefix(" "),new caterwaul.syntax("prototype")),new caterwaul.syntax("hasOwnProperty")),new caterwaul.syntax("call")),new caterwaul.syntax(",",new caterwaul.syntax("o"),(new caterwaul.syntax("k")).prefix(" "))),new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("ps")).prefix(" "),new caterwaul.syntax("push")),new caterwaul.syntax("[",new caterwaul.syntax(",",new caterwaul.syntax("k"),new caterwaul.syntax("[]",(new caterwaul.syntax("o")).prefix(" "),new caterwaul.syntax("k"))))))).prefix(" "))).prefix(" ")),(new caterwaul.syntax("return",(new caterwaul.syntax("ps")).prefix(" "))).prefix(" ")),new caterwaul.syntax(";",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("r")).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax(""))).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("i")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",(new caterwaul.syntax("l")).prefix(" "),new caterwaul.syntax(".",(new caterwaul.syntax("o")).prefix(" "),new caterwaul.syntax("length")))).prefix(" ")),(new caterwaul.syntax("x")).prefix(" "))),(new caterwaul.syntax("<",(new caterwaul.syntax("i")).prefix(" "),(new caterwaul.syntax("l")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u++",new caterwaul.syntax("i"))).prefix(" ")))).prefix(" "),new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("x")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("o")).prefix(" "),new caterwaul.syntax("i")))).prefix(" "),(new caterwaul.syntax("=",new caterwaul.syntax("[]",(new caterwaul.syntax("r")).prefix(" "),new caterwaul.syntax("[]",new caterwaul.syntax("x"),new caterwaul.syntax("0"))),new caterwaul.syntax("[]",(new caterwaul.syntax("x")).prefix(" "),new caterwaul.syntax("1")))).prefix(" "))),(new caterwaul.syntax("return",(new caterwaul.syntax("r")).prefix(" "))).prefix(" ")),new caterwaul.syntax(";",new caterwaul.syntax("for",(new caterwaul.syntax("(",new caterwaul.syntax(";",new caterwaul.syntax(";",new caterwaul.syntax("var",new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("r")).prefix(" "),(new caterwaul.syntax("{",new caterwaul.syntax(""))).prefix(" "))).prefix(" "),(new caterwaul.syntax("=",(new caterwaul.syntax("i")).prefix(" "),(new caterwaul.syntax("0")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("=",(new caterwaul.syntax("l")).prefix(" "),new caterwaul.syntax(".",(new caterwaul.syntax("o")).prefix(" "),new caterwaul.syntax("length")))).prefix(" ")),(new caterwaul.syntax("x")).prefix(" "))),(new caterwaul.syntax("<",(new caterwaul.syntax("i")).prefix(" "),(new caterwaul.syntax("l")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("u++",new caterwaul.syntax("i"))).prefix(" ")))).prefix(" "),new caterwaul.syntax(",",(new caterwaul.syntax("=",(new caterwaul.syntax("x")).prefix(" "),new caterwaul.syntax("[]",(new caterwaul.syntax("o")).prefix(" "),new caterwaul.syntax("i")))).prefix(" "),new caterwaul.syntax("()",new caterwaul.syntax(".",(new caterwaul.syntax("(",(new caterwaul.syntax("||",new caterwaul.syntax("[]",new caterwaul.syntax("r"),new caterwaul.syntax("[]",new caterwaul.syntax("x"),new caterwaul.syntax("0"))),(new caterwaul.syntax("(",(new caterwaul.syntax("=",new caterwaul.syntax("[]",new caterwaul.syntax("r"),new caterwaul.syntax("[]",new caterwaul.syntax("x"),new caterwaul.syntax("0"))),(new caterwaul.syntax("[",new caterwaul.syntax(""))).prefix(" "))).prefix(" "))).prefix(" "))).prefix(" "))).prefix(" "),new caterwaul.syntax("push")),new caterwaul.syntax("[]",new caterwaul.syntax("x"),new caterwaul.syntax("1"))))),(new caterwaul.syntax("return",(new caterwaul.syntax("r")).prefix(" "))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("[]",new caterwaul.syntax("n"),new caterwaul.syntax("_u"))),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("[]",new caterwaul.syntax("ni"),new caterwaul.syntax("_u"))),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("[]",new caterwaul.syntax("n"),new caterwaul.syntax(",",new caterwaul.syntax("_l"),(new caterwaul.syntax("_u")).prefix(" ")))),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("[]",new caterwaul.syntax("ni"),new caterwaul.syntax(",",new caterwaul.syntax("_l"),(new caterwaul.syntax("_u")).prefix(" ")))),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("[]",new caterwaul.syntax("n"),new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax("_l"),(new caterwaul.syntax("_u")).prefix(" ")),(new caterwaul.syntax("_step")).prefix(" ")))),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("[]",new caterwaul.syntax("ni"),new caterwaul.syntax(",",new caterwaul.syntax(",",new caterwaul.syntax("_l"),(new caterwaul.syntax("_u")).prefix(" ")),(new caterwaul.syntax("_step")).prefix(" ")))),new caterwaul.syntax("[]",new caterwaul.syntax("S"),(new caterwaul.syntax("/",new caterwaul.syntax("_o"),new caterwaul.syntax("keys"))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),(new caterwaul.syntax("|",new caterwaul.syntax("_o"),new caterwaul.syntax("object"))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),(new caterwaul.syntax("/",new caterwaul.syntax("_o"),new caterwaul.syntax("mobject"))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),(new caterwaul.syntax("/",new caterwaul.syntax("_o"),new caterwaul.syntax("values"))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),(new caterwaul.syntax("-",new caterwaul.syntax("_o"),new caterwaul.syntax("object"))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),(new caterwaul.syntax("-",new caterwaul.syntax("_o"),new caterwaul.syntax("mobject"))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),(new caterwaul.syntax("/",new caterwaul.syntax("_o"),new caterwaul.syntax("pairs"))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),(new caterwaul.syntax("/",new caterwaul.syntax("_o"),new caterwaul.syntax("object"))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),(new caterwaul.syntax("|",new caterwaul.syntax("_o"),new caterwaul.syntax("mobject"))).prefix(" "))));
caterwaul.module("std",function($){$.js_all=function(){return this("js js_literals words seq")};$.all.push("js_all")});
14 core/caterwaul/caterwaul.ui.min.js
caterwaul.module("ui.jquery",(function(qs,qs1,qs2,qs3,qs4,qs5,qs6,qs7,qs8,qs9,qsa,qsb,qsc,qsd,qse,qsf,qsg,qsh,qsi,qsj,qsk,qsl,qsm,qsn,qso,qsp,qsq,qsr,qss,qst,qsu,qsv,qsw,qsx,qsy,qsz,qs10,qs11,qs12,qs13,qs14,qs15,qs16,qs17,qs18,qs19,qs1a,qs1b,qs1c,qs1d,qs1e,qs1f,qs1g,qs1h,qs1i,qs1j,qs1k,qs1l,qs1m,qs1n){var result=(function($){$.jquery=function(caterwaul_function){return(function(it){return it.modifiers.jquery=$.grammar("J",{initial:qs},(function(rule,anon){return(function(){var jq=qs1,hyphenate=function(s){return s.replace(/_/g,"-")
},p=(function(){var p_pattern=anon(qs2);return(function(node){return p_pattern.replace({_thing:node})})}).call(this),jquery_macros=(function(){var dom_node_template=anon((""+(jq)+"(TS[_element])")),jquery_template=anon((""+(jq)+'("<span>" + (_element) + "</span>")')),become_dom_node=function(match){return dom_node_template.replace(match)
},wrap_in_jquery=function(match){return jquery_template.replace(match)};return[rule(qs3,(function(match){return match._element.is_constant()||match._element.length?wrap_in_jquery(match):become_dom_node(match)
})),rule(qs4,qs5),rule(qs6,qs7),rule(qs8,qs9),rule(qsa,qsb),rule(qsc,qsd),rule(qse,qsf),rule(qsg,qsh),rule(qsi,qsj),rule(qsk,qsl),rule(qsm,qsn),rule(qso,qsp),rule(qsq,qsr),rule(qss,qst),rule(qsu,qsv),rule(qsw,qsx),rule(qsy,qsz),rule(qs10,qs11),rule(qs12,qs13),rule(qs14,qs15),rule(qs16,qs17)]
}).call(this),string_macros=(function(){var string=function(s){return new $.syntax('"'+s.replace(/\\/g,"\\\\").replace(/"/g,'\\"')+'"')};return[rule(qs18,(function(match){return string(("<"+(hyphenate(match._identifier.data))+">"))
})),rule(qs19,(function(match){return string(hyphenate(match._identifier.data))})),rule(qs1a,(function(match){return string(expand(p(match._identifier)).data)}))]
}).call(this),search_macros=(function(){var interpolated=function(node){return("("+(node.toString())+').replace(/(\\)/g, "$1$1").replace(/(")/g, "\\$1")')},binary=function(op){return function(match){return new $.syntax((""+(expand(p(match._element1)).data)+""+(op)+""+(expand(p(match._element2)).data)+""))
}};return[rule(qs1b,(function(match){return new $.syntax(hyphenate((function(it){return it==="_"?"*":it}).call(this,(match._element.data))))})),rule(qs1c,(function(match){return new $.syntax((""+(this(p(match._element)).data)+"."+(hyphenate(match._class.data))+""))
})),rule(qs1d,(function(match){return new $.syntax((""+(this(p(match._element)).data)+"["+(this(p(match._attributes)))+"]"))})),rule(qs1e,(function(match){return new $.syntax((""+(this(p(match._attribute)).data)+'="')+interpolated(match._value)+'}"')
})),rule(qs1f,"P[_element]"),rule(qs1g,binary(", ")),rule(qs1h,binary(", ")),rule(qs1i,binary(" ")),rule(qs1j,binary(" ")),rule(qs1k,binary(" > ")),rule(qs1l,binary(" > ")),rule(qs1m,(function(match){return new $.syntax((""+(expand(p(match._element)).data)+":"+(hyphenate(match._selector.data))+""))
})),rule(qs1n,(function(match){return new $.syntax((""+(expand(p(match._element)).data)+":"+(hyphenate(match._selector.data))+'("#')+"{"+interpolated(match._value)+'}")')
}))]}).call(this);return(jquery_macros).concat(string_macros)}).call(this)})),it}).call(this,(caterwaul_function))}});result.caterwaul_expression_ref_table={qs:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_expression"))'),qs1:('new caterwaul.syntax( "jQuery")'),qs2:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "P") ,new caterwaul.syntax( "_thing"))'),qs3:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element"))'),qs4:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_element") ,new caterwaul.syntax( "_class")))'),qs5:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element")) ,new caterwaul.syntax( "addClass")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_class")))'),qs6:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "*" ,new caterwaul.syntax( "_element") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "_attr") ,new caterwaul.syntax( "_val"))) .prefix( " "))'),qs7:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element")) ,new caterwaul.syntax( "attr")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_attr")) ,new caterwaul.syntax( "_val") .prefix( " ")))'),qs8:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "*" ,new caterwaul.syntax( "_element") ,new caterwaul.syntax( "u!" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "_name") ,new caterwaul.syntax( "_val")))) .prefix( " "))'),qs9:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element")) ,new caterwaul.syntax( "data")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_name")) ,new caterwaul.syntax( "_val") .prefix( " ")))'),qsa:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "/" ,new caterwaul.syntax( "_element") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "_method") ,new caterwaul.syntax( "_args"))) .prefix( " "))'),qsb:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element")) ,new caterwaul.syntax( "_method")) ,new caterwaul.syntax( "_args"))'),qsc:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "/" ,new caterwaul.syntax( "_element") ,new caterwaul.syntax( "u!" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "_event") ,new caterwaul.syntax( "_args")))) .prefix( " "))'),qsd:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element")) ,new caterwaul.syntax( "bind")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_event")) ,new caterwaul.syntax( "_args") .prefix( " ")))'),qse:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "%" ,new caterwaul.syntax( "_element") ,new caterwaul.syntax( "_function")) .prefix( " "))'),qsf:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "_function") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element")))'),qsg:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "_element") ,new caterwaul.syntax( "_children")))'),qsh:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element")) ,new caterwaul.syntax( "append")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_children")))'),qsi:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_element") ,new caterwaul.syntax( "_children")))'),qsj:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element")) ,new caterwaul.syntax( "append")) ,new caterwaul.syntax( "_children"))'),qsk:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "<" ,new caterwaul.syntax( "_element") ,new caterwaul.syntax( "_tree") .prefix( " ")) .prefix( " "))'),qsl:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element")) ,new caterwaul.syntax( "append")) ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_tree")) ,new caterwaul.syntax( "toString")) ,new caterwaul.syntax( "")))'),qsm:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( ">" ,new caterwaul.syntax( "_element") ,new caterwaul.syntax( "_child") .prefix( " ")) .prefix( " "))'),qsn:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element")) ,new caterwaul.syntax( "append")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_child")))'),qso:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( ">=" ,new caterwaul.syntax( "_element") ,new caterwaul.syntax( "_child") .prefix( " ")) .prefix( " "))'),qsp:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element")) ,new caterwaul.syntax( "append")) ,new caterwaul.syntax( "_child"))'),qsq:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_element1") ,new caterwaul.syntax( "_element2") .prefix( " ")))'),qsr:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element1")) ,new caterwaul.syntax( "add")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element2")))'),qss:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "+" ,new caterwaul.syntax( "_element1") ,new caterwaul.syntax( "_element2") .prefix( " ")) .prefix( " "))'),qst:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element1")) ,new caterwaul.syntax( "add")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element2")))'),qsu:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "-" ,new caterwaul.syntax( "_element1") ,new caterwaul.syntax( "_element2") .prefix( " ")) .prefix( " "))'),qsv:('new caterwaul.syntax( "-" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element1")) ,new caterwaul.syntax( "_element2") .prefix( " ")) .prefix( " ")'),qsw:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( ">>" ,new caterwaul.syntax( "_element") ,new caterwaul.syntax( "_pattern") .prefix( " ")) .prefix( " "))'),qsx:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element")) ,new caterwaul.syntax( "filter")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "PS") ,new caterwaul.syntax( "_pattern")))'),qsy:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( ">>>" ,new caterwaul.syntax( "_element") ,new caterwaul.syntax( "_pattern") .prefix( " ")) .prefix( " "))'),qsz:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element")) ,new caterwaul.syntax( "find")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "PS") ,new caterwaul.syntax( "_pattern")))'),qs10:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "<<" ,new caterwaul.syntax( "_element") ,new caterwaul.syntax( "_pattern") .prefix( " ")) .prefix( " "))'),qs11:('new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element")) ,new caterwaul.syntax( "parents")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "PS") ,new caterwaul.syntax( "_pattern")))'),qs12:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_element")))'),qs13:('new caterwaul.syntax( "(" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element")))'),qs14:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "_element")))'),qs15:('new caterwaul.syntax( "[" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "_element")))'),qs16:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "J") ,new caterwaul.syntax( "u+" ,new caterwaul.syntax( "_expression")))'),qs17:('new caterwaul.syntax( "_expression")'),qs18:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "TS") ,new caterwaul.syntax( "_identifier"))'),qs19:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "S") ,new caterwaul.syntax( "_identifier"))'),qs1a:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "PS") ,new caterwaul.syntax( "_identifier"))'),qs1b:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "P") ,new caterwaul.syntax( "_element"))'),qs1c:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "P") ,new caterwaul.syntax( "." ,new caterwaul.syntax( "_element") ,new caterwaul.syntax( "_class")))'),qs1d:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "P") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "_element") ,new caterwaul.syntax( "_attributes")))'),qs1e:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "P") ,new caterwaul.syntax( "=" ,new caterwaul.syntax( "_attribute") ,new caterwaul.syntax( "_value") .prefix( " ")) .prefix( " "))'),qs1f:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "P") ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_element")))'),qs1g:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "P") ,new caterwaul.syntax( "+" ,new caterwaul.syntax( "_element1") ,new caterwaul.syntax( "_element2") .prefix( "   ")) .prefix( " "))'),qs1h:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "P") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "_element1") ,new caterwaul.syntax( "_element2") .prefix( "    ")))'),qs1i:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "P") ,new caterwaul.syntax( ">>" ,new caterwaul.syntax( "_element1") ,new caterwaul.syntax( "_element2") .prefix( "  ")) .prefix( " "))'),qs1j:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "P") ,new caterwaul.syntax( ">>>" ,new caterwaul.syntax( "_element1") ,new caterwaul.syntax( "_element2") .prefix( " ")) .prefix( " "))'),qs1k:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "P") ,new caterwaul.syntax( ">" ,new caterwaul.syntax( "_element1") ,new caterwaul.syntax( "_element2") .prefix( "   ")) .prefix( " "))'),qs1l:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "P") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "_element1") ,new caterwaul.syntax( "_element2")))'),qs1m:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "P") ,new caterwaul.syntax( "/" ,new caterwaul.syntax( "_element") ,new caterwaul.syntax( "_selector")) .prefix( " "))'),qs1n:('new caterwaul.syntax( "[]" ,new caterwaul.syntax( "P") ,new caterwaul.syntax( "/" ,new caterwaul.syntax( "_element") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "_selector") ,new caterwaul.syntax( "_value"))) .prefix( " "))')};
return(result)}).call(this,new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_expression")),new caterwaul.syntax("jQuery"),new caterwaul.syntax("[]",new caterwaul.syntax("P"),new caterwaul.syntax("_thing")),new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element")),new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax(".",new caterwaul.syntax("_element"),new caterwaul.syntax("_class"))),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element")),new caterwaul.syntax("addClass")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_class"))),new caterwaul.syntax("[]",new caterwaul.syntax("J"),(new caterwaul.syntax("*",new caterwaul.syntax("_element"),new caterwaul.syntax("()",new caterwaul.syntax("_attr"),new caterwaul.syntax("_val")))).prefix(" ")),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element")),new caterwaul.syntax("attr")),new caterwaul.syntax(",",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_attr")),(new caterwaul.syntax("_val")).prefix(" "))),new caterwaul.syntax("[]",new caterwaul.syntax("J"),(new caterwaul.syntax("*",new caterwaul.syntax("_element"),new caterwaul.syntax("u!",new caterwaul.syntax("()",new caterwaul.syntax("_name"),new caterwaul.syntax("_val"))))).prefix(" ")),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element")),new caterwaul.syntax("data")),new caterwaul.syntax(",",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_name")),(new caterwaul.syntax("_val")).prefix(" "))),new caterwaul.syntax("[]",new caterwaul.syntax("J"),(new caterwaul.syntax("/",new caterwaul.syntax("_element"),new caterwaul.syntax("()",new caterwaul.syntax("_method"),new caterwaul.syntax("_args")))).prefix(" ")),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element")),new caterwaul.syntax("_method")),new caterwaul.syntax("_args")),new caterwaul.syntax("[]",new caterwaul.syntax("J"),(new caterwaul.syntax("/",new caterwaul.syntax("_element"),new caterwaul.syntax("u!",new caterwaul.syntax("()",new caterwaul.syntax("_event"),new caterwaul.syntax("_args"))))).prefix(" ")),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element")),new caterwaul.syntax("bind")),new caterwaul.syntax(",",new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_event")),(new caterwaul.syntax("_args")).prefix(" "))),new caterwaul.syntax("[]",new caterwaul.syntax("J"),(new caterwaul.syntax("%",new caterwaul.syntax("_element"),new caterwaul.syntax("_function"))).prefix(" ")),new caterwaul.syntax("()",new caterwaul.syntax("_function"),new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element"))),new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("()",new caterwaul.syntax("_element"),new caterwaul.syntax("_children"))),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element")),new caterwaul.syntax("append")),new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_children"))),new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("[]",new caterwaul.syntax("_element"),new caterwaul.syntax("_children"))),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element")),new caterwaul.syntax("append")),new caterwaul.syntax("_children")),new caterwaul.syntax("[]",new caterwaul.syntax("J"),(new caterwaul.syntax("<",new caterwaul.syntax("_element"),(new caterwaul.syntax("_tree")).prefix(" "))).prefix(" ")),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element")),new caterwaul.syntax("append")),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("(",new caterwaul.syntax("_tree")),new caterwaul.syntax("toString")),new caterwaul.syntax(""))),new caterwaul.syntax("[]",new caterwaul.syntax("J"),(new caterwaul.syntax(">",new caterwaul.syntax("_element"),(new caterwaul.syntax("_child")).prefix(" "))).prefix(" ")),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element")),new caterwaul.syntax("append")),new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_child"))),new caterwaul.syntax("[]",new caterwaul.syntax("J"),(new caterwaul.syntax(">=",new caterwaul.syntax("_element"),(new caterwaul.syntax("_child")).prefix(" "))).prefix(" ")),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element")),new caterwaul.syntax("append")),new caterwaul.syntax("_child")),new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax(",",new caterwaul.syntax("_element1"),(new caterwaul.syntax("_element2")).prefix(" "))),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element1")),new caterwaul.syntax("add")),new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element2"))),new caterwaul.syntax("[]",new caterwaul.syntax("J"),(new caterwaul.syntax("+",new caterwaul.syntax("_element1"),(new caterwaul.syntax("_element2")).prefix(" "))).prefix(" ")),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element1")),new caterwaul.syntax("add")),new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element2"))),new caterwaul.syntax("[]",new caterwaul.syntax("J"),(new caterwaul.syntax("-",new caterwaul.syntax("_element1"),(new caterwaul.syntax("_element2")).prefix(" "))).prefix(" ")),(new caterwaul.syntax("-",new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element1")),(new caterwaul.syntax("_element2")).prefix(" "))).prefix(" "),new caterwaul.syntax("[]",new caterwaul.syntax("J"),(new caterwaul.syntax(">>",new caterwaul.syntax("_element"),(new caterwaul.syntax("_pattern")).prefix(" "))).prefix(" ")),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element")),new caterwaul.syntax("filter")),new caterwaul.syntax("[]",new caterwaul.syntax("PS"),new caterwaul.syntax("_pattern"))),new caterwaul.syntax("[]",new caterwaul.syntax("J"),(new caterwaul.syntax(">>>",new caterwaul.syntax("_element"),(new caterwaul.syntax("_pattern")).prefix(" "))).prefix(" ")),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element")),new caterwaul.syntax("find")),new caterwaul.syntax("[]",new caterwaul.syntax("PS"),new caterwaul.syntax("_pattern"))),new caterwaul.syntax("[]",new caterwaul.syntax("J"),(new caterwaul.syntax("<<",new caterwaul.syntax("_element"),(new caterwaul.syntax("_pattern")).prefix(" "))).prefix(" ")),new caterwaul.syntax("()",new caterwaul.syntax(".",new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element")),new caterwaul.syntax("parents")),new caterwaul.syntax("[]",new caterwaul.syntax("PS"),new caterwaul.syntax("_pattern"))),new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("(",new caterwaul.syntax("_element"))),new caterwaul.syntax("(",new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element"))),new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("[",new caterwaul.syntax("_element"))),new caterwaul.syntax("[",new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("_element"))),new caterwaul.syntax("[]",new caterwaul.syntax("J"),new caterwaul.syntax("u+",new caterwaul.syntax("_expression"))),new caterwaul.syntax("_expression"),new caterwaul.syntax("[]",new caterwaul.syntax("TS"),new caterwaul.syntax("_identifier")),new caterwaul.syntax("[]",new caterwaul.syntax("S"),new caterwaul.syntax("_identifier")),new caterwaul.syntax("[]",new caterwaul.syntax("PS"),new caterwaul.syntax("_identifier")),new caterwaul.syntax("[]",new caterwaul.syntax("P"),new caterwaul.syntax("_element")),new caterwaul.syntax("[]",new caterwaul.syntax("P"),new caterwaul.syntax(".",new caterwaul.syntax("_element"),new caterwaul.syntax("_class"))),new caterwaul.syntax("[]",new caterwaul.syntax("P"),new caterwaul.syntax("[]",new caterwaul.syntax("_element"),new caterwaul.syntax("_attributes"))),new caterwaul.syntax("[]",new caterwaul.syntax("P"),(new caterwaul.syntax("=",new caterwaul.syntax("_attribute"),(new caterwaul.syntax("_value")).prefix(" "))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("P"),new caterwaul.syntax("(",new caterwaul.syntax("_element"))),new caterwaul.syntax("[]",new caterwaul.syntax("P"),(new caterwaul.syntax("+",new caterwaul.syntax("_element1"),(new caterwaul.syntax("_element2")).prefix("   "))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("P"),new caterwaul.syntax(",",new caterwaul.syntax("_element1"),(new caterwaul.syntax("_element2")).prefix("    "))),new caterwaul.syntax("[]",new caterwaul.syntax("P"),(new caterwaul.syntax(">>",new caterwaul.syntax("_element1"),(new caterwaul.syntax("_element2")).prefix("  "))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("P"),(new caterwaul.syntax(">>>",new caterwaul.syntax("_element1"),(new caterwaul.syntax("_element2")).prefix(" "))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("P"),(new caterwaul.syntax(">",new caterwaul.syntax("_element1"),(new caterwaul.syntax("_element2")).prefix("   "))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("P"),new caterwaul.syntax("()",new caterwaul.syntax("_element1"),new caterwaul.syntax("_element2"))),new caterwaul.syntax("[]",new caterwaul.syntax("P"),(new caterwaul.syntax("/",new caterwaul.syntax("_element"),new caterwaul.syntax("_selector"))).prefix(" ")),new caterwaul.syntax("[]",new caterwaul.syntax("P"),(new caterwaul.syntax("/",new caterwaul.syntax("_element"),new caterwaul.syntax("()",new caterwaul.syntax("_selector"),new caterwaul.syntax("_value")))).prefix(" "))));
caterwaul.module("ui",function($){$.all.push("jquery")});
19 core/jsplot/lib
jquery.min.js
jquery.mousewheel.min.js
modus.js
vector.js

murmurhash3.js

axis.waul
label.waul
dataframe.waul
matrix.waul
socket.waul
render.waul
camera.waul
interface.waul

css
html
jsplot.pl
4 core/jsplot/jquery.min.js
/*! jQuery v1.11.1 | (c) 2005, 2014 jQuery Foundation, Inc. | jquery.org/license */
!function(a,b){"object"==typeof module&&"object"==typeof module.exports?module.exports=a.document?b(a,!0):function(a){if(!a.document)throw new Error("jQuery requires a window with a document");return b(a)}:b(a)}("undefined"!=typeof window?window:this,function(a,b){var c=[],d=c.slice,e=c.concat,f=c.push,g=c.indexOf,h={},i=h.toString,j=h.hasOwnProperty,k={},l="1.11.1",m=function(a,b){return new m.fn.init(a,b)},n=/^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g,o=/^-ms-/,p=/-([\da-z])/gi,q=function(a,b){return b.toUpperCase()};m.fn=m.prototype={jquery:l,constructor:m,selector:"",length:0,toArray:function(){return d.call(this)},get:function(a){return null!=a?0>a?this[a+this.length]:this[a]:d.call(this)},pushStack:function(a){var b=m.merge(this.constructor(),a);return b.prevObject=this,b.context=this.context,b},each:function(a,b){return m.each(this,a,b)},map:function(a){return this.pushStack(m.map(this,function(b,c){return a.call(b,c,b)}))},slice:function(){return this.pushStack(d.apply(this,arguments))},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},eq:function(a){var b=this.length,c=+a+(0>a?b:0);return this.pushStack(c>=0&&b>c?[this[c]]:[])},end:function(){return this.prevObject||this.constructor(null)},push:f,sort:c.sort,splice:c.splice},m.extend=m.fn.extend=function(){var a,b,c,d,e,f,g=arguments[0]||{},h=1,i=arguments.length,j=!1;for("boolean"==typeof g&&(j=g,g=arguments[h]||{},h++),"object"==typeof g||m.isFunction(g)||(g={}),h===i&&(g=this,h--);i>h;h++)if(null!=(e=arguments[h]))for(d in e)a=g[d],c=e[d],g!==c&&(j&&c&&(m.isPlainObject(c)||(b=m.isArray(c)))?(b?(b=!1,f=a&&m.isArray(a)?a:[]):f=a&&m.isPlainObject(a)?a:{},g[d]=m.extend(j,f,c)):void 0!==c&&(g[d]=c));return g},m.extend({expando:"jQuery"+(l+Math.random()).replace(/\D/g,""),isReady:!0,error:function(a){throw new Error(a)},noop:function(){},isFunction:function(a){return"function"===m.type(a)},isArray:Array.isArray||function(a){return"array"===m.type(a)},isWindow:function(a){return null!=a&&a==a.window},isNumeric:function(a){return!m.isArray(a)&&a-parseFloat(a)>=0},isEmptyObject:function(a){var b;for(b in a)return!1;return!0},isPlainObject:function(a){var b;if(!a||"object"!==m.type(a)||a.nodeType||m.isWindow(a))return!1;try{if(a.constructor&&!j.call(a,"constructor")&&!j.call(a.constructor.prototype,"isPrototypeOf"))return!1}catch(c){return!1}if(k.ownLast)for(b in a)return j.call(a,b);for(b in a);return void 0===b||j.call(a,b)},type:function(a){return null==a?a+"":"object"==typeof a||"function"==typeof a?h[i.call(a)]||"object":typeof a},globalEval:function(b){b&&m.trim(b)&&(a.execScript||function(b){a.eval.call(a,b)})(b)},camelCase:function(a){return a.replace(o,"ms-").replace(p,q)},nodeName:function(a,b){return a.nodeName&&a.nodeName.toLowerCase()===b.toLowerCase()},each:function(a,b,c){var d,e=0,f=a.length,g=r(a);if(c){if(g){for(;f>e;e++)if(d=b.apply(a[e],c),d===!1)break}else for(e in a)if(d=b.apply(a[e],c),d===!1)break}else if(g){for(;f>e;e++)if(d=b.call(a[e],e,a[e]),d===!1)break}else for(e in a)if(d=b.call(a[e],e,a[e]),d===!1)break;return a},trim:function(a){return null==a?"":(a+"").replace(n,"")},makeArray:function(a,b){var c=b||[];return null!=a&&(r(Object(a))?m.merge(c,"string"==typeof a?[a]:a):f.call(c,a)),c},inArray:function(a,b,c){var d;if(b){if(g)return g.call(b,a,c);for(d=b.length,c=c?0>c?Math.max(0,d+c):c:0;d>c;c++)if(c in b&&b[c]===a)return c}return-1},merge:function(a,b){var c=+b.length,d=0,e=a.length;while(c>d)a[e++]=b[d++];if(c!==c)while(void 0!==b[d])a[e++]=b[d++];return a.length=e,a},grep:function(a,b,c){for(var d,e=[],f=0,g=a.length,h=!c;g>f;f++)d=!b(a[f],f),d!==h&&e.push(a[f]);return e},map:function(a,b,c){var d,f=0,g=a.length,h=r(a),i=[];if(h)for(;g>f;f++)d=b(a[f],f,c),null!=d&&i.push(d);else for(f in a)d=b(a[f],f,c),null!=d&&i.push(d);return e.apply([],i)},guid:1,proxy:function(a,b){var c,e,f;return"string"==typeof b&&(f=a[b],b=a,a=f),m.isFunction(a)?(c=d.call(arguments,2),e=function(){return a.apply(b||this,c.concat(d.call(arguments)))},e.guid=a.guid=a.guid||m.guid++,e):void 0},now:function(){return+new Date},support:k}),m.each("Boolean Number String Function Array Date RegExp Object Error".split(" "),function(a,b){h["[object "+b+"]"]=b.toLowerCase()});function r(a){var b=a.length,c=m.type(a);return"function"===c||m.isWindow(a)?!1:1===a.nodeType&&b?!0:"array"===c||0===b||"number"==typeof b&&b>0&&b-1 in a}var s=function(a){var b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u="sizzle"+-new Date,v=a.document,w=0,x=0,y=gb(),z=gb(),A=gb(),B=function(a,b){return a===b&&(l=!0),0},C="undefined",D=1<<31,E={}.hasOwnProperty,F=[],G=F.pop,H=F.push,I=F.push,J=F.slice,K=F.indexOf||function(a){for(var b=0,c=this.length;c>b;b++)if(this[b]===a)return b;return-1},L="checked|selected|async|autofocus|autoplay|controls|defer|disabled|hidden|ismap|loop|multiple|open|readonly|required|scoped",M="[\\x20\\t\\r\\n\\f]",N="(?:\\\\.|[\\w-]|[^\\x00-\\xa0])+",O=N.replace("w","w#"),P="\\["+M+"*("+N+")(?:"+M+"*([*^$|!~]?=)"+M+"*(?:'((?:\\\\.|[^\\\\'])*)'|\"((?:\\\\.|[^\\\\\"])*)\"|("+O+"))|)"+M+"*\\]",Q=":("+N+")(?:\\((('((?:\\\\.|[^\\\\'])*)'|\"((?:\\\\.|[^\\\\\"])*)\")|((?:\\\\.|[^\\\\()[\\]]|"+P+")*)|.*)\\)|)",R=new RegExp("^"+M+"+|((?:^|[^\\\\])(?:\\\\.)*)"+M+"+$","g"),S=new RegExp("^"+M+"*,"+M+"*"),T=new RegExp("^"+M+"*([>+~]|"+M+")"+M+"*"),U=new RegExp("="+M+"*([^\\]'\"]*?)"+M+"*\\]","g"),V=new RegExp(Q),W=new RegExp("^"+O+"$"),X={ID:new RegExp("^#("+N+")"),CLASS:new RegExp("^\\.("+N+")"),TAG:new RegExp("^("+N.replace("w","w*")+")"),ATTR:new RegExp("^"+P),PSEUDO:new RegExp("^"+Q),CHILD:new RegExp("^:(only|first|last|nth|nth-last)-(child|of-type)(?:\\("+M+"*(even|odd|(([+-]|)(\\d*)n|)"+M+"*(?:([+-]|)"+M+"*(\\d+)|))"+M+"*\\)|)","i"),bool:new RegExp("^(?:"+L+")$","i"),needsContext:new RegExp("^"+M+"*[>+~]|:(even|odd|eq|gt|lt|nth|first|last)(?:\\("+M+"*((?:-\\d)?\\d*)"+M+"*\\)|)(?=[^-]|$)","i")},Y=/^(?:input|select|textarea|button)$/i,Z=/^h\d$/i,$=/^[^{]+\{\s*\[native \w/,_=/^(?:#([\w-]+)|(\w+)|\.([\w-]+))$/,ab=/[+~]/,bb=/'|\\/g,cb=new RegExp("\\\\([\\da-f]{1,6}"+M+"?|("+M+")|.)","ig"),db=function(a,b,c){var d="0x"+b-65536;return d!==d||c?b:0>d?String.fromCharCode(d+65536):String.fromCharCode(d>>10|55296,1023&d|56320)};try{I.apply(F=J.call(v.childNodes),v.childNodes),F[v.childNodes.length].nodeType}catch(eb){I={apply:F.length?function(a,b){H.apply(a,J.call(b))}:function(a,b){var c=a.length,d=0;while(a[c++]=b[d++]);a.length=c-1}}}function fb(a,b,d,e){var f,h,j,k,l,o,r,s,w,x;if((b?b.ownerDocument||b:v)!==n&&m(b),b=b||n,d=d||[],!a||"string"!=typeof a)return d;if(1!==(k=b.nodeType)&&9!==k)return[];if(p&&!e){if(f=_.exec(a))if(j=f[1]){if(9===k){if(h=b.getElementById(j),!h||!h.parentNode)return d;if(h.id===j)return d.push(h),d}else if(b.ownerDocument&&(h=b.ownerDocument.getElementById(j))&&t(b,h)&&h.id===j)return d.push(h),d}else{if(f[2])return I.apply(d,b.getElementsByTagName(a)),d;if((j=f[3])&&c.getElementsByClassName&&b.getElementsByClassName)return I.apply(d,b.getElementsByClassName(j)),d}if(c.qsa&&(!q||!q.test(a))){if(s=r=u,w=b,x=9===k&&a,1===k&&"object"!==b.nodeName.toLowerCase()){o=g(a),(r=b.getAttribute("id"))?s=r.replace(bb,"\\$&"):b.setAttribute("id",s),s="[id='"+s+"'] ",l=o.length;while(l--)o[l]=s+qb(o[l]);w=ab.test(a)&&ob(b.parentNode)||b,x=o.join(",")}if(x)try{return I.apply(d,w.querySelectorAll(x)),d}catch(y){}finally{r||b.removeAttribute("id")}}}return i(a.replace(R,"$1"),b,d,e)}function gb(){var a=[];function b(c,e){return a.push(c+" ")>d.cacheLength&&delete b[a.shift()],b[c+" "]=e}return b}function hb(a){return a[u]=!0,a}function ib(a){var b=n.createElement("div");try{return!!a(b)}catch(c){return!1}finally{b.parentNode&&b.parentNode.removeChild(b),b=null}}function jb(a,b){var c=a.split("|"),e=a.length;while(e--)d.attrHandle[c[e]]=b}function kb(a,b){var c=b&&a,d=c&&1===a.nodeType&&1===b.nodeType&&(~b.sourceIndex||D)-(~a.sourceIndex||D);if(d)return d;if(c)while(c=c.nextSibling)if(c===b)return-1;return a?1:-1}function lb(a){return function(b){var c=b.nodeName.toLowerCase();return"input"===c&&b.type===a}}function mb(a){return function(b){var c=b.nodeName.toLowerCase();return("input"===c||"button"===c)&&b.type===a}}function nb(a){return hb(function(b){return b=+b,hb(function(c,d){var e,f=a([],c.length,b),g=f.length;while(g--)c[e=f[g]]&&(c[e]=!(d[e]=c[e]))})})}function ob(a){return a&&typeof a.getElementsByTagName!==C&&a}c=fb.support={},f=fb.isXML=function(a){var b=a&&(a.ownerDocument||a).documentElement;return b?"HTML"!==b.nodeName:!1},m=fb.setDocument=function(a){var b,e=a?a.ownerDocument||a:v,g=e.defaultView;return e!==n&&9===e.nodeType&&e.documentElement?(n=e,o=e.documentElement,p=!f(e),g&&g!==g.top&&(g.addEventListener?g.addEventListener("unload",function(){m()},!1):g.attachEvent&&g.attachEvent("onunload",function(){m()})),c.attributes=ib(function(a){return a.className="i",!a.getAttribute("className")}),c.getElementsByTagName=ib(function(a){return a.appendChild(e.createComment("")),!a.getElementsByTagName("*").length}),c.getElementsByClassName=$.test(e.getElementsByClassName)&&ib(function(a){return a.innerHTML="<div class='a'></div><div class='a i'></div>",a.firstChild.className="i",2===a.getElementsByClassName("i").length}),c.getById=ib(function(a){return o.appendChild(a).id=u,!e.getElementsByName||!e.getElementsByName(u).length}),c.getById?(d.find.ID=function(a,b){if(typeof b.getElementById!==C&&p){var c=b.getElementById(a);return c&&c.parentNode?[c]:[]}},d.filter.ID=function(a){var b=a.replace(cb,db);return function(a){return a.getAttribute("id")===b}}):(delete d.find.ID,d.filter.ID=function(a){var b=a.replace(cb,db);return function(a){var c=typeof a.getAttributeNode!==C&&a.getAttributeNode("id");return c&&c.value===b}}),d.find.TAG=c.getElementsByTagName?function(a,b){return typeof b.getElementsByTagName!==C?b.getElementsByTagName(a):void 0}:function(a,b){var c,d=[],e=0,f=b.getElementsByTagName(a);if("*"===a){while(c=f[e++])1===c.nodeType&&d.push(c);return d}return f},d.find.CLASS=c.getElementsByClassName&&function(a,b){return typeof b.getElementsByClassName!==C&&p?b.getElementsByClassName(a):void 0},r=[],q=[],(c.qsa=$.test(e.querySelectorAll))&&(ib(function(a){a.innerHTML="<select msallowclip=''><option selected=''></option></select>",a.querySelectorAll("[msallowclip^='']").length&&q.push("[*^$]="+M+"*(?:''|\"\")"),a.querySelectorAll("[selected]").length||q.push("\\["+M+"*(?:value|"+L+")"),a.querySelectorAll(":checked").length||q.push(":checked")}),ib(function(a){var b=e.createElement("input");b.setAttribute("type","hidden"),a.appendChild(b).setAttribute("name","D"),a.querySelectorAll("[name=d]").length&&q.push("name"+M+"*[*^$|!~]?="),a.querySelectorAll(":enabled").length||q.push(":enabled",":disabled"),a.querySelectorAll("*,:x"),q.push(",.*:")})),(c.matchesSelector=$.test(s=o.matches||o.webkitMatchesSelector||o.mozMatchesSelector||o.oMatchesSelector||o.msMatchesSelector))&&ib(function(a){c.disconnectedMatch=s.call(a,"div"),s.call(a,"[s!='']:x"),r.push("!=",Q)}),q=q.length&&new RegExp(q.join("|")),r=r.length&&new RegExp(r.join("|")),b=$.test(o.compareDocumentPosition),t=b||$.test(o.contains)?function(a,b){var c=9===a.nodeType?a.documentElement:a,d=b&&b.parentNode;return a===d||!(!d||1!==d.nodeType||!(c.contains?c.contains(d):a.compareDocumentPosition&&16&a.compareDocumentPosition(d)))}:function(a,b){if(b)while(b=b.parentNode)if(b===a)return!0;return!1},B=b?function(a,b){if(a===b)return l=!0,0;var d=!a.compareDocumentPosition-!b.compareDocumentPosition;return d?d:(d=(a.ownerDocument||a)===(b.ownerDocument||b)?a.compareDocumentPosition(b):1,1&d||!c.sortDetached&&b.compareDocumentPosition(a)===d?a===e||a.ownerDocument===v&&t(v,a)?-1:b===e||b.ownerDocument===v&&t(v,b)?1:k?K.call(k,a)-K.call(k,b):0:4&d?-1:1)}:function(a,b){if(a===b)return l=!0,0;var c,d=0,f=a.parentNode,g=b.parentNode,h=[a],i=[b];if(!f||!g)return a===e?-1:b===e?1:f?-1:g?1:k?K.call(k,a)-K.call(k,b):0;if(f===g)return kb(a,b);c=a;while(c=c.parentNode)h.unshift(c);c=b;while(c=c.parentNode)i.unshift(c);while(h[d]===i[d])d++;return d?kb(h[d],i[d]):h[d]===v?-1:i[d]===v?1:0},e):n},fb.matches=function(a,b){return fb(a,null,null,b)},fb.matchesSelector=function(a,b){if((a.ownerDocument||a)!==n&&m(a),b=b.replace(U,"='$1']"),!(!c.matchesSelector||!p||r&&r.test(b)||q&&q.test(b)))try{var d=s.call(a,b);if(d||c.disconnectedMatch||a.document&&11!==a.document.nodeType)return d}catch(e){}return fb(b,n,null,[a]).length>0},fb.contains=function(a,b){return(a.ownerDocument||a)!==n&&m(a),t(a,b)},fb.attr=function(a,b){(a.ownerDocument||a)!==n&&m(a);var e=d.attrHandle[b.toLowerCase()],f=e&&E.call(d.attrHandle,b.toLowerCase())?e(a,b,!p):void 0;return void 0!==f?f:c.attributes||!p?a.getAttribute(b):(f=a.getAttributeNode(b))&&f.specified?f.value:null},fb.error=function(a){throw new Error("Syntax error, unrecognized expression: "+a)},fb.uniqueSort=function(a){var b,d=[],e=0,f=0;if(l=!c.detectDuplicates,k=!c.sortStable&&a.slice(0),a.sort(B),l){while(b=a[f++])b===a[f]&&(e=d.push(f));while(e--)a.splice(d[e],1)}return k=null,a},e=fb.getText=function(a){var b,c="",d=0,f=a.nodeType;if(f){if(1===f||9===f||11===f){if("string"==typeof a.textContent)return a.textContent;for(a=a.firstChild;a;a=a.nextSibling)c+=e(a)}else if(3===f||4===f)return a.nodeValue}else while(b=a[d++])c+=e(b);return c},d=fb.selectors={cacheLength:50,createPseudo:hb,match:X,attrHandle:{},find:{},relative:{">":{dir:"parentNode",first:!0}," ":{dir:"parentNode"},"+":{dir:"previousSibling",first:!0},"~":{dir:"previousSibling"}},preFilter:{ATTR:function(a){return a[1]=a[1].replace(cb,db),a[3]=(a[3]||a[4]||a[5]||"").replace(cb,db),"~="===a[2]&&(a[3]=" "+a[3]+" "),a.slice(0,4)},CHILD:function(a){return a[1]=a[1].toLowerCase(),"nth"===a[1].slice(0,3)?(a[3]||fb.error(a[0]),a[4]=+(a[4]?a[5]+(a[6]||1):2*("even"===a[3]||"odd"===a[3])),a[5]=+(a[7]+a[8]||"odd"===a[3])):a[3]&&fb.error(a[0]),a},PSEUDO:function(a){var b,c=!a[6]&&a[2];return X.CHILD.test(a[0])?null:(a[3]?a[2]=a[4]||a[5]||"":c&&V.test(c)&&(b=g(c,!0))&&(b=c.indexOf(")",c.length-b)-c.length)&&(a[0]=a[0].slice(0,b),a[2]=c.slice(0,b)),a.slice(0,3))}},filter:{TAG:function(a){var b=a.replace(cb,db).toLowerCase();return"*"===a?function(){return!0}:function(a){return a.nodeName&&a.nodeName.toLowerCase()===b}},CLASS:function(a){var b=y[a+" "];return b||(b=new RegExp("(^|"+M+")"+a+"("+M+"|$)"))&&y(a,function(a){return b.test("string"==typeof a.className&&a.className||typeof a.getAttribute!==C&&a.getAttribute("class")||"")})},ATTR:function(a,b,c){return function(d){var e=fb.attr(d,a);return null==e?"!="===b:b?(e+="","="===b?e===c:"!="===b?e!==c:"^="===b?c&&0===e.indexOf(c):"*="===b?c&&e.indexOf(c)>-1:"$="===b?c&&e.slice(-c.length)===c:"~="===b?(" "+e+" ").indexOf(c)>-1:"|="===b?e===c||e.slice(0,c.length+1)===c+"-":!1):!0}},CHILD:function(a,b,c,d,e){var f="nth"!==a.slice(0,3),g="last"!==a.slice(-4),h="of-type"===b;return 1===d&&0===e?function(a){return!!a.parentNode}:function(b,c,i){var j,k,l,m,n,o,p=f!==g?"nextSibling":"previousSibling",q=b.parentNode,r=h&&b.nodeName.toLowerCase(),s=!i&&!h;if(q){if(f){while(p){l=b;while(l=l[p])if(h?l.nodeName.toLowerCase()===r:1===l.nodeType)return!1;o=p="only"===a&&!o&&"nextSibling"}return!0}if(o=[g?q.firstChild:q.lastChild],g&&s){k=q[u]||(q[u]={}),j=k[a]||[],n=j[0]===w&&j[1],m=j[0]===w&&j[2],l=n&&q.childNodes[n];while(l=++n&&l&&l[p]||(m=n=0)||o.pop())if(1===l.nodeType&&++m&&l===b){k[a]=[w,n,m];break}}else if(s&&(j=(b[u]||(b[u]={}))[a])&&j[0]===w)m=j[1];else while(l=++n&&l&&l[p]||(m=n=0)||o.pop())if((h?l.nodeName.toLowerCase()===r:1===l.nodeType)&&++m&&(s&&((l[u]||(l[u]={}))[a]=[w,m]),l===b))break;return m-=e,m===d||m%d===0&&m/d>=0}}},PSEUDO:function(a,b){var c,e=d.pseudos[a]||d.setFilters[a.toLowerCase()]||fb.error("unsupported pseudo: "+a);return e[u]?e(b):e.length>1?(c=[a,a,"",b],d.setFilters.hasOwnProperty(a.toLowerCase())?hb(function(a,c){var d,f=e(a,b),g=f.length;while(g--)d=K.call(a,f[g]),a[d]=!(c[d]=f[g])}):function(a){return e(a,0,c)}):e}},pseudos:{not:hb(function(a){var b=[],c=[],d=h(a.replace(R,"$1"));return d[u]?hb(function(a,b,c,e){var f,g=d(a,null,e,[]),h=a.length;while(h--)(f=g[h])&&(a[h]=!(b[h]=f))}):function(a,e,f){return b[0]=a,d(b,null,f,c),!c.pop()}}),has:hb(function(a){return function(b){return fb(a,b).length>0}}),contains:hb(function(a){return function(b){return(b.textContent||b.innerText||e(b)).indexOf(a)>-1}}),lang:hb(function(a){return W.test(a||"")||fb.error("unsupported lang: "+a),a=a.replace(cb,db).toLowerCase(),function(b){var c;do if(c=p?b.lang:b.getAttribute("xml:lang")||b.getAttribute("lang"))return c=c.toLowerCase(),c===a||0===c.indexOf(a+"-");while((b=b.parentNode)&&1===b.nodeType);return!1}}),target:function(b){var c=a.location&&a.location.hash;return c&&c.slice(1)===b.id},root:function(a){return a===o},focus:function(a){return a===n.activeElement&&(!n.hasFocus||n.hasFocus())&&!!(a.type||a.href||~a.tabIndex)},enabled:function(a){return a.disabled===!1},disabled:function(a){return a.disabled===!0},checked:function(a){var b=a.nodeName.toLowerCase();return"input"===b&&!!a.checked||"option"===b&&!!a.selected},selected:function(a){return a.parentNode&&a.parentNode.selectedIndex,a.selected===!0},empty:function(a){for(a=a.firstChild;a;a=a.nextSibling)if(a.nodeType<6)return!1;return!0},parent:function(a){return!d.pseudos.empty(a)},header:function(a){return Z.test(a.nodeName)},input:function(a){return Y.test(a.nodeName)},button:function(a){var b=a.nodeName.toLowerCase();return"input"===b&&"button"===a.type||"button"===b},text:function(a){var b;return"input"===a.nodeName.toLowerCase()&&"text"===a.type&&(null==(b=a.getAttribute("type"))||"text"===b.toLowerCase())},first:nb(function(){return[0]}),last:nb(function(a,b){return[b-1]}),eq:nb(function(a,b,c){return[0>c?c+b:c]}),even:nb(function(a,b){for(var c=0;b>c;c+=2)a.push(c);return a}),odd:nb(function(a,b){for(var c=1;b>c;c+=2)a.push(c);return a}),lt:nb(function(a,b,c){for(var d=0>c?c+b:c;--d>=0;)a.push(d);return a}),gt:nb(function(a,b,c){for(var d=0>c?c+b:c;++d<b;)a.push(d);return a})}},d.pseudos.nth=d.pseudos.eq;for(b in{radio:!0,checkbox:!0,file:!0,password:!0,image:!0})d.pseudos[b]=lb(b);for(b in{submit:!0,reset:!0})d.pseudos[b]=mb(b);function pb(){}pb.prototype=d.filters=d.pseudos,d.setFilters=new pb,g=fb.tokenize=function(a,b){var c,e,f,g,h,i,j,k=z[a+" "];if(k)return b?0:k.slice(0);h=a,i=[],j=d.preFilter;while(h){(!c||(e=S.exec(h)))&&(e&&(h=h.slice(e[0].length)||h),i.push(f=[])),c=!1,(e=T.exec(h))&&(c=e.shift(),f.push({value:c,type:e[0].replace(R," ")}),h=h.slice(c.length));for(g in d.filter)!(e=X[g].exec(h))||j[g]&&!(e=j[g](e))||(c=e.shift(),f.push({value:c,type:g,matches:e}),h=h.slice(c.length));if(!c)break}return b?h.length:h?fb.error(a):z(a,i).slice(0)};function qb(a){for(var b=0,c=a.length,d="";c>b;b++)d+=a[b].value;return d}function rb(a,b,c){var d=b.dir,e=c&&"parentNode"===d,f=x++;return b.first?function(b,c,f){while(b=b[d])if(1===b.nodeType||e)return a(b,c,f)}:function(b,c,g){var h,i,j=[w,f];if(g){while(b=b[d])if((1===b.nodeType||e)&&a(b,c,g))return!0}else while(b=b[d])if(1===b.nodeType||e){if(i=b[u]||(b[u]={}),(h=i[d])&&h[0]===w&&h[1]===f)return j[2]=h[2];if(i[d]=j,j[2]=a(b,c,g))return!0}}}function sb(a){return a.length>1?function(b,c,d){var e=a.length;while(e--)if(!a[e](b,c,d))return!1;return!0}:a[0]}function tb(a,b,c){for(var d=0,e=b.length;e>d;d++)fb(a,b[d],c);return c}function ub(a,b,c,d,e){for(var f,g=[],h=0,i=a.length,j=null!=b;i>h;h++)(f=a[h])&&(!c||c(f,d,e))&&(g.push(f),j&&b.push(h));return g}function vb(a,b,c,d,e,f){return d&&!d[u]&&(d=vb(d)),e&&!e[u]&&(e=vb(e,f)),hb(function(f,g,h,i){var j,k,l,m=[],n=[],o=g.length,p=f||tb(b||"*",h.nodeType?[h]:h,[]),q=!a||!f&&b?p:ub(p,m,a,h,i),r=c?e||(f?a:o||d)?[]:g:q;if(c&&c(q,r,h,i),d){j=ub(r,n),d(j,[],h,i),k=j.length;while(k--)(l=j[k])&&(r[n[k]]=!(q[n[k]]=l))}if(f){if(e||a){if(e){j=[],k=r.length;while(k--)(l=r[k])&&j.push(q[k]=l);e(null,r=[],j,i)}k=r.length;while(k--)(l=r[k])&&(j=e?K.call(f,l):m[k])>-1&&(f[j]=!(g[j]=l))}}else r=ub(r===g?r.splice(o,r.length):r),e?e(null,g,r,i):I.apply(g,r)})}function wb(a){for(var b,c,e,f=a.length,g=d.relative[a[0].type],h=g||d.relative[" "],i=g?1:0,k=rb(function(a){return a===b},h,!0),l=rb(function(a){return K.call(b,a)>-1},h,!0),m=[function(a,c,d){return!g&&(d||c!==j)||((b=c).nodeType?k(a,c,d):l(a,c,d))}];f>i;i++)if(c=d.relative[a[i].type])m=[rb(sb(m),c)];else{if(c=d.filter[a[i].type].apply(null,a[i].matches),c[u]){for(e=++i;f>e;e++)if(d.relative[a[e].type])break;return vb(i>1&&sb(m),i>1&&qb(a.slice(0,i-1).concat({value:" "===a[i-2].type?"*":""})).replace(R,"$1"),c,e>i&&wb(a.slice(i,e)),f>e&&wb(a=a.slice(e)),f>e&&qb(a))}m.push(c)}return sb(m)}function xb(a,b){var c=b.length>0,e=a.length>0,f=function(f,g,h,i,k){var l,m,o,p=0,q="0",r=f&&[],s=[],t=j,u=f||e&&d.find.TAG("*",k),v=w+=null==t?1:Math.random()||.1,x=u.length;for(k&&(j=g!==n&&g);q!==x&&null!=(l=u[q]);q++){if(e&&l){m=0;while(o=a[m++])if(o(l,g,h)){i.push(l);break}k&&(w=v)}c&&((l=!o&&l)&&p--,f&&r.push(l))}if(p+=q,c&&q!==p){m=0;while(o=b[m++])o(r,s,g,h);if(f){if(p>0)while(q--)r[q]||s[q]||(s[q]=G.call(i));s=ub(s)}I.apply(i,s),k&&!f&&s.length>0&&p+b.length>1&&fb.uniqueSort(i)}return k&&(w=v,j=t),r};return c?hb(f):f}return h=fb.compile=function(a,b){var c,d=[],e=[],f=A[a+" "];if(!f){b||(b=g(a)),c=b.length;while(c--)f=wb(b[c]),f[u]?d.push(f):e.push(f);f=A(a,xb(e,d)),f.selector=a}return f},i=fb.select=function(a,b,e,f){var i,j,k,l,m,n="function"==typeof a&&a,o=!f&&g(a=n.selector||a);if(e=e||[],1===o.length){if(j=o[0]=o[0].slice(0),j.length>2&&"ID"===(k=j[0]).type&&c.getById&&9===b.nodeType&&p&&d.relative[j[1].type]){if(b=(d.find.ID(k.matches[0].replace(cb,db),b)||[])[0],!b)return e;n&&(b=b.parentNode),a=a.slice(j.shift().value.length)}i=X.needsContext.test(a)?0:j.length;while(i--){if(k=j[i],d.relative[l=k.type])break;if((m=d.find[l])&&(f=m(k.matches[0].replace(cb,db),ab.test(j[0].type)&&ob(b.parentNode)||b))){if(j.splice(i,1),a=f.length&&qb(j),!a)return I.apply(e,f),e;break}}}return(n||h(a,o))(f,b,!p,e,ab.test(a)&&ob(b.parentNode)||b),e},c.sortStable=u.split("").sort(B).join("")===u,c.detectDuplicates=!!l,m(),c.sortDetached=ib(function(a){return 1&a.compareDocumentPosition(n.createElement("div"))}),ib(function(a){return a.innerHTML="<a href='#'></a>","#"===a.firstChild.getAttribute("href")})||jb("type|href|height|width",function(a,b,c){return c?void 0:a.getAttribute(b,"type"===b.toLowerCase()?1:2)}),c.attributes&&ib(function(a){return a.innerHTML="<input/>",a.firstChild.setAttribute("value",""),""===a.firstChild.getAttribute("value")})||jb("value",function(a,b,c){return c||"input"!==a.nodeName.toLowerCase()?void 0:a.defaultValue}),ib(function(a){return null==a.getAttribute("disabled")})||jb(L,function(a,b,c){var d;return c?void 0:a[b]===!0?b.toLowerCase():(d=a.getAttributeNode(b))&&d.specified?d.value:null}),fb}(a);m.find=s,m.expr=s.selectors,m.expr[":"]=m.expr.pseudos,m.unique=s.uniqueSort,m.text=s.getText,m.isXMLDoc=s.isXML,m.contains=s.contains;var t=m.expr.match.needsContext,u=/^<(\w+)\s*\/?>(?:<\/\1>|)$/,v=/^.[^:#\[\.,]*$/;function w(a,b,c){if(m.isFunction(b))return m.grep(a,function(a,d){return!!b.call(a,d,a)!==c});if(b.nodeType)return m.grep(a,function(a){return a===b!==c});if("string"==typeof b){if(v.test(b))return m.filter(b,a,c);b=m.filter(b,a)}return m.grep(a,function(a){return m.inArray(a,b)>=0!==c})}m.filter=function(a,b,c){var d=b[0];return c&&(a=":not("+a+")"),1===b.length&&1===d.nodeType?m.find.matchesSelector(d,a)?[d]:[]:m.find.matches(a,m.grep(b,function(a){return 1===a.nodeType}))},m.fn.extend({find:function(a){var b,c=[],d=this,e=d.length;if("string"!=typeof a)return this.pushStack(m(a).filter(function(){for(b=0;e>b;b++)if(m.contains(d[b],this))return!0}));for(b=0;e>b;b++)m.find(a,d[b],c);return c=this.pushStack(e>1?m.unique(c):c),c.selector=this.selector?this.selector+" "+a:a,c},filter:function(a){return this.pushStack(w(this,a||[],!1))},not:function(a){return this.pushStack(w(this,a||[],!0))},is:function(a){return!!w(this,"string"==typeof a&&t.test(a)?m(a):a||[],!1).length}});var x,y=a.document,z=/^(?:\s*(<[\w\W]+>)[^>]*|#([\w-]*))$/,A=m.fn.init=function(a,b){var c,d;if(!a)return this;if("string"==typeof a){if(c="<"===a.charAt(0)&&">"===a.charAt(a.length-1)&&a.length>=3?[null,a,null]:z.exec(a),!c||!c[1]&&b)return!b||b.jquery?(b||x).find(a):this.constructor(b).find(a);if(c[1]){if(b=b instanceof m?b[0]:b,m.merge(this,m.parseHTML(c[1],b&&b.nodeType?b.ownerDocument||b:y,!0)),u.test(c[1])&&m.isPlainObject(b))for(c in b)m.isFunction(this[c])?this[c](b[c]):this.attr(c,b[c]);return this}if(d=y.getElementById(c[2]),d&&d.parentNode){if(d.id!==c[2])return x.find(a);this.length=1,this[0]=d}return this.context=y,this.selector=a,this}return a.nodeType?(this.context=this[0]=a,this.length=1,this):m.isFunction(a)?"undefined"!=typeof x.ready?x.ready(a):a(m):(void 0!==a.selector&&(this.selector=a.selector,this.context=a.context),m.makeArray(a,this))};A.prototype=m.fn,x=m(y);var B=/^(?:parents|prev(?:Until|All))/,C={children:!0,contents:!0,next:!0,prev:!0};m.extend({dir:function(a,b,c){var d=[],e=a[b];while(e&&9!==e.nodeType&&(void 0===c||1!==e.nodeType||!m(e).is(c)))1===e.nodeType&&d.push(e),e=e[b];return d},sibling:function(a,b){for(var c=[];a;a=a.nextSibling)1===a.nodeType&&a!==b&&c.push(a);return c}}),m.fn.extend({has:function(a){var b,c=m(a,this),d=c.length;return this.filter(function(){for(b=0;d>b;b++)if(m.contains(this,c[b]))return!0})},closest:function(a,b){for(var c,d=0,e=this.length,f=[],g=t.test(a)||"string"!=typeof a?m(a,b||this.context):0;e>d;d++)for(c=this[d];c&&c!==b;c=c.parentNode)if(c.nodeType<11&&(g?g.index(c)>-1:1===c.nodeType&&m.find.matchesSelector(c,a))){f.push(c);break}return this.pushStack(f.length>1?m.unique(f):f)},index:function(a){return a?"string"==typeof a?m.inArray(this[0],m(a)):m.inArray(a.jquery?a[0]:a,this):this[0]&&this[0].parentNode?this.first().prevAll().length:-1},add:function(a,b){return this.pushStack(m.unique(m.merge(this.get(),m(a,b))))},addBack:function(a){return this.add(null==a?this.prevObject:this.prevObject.filter(a))}});function D(a,b){do a=a[b];while(a&&1!==a.nodeType);return a}m.each({parent:function(a){var b=a.parentNode;return b&&11!==b.nodeType?b:null},parents:function(a){return m.dir(a,"parentNode")},parentsUntil:function(a,b,c){return m.dir(a,"parentNode",c)},next:function(a){return D(a,"nextSibling")},prev:function(a){return D(a,"previousSibling")},nextAll:function(a){return m.dir(a,"nextSibling")},prevAll:function(a){return m.dir(a,"previousSibling")},nextUntil:function(a,b,c){return m.dir(a,"nextSibling",c)},prevUntil:function(a,b,c){return m.dir(a,"previousSibling",c)},siblings:function(a){return m.sibling((a.parentNode||{}).firstChild,a)},children:function(a){return m.sibling(a.firstChild)},contents:function(a){return m.nodeName(a,"iframe")?a.contentDocument||a.contentWindow.document:m.merge([],a.childNodes)}},function(a,b){m.fn[a]=function(c,d){var e=m.map(this,b,c);return"Until"!==a.slice(-5)&&(d=c),d&&"string"==typeof d&&(e=m.filter(d,e)),this.length>1&&(C[a]||(e=m.unique(e)),B.test(a)&&(e=e.reverse())),this.pushStack(e)}});var E=/\S+/g,F={};function G(a){var b=F[a]={};return m.each(a.match(E)||[],function(a,c){b[c]=!0}),b}m.Callbacks=function(a){a="string"==typeof a?F[a]||G(a):m.extend({},a);var b,c,d,e,f,g,h=[],i=!a.once&&[],j=function(l){for(c=a.memory&&l,d=!0,f=g||0,g=0,e=h.length,b=!0;h&&e>f;f++)if(h[f].apply(l[0],l[1])===!1&&a.stopOnFalse){c=!1;break}b=!1,h&&(i?i.length&&j(i.shift()):c?h=[]:k.disable())},k={add:function(){if(h){var d=h.length;!function f(b){m.each(b,function(b,c){var d=m.type(c);"function"===d?a.unique&&k.has(c)||h.push(c):c&&c.length&&"string"!==d&&f(c)})}(arguments),b?e=h.length:c&&(g=d,j(c))}return this},remove:function(){return h&&m.each(arguments,function(a,c){var d;while((d=m.inArray(c,h,d))>-1)h.splice(d,1),b&&(e>=d&&e--,f>=d&&f--)}),this},has:function(a){return a?m.inArray(a,h)>-1:!(!h||!h.length)},empty:function(){return h=[],e=0,this},disable:function(){return h=i=c=void 0,this},disabled:function(){return!h},lock:function(){return i=void 0,c||k.disable(),this},locked:function(){return!i},fireWith:function(a,c){return!h||d&&!i||(c=c||[],c=[a,c.slice?c.slice():c],b?i.push(c):j(c)),this},fire:function(){return k.fireWith(this,arguments),this},fired:function(){return!!d}};return k},m.extend({Deferred:function(a){var b=[["resolve","done",m.Callbacks("once memory"),"resolved"],["reject","fail",m.Callbacks("once memory"),"rejected"],["notify","progress",m.Callbacks("memory")]],c="pending",d={state:function(){return c},always:function(){return e.done(arguments).fail(arguments),this},then:function(){var a=arguments;return m.Deferred(function(c){m.each(b,function(b,f){var g=m.isFunction(a[b])&&a[b];e[f[1]](function(){var a=g&&g.apply(this,arguments);a&&m.isFunction(a.promise)?a.promise().done(c.resolve).fail(c.reject).progress(c.notify):c[f[0]+"With"](this===d?c.promise():this,g?[a]:arguments)})}),a=null}).promise()},promise:function(a){return null!=a?m.extend(a,d):d}},e={};return d.pipe=d.then,m.each(b,function(a,f){var g=f[2],h=f[3];d[f[1]]=g.add,h&&g.add(function(){c=h},b[1^a][2].disable,b[2][2].lock),e[f[0]]=function(){return e[f[0]+"With"](this===e?d:this,arguments),this},e[f[0]+"With"]=g.fireWith}),d.promise(e),a&&a.call(e,e),e},when:function(a){var b=0,c=d.call(arguments),e=c.length,f=1!==e||a&&m.isFunction(a.promise)?e:0,g=1===f?a:m.Deferred(),h=function(a,b,c){return function(e){b[a]=this,c[a]=arguments.length>1?d.call(arguments):e,c===i?g.notifyWith(b,c):--f||g.resolveWith(b,c)}},i,j,k;if(e>1)for(i=new Array(e),j=new Array(e),k=new Array(e);e>b;b++)c[b]&&m.isFunction(c[b].promise)?c[b].promise().done(h(b,k,c)).fail(g.reject).progress(h(b,j,i)):--f;return f||g.resolveWith(k,c),g.promise()}});var H;m.fn.ready=function(a){return m.ready.promise().done(a),this},m.extend({isReady:!1,readyWait:1,holdReady:function(a){a?m.readyWait++:m.ready(!0)},ready:function(a){if(a===!0?!--m.readyWait:!m.isReady){if(!y.body)return setTimeout(m.ready);m.isReady=!0,a!==!0&&--m.readyWait>0||(H.resolveWith(y,[m]),m.fn.triggerHandler&&(m(y).triggerHandler("ready"),m(y).off("ready")))}}});function I(){y.addEventListener?(y.removeEventListener("DOMContentLoaded",J,!1),a.removeEventListener("load",J,!1)):(y.detachEvent("onreadystatechange",J),a.detachEvent("onload",J))}function J(){(y.addEventListener||"load"===event.type||"complete"===y.readyState)&&(I(),m.ready())}m.ready.promise=function(b){if(!H)if(H=m.Deferred(),"complete"===y.readyState)setTimeout(m.ready);else if(y.addEventListener)y.addEventListener("DOMContentLoaded",J,!1),a.addEventListener("load",J,!1);else{y.attachEvent("onreadystatechange",J),a.attachEvent("onload",J);var c=!1;try{c=null==a.frameElement&&y.documentElement}catch(d){}c&&c.doScroll&&!function e(){if(!m.isReady){try{c.doScroll("left")}catch(a){return setTimeout(e,50)}I(),m.ready()}}()}return H.promise(b)};var K="undefined",L;for(L in m(k))break;k.ownLast="0"!==L,k.inlineBlockNeedsLayout=!1,m(function(){var a,b,c,d;c=y.getElementsByTagName("body")[0],c&&c.style&&(b=y.createElement("div"),d=y.createElement("div"),d.style.cssText="position:absolute;border:0;width:0;height:0;top:0;left:-9999px",c.appendChild(d).appendChild(b),typeof b.style.zoom!==K&&(b.style.cssText="display:inline;margin:0;border:0;padding:1px;width:1px;zoom:1",k.inlineBlockNeedsLayout=a=3===b.offsetWidth,a&&(c.style.zoom=1)),c.removeChild(d))}),function(){var a=y.createElement("div");if(null==k.deleteExpando){k.deleteExpando=!0;try{delete a.test}catch(b){k.deleteExpando=!1}}a=null}(),m.acceptData=function(a){var b=m.noData[(a.nodeName+" ").toLowerCase()],c=+a.nodeType||1;return 1!==c&&9!==c?!1:!b||b!==!0&&a.getAttribute("classid")===b};var M=/^(?:\{[\w\W]*\}|\[[\w\W]*\])$/,N=/([A-Z])/g;function O(a,b,c){if(void 0===c&&1===a.nodeType){var d="data-"+b.replace(N,"-$1").toLowerCase();if(c=a.getAttribute(d),"string"==typeof c){try{c="true"===c?!0:"false"===c?!1:"null"===c?null:+c+""===c?+c:M.test(c)?m.parseJSON(c):c}catch(e){}m.data(a,b,c)}else c=void 0}return c}function P(a){var b;for(b in a)if(("data"!==b||!m.isEmptyObject(a[b]))&&"toJSON"!==b)return!1;return!0}function Q(a,b,d,e){if(m.acceptData(a)){var f,g,h=m.expando,i=a.nodeType,j=i?m.cache:a,k=i?a[h]:a[h]&&h;
if(k&&j[k]&&(e||j[k].data)||void 0!==d||"string"!=typeof b)return k||(k=i?a[h]=c.pop()||m.guid++:h),j[k]||(j[k]=i?{}:{toJSON:m.noop}),("object"==typeof b||"function"==typeof b)&&(e?j[k]=m.extend(j[k],b):j[k].data=m.extend(j[k].data,b)),g=j[k],e||(g.data||(g.data={}),g=g.data),void 0!==d&&(g[m.camelCase(b)]=d),"string"==typeof b?(f=g[b],null==f&&(f=g[m.camelCase(b)])):f=g,f}}function R(a,b,c){if(m.acceptData(a)){var d,e,f=a.nodeType,g=f?m.cache:a,h=f?a[m.expando]:m.expando;if(g[h]){if(b&&(d=c?g[h]:g[h].data)){m.isArray(b)?b=b.concat(m.map(b,m.camelCase)):b in d?b=[b]:(b=m.camelCase(b),b=b in d?[b]:b.split(" ")),e=b.length;while(e--)delete d[b[e]];if(c?!P(d):!m.isEmptyObject(d))return}(c||(delete g[h].data,P(g[h])))&&(f?m.cleanData([a],!0):k.deleteExpando||g!=g.window?delete g[h]:g[h]=null)}}}m.extend({cache:{},noData:{"applet ":!0,"embed ":!0,"object ":"clsid:D27CDB6E-AE6D-11cf-96B8-444553540000"},hasData:function(a){return a=a.nodeType?m.cache[a[m.expando]]:a[m.expando],!!a&&!P(a)},data:function(a,b,c){return Q(a,b,c)},removeData:function(a,b){return R(a,b)},_data:function(a,b,c){return Q(a,b,c,!0)},_removeData:function(a,b){return R(a,b,!0)}}),m.fn.extend({data:function(a,b){var c,d,e,f=this[0],g=f&&f.attributes;if(void 0===a){if(this.length&&(e=m.data(f),1===f.nodeType&&!m._data(f,"parsedAttrs"))){c=g.length;while(c--)g[c]&&(d=g[c].name,0===d.indexOf("data-")&&(d=m.camelCase(d.slice(5)),O(f,d,e[d])));m._data(f,"parsedAttrs",!0)}return e}return"object"==typeof a?this.each(function(){m.data(this,a)}):arguments.length>1?this.each(function(){m.data(this,a,b)}):f?O(f,a,m.data(f,a)):void 0},removeData:function(a){return this.each(function(){m.removeData(this,a)})}}),m.extend({queue:function(a,b,c){var d;return a?(b=(b||"fx")+"queue",d=m._data(a,b),c&&(!d||m.isArray(c)?d=m._data(a,b,m.makeArray(c)):d.push(c)),d||[]):void 0},dequeue:function(a,b){b=b||"fx";var c=m.queue(a,b),d=c.length,e=c.shift(),f=m._queueHooks(a,b),g=function(){m.dequeue(a,b)};"inprogress"===e&&(e=c.shift(),d--),e&&("fx"===b&&c.unshift("inprogress"),delete f.stop,e.call(a,g,f)),!d&&f&&f.empty.fire()},_queueHooks:function(a,b){var c=b+"queueHooks";return m._data(a,c)||m._data(a,c,{empty:m.Callbacks("once memory").add(function(){m._removeData(a,b+"queue"),m._removeData(a,c)})})}}),m.fn.extend({queue:function(a,b){var c=2;return"string"!=typeof a&&(b=a,a="fx",c--),arguments.length<c?m.queue(this[0],a):void 0===b?this:this.each(function(){var c=m.queue(this,a,b);m._queueHooks(this,a),"fx"===a&&"inprogress"!==c[0]&&m.dequeue(this,a)})},dequeue:function(a){return this.each(function(){m.dequeue(this,a)})},clearQueue:function(a){return this.queue(a||"fx",[])},promise:function(a,b){var c,d=1,e=m.Deferred(),f=this,g=this.length,h=function(){--d||e.resolveWith(f,[f])};"string"!=typeof a&&(b=a,a=void 0),a=a||"fx";while(g--)c=m._data(f[g],a+"queueHooks"),c&&c.empty&&(d++,c.empty.add(h));return h(),e.promise(b)}});var S=/[+-]?(?:\d*\.|)\d+(?:[eE][+-]?\d+|)/.source,T=["Top","Right","Bottom","Left"],U=function(a,b){return a=b||a,"none"===m.css(a,"display")||!m.contains(a.ownerDocument,a)},V=m.access=function(a,b,c,d,e,f,g){var h=0,i=a.length,j=null==c;if("object"===m.type(c)){e=!0;for(h in c)m.access(a,b,h,c[h],!0,f,g)}else if(void 0!==d&&(e=!0,m.isFunction(d)||(g=!0),j&&(g?(b.call(a,d),b=null):(j=b,b=function(a,b,c){return j.call(m(a),c)})),b))for(;i>h;h++)b(a[h],c,g?d:d.call(a[h],h,b(a[h],c)));return e?a:j?b.call(a):i?b(a[0],c):f},W=/^(?:checkbox|radio)$/i;!function(){var a=y.createElement("input"),b=y.createElement("div"),c=y.createDocumentFragment();if(b.innerHTML="  <link/><table></table><a href='/a'>a</a><input type='checkbox'/>",k.leadingWhitespace=3===b.firstChild.nodeType,k.tbody=!b.getElementsByTagName("tbody").length,k.htmlSerialize=!!b.getElementsByTagName("link").length,k.html5Clone="<:nav></:nav>"!==y.createElement("nav").cloneNode(!0).outerHTML,a.type="checkbox",a.checked=!0,c.appendChild(a),k.appendChecked=a.checked,b.innerHTML="<textarea>x</textarea>",k.noCloneChecked=!!b.cloneNode(!0).lastChild.defaultValue,c.appendChild(b),b.innerHTML="<input type='radio' checked='checked' name='t'/>",k.checkClone=b.cloneNode(!0).cloneNode(!0).lastChild.checked,k.noCloneEvent=!0,b.attachEvent&&(b.attachEvent("onclick",function(){k.noCloneEvent=!1}),b.cloneNode(!0).click()),null==k.deleteExpando){k.deleteExpando=!0;try{delete b.test}catch(d){k.deleteExpando=!1}}}(),function(){var b,c,d=y.createElement("div");for(b in{submit:!0,change:!0,focusin:!0})c="on"+b,(k[b+"Bubbles"]=c in a)||(d.setAttribute(c,"t"),k[b+"Bubbles"]=d.attributes[c].expando===!1);d=null}();var X=/^(?:input|select|textarea)$/i,Y=/^key/,Z=/^(?:mouse|pointer|contextmenu)|click/,$=/^(?:focusinfocus|focusoutblur)$/,_=/^([^.]*)(?:\.(.+)|)$/;function ab(){return!0}function bb(){return!1}function cb(){try{return y.activeElement}catch(a){}}m.event={global:{},add:function(a,b,c,d,e){var f,g,h,i,j,k,l,n,o,p,q,r=m._data(a);if(r){c.handler&&(i=c,c=i.handler,e=i.selector),c.guid||(c.guid=m.guid++),(g=r.events)||(g=r.events={}),(k=r.handle)||(k=r.handle=function(a){return typeof m===K||a&&m.event.triggered===a.type?void 0:m.event.dispatch.apply(k.elem,arguments)},k.elem=a),b=(b||"").match(E)||[""],h=b.length;while(h--)f=_.exec(b[h])||[],o=q=f[1],p=(f[2]||"").split(".").sort(),o&&(j=m.event.special[o]||{},o=(e?j.delegateType:j.bindType)||o,j=m.event.special[o]||{},l=m.extend({type:o,origType:q,data:d,handler:c,guid:c.guid,selector:e,needsContext:e&&m.expr.match.needsContext.test(e),namespace:p.join(".")},i),(n=g[o])||(n=g[o]=[],n.delegateCount=0,j.setup&&j.setup.call(a,d,p,k)!==!1||(a.addEventListener?a.addEventListener(o,k,!1):a.attachEvent&&a.attachEvent("on"+o,k))),j.add&&(j.add.call(a,l),l.handler.guid||(l.handler.guid=c.guid)),e?n.splice(n.delegateCount++,0,l):n.push(l),m.event.global[o]=!0);a=null}},remove:function(a,b,c,d,e){var f,g,h,i,j,k,l,n,o,p,q,r=m.hasData(a)&&m._data(a);if(r&&(k=r.events)){b=(b||"").match(E)||[""],j=b.length;while(j--)if(h=_.exec(b[j])||[],o=q=h[1],p=(h[2]||"").split(".").sort(),o){l=m.event.special[o]||{},o=(d?l.delegateType:l.bindType)||o,n=k[o]||[],h=h[2]&&new RegExp("(^|\\.)"+p.join("\\.(?:.*\\.|)")+"(\\.|$)"),i=f=n.length;while(f--)g=n[f],!e&&q!==g.origType||c&&c.guid!==g.guid||h&&!h.test(g.namespace)||d&&d!==g.selector&&("**"!==d||!g.selector)||(n.splice(f,1),g.selector&&n.delegateCount--,l.remove&&l.remove.call(a,g));i&&!n.length&&(l.teardown&&l.teardown.call(a,p,r.handle)!==!1||m.removeEvent(a,o,r.handle),delete k[o])}else for(o in k)m.event.remove(a,o+b[j],c,d,!0);m.isEmptyObject(k)&&(delete r.handle,m._removeData(a,"events"))}},trigger:function(b,c,d,e){var f,g,h,i,k,l,n,o=[d||y],p=j.call(b,"type")?b.type:b,q=j.call(b,"namespace")?b.namespace.split("."):[];if(h=l=d=d||y,3!==d.nodeType&&8!==d.nodeType&&!$.test(p+m.event.triggered)&&(p.indexOf(".")>=0&&(q=p.split("."),p=q.shift(),q.sort()),g=p.indexOf(":")<0&&"on"+p,b=b[m.expando]?b:new m.Event(p,"object"==typeof b&&b),b.isTrigger=e?2:3,b.namespace=q.join("."),b.namespace_re=b.namespace?new RegExp("(^|\\.)"+q.join("\\.(?:.*\\.|)")+"(\\.|$)"):null,b.result=void 0,b.target||(b.target=d),c=null==c?[b]:m.makeArray(c,[b]),k=m.event.special[p]||{},e||!k.trigger||k.trigger.apply(d,c)!==!1)){if(!e&&!k.noBubble&&!m.isWindow(d)){for(i=k.delegateType||p,$.test(i+p)||(h=h.parentNode);h;h=h.parentNode)o.push(h),l=h;l===(d.ownerDocument||y)&&o.push(l.defaultView||l.parentWindow||a)}n=0;while((h=o[n++])&&!b.isPropagationStopped())b.type=n>1?i:k.bindType||p,f=(m._data(h,"events")||{})[b.type]&&m._data(h,"handle"),f&&f.apply(h,c),f=g&&h[g],f&&f.apply&&m.acceptData(h)&&(b.result=f.apply(h,c),b.result===!1&&b.preventDefault());if(b.type=p,!e&&!b.isDefaultPrevented()&&(!k._default||k._default.apply(o.pop(),c)===!1)&&m.acceptData(d)&&g&&d[p]&&!m.isWindow(d)){l=d[g],l&&(d[g]=null),m.event.triggered=p;try{d[p]()}catch(r){}m.event.triggered=void 0,l&&(d[g]=l)}return b.result}},dispatch:function(a){a=m.event.fix(a);var b,c,e,f,g,h=[],i=d.call(arguments),j=(m._data(this,"events")||{})[a.type]||[],k=m.event.special[a.type]||{};if(i[0]=a,a.delegateTarget=this,!k.preDispatch||k.preDispatch.call(this,a)!==!1){h=m.event.handlers.call(this,a,j),b=0;while((f=h[b++])&&!a.isPropagationStopped()){a.currentTarget=f.elem,g=0;while((e=f.handlers[g++])&&!a.isImmediatePropagationStopped())(!a.namespace_re||a.namespace_re.test(e.namespace))&&(a.handleObj=e,a.data=e.data,c=((m.event.special[e.origType]||{}).handle||e.handler).apply(f.elem,i),void 0!==c&&(a.result=c)===!1&&(a.preventDefault(),a.stopPropagation()))}return k.postDispatch&&k.postDispatch.call(this,a),a.result}},handlers:function(a,b){var c,d,e,f,g=[],h=b.delegateCount,i=a.target;if(h&&i.nodeType&&(!a.button||"click"!==a.type))for(;i!=this;i=i.parentNode||this)if(1===i.nodeType&&(i.disabled!==!0||"click"!==a.type)){for(e=[],f=0;h>f;f++)d=b[f],c=d.selector+" ",void 0===e[c]&&(e[c]=d.needsContext?m(c,this).index(i)>=0:m.find(c,this,null,[i]).length),e[c]&&e.push(d);e.length&&g.push({elem:i,handlers:e})}return h<b.length&&g.push({elem:this,handlers:b.slice(h)}),g},fix:function(a){if(a[m.expando])return a;var b,c,d,e=a.type,f=a,g=this.fixHooks[e];g||(this.fixHooks[e]=g=Z.test(e)?this.mouseHooks:Y.test(e)?this.keyHooks:{}),d=g.props?this.props.concat(g.props):this.props,a=new m.Event(f),b=d.length;while(b--)c=d[b],a[c]=f[c];return a.target||(a.target=f.srcElement||y),3===a.target.nodeType&&(a.target=a.target.parentNode),a.metaKey=!!a.metaKey,g.filter?g.filter(a,f):a},props:"altKey bubbles cancelable ctrlKey currentTarget eventPhase metaKey relatedTarget shiftKey target timeStamp view which".split(" "),fixHooks:{},keyHooks:{props:"char charCode key keyCode".split(" "),filter:function(a,b){return null==a.which&&(a.which=null!=b.charCode?b.charCode:b.keyCode),a}},mouseHooks:{props:"button buttons clientX clientY fromElement offsetX offsetY pageX pageY screenX screenY toElement".split(" "),filter:function(a,b){var c,d,e,f=b.button,g=b.fromElement;return null==a.pageX&&null!=b.clientX&&(d=a.target.ownerDocument||y,e=d.documentElement,c=d.body,a.pageX=b.clientX+(e&&e.scrollLeft||c&&c.scrollLeft||0)-(e&&e.clientLeft||c&&c.clientLeft||0),a.pageY=b.clientY+(e&&e.scrollTop||c&&c.scrollTop||0)-(e&&e.clientTop||c&&c.clientTop||0)),!a.relatedTarget&&g&&(a.relatedTarget=g===a.target?b.toElement:g),a.which||void 0===f||(a.which=1&f?1:2&f?3:4&f?2:0),a}},special:{load:{noBubble:!0},focus:{trigger:function(){if(this!==cb()&&this.focus)try{return this.focus(),!1}catch(a){}},delegateType:"focusin"},blur:{trigger:function(){return this===cb()&&this.blur?(this.blur(),!1):void 0},delegateType:"focusout"},click:{trigger:function(){return m.nodeName(this,"input")&&"checkbox"===this.type&&this.click?(this.click(),!1):void 0},_default:function(a){return m.nodeName(a.target,"a")}},beforeunload:{postDispatch:function(a){void 0!==a.result&&a.originalEvent&&(a.originalEvent.returnValue=a.result)}}},simulate:function(a,b,c,d){var e=m.extend(new m.Event,c,{type:a,isSimulated:!0,originalEvent:{}});d?m.event.trigger(e,null,b):m.event.dispatch.call(b,e),e.isDefaultPrevented()&&c.preventDefault()}},m.removeEvent=y.removeEventListener?function(a,b,c){a.removeEventListener&&a.removeEventListener(b,c,!1)}:function(a,b,c){var d="on"+b;a.detachEvent&&(typeof a[d]===K&&(a[d]=null),a.detachEvent(d,c))},m.Event=function(a,b){return this instanceof m.Event?(a&&a.type?(this.originalEvent=a,this.type=a.type,this.isDefaultPrevented=a.defaultPrevented||void 0===a.defaultPrevented&&a.returnValue===!1?ab:bb):this.type=a,b&&m.extend(this,b),this.timeStamp=a&&a.timeStamp||m.now(),void(this[m.expando]=!0)):new m.Event(a,b)},m.Event.prototype={isDefaultPrevented:bb,isPropagationStopped:bb,isImmediatePropagationStopped:bb,preventDefault:function(){var a=this.originalEvent;this.isDefaultPrevented=ab,a&&(a.preventDefault?a.preventDefault():a.returnValue=!1)},stopPropagation:function(){var a=this.originalEvent;this.isPropagationStopped=ab,a&&(a.stopPropagation&&a.stopPropagation(),a.cancelBubble=!0)},stopImmediatePropagation:function(){var a=this.originalEvent;this.isImmediatePropagationStopped=ab,a&&a.stopImmediatePropagation&&a.stopImmediatePropagation(),this.stopPropagation()}},m.each({mouseenter:"mouseover",mouseleave:"mouseout",pointerenter:"pointerover",pointerleave:"pointerout"},function(a,b){m.event.special[a]={delegateType:b,bindType:b,handle:function(a){var c,d=this,e=a.relatedTarget,f=a.handleObj;return(!e||e!==d&&!m.contains(d,e))&&(a.type=f.origType,c=f.handler.apply(this,arguments),a.type=b),c}}}),k.submitBubbles||(m.event.special.submit={setup:function(){return m.nodeName(this,"form")?!1:void m.event.add(this,"click._submit keypress._submit",function(a){var b=a.target,c=m.nodeName(b,"input")||m.nodeName(b,"button")?b.form:void 0;c&&!m._data(c,"submitBubbles")&&(m.event.add(c,"submit._submit",function(a){a._submit_bubble=!0}),m._data(c,"submitBubbles",!0))})},postDispatch:function(a){a._submit_bubble&&(delete a._submit_bubble,this.parentNode&&!a.isTrigger&&m.event.simulate("submit",this.parentNode,a,!0))},teardown:function(){return m.nodeName(this,"form")?!1:void m.event.remove(this,"._submit")}}),k.changeBubbles||(m.event.special.change={setup:function(){return X.test(this.nodeName)?(("checkbox"===this.type||"radio"===this.type)&&(m.event.add(this,"propertychange._change",function(a){"checked"===a.originalEvent.propertyName&&(this._just_changed=!0)}),m.event.add(this,"click._change",function(a){this._just_changed&&!a.isTrigger&&(this._just_changed=!1),m.event.simulate("change",this,a,!0)})),!1):void m.event.add(this,"beforeactivate._change",function(a){var b=a.target;X.test(b.nodeName)&&!m._data(b,"changeBubbles")&&(m.event.add(b,"change._change",function(a){!this.parentNode||a.isSimulated||a.isTrigger||m.event.simulate("change",this.parentNode,a,!0)}),m._data(b,"changeBubbles",!0))})},handle:function(a){var b=a.target;return this!==b||a.isSimulated||a.isTrigger||"radio"!==b.type&&"checkbox"!==b.type?a.handleObj.handler.apply(this,arguments):void 0},teardown:function(){return m.event.remove(this,"._change"),!X.test(this.nodeName)}}),k.focusinBubbles||m.each({focus:"focusin",blur:"focusout"},function(a,b){var c=function(a){m.event.simulate(b,a.target,m.event.fix(a),!0)};m.event.special[b]={setup:function(){var d=this.ownerDocument||this,e=m._data(d,b);e||d.addEventListener(a,c,!0),m._data(d,b,(e||0)+1)},teardown:function(){var d=this.ownerDocument||this,e=m._data(d,b)-1;e?m._data(d,b,e):(d.removeEventListener(a,c,!0),m._removeData(d,b))}}}),m.fn.extend({on:function(a,b,c,d,e){var f,g;if("object"==typeof a){"string"!=typeof b&&(c=c||b,b=void 0);for(f in a)this.on(f,b,c,a[f],e);return this}if(null==c&&null==d?(d=b,c=b=void 0):null==d&&("string"==typeof b?(d=c,c=void 0):(d=c,c=b,b=void 0)),d===!1)d=bb;else if(!d)return this;return 1===e&&(g=d,d=function(a){return m().off(a),g.apply(this,arguments)},d.guid=g.guid||(g.guid=m.guid++)),this.each(function(){m.event.add(this,a,d,c,b)})},one:function(a,b,c,d){return this.on(a,b,c,d,1)},off:function(a,b,c){var d,e;if(a&&a.preventDefault&&a.handleObj)return d=a.handleObj,m(a.delegateTarget).off(d.namespace?d.origType+"."+d.namespace:d.origType,d.selector,d.handler),this;if("object"==typeof a){for(e in a)this.off(e,b,a[e]);return this}return(b===!1||"function"==typeof b)&&(c=b,b=void 0),c===!1&&(c=bb),this.each(function(){m.event.remove(this,a,c,b)})},trigger:function(a,b){return this.each(function(){m.event.trigger(a,b,this)})},triggerHandler:function(a,b){var c=this[0];return c?m.event.trigger(a,b,c,!0):void 0}});function db(a){var b=eb.split("|"),c=a.createDocumentFragment();if(c.createElement)while(b.length)c.createElement(b.pop());return c}var eb="abbr|article|aside|audio|bdi|canvas|data|datalist|details|figcaption|figure|footer|header|hgroup|mark|meter|nav|output|progress|section|summary|time|video",fb=/ jQuery\d+="(?:null|\d+)"/g,gb=new RegExp("<(?:"+eb+")[\\s/>]","i"),hb=/^\s+/,ib=/<(?!area|br|col|embed|hr|img|input|link|meta|param)(([\w:]+)[^>]*)\/>/gi,jb=/<([\w:]+)/,kb=/<tbody/i,lb=/<|&#?\w+;/,mb=/<(?:script|style|link)/i,nb=/checked\s*(?:[^=]|=\s*.checked.)/i,ob=/^$|\/(?:java|ecma)script/i,pb=/^true\/(.*)/,qb=/^\s*<!(?:\[CDATA\[|--)|(?:\]\]|--)>\s*$/g,rb={option:[1,"<select multiple='multiple'>","</select>"],legend:[1,"<fieldset>","</fieldset>"],area:[1,"<map>","</map>"],param:[1,"<object>","</object>"],thead:[1,"<table>","</table>"],tr:[2,"<table><tbody>","</tbody></table>"],col:[2,"<table><tbody></tbody><colgroup>","</colgroup></table>"],td:[3,"<table><tbody><tr>","</tr></tbody></table>"],_default:k.htmlSerialize?[0,"",""]:[1,"X<div>","</div>"]},sb=db(y),tb=sb.appendChild(y.createElement("div"));rb.optgroup=rb.option,rb.tbody=rb.tfoot=rb.colgroup=rb.caption=rb.thead,rb.th=rb.td;function ub(a,b){var c,d,e=0,f=typeof a.getElementsByTagName!==K?a.getElementsByTagName(b||"*"):typeof a.querySelectorAll!==K?a.querySelectorAll(b||"*"):void 0;if(!f)for(f=[],c=a.childNodes||a;null!=(d=c[e]);e++)!b||m.nodeName(d,b)?f.push(d):m.merge(f,ub(d,b));return void 0===b||b&&m.nodeName(a,b)?m.merge([a],f):f}function vb(a){W.test(a.type)&&(a.defaultChecked=a.checked)}function wb(a,b){return m.nodeName(a,"table")&&m.nodeName(11!==b.nodeType?b:b.firstChild,"tr")?a.getElementsByTagName("tbody")[0]||a.appendChild(a.ownerDocument.createElement("tbody")):a}function xb(a){return a.type=(null!==m.find.attr(a,"type"))+"/"+a.type,a}function yb(a){var b=pb.exec(a.type);return b?a.type=b[1]:a.removeAttribute("type"),a}function zb(a,b){for(var c,d=0;null!=(c=a[d]);d++)m._data(c,"globalEval",!b||m._data(b[d],"globalEval"))}function Ab(a,b){if(1===b.nodeType&&m.hasData(a)){var c,d,e,f=m._data(a),g=m._data(b,f),h=f.events;if(h){delete g.handle,g.events={};for(c in h)for(d=0,e=h[c].length;e>d;d++)m.event.add(b,c,h[c][d])}g.data&&(g.data=m.extend({},g.data))}}function Bb(a,b){var c,d,e;if(1===b.nodeType){if(c=b.nodeName.toLowerCase(),!k.noCloneEvent&&b[m.expando]){e=m._data(b);for(d in e.events)m.removeEvent(b,d,e.handle);b.removeAttribute(m.expando)}"script"===c&&b.text!==a.text?(xb(b).text=a.text,yb(b)):"object"===c?(b.parentNode&&(b.outerHTML=a.outerHTML),k.html5Clone&&a.innerHTML&&!m.trim(b.innerHTML)&&(b.innerHTML=a.innerHTML)):"input"===c&&W.test(a.type)?(b.defaultChecked=b.checked=a.checked,b.value!==a.value&&(b.value=a.value)):"option"===c?b.defaultSelected=b.selected=a.defaultSelected:("input"===c||"textarea"===c)&&(b.defaultValue=a.defaultValue)}}m.extend({clone:function(a,b,c){var d,e,f,g,h,i=m.contains(a.ownerDocument,a);if(k.html5Clone||m.isXMLDoc(a)||!gb.test("<"+a.nodeName+">")?f=a.cloneNode(!0):(tb.innerHTML=a.outerHTML,tb.removeChild(f=tb.firstChild)),!(k.noCloneEvent&&k.noCloneChecked||1!==a.nodeType&&11!==a.nodeType||m.isXMLDoc(a)))for(d=ub(f),h=ub(a),g=0;null!=(e=h[g]);++g)d[g]&&Bb(e,d[g]);if(b)if(c)for(h=h||ub(a),d=d||ub(f),g=0;null!=(e=h[g]);g++)Ab(e,d[g]);else Ab(a,f);return d=ub(f,"script"),d.length>0&&zb(d,!i&&ub(a,"script")),d=h=e=null,f},buildFragment:function(a,b,c,d){for(var e,f,g,h,i,j,l,n=a.length,o=db(b),p=[],q=0;n>q;q++)if(f=a[q],f||0===f)if("object"===m.type(f))m.merge(p,f.nodeType?[f]:f);else if(lb.test(f)){h=h||o.appendChild(b.createElement("div")),i=(jb.exec(f)||["",""])[1].toLowerCase(),l=rb[i]||rb._default,h.innerHTML=l[1]+f.replace(ib,"<$1></$2>")+l[2],e=l[0];while(e--)h=h.lastChild;if(!k.leadingWhitespace&&hb.test(f)&&p.push(b.createTextNode(hb.exec(f)[0])),!k.tbody){f="table"!==i||kb.test(f)?"<table>"!==l[1]||kb.test(f)?0:h:h.firstChild,e=f&&f.childNodes.length;while(e--)m.nodeName(j=f.childNodes[e],"tbody")&&!j.childNodes.length&&f.removeChild(j)}m.merge(p,h.childNodes),h.textContent="";while(h.firstChild)h.removeChild(h.firstChild);h=o.lastChild}else p.push(b.createTextNode(f));h&&o.removeChild(h),k.appendChecked||m.grep(ub(p,"input"),vb),q=0;while(f=p[q++])if((!d||-1===m.inArray(f,d))&&(g=m.contains(f.ownerDocument,f),h=ub(o.appendChild(f),"script"),g&&zb(h),c)){e=0;while(f=h[e++])ob.test(f.type||"")&&c.push(f)}return h=null,o},cleanData:function(a,b){for(var d,e,f,g,h=0,i=m.expando,j=m.cache,l=k.deleteExpando,n=m.event.special;null!=(d=a[h]);h++)if((b||m.acceptData(d))&&(f=d[i],g=f&&j[f])){if(g.events)for(e in g.events)n[e]?m.event.remove(d,e):m.removeEvent(d,e,g.handle);j[f]&&(delete j[f],l?delete d[i]:typeof d.removeAttribute!==K?d.removeAttribute(i):d[i]=null,c.push(f))}}}),m.fn.extend({text:function(a){return V(this,function(a){return void 0===a?m.text(this):this.empty().append((this[0]&&this[0].ownerDocument||y).createTextNode(a))},null,a,arguments.length)},append:function(){return this.domManip(arguments,function(a){if(1===this.nodeType||11===this.nodeType||9===this.nodeType){var b=wb(this,a);b.appendChild(a)}})},prepend:function(){return this.domManip(arguments,function(a){if(1===this.nodeType||11===this.nodeType||9===this.nodeType){var b=wb(this,a);b.insertBefore(a,b.firstChild)}})},before:function(){return this.domManip(arguments,function(a){this.parentNode&&this.parentNode.insertBefore(a,this)})},after:function(){return this.domManip(arguments,function(a){this.parentNode&&this.parentNode.insertBefore(a,this.nextSibling)})},remove:function(a,b){for(var c,d=a?m.filter(a,this):this,e=0;null!=(c=d[e]);e++)b||1!==c.nodeType||m.cleanData(ub(c)),c.parentNode&&(b&&m.contains(c.ownerDocument,c)&&zb(ub(c,"script")),c.parentNode.removeChild(c));return this},empty:function(){for(var a,b=0;null!=(a=this[b]);b++){1===a.nodeType&&m.cleanData(ub(a,!1));while(a.firstChild)a.removeChild(a.firstChild);a.options&&m.nodeName(a,"select")&&(a.options.length=0)}return this},clone:function(a,b){return a=null==a?!1:a,b=null==b?a:b,this.map(function(){return m.clone(this,a,b)})},html:function(a){return V(this,function(a){var b=this[0]||{},c=0,d=this.length;if(void 0===a)return 1===b.nodeType?b.innerHTML.replace(fb,""):void 0;if(!("string"!=typeof a||mb.test(a)||!k.htmlSerialize&&gb.test(a)||!k.leadingWhitespace&&hb.test(a)||rb[(jb.exec(a)||["",""])[1].toLowerCase()])){a=a.replace(ib,"<$1></$2>");try{for(;d>c;c++)b=this[c]||{},1===b.nodeType&&(m.cleanData(ub(b,!1)),b.innerHTML=a);b=0}catch(e){}}b&&this.empty().append(a)},null,a,arguments.length)},replaceWith:function(){var a=arguments[0];return this.domManip(arguments,function(b){a=this.parentNode,m.cleanData(ub(this)),a&&a.replaceChild(b,this)}),a&&(a.length||a.nodeType)?this:this.remove()},detach:function(a){return this.remove(a,!0)},domManip:function(a,b){a=e.apply([],a);var c,d,f,g,h,i,j=0,l=this.length,n=this,o=l-1,p=a[0],q=m.isFunction(p);if(q||l>1&&"string"==typeof p&&!k.checkClone&&nb.test(p))return this.each(function(c){var d=n.eq(c);q&&(a[0]=p.call(this,c,d.html())),d.domManip(a,b)});if(l&&(i=m.buildFragment(a,this[0].ownerDocument,!1,this),c=i.firstChild,1===i.childNodes.length&&(i=c),c)){for(g=m.map(ub(i,"script"),xb),f=g.length;l>j;j++)d=i,j!==o&&(d=m.clone(d,!0,!0),f&&m.merge(g,ub(d,"script"))),b.call(this[j],d,j);if(f)for(h=g[g.length-1].ownerDocument,m.map(g,yb),j=0;f>j;j++)d=g[j],ob.test(d.type||"")&&!m._data(d,"globalEval")&&m.contains(h,d)&&(d.src?m._evalUrl&&m._evalUrl(d.src):m.globalEval((d.text||d.textContent||d.innerHTML||"").replace(qb,"")));i=c=null}return this}}),m.each({appendTo:"append",prependTo:"prepend",insertBefore:"before",insertAfter:"after",replaceAll:"replaceWith"},function(a,b){m.fn[a]=function(a){for(var c,d=0,e=[],g=m(a),h=g.length-1;h>=d;d++)c=d===h?this:this.clone(!0),m(g[d])[b](c),f.apply(e,c.get());return this.pushStack(e)}});var Cb,Db={};function Eb(b,c){var d,e=m(c.createElement(b)).appendTo(c.body),f=a.getDefaultComputedStyle&&(d=a.getDefaultComputedStyle(e[0]))?d.display:m.css(e[0],"display");return e.detach(),f}function Fb(a){var b=y,c=Db[a];return c||(c=Eb(a,b),"none"!==c&&c||(Cb=(Cb||m("<iframe frameborder='0' width='0' height='0'/>")).appendTo(b.documentElement),b=(Cb[0].contentWindow||Cb[0].contentDocument).document,b.write(),b.close(),c=Eb(a,b),Cb.detach()),Db[a]=c),c}!function(){var a;k.shrinkWrapBlocks=function(){if(null!=a)return a;a=!1;var b,c,d;return c=y.getElementsByTagName("body")[0],c&&c.style?(b=y.createElement("div"),d=y.createElement("div"),d.style.cssText="position:absolute;border:0;width:0;height:0;top:0;left:-9999px",c.appendChild(d).appendChild(b),typeof b.style.zoom!==K&&(b.style.cssText="-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box;display:block;margin:0;border:0;padding:1px;width:1px;zoom:1",b.appendChild(y.createElement("div")).style.width="5px",a=3!==b.offsetWidth),c.removeChild(d),a):void 0}}();var Gb=/^margin/,Hb=new RegExp("^("+S+")(?!px)[a-z%]+$","i"),Ib,Jb,Kb=/^(top|right|bottom|left)$/;a.getComputedStyle?(Ib=function(a){return a.ownerDocument.defaultView.getComputedStyle(a,null)},Jb=function(a,b,c){var d,e,f,g,h=a.style;return c=c||Ib(a),g=c?c.getPropertyValue(b)||c[b]:void 0,c&&(""!==g||m.contains(a.ownerDocument,a)||(g=m.style(a,b)),Hb.test(g)&&Gb.test(b)&&(d=h.width,e=h.minWidth,f=h.maxWidth,h.minWidth=h.maxWidth=h.width=g,g=c.width,h.width=d,h.minWidth=e,h.maxWidth=f)),void 0===g?g:g+""}):y.documentElement.currentStyle&&(Ib=function(a){return a.currentStyle},Jb=function(a,b,c){var d,e,f,g,h=a.style;return c=c||Ib(a),g=c?c[b]:void 0,null==g&&h&&h[b]&&(g=h[b]),Hb.test(g)&&!Kb.test(b)&&(d=h.left,e=a.runtimeStyle,f=e&&e.left,f&&(e.left=a.currentStyle.left),h.left="fontSize"===b?"1em":g,g=h.pixelLeft+"px",h.left=d,f&&(e.left=f)),void 0===g?g:g+""||"auto"});function Lb(a,b){return{get:function(){var c=a();if(null!=c)return c?void delete this.get:(this.get=b).apply(this,arguments)}}}!function(){var b,c,d,e,f,g,h;if(b=y.createElement("div"),b.innerHTML="  <link/><table></table><a href='/a'>a</a><input type='checkbox'/>",d=b.getElementsByTagName("a")[0],c=d&&d.style){c.cssText="float:left;opacity:.5",k.opacity="0.5"===c.opacity,k.cssFloat=!!c.cssFloat,b.style.backgroundClip="content-box",b.cloneNode(!0).style.backgroundClip="",k.clearCloneStyle="content-box"===b.style.backgroundClip,k.boxSizing=""===c.boxSizing||""===c.MozBoxSizing||""===c.WebkitBoxSizing,m.extend(k,{reliableHiddenOffsets:function(){return null==g&&i(),g},boxSizingReliable:function(){return null==f&&i(),f},pixelPosition:function(){return null==e&&i(),e},reliableMarginRight:function(){return null==h&&i(),h}});function i(){var b,c,d,i;c=y.getElementsByTagName("body")[0],c&&c.style&&(b=y.createElement("div"),d=y.createElement("div"),d.style.cssText="position:absolute;border:0;width:0;height:0;top:0;left:-9999px",c.appendChild(d).appendChild(b),b.style.cssText="-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box;display:block;margin-top:1%;top:1%;border:1px;padding:1px;width:4px;position:absolute",e=f=!1,h=!0,a.getComputedStyle&&(e="1%"!==(a.getComputedStyle(b,null)||{}).top,f="4px"===(a.getComputedStyle(b,null)||{width:"4px"}).width,i=b.appendChild(y.createElement("div")),i.style.cssText=b.style.cssText="-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box;display:block;margin:0;border:0;padding:0",i.style.marginRight=i.style.width="0",b.style.width="1px",h=!parseFloat((a.getComputedStyle(i,null)||{}).marginRight)),b.innerHTML="<table><tr><td></td><td>t</td></tr></table>",i=b.getElementsByTagName("td"),i[0].style.cssText="margin:0;border:0;padding:0;display:none",g=0===i[0].offsetHeight,g&&(i[0].style.display="",i[1].style.display="none",g=0===i[0].offsetHeight),c.removeChild(d))}}}(),m.swap=function(a,b,c,d){var e,f,g={};for(f in b)g[f]=a.style[f],a.style[f]=b[f];e=c.apply(a,d||[]);for(f in b)a.style[f]=g[f];return e};var Mb=/alpha\([^)]*\)/i,Nb=/opacity\s*=\s*([^)]*)/,Ob=/^(none|table(?!-c[ea]).+)/,Pb=new RegExp("^("+S+")(.*)$","i"),Qb=new RegExp("^([+-])=("+S+")","i"),Rb={position:"absolute",visibility:"hidden",display:"block"},Sb={letterSpacing:"0",fontWeight:"400"},Tb=["Webkit","O","Moz","ms"];function Ub(a,b){if(b in a)return b;var c=b.charAt(0).toUpperCase()+b.slice(1),d=b,e=Tb.length;while(e--)if(b=Tb[e]+c,b in a)return b;return d}function Vb(a,b){for(var c,d,e,f=[],g=0,h=a.length;h>g;g++)d=a[g],d.style&&(f[g]=m._data(d,"olddisplay"),c=d.style.display,b?(f[g]||"none"!==c||(d.style.display=""),""===d.style.display&&U(d)&&(f[g]=m._data(d,"olddisplay",Fb(d.nodeName)))):(e=U(d),(c&&"none"!==c||!e)&&m._data(d,"olddisplay",e?c:m.css(d,"display"))));for(g=0;h>g;g++)d=a[g],d.style&&(b&&"none"!==d.style.display&&""!==d.style.display||(d.style.display=b?f[g]||"":"none"));return a}function Wb(a,b,c){var d=Pb.exec(b);return d?Math.max(0,d[1]-(c||0))+(d[2]||"px"):b}function Xb(a,b,c,d,e){for(var f=c===(d?"border":"content")?4:"width"===b?1:0,g=0;4>f;f+=2)"margin"===c&&(g+=m.css(a,c+T[f],!0,e)),d?("content"===c&&(g-=m.css(a,"padding"+T[f],!0,e)),"margin"!==c&&(g-=m.css(a,"border"+T[f]+"Width",!0,e))):(g+=m.css(a,"padding"+T[f],!0,e),"padding"!==c&&(g+=m.css(a,"border"+T[f]+"Width",!0,e)));return g}function Yb(a,b,c){var d=!0,e="width"===b?a.offsetWidth:a.offsetHeight,f=Ib(a),g=k.boxSizing&&"border-box"===m.css(a,"boxSizing",!1,f);if(0>=e||null==e){if(e=Jb(a,b,f),(0>e||null==e)&&(e=a.style[b]),Hb.test(e))return e;d=g&&(k.boxSizingReliable()||e===a.style[b]),e=parseFloat(e)||0}return e+Xb(a,b,c||(g?"border":"content"),d,f)+"px"}m.extend({cssHooks:{opacity:{get:function(a,b){if(b){var c=Jb(a,"opacity");return""===c?"1":c}}}},cssNumber:{columnCount:!0,fillOpacity:!0,flexGrow:!0,flexShrink:!0,fontWeight:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,widows:!0,zIndex:!0,zoom:!0},cssProps:{"float":k.cssFloat?"cssFloat":"styleFloat"},style:function(a,b,c,d){if(a&&3!==a.nodeType&&8!==a.nodeType&&a.style){var e,f,g,h=m.camelCase(b),i=a.style;if(b=m.cssProps[h]||(m.cssProps[h]=Ub(i,h)),g=m.cssHooks[b]||m.cssHooks[h],void 0===c)return g&&"get"in g&&void 0!==(e=g.get(a,!1,d))?e:i[b];if(f=typeof c,"string"===f&&(e=Qb.exec(c))&&(c=(e[1]+1)*e[2]+parseFloat(m.css(a,b)),f="number"),null!=c&&c===c&&("number"!==f||m.cssNumber[h]||(c+="px"),k.clearCloneStyle||""!==c||0!==b.indexOf("background")||(i[b]="inherit"),!(g&&"set"in g&&void 0===(c=g.set(a,c,d)))))try{i[b]=c}catch(j){}}},css:function(a,b,c,d){var e,f,g,h=m.camelCase(b);return b=m.cssProps[h]||(m.cssProps[h]=Ub(a.style,h)),g=m.cssHooks[b]||m.cssHooks[h],g&&"get"in g&&(f=g.get(a,!0,c)),void 0===f&&(f=Jb(a,b,d)),"normal"===f&&b in Sb&&(f=Sb[b]),""===c||c?(e=parseFloat(f),c===!0||m.isNumeric(e)?e||0:f):f}}),m.each(["height","width"],function(a,b){m.cssHooks[b]={get:function(a,c,d){return c?Ob.test(m.css(a,"display"))&&0===a.offsetWidth?m.swap(a,Rb,function(){return Yb(a,b,d)}):Yb(a,b,d):void 0},set:function(a,c,d){var e=d&&Ib(a);return Wb(a,c,d?Xb(a,b,d,k.boxSizing&&"border-box"===m.css(a,"boxSizing",!1,e),e):0)}}}),k.opacity||(m.cssHooks.opacity={get:function(a,b){return Nb.test((b&&a.currentStyle?a.currentStyle.filter:a.style.filter)||"")?.01*parseFloat(RegExp.$1)+"":b?"1":""},set:function(a,b){var c=a.style,d=a.currentStyle,e=m.isNumeric(b)?"alpha(opacity="+100*b+")":"",f=d&&d.filter||c.filter||"";c.zoom=1,(b>=1||""===b)&&""===m.trim(f.replace(Mb,""))&&c.removeAttribute&&(c.removeAttribute("filter"),""===b||d&&!d.filter)||(c.filter=Mb.test(f)?f.replace(Mb,e):f+" "+e)}}),m.cssHooks.marginRight=Lb(k.reliableMarginRight,function(a,b){return b?m.swap(a,{display:"inline-block"},Jb,[a,"marginRight"]):void 0}),m.each({margin:"",padding:"",border:"Width"},function(a,b){m.cssHooks[a+b]={expand:function(c){for(var d=0,e={},f="string"==typeof c?c.split(" "):[c];4>d;d++)e[a+T[d]+b]=f[d]||f[d-2]||f[0];return e}},Gb.test(a)||(m.cssHooks[a+b].set=Wb)}),m.fn.extend({css:function(a,b){return V(this,function(a,b,c){var d,e,f={},g=0;if(m.isArray(b)){for(d=Ib(a),e=b.length;e>g;g++)f[b[g]]=m.css(a,b[g],!1,d);return f}return void 0!==c?m.style(a,b,c):m.css(a,b)},a,b,arguments.length>1)},show:function(){return Vb(this,!0)},hide:function(){return Vb(this)},toggle:function(a){return"boolean"==typeof a?a?this.show():this.hide():this.each(function(){U(this)?m(this).show():m(this).hide()})}});function Zb(a,b,c,d,e){return new Zb.prototype.init(a,b,c,d,e)}m.Tween=Zb,Zb.prototype={constructor:Zb,init:function(a,b,c,d,e,f){this.elem=a,this.prop=c,this.easing=e||"swing",this.options=b,this.start=this.now=this.cur(),this.end=d,this.unit=f||(m.cssNumber[c]?"":"px")
},cur:function(){var a=Zb.propHooks[this.prop];return a&&a.get?a.get(this):Zb.propHooks._default.get(this)},run:function(a){var b,c=Zb.propHooks[this.prop];return this.pos=b=this.options.duration?m.easing[this.easing](a,this.options.duration*a,0,1,this.options.duration):a,this.now=(this.end-this.start)*b+this.start,this.options.step&&this.options.step.call(this.elem,this.now,this),c&&c.set?c.set(this):Zb.propHooks._default.set(this),this}},Zb.prototype.init.prototype=Zb.prototype,Zb.propHooks={_default:{get:function(a){var b;return null==a.elem[a.prop]||a.elem.style&&null!=a.elem.style[a.prop]?(b=m.css(a.elem,a.prop,""),b&&"auto"!==b?b:0):a.elem[a.prop]},set:function(a){m.fx.step[a.prop]?m.fx.step[a.prop](a):a.elem.style&&(null!=a.elem.style[m.cssProps[a.prop]]||m.cssHooks[a.prop])?m.style(a.elem,a.prop,a.now+a.unit):a.elem[a.prop]=a.now}}},Zb.propHooks.scrollTop=Zb.propHooks.scrollLeft={set:function(a){a.elem.nodeType&&a.elem.parentNode&&(a.elem[a.prop]=a.now)}},m.easing={linear:function(a){return a},swing:function(a){return.5-Math.cos(a*Math.PI)/2}},m.fx=Zb.prototype.init,m.fx.step={};var $b,_b,ac=/^(?:toggle|show|hide)$/,bc=new RegExp("^(?:([+-])=|)("+S+")([a-z%]*)$","i"),cc=/queueHooks$/,dc=[ic],ec={"*":[function(a,b){var c=this.createTween(a,b),d=c.cur(),e=bc.exec(b),f=e&&e[3]||(m.cssNumber[a]?"":"px"),g=(m.cssNumber[a]||"px"!==f&&+d)&&bc.exec(m.css(c.elem,a)),h=1,i=20;if(g&&g[3]!==f){f=f||g[3],e=e||[],g=+d||1;do h=h||".5",g/=h,m.style(c.elem,a,g+f);while(h!==(h=c.cur()/d)&&1!==h&&--i)}return e&&(g=c.start=+g||+d||0,c.unit=f,c.end=e[1]?g+(e[1]+1)*e[2]:+e[2]),c}]};function fc(){return setTimeout(function(){$b=void 0}),$b=m.now()}function gc(a,b){var c,d={height:a},e=0;for(b=b?1:0;4>e;e+=2-b)c=T[e],d["margin"+c]=d["padding"+c]=a;return b&&(d.opacity=d.width=a),d}function hc(a,b,c){for(var d,e=(ec[b]||[]).concat(ec["*"]),f=0,g=e.length;g>f;f++)if(d=e[f].call(c,b,a))return d}function ic(a,b,c){var d,e,f,g,h,i,j,l,n=this,o={},p=a.style,q=a.nodeType&&U(a),r=m._data(a,"fxshow");c.queue||(h=m._queueHooks(a,"fx"),null==h.unqueued&&(h.unqueued=0,i=h.empty.fire,h.empty.fire=function(){h.unqueued||i()}),h.unqueued++,n.always(function(){n.always(function(){h.unqueued--,m.queue(a,"fx").length||h.empty.fire()})})),1===a.nodeType&&("height"in b||"width"in b)&&(c.overflow=[p.overflow,p.overflowX,p.overflowY],j=m.css(a,"display"),l="none"===j?m._data(a,"olddisplay")||Fb(a.nodeName):j,"inline"===l&&"none"===m.css(a,"float")&&(k.inlineBlockNeedsLayout&&"inline"!==Fb(a.nodeName)?p.zoom=1:p.display="inline-block")),c.overflow&&(p.overflow="hidden",k.shrinkWrapBlocks()||n.always(function(){p.overflow=c.overflow[0],p.overflowX=c.overflow[1],p.overflowY=c.overflow[2]}));for(d in b)if(e=b[d],ac.exec(e)){if(delete b[d],f=f||"toggle"===e,e===(q?"hide":"show")){if("show"!==e||!r||void 0===r[d])continue;q=!0}o[d]=r&&r[d]||m.style(a,d)}else j=void 0;if(m.isEmptyObject(o))"inline"===("none"===j?Fb(a.nodeName):j)&&(p.display=j);else{r?"hidden"in r&&(q=r.hidden):r=m._data(a,"fxshow",{}),f&&(r.hidden=!q),q?m(a).show():n.done(function(){m(a).hide()}),n.done(function(){var b;m._removeData(a,"fxshow");for(b in o)m.style(a,b,o[b])});for(d in o)g=hc(q?r[d]:0,d,n),d in r||(r[d]=g.start,q&&(g.end=g.start,g.start="width"===d||"height"===d?1:0))}}function jc(a,b){var c,d,e,f,g;for(c in a)if(d=m.camelCase(c),e=b[d],f=a[c],m.isArray(f)&&(e=f[1],f=a[c]=f[0]),c!==d&&(a[d]=f,delete a[c]),g=m.cssHooks[d],g&&"expand"in g){f=g.expand(f),delete a[d];for(c in f)c in a||(a[c]=f[c],b[c]=e)}else b[d]=e}function kc(a,b,c){var d,e,f=0,g=dc.length,h=m.Deferred().always(function(){delete i.elem}),i=function(){if(e)return!1;for(var b=$b||fc(),c=Math.max(0,j.startTime+j.duration-b),d=c/j.duration||0,f=1-d,g=0,i=j.tweens.length;i>g;g++)j.tweens[g].run(f);return h.notifyWith(a,[j,f,c]),1>f&&i?c:(h.resolveWith(a,[j]),!1)},j=h.promise({elem:a,props:m.extend({},b),opts:m.extend(!0,{specialEasing:{}},c),originalProperties:b,originalOptions:c,startTime:$b||fc(),duration:c.duration,tweens:[],createTween:function(b,c){var d=m.Tween(a,j.opts,b,c,j.opts.specialEasing[b]||j.opts.easing);return j.tweens.push(d),d},stop:function(b){var c=0,d=b?j.tweens.length:0;if(e)return this;for(e=!0;d>c;c++)j.tweens[c].run(1);return b?h.resolveWith(a,[j,b]):h.rejectWith(a,[j,b]),this}}),k=j.props;for(jc(k,j.opts.specialEasing);g>f;f++)if(d=dc[f].call(j,a,k,j.opts))return d;return m.map(k,hc,j),m.isFunction(j.opts.start)&&j.opts.start.call(a,j),m.fx.timer(m.extend(i,{elem:a,anim:j,queue:j.opts.queue})),j.progress(j.opts.progress).done(j.opts.done,j.opts.complete).fail(j.opts.fail).always(j.opts.always)}m.Animation=m.extend(kc,{tweener:function(a,b){m.isFunction(a)?(b=a,a=["*"]):a=a.split(" ");for(var c,d=0,e=a.length;e>d;d++)c=a[d],ec[c]=ec[c]||[],ec[c].unshift(b)},prefilter:function(a,b){b?dc.unshift(a):dc.push(a)}}),m.speed=function(a,b,c){var d=a&&"object"==typeof a?m.extend({},a):{complete:c||!c&&b||m.isFunction(a)&&a,duration:a,easing:c&&b||b&&!m.isFunction(b)&&b};return d.duration=m.fx.off?0:"number"==typeof d.duration?d.duration:d.duration in m.fx.speeds?m.fx.speeds[d.duration]:m.fx.speeds._default,(null==d.queue||d.queue===!0)&&(d.queue="fx"),d.old=d.complete,d.complete=function(){m.isFunction(d.old)&&d.old.call(this),d.queue&&m.dequeue(this,d.queue)},d},m.fn.extend({fadeTo:function(a,b,c,d){return this.filter(U).css("opacity",0).show().end().animate({opacity:b},a,c,d)},animate:function(a,b,c,d){var e=m.isEmptyObject(a),f=m.speed(b,c,d),g=function(){var b=kc(this,m.extend({},a),f);(e||m._data(this,"finish"))&&b.stop(!0)};return g.finish=g,e||f.queue===!1?this.each(g):this.queue(f.queue,g)},stop:function(a,b,c){var d=function(a){var b=a.stop;delete a.stop,b(c)};return"string"!=typeof a&&(c=b,b=a,a=void 0),b&&a!==!1&&this.queue(a||"fx",[]),this.each(function(){var b=!0,e=null!=a&&a+"queueHooks",f=m.timers,g=m._data(this);if(e)g[e]&&g[e].stop&&d(g[e]);else for(e in g)g[e]&&g[e].stop&&cc.test(e)&&d(g[e]);for(e=f.length;e--;)f[e].elem!==this||null!=a&&f[e].queue!==a||(f[e].anim.stop(c),b=!1,f.splice(e,1));(b||!c)&&m.dequeue(this,a)})},finish:function(a){return a!==!1&&(a=a||"fx"),this.each(function(){var b,c=m._data(this),d=c[a+"queue"],e=c[a+"queueHooks"],f=m.timers,g=d?d.length:0;for(c.finish=!0,m.queue(this,a,[]),e&&e.stop&&e.stop.call(this,!0),b=f.length;b--;)f[b].elem===this&&f[b].queue===a&&(f[b].anim.stop(!0),f.splice(b,1));for(b=0;g>b;b++)d[b]&&d[b].finish&&d[b].finish.call(this);delete c.finish})}}),m.each(["toggle","show","hide"],function(a,b){var c=m.fn[b];m.fn[b]=function(a,d,e){return null==a||"boolean"==typeof a?c.apply(this,arguments):this.animate(gc(b,!0),a,d,e)}}),m.each({slideDown:gc("show"),slideUp:gc("hide"),slideToggle:gc("toggle"),fadeIn:{opacity:"show"},fadeOut:{opacity:"hide"},fadeToggle:{opacity:"toggle"}},function(a,b){m.fn[a]=function(a,c,d){return this.animate(b,a,c,d)}}),m.timers=[],m.fx.tick=function(){var a,b=m.timers,c=0;for($b=m.now();c<b.length;c++)a=b[c],a()||b[c]!==a||b.splice(c--,1);b.length||m.fx.stop(),$b=void 0},m.fx.timer=function(a){m.timers.push(a),a()?m.fx.start():m.timers.pop()},m.fx.interval=13,m.fx.start=function(){_b||(_b=setInterval(m.fx.tick,m.fx.interval))},m.fx.stop=function(){clearInterval(_b),_b=null},m.fx.speeds={slow:600,fast:200,_default:400},m.fn.delay=function(a,b){return a=m.fx?m.fx.speeds[a]||a:a,b=b||"fx",this.queue(b,function(b,c){var d=setTimeout(b,a);c.stop=function(){clearTimeout(d)}})},function(){var a,b,c,d,e;b=y.createElement("div"),b.setAttribute("className","t"),b.innerHTML="  <link/><table></table><a href='/a'>a</a><input type='checkbox'/>",d=b.getElementsByTagName("a")[0],c=y.createElement("select"),e=c.appendChild(y.createElement("option")),a=b.getElementsByTagName("input")[0],d.style.cssText="top:1px",k.getSetAttribute="t"!==b.className,k.style=/top/.test(d.getAttribute("style")),k.hrefNormalized="/a"===d.getAttribute("href"),k.checkOn=!!a.value,k.optSelected=e.selected,k.enctype=!!y.createElement("form").enctype,c.disabled=!0,k.optDisabled=!e.disabled,a=y.createElement("input"),a.setAttribute("value",""),k.input=""===a.getAttribute("value"),a.value="t",a.setAttribute("type","radio"),k.radioValue="t"===a.value}();var lc=/\r/g;m.fn.extend({val:function(a){var b,c,d,e=this[0];{if(arguments.length)return d=m.isFunction(a),this.each(function(c){var e;1===this.nodeType&&(e=d?a.call(this,c,m(this).val()):a,null==e?e="":"number"==typeof e?e+="":m.isArray(e)&&(e=m.map(e,function(a){return null==a?"":a+""})),b=m.valHooks[this.type]||m.valHooks[this.nodeName.toLowerCase()],b&&"set"in b&&void 0!==b.set(this,e,"value")||(this.value=e))});if(e)return b=m.valHooks[e.type]||m.valHooks[e.nodeName.toLowerCase()],b&&"get"in b&&void 0!==(c=b.get(e,"value"))?c:(c=e.value,"string"==typeof c?c.replace(lc,""):null==c?"":c)}}}),m.extend({valHooks:{option:{get:function(a){var b=m.find.attr(a,"value");return null!=b?b:m.trim(m.text(a))}},select:{get:function(a){for(var b,c,d=a.options,e=a.selectedIndex,f="select-one"===a.type||0>e,g=f?null:[],h=f?e+1:d.length,i=0>e?h:f?e:0;h>i;i++)if(c=d[i],!(!c.selected&&i!==e||(k.optDisabled?c.disabled:null!==c.getAttribute("disabled"))||c.parentNode.disabled&&m.nodeName(c.parentNode,"optgroup"))){if(b=m(c).val(),f)return b;g.push(b)}return g},set:function(a,b){var c,d,e=a.options,f=m.makeArray(b),g=e.length;while(g--)if(d=e[g],m.inArray(m.valHooks.option.get(d),f)>=0)try{d.selected=c=!0}catch(h){d.scrollHeight}else d.selected=!1;return c||(a.selectedIndex=-1),e}}}}),m.each(["radio","checkbox"],function(){m.valHooks[this]={set:function(a,b){return m.isArray(b)?a.checked=m.inArray(m(a).val(),b)>=0:void 0}},k.checkOn||(m.valHooks[this].get=function(a){return null===a.getAttribute("value")?"on":a.value})});var mc,nc,oc=m.expr.attrHandle,pc=/^(?:checked|selected)$/i,qc=k.getSetAttribute,rc=k.input;m.fn.extend({attr:function(a,b){return V(this,m.attr,a,b,arguments.length>1)},removeAttr:function(a){return this.each(function(){m.removeAttr(this,a)})}}),m.extend({attr:function(a,b,c){var d,e,f=a.nodeType;if(a&&3!==f&&8!==f&&2!==f)return typeof a.getAttribute===K?m.prop(a,b,c):(1===f&&m.isXMLDoc(a)||(b=b.toLowerCase(),d=m.attrHooks[b]||(m.expr.match.bool.test(b)?nc:mc)),void 0===c?d&&"get"in d&&null!==(e=d.get(a,b))?e:(e=m.find.attr(a,b),null==e?void 0:e):null!==c?d&&"set"in d&&void 0!==(e=d.set(a,c,b))?e:(a.setAttribute(b,c+""),c):void m.removeAttr(a,b))},removeAttr:function(a,b){var c,d,e=0,f=b&&b.match(E);if(f&&1===a.nodeType)while(c=f[e++])d=m.propFix[c]||c,m.expr.match.bool.test(c)?rc&&qc||!pc.test(c)?a[d]=!1:a[m.camelCase("default-"+c)]=a[d]=!1:m.attr(a,c,""),a.removeAttribute(qc?c:d)},attrHooks:{type:{set:function(a,b){if(!k.radioValue&&"radio"===b&&m.nodeName(a,"input")){var c=a.value;return a.setAttribute("type",b),c&&(a.value=c),b}}}}}),nc={set:function(a,b,c){return b===!1?m.removeAttr(a,c):rc&&qc||!pc.test(c)?a.setAttribute(!qc&&m.propFix[c]||c,c):a[m.camelCase("default-"+c)]=a[c]=!0,c}},m.each(m.expr.match.bool.source.match(/\w+/g),function(a,b){var c=oc[b]||m.find.attr;oc[b]=rc&&qc||!pc.test(b)?function(a,b,d){var e,f;return d||(f=oc[b],oc[b]=e,e=null!=c(a,b,d)?b.toLowerCase():null,oc[b]=f),e}:function(a,b,c){return c?void 0:a[m.camelCase("default-"+b)]?b.toLowerCase():null}}),rc&&qc||(m.attrHooks.value={set:function(a,b,c){return m.nodeName(a,"input")?void(a.defaultValue=b):mc&&mc.set(a,b,c)}}),qc||(mc={set:function(a,b,c){var d=a.getAttributeNode(c);return d||a.setAttributeNode(d=a.ownerDocument.createAttribute(c)),d.value=b+="","value"===c||b===a.getAttribute(c)?b:void 0}},oc.id=oc.name=oc.coords=function(a,b,c){var d;return c?void 0:(d=a.getAttributeNode(b))&&""!==d.value?d.value:null},m.valHooks.button={get:function(a,b){var c=a.getAttributeNode(b);return c&&c.specified?c.value:void 0},set:mc.set},m.attrHooks.contenteditable={set:function(a,b,c){mc.set(a,""===b?!1:b,c)}},m.each(["width","height"],function(a,b){m.attrHooks[b]={set:function(a,c){return""===c?(a.setAttribute(b,"auto"),c):void 0}}})),k.style||(m.attrHooks.style={get:function(a){return a.style.cssText||void 0},set:function(a,b){return a.style.cssText=b+""}});var sc=/^(?:input|select|textarea|button|object)$/i,tc=/^(?:a|area)$/i;m.fn.extend({prop:function(a,b){return V(this,m.prop,a,b,arguments.length>1)},removeProp:function(a){return a=m.propFix[a]||a,this.each(function(){try{this[a]=void 0,delete this[a]}catch(b){}})}}),m.extend({propFix:{"for":"htmlFor","class":"className"},prop:function(a,b,c){var d,e,f,g=a.nodeType;if(a&&3!==g&&8!==g&&2!==g)return f=1!==g||!m.isXMLDoc(a),f&&(b=m.propFix[b]||b,e=m.propHooks[b]),void 0!==c?e&&"set"in e&&void 0!==(d=e.set(a,c,b))?d:a[b]=c:e&&"get"in e&&null!==(d=e.get(a,b))?d:a[b]},propHooks:{tabIndex:{get:function(a){var b=m.find.attr(a,"tabindex");return b?parseInt(b,10):sc.test(a.nodeName)||tc.test(a.nodeName)&&a.href?0:-1}}}}),k.hrefNormalized||m.each(["href","src"],function(a,b){m.propHooks[b]={get:function(a){return a.getAttribute(b,4)}}}),k.optSelected||(m.propHooks.selected={get:function(a){var b=a.parentNode;return b&&(b.selectedIndex,b.parentNode&&b.parentNode.selectedIndex),null}}),m.each(["tabIndex","readOnly","maxLength","cellSpacing","cellPadding","rowSpan","colSpan","useMap","frameBorder","contentEditable"],function(){m.propFix[this.toLowerCase()]=this}),k.enctype||(m.propFix.enctype="encoding");var uc=/[\t\r\n\f]/g;m.fn.extend({addClass:function(a){var b,c,d,e,f,g,h=0,i=this.length,j="string"==typeof a&&a;if(m.isFunction(a))return this.each(function(b){m(this).addClass(a.call(this,b,this.className))});if(j)for(b=(a||"").match(E)||[];i>h;h++)if(c=this[h],d=1===c.nodeType&&(c.className?(" "+c.className+" ").replace(uc," "):" ")){f=0;while(e=b[f++])d.indexOf(" "+e+" ")<0&&(d+=e+" ");g=m.trim(d),c.className!==g&&(c.className=g)}return this},removeClass:function(a){var b,c,d,e,f,g,h=0,i=this.length,j=0===arguments.length||"string"==typeof a&&a;if(m.isFunction(a))return this.each(function(b){m(this).removeClass(a.call(this,b,this.className))});if(j)for(b=(a||"").match(E)||[];i>h;h++)if(c=this[h],d=1===c.nodeType&&(c.className?(" "+c.className+" ").replace(uc," "):"")){f=0;while(e=b[f++])while(d.indexOf(" "+e+" ")>=0)d=d.replace(" "+e+" "," ");g=a?m.trim(d):"",c.className!==g&&(c.className=g)}return this},toggleClass:function(a,b){var c=typeof a;return"boolean"==typeof b&&"string"===c?b?this.addClass(a):this.removeClass(a):this.each(m.isFunction(a)?function(c){m(this).toggleClass(a.call(this,c,this.className,b),b)}:function(){if("string"===c){var b,d=0,e=m(this),f=a.match(E)||[];while(b=f[d++])e.hasClass(b)?e.removeClass(b):e.addClass(b)}else(c===K||"boolean"===c)&&(this.className&&m._data(this,"__className__",this.className),this.className=this.className||a===!1?"":m._data(this,"__className__")||"")})},hasClass:function(a){for(var b=" "+a+" ",c=0,d=this.length;d>c;c++)if(1===this[c].nodeType&&(" "+this[c].className+" ").replace(uc," ").indexOf(b)>=0)return!0;return!1}}),m.each("blur focus focusin focusout load resize scroll unload click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup error contextmenu".split(" "),function(a,b){m.fn[b]=function(a,c){return arguments.length>0?this.on(b,null,a,c):this.trigger(b)}}),m.fn.extend({hover:function(a,b){return this.mouseenter(a).mouseleave(b||a)},bind:function(a,b,c){return this.on(a,null,b,c)},unbind:function(a,b){return this.off(a,null,b)},delegate:function(a,b,c,d){return this.on(b,a,c,d)},undelegate:function(a,b,c){return 1===arguments.length?this.off(a,"**"):this.off(b,a||"**",c)}});var vc=m.now(),wc=/\?/,xc=/(,)|(\[|{)|(}|])|"(?:[^"\\\r\n]|\\["\\\/bfnrt]|\\u[\da-fA-F]{4})*"\s*:?|true|false|null|-?(?!0\d)\d+(?:\.\d+|)(?:[eE][+-]?\d+|)/g;m.parseJSON=function(b){if(a.JSON&&a.JSON.parse)return a.JSON.parse(b+"");var c,d=null,e=m.trim(b+"");return e&&!m.trim(e.replace(xc,function(a,b,e,f){return c&&b&&(d=0),0===d?a:(c=e||b,d+=!f-!e,"")}))?Function("return "+e)():m.error("Invalid JSON: "+b)},m.parseXML=function(b){var c,d;if(!b||"string"!=typeof b)return null;try{a.DOMParser?(d=new DOMParser,c=d.parseFromString(b,"text/xml")):(c=new ActiveXObject("Microsoft.XMLDOM"),c.async="false",c.loadXML(b))}catch(e){c=void 0}return c&&c.documentElement&&!c.getElementsByTagName("parsererror").length||m.error("Invalid XML: "+b),c};var yc,zc,Ac=/#.*$/,Bc=/([?&])_=[^&]*/,Cc=/^(.*?):[ \t]*([^\r\n]*)\r?$/gm,Dc=/^(?:about|app|app-storage|.+-extension|file|res|widget):$/,Ec=/^(?:GET|HEAD)$/,Fc=/^\/\//,Gc=/^([\w.+-]+:)(?:\/\/(?:[^\/?#]*@|)([^\/?#:]*)(?::(\d+)|)|)/,Hc={},Ic={},Jc="*/".concat("*");try{zc=location.href}catch(Kc){zc=y.createElement("a"),zc.href="",zc=zc.href}yc=Gc.exec(zc.toLowerCase())||[];function Lc(a){return function(b,c){"string"!=typeof b&&(c=b,b="*");var d,e=0,f=b.toLowerCase().match(E)||[];if(m.isFunction(c))while(d=f[e++])"+"===d.charAt(0)?(d=d.slice(1)||"*",(a[d]=a[d]||[]).unshift(c)):(a[d]=a[d]||[]).push(c)}}function Mc(a,b,c,d){var e={},f=a===Ic;function g(h){var i;return e[h]=!0,m.each(a[h]||[],function(a,h){var j=h(b,c,d);return"string"!=typeof j||f||e[j]?f?!(i=j):void 0:(b.dataTypes.unshift(j),g(j),!1)}),i}return g(b.dataTypes[0])||!e["*"]&&g("*")}function Nc(a,b){var c,d,e=m.ajaxSettings.flatOptions||{};for(d in b)void 0!==b[d]&&((e[d]?a:c||(c={}))[d]=b[d]);return c&&m.extend(!0,a,c),a}function Oc(a,b,c){var d,e,f,g,h=a.contents,i=a.dataTypes;while("*"===i[0])i.shift(),void 0===e&&(e=a.mimeType||b.getResponseHeader("Content-Type"));if(e)for(g in h)if(h[g]&&h[g].test(e)){i.unshift(g);break}if(i[0]in c)f=i[0];else{for(g in c){if(!i[0]||a.converters[g+" "+i[0]]){f=g;break}d||(d=g)}f=f||d}return f?(f!==i[0]&&i.unshift(f),c[f]):void 0}function Pc(a,b,c,d){var e,f,g,h,i,j={},k=a.dataTypes.slice();if(k[1])for(g in a.converters)j[g.toLowerCase()]=a.converters[g];f=k.shift();while(f)if(a.responseFields[f]&&(c[a.responseFields[f]]=b),!i&&d&&a.dataFilter&&(b=a.dataFilter(b,a.dataType)),i=f,f=k.shift())if("*"===f)f=i;else if("*"!==i&&i!==f){if(g=j[i+" "+f]||j["* "+f],!g)for(e in j)if(h=e.split(" "),h[1]===f&&(g=j[i+" "+h[0]]||j["* "+h[0]])){g===!0?g=j[e]:j[e]!==!0&&(f=h[0],k.unshift(h[1]));break}if(g!==!0)if(g&&a["throws"])b=g(b);else try{b=g(b)}catch(l){return{state:"parsererror",error:g?l:"No conversion from "+i+" to "+f}}}return{state:"success",data:b}}m.extend({active:0,lastModified:{},etag:{},ajaxSettings:{url:zc,type:"GET",isLocal:Dc.test(yc[1]),global:!0,processData:!0,async:!0,contentType:"application/x-www-form-urlencoded; charset=UTF-8",accepts:{"*":Jc,text:"text/plain",html:"text/html",xml:"application/xml, text/xml",json:"application/json, text/javascript"},contents:{xml:/xml/,html:/html/,json:/json/},responseFields:{xml:"responseXML",text:"responseText",json:"responseJSON"},converters:{"* text":String,"text html":!0,"text json":m.parseJSON,"text xml":m.parseXML},flatOptions:{url:!0,context:!0}},ajaxSetup:function(a,b){return b?Nc(Nc(a,m.ajaxSettings),b):Nc(m.ajaxSettings,a)},ajaxPrefilter:Lc(Hc),ajaxTransport:Lc(Ic),ajax:function(a,b){"object"==typeof a&&(b=a,a=void 0),b=b||{};var c,d,e,f,g,h,i,j,k=m.ajaxSetup({},b),l=k.context||k,n=k.context&&(l.nodeType||l.jquery)?m(l):m.event,o=m.Deferred(),p=m.Callbacks("once memory"),q=k.statusCode||{},r={},s={},t=0,u="canceled",v={readyState:0,getResponseHeader:function(a){var b;if(2===t){if(!j){j={};while(b=Cc.exec(f))j[b[1].toLowerCase()]=b[2]}b=j[a.toLowerCase()]}return null==b?null:b},getAllResponseHeaders:function(){return 2===t?f:null},setRequestHeader:function(a,b){var c=a.toLowerCase();return t||(a=s[c]=s[c]||a,r[a]=b),this},overrideMimeType:function(a){return t||(k.mimeType=a),this},statusCode:function(a){var b;if(a)if(2>t)for(b in a)q[b]=[q[b],a[b]];else v.always(a[v.status]);return this},abort:function(a){var b=a||u;return i&&i.abort(b),x(0,b),this}};if(o.promise(v).complete=p.add,v.success=v.done,v.error=v.fail,k.url=((a||k.url||zc)+"").replace(Ac,"").replace(Fc,yc[1]+"//"),k.type=b.method||b.type||k.method||k.type,k.dataTypes=m.trim(k.dataType||"*").toLowerCase().match(E)||[""],null==k.crossDomain&&(c=Gc.exec(k.url.toLowerCase()),k.crossDomain=!(!c||c[1]===yc[1]&&c[2]===yc[2]&&(c[3]||("http:"===c[1]?"80":"443"))===(yc[3]||("http:"===yc[1]?"80":"443")))),k.data&&k.processData&&"string"!=typeof k.data&&(k.data=m.param(k.data,k.traditional)),Mc(Hc,k,b,v),2===t)return v;h=k.global,h&&0===m.active++&&m.event.trigger("ajaxStart"),k.type=k.type.toUpperCase(),k.hasContent=!Ec.test(k.type),e=k.url,k.hasContent||(k.data&&(e=k.url+=(wc.test(e)?"&":"?")+k.data,delete k.data),k.cache===!1&&(k.url=Bc.test(e)?e.replace(Bc,"$1_="+vc++):e+(wc.test(e)?"&":"?")+"_="+vc++)),k.ifModified&&(m.lastModified[e]&&v.setRequestHeader("If-Modified-Since",m.lastModified[e]),m.etag[e]&&v.setRequestHeader("If-None-Match",m.etag[e])),(k.data&&k.hasContent&&k.contentType!==!1||b.contentType)&&v.setRequestHeader("Content-Type",k.contentType),v.setRequestHeader("Accept",k.dataTypes[0]&&k.accepts[k.dataTypes[0]]?k.accepts[k.dataTypes[0]]+("*"!==k.dataTypes[0]?", "+Jc+"; q=0.01":""):k.accepts["*"]);for(d in k.headers)v.setRequestHeader(d,k.headers[d]);if(k.beforeSend&&(k.beforeSend.call(l,v,k)===!1||2===t))return v.abort();u="abort";for(d in{success:1,error:1,complete:1})v[d](k[d]);if(i=Mc(Ic,k,b,v)){v.readyState=1,h&&n.trigger("ajaxSend",[v,k]),k.async&&k.timeout>0&&(g=setTimeout(function(){v.abort("timeout")},k.timeout));try{t=1,i.send(r,x)}catch(w){if(!(2>t))throw w;x(-1,w)}}else x(-1,"No Transport");function x(a,b,c,d){var j,r,s,u,w,x=b;2!==t&&(t=2,g&&clearTimeout(g),i=void 0,f=d||"",v.readyState=a>0?4:0,j=a>=200&&300>a||304===a,c&&(u=Oc(k,v,c)),u=Pc(k,u,v,j),j?(k.ifModified&&(w=v.getResponseHeader("Last-Modified"),w&&(m.lastModified[e]=w),w=v.getResponseHeader("etag"),w&&(m.etag[e]=w)),204===a||"HEAD"===k.type?x="nocontent":304===a?x="notmodified":(x=u.state,r=u.data,s=u.error,j=!s)):(s=x,(a||!x)&&(x="error",0>a&&(a=0))),v.status=a,v.statusText=(b||x)+"",j?o.resolveWith(l,[r,x,v]):o.rejectWith(l,[v,x,s]),v.statusCode(q),q=void 0,h&&n.trigger(j?"ajaxSuccess":"ajaxError",[v,k,j?r:s]),p.fireWith(l,[v,x]),h&&(n.trigger("ajaxComplete",[v,k]),--m.active||m.event.trigger("ajaxStop")))}return v},getJSON:function(a,b,c){return m.get(a,b,c,"json")},getScript:function(a,b){return m.get(a,void 0,b,"script")}}),m.each(["get","post"],function(a,b){m[b]=function(a,c,d,e){return m.isFunction(c)&&(e=e||d,d=c,c=void 0),m.ajax({url:a,type:b,dataType:e,data:c,success:d})}}),m.each(["ajaxStart","ajaxStop","ajaxComplete","ajaxError","ajaxSuccess","ajaxSend"],function(a,b){m.fn[b]=function(a){return this.on(b,a)}}),m._evalUrl=function(a){return m.ajax({url:a,type:"GET",dataType:"script",async:!1,global:!1,"throws":!0})},m.fn.extend({wrapAll:function(a){if(m.isFunction(a))return this.each(function(b){m(this).wrapAll(a.call(this,b))});if(this[0]){var b=m(a,this[0].ownerDocument).eq(0).clone(!0);this[0].parentNode&&b.insertBefore(this[0]),b.map(function(){var a=this;while(a.firstChild&&1===a.firstChild.nodeType)a=a.firstChild;return a}).append(this)}return this},wrapInner:function(a){return this.each(m.isFunction(a)?function(b){m(this).wrapInner(a.call(this,b))}:function(){var b=m(this),c=b.contents();c.length?c.wrapAll(a):b.append(a)})},wrap:function(a){var b=m.isFunction(a);return this.each(function(c){m(this).wrapAll(b?a.call(this,c):a)})},unwrap:function(){return this.parent().each(function(){m.nodeName(this,"body")||m(this).replaceWith(this.childNodes)}).end()}}),m.expr.filters.hidden=function(a){return a.offsetWidth<=0&&a.offsetHeight<=0||!k.reliableHiddenOffsets()&&"none"===(a.style&&a.style.display||m.css(a,"display"))},m.expr.filters.visible=function(a){return!m.expr.filters.hidden(a)};var Qc=/%20/g,Rc=/\[\]$/,Sc=/\r?\n/g,Tc=/^(?:submit|button|image|reset|file)$/i,Uc=/^(?:input|select|textarea|keygen)/i;function Vc(a,b,c,d){var e;if(m.isArray(b))m.each(b,function(b,e){c||Rc.test(a)?d(a,e):Vc(a+"["+("object"==typeof e?b:"")+"]",e,c,d)});else if(c||"object"!==m.type(b))d(a,b);else for(e in b)Vc(a+"["+e+"]",b[e],c,d)}m.param=function(a,b){var c,d=[],e=function(a,b){b=m.isFunction(b)?b():null==b?"":b,d[d.length]=encodeURIComponent(a)+"="+encodeURIComponent(b)};if(void 0===b&&(b=m.ajaxSettings&&m.ajaxSettings.traditional),m.isArray(a)||a.jquery&&!m.isPlainObject(a))m.each(a,function(){e(this.name,this.value)});else for(c in a)Vc(c,a[c],b,e);return d.join("&").replace(Qc,"+")},m.fn.extend({serialize:function(){return m.param(this.serializeArray())},serializeArray:function(){return this.map(function(){var a=m.prop(this,"elements");return a?m.makeArray(a):this}).filter(function(){var a=this.type;return this.name&&!m(this).is(":disabled")&&Uc.test(this.nodeName)&&!Tc.test(a)&&(this.checked||!W.test(a))}).map(function(a,b){var c=m(this).val();return null==c?null:m.isArray(c)?m.map(c,function(a){return{name:b.name,value:a.replace(Sc,"\r\n")}}):{name:b.name,value:c.replace(Sc,"\r\n")}}).get()}}),m.ajaxSettings.xhr=void 0!==a.ActiveXObject?function(){return!this.isLocal&&/^(get|post|head|put|delete|options)$/i.test(this.type)&&Zc()||$c()}:Zc;var Wc=0,Xc={},Yc=m.ajaxSettings.xhr();a.ActiveXObject&&m(a).on("unload",function(){for(var a in Xc)Xc[a](void 0,!0)}),k.cors=!!Yc&&"withCredentials"in Yc,Yc=k.ajax=!!Yc,Yc&&m.ajaxTransport(function(a){if(!a.crossDomain||k.cors){var b;return{send:function(c,d){var e,f=a.xhr(),g=++Wc;if(f.open(a.type,a.url,a.async,a.username,a.password),a.xhrFields)for(e in a.xhrFields)f[e]=a.xhrFields[e];a.mimeType&&f.overrideMimeType&&f.overrideMimeType(a.mimeType),a.crossDomain||c["X-Requested-With"]||(c["X-Requested-With"]="XMLHttpRequest");for(e in c)void 0!==c[e]&&f.setRequestHeader(e,c[e]+"");f.send(a.hasContent&&a.data||null),b=function(c,e){var h,i,j;if(b&&(e||4===f.readyState))if(delete Xc[g],b=void 0,f.onreadystatechange=m.noop,e)4!==f.readyState&&f.abort();else{j={},h=f.status,"string"==typeof f.responseText&&(j.text=f.responseText);try{i=f.statusText}catch(k){i=""}h||!a.isLocal||a.crossDomain?1223===h&&(h=204):h=j.text?200:404}j&&d(h,i,j,f.getAllResponseHeaders())},a.async?4===f.readyState?setTimeout(b):f.onreadystatechange=Xc[g]=b:b()},abort:function(){b&&b(void 0,!0)}}}});function Zc(){try{return new a.XMLHttpRequest}catch(b){}}function $c(){try{return new a.ActiveXObject("Microsoft.XMLHTTP")}catch(b){}}m.ajaxSetup({accepts:{script:"text/javascript, application/javascript, application/ecmascript, application/x-ecmascript"},contents:{script:/(?:java|ecma)script/},converters:{"text script":function(a){return m.globalEval(a),a}}}),m.ajaxPrefilter("script",function(a){void 0===a.cache&&(a.cache=!1),a.crossDomain&&(a.type="GET",a.global=!1)}),m.ajaxTransport("script",function(a){if(a.crossDomain){var b,c=y.head||m("head")[0]||y.documentElement;return{send:function(d,e){b=y.createElement("script"),b.async=!0,a.scriptCharset&&(b.charset=a.scriptCharset),b.src=a.url,b.onload=b.onreadystatechange=function(a,c){(c||!b.readyState||/loaded|complete/.test(b.readyState))&&(b.onload=b.onreadystatechange=null,b.parentNode&&b.parentNode.removeChild(b),b=null,c||e(200,"success"))},c.insertBefore(b,c.firstChild)},abort:function(){b&&b.onload(void 0,!0)}}}});var _c=[],ad=/(=)\?(?=&|$)|\?\?/;m.ajaxSetup({jsonp:"callback",jsonpCallback:function(){var a=_c.pop()||m.expando+"_"+vc++;return this[a]=!0,a}}),m.ajaxPrefilter("json jsonp",function(b,c,d){var e,f,g,h=b.jsonp!==!1&&(ad.test(b.url)?"url":"string"==typeof b.data&&!(b.contentType||"").indexOf("application/x-www-form-urlencoded")&&ad.test(b.data)&&"data");return h||"jsonp"===b.dataTypes[0]?(e=b.jsonpCallback=m.isFunction(b.jsonpCallback)?b.jsonpCallback():b.jsonpCallback,h?b[h]=b[h].replace(ad,"$1"+e):b.jsonp!==!1&&(b.url+=(wc.test(b.url)?"&":"?")+b.jsonp+"="+e),b.converters["script json"]=function(){return g||m.error(e+" was not called"),g[0]},b.dataTypes[0]="json",f=a[e],a[e]=function(){g=arguments},d.always(function(){a[e]=f,b[e]&&(b.jsonpCallback=c.jsonpCallback,_c.push(e)),g&&m.isFunction(f)&&f(g[0]),g=f=void 0}),"script"):void 0}),m.parseHTML=function(a,b,c){if(!a||"string"!=typeof a)return null;"boolean"==typeof b&&(c=b,b=!1),b=b||y;var d=u.exec(a),e=!c&&[];return d?[b.createElement(d[1])]:(d=m.buildFragment([a],b,e),e&&e.length&&m(e).remove(),m.merge([],d.childNodes))};var bd=m.fn.load;m.fn.load=function(a,b,c){if("string"!=typeof a&&bd)return bd.apply(this,arguments);var d,e,f,g=this,h=a.indexOf(" ");return h>=0&&(d=m.trim(a.slice(h,a.length)),a=a.slice(0,h)),m.isFunction(b)?(c=b,b=void 0):b&&"object"==typeof b&&(f="POST"),g.length>0&&m.ajax({url:a,type:f,dataType:"html",data:b}).done(function(a){e=arguments,g.html(d?m("<div>").append(m.parseHTML(a)).find(d):a)}).complete(c&&function(a,b){g.each(c,e||[a.responseText,b,a])}),this},m.expr.filters.animated=function(a){return m.grep(m.timers,function(b){return a===b.elem}).length};var cd=a.document.documentElement;function dd(a){return m.isWindow(a)?a:9===a.nodeType?a.defaultView||a.parentWindow:!1}m.offset={setOffset:function(a,b,c){var d,e,f,g,h,i,j,k=m.css(a,"position"),l=m(a),n={};"static"===k&&(a.style.position="relative"),h=l.offset(),f=m.css(a,"top"),i=m.css(a,"left"),j=("absolute"===k||"fixed"===k)&&m.inArray("auto",[f,i])>-1,j?(d=l.position(),g=d.top,e=d.left):(g=parseFloat(f)||0,e=parseFloat(i)||0),m.isFunction(b)&&(b=b.call(a,c,h)),null!=b.top&&(n.top=b.top-h.top+g),null!=b.left&&(n.left=b.left-h.left+e),"using"in b?b.using.call(a,n):l.css(n)}},m.fn.extend({offset:function(a){if(arguments.length)return void 0===a?this:this.each(function(b){m.offset.setOffset(this,a,b)});var b,c,d={top:0,left:0},e=this[0],f=e&&e.ownerDocument;if(f)return b=f.documentElement,m.contains(b,e)?(typeof e.getBoundingClientRect!==K&&(d=e.getBoundingClientRect()),c=dd(f),{top:d.top+(c.pageYOffset||b.scrollTop)-(b.clientTop||0),left:d.left+(c.pageXOffset||b.scrollLeft)-(b.clientLeft||0)}):d},position:function(){if(this[0]){var a,b,c={top:0,left:0},d=this[0];return"fixed"===m.css(d,"position")?b=d.getBoundingClientRect():(a=this.offsetParent(),b=this.offset(),m.nodeName(a[0],"html")||(c=a.offset()),c.top+=m.css(a[0],"borderTopWidth",!0),c.left+=m.css(a[0],"borderLeftWidth",!0)),{top:b.top-c.top-m.css(d,"marginTop",!0),left:b.left-c.left-m.css(d,"marginLeft",!0)}}},offsetParent:function(){return this.map(function(){var a=this.offsetParent||cd;while(a&&!m.nodeName(a,"html")&&"static"===m.css(a,"position"))a=a.offsetParent;return a||cd})}}),m.each({scrollLeft:"pageXOffset",scrollTop:"pageYOffset"},function(a,b){var c=/Y/.test(b);m.fn[a]=function(d){return V(this,function(a,d,e){var f=dd(a);return void 0===e?f?b in f?f[b]:f.document.documentElement[d]:a[d]:void(f?f.scrollTo(c?m(f).scrollLeft():e,c?e:m(f).scrollTop()):a[d]=e)},a,d,arguments.length,null)}}),m.each(["top","left"],function(a,b){m.cssHooks[b]=Lb(k.pixelPosition,function(a,c){return c?(c=Jb(a,b),Hb.test(c)?m(a).position()[b]+"px":c):void 0})}),m.each({Height:"height",Width:"width"},function(a,b){m.each({padding:"inner"+a,content:b,"":"outer"+a},function(c,d){m.fn[d]=function(d,e){var f=arguments.length&&(c||"boolean"!=typeof d),g=c||(d===!0||e===!0?"margin":"border");return V(this,function(b,c,d){var e;return m.isWindow(b)?b.document.documentElement["client"+a]:9===b.nodeType?(e=b.documentElement,Math.max(b.body["scroll"+a],e["scroll"+a],b.body["offset"+a],e["offset"+a],e["client"+a])):void 0===d?m.css(b,c,g):m.style(b,c,d,g)},b,f?d:void 0,f,null)}})}),m.fn.size=function(){return this.length},m.fn.andSelf=m.fn.addBack,"function"==typeof define&&define.amd&&define("jquery",[],function(){return m});var ed=a.jQuery,fd=a.$;return m.noConflict=function(b){return a.$===m&&(a.$=fd),b&&a.jQuery===m&&(a.jQuery=ed),m},typeof b===K&&(a.jQuery=a.$=m),m});
8 core/jsplot/jquery.mousewheel.min.js
/*!
 * jQuery Mousewheel 3.1.13
 *
 * Copyright 2015 jQuery Foundation and other contributors
 * Released under the MIT license.
 * http://jquery.org/license
 */
!function(a){"function"==typeof define&&define.amd?define(["jquery"],a):"object"==typeof exports?module.exports=a:a(jQuery)}(function(a){function b(b){var g=b||window.event,h=i.call(arguments,1),j=0,l=0,m=0,n=0,o=0,p=0;if(b=a.event.fix(g),b.type="mousewheel","detail"in g&&(m=-1*g.detail),"wheelDelta"in g&&(m=g.wheelDelta),"wheelDeltaY"in g&&(m=g.wheelDeltaY),"wheelDeltaX"in g&&(l=-1*g.wheelDeltaX),"axis"in g&&g.axis===g.HORIZONTAL_AXIS&&(l=-1*m,m=0),j=0===m?l:m,"deltaY"in g&&(m=-1*g.deltaY,j=m),"deltaX"in g&&(l=g.deltaX,0===m&&(j=-1*l)),0!==m||0!==l){if(1===g.deltaMode){var q=a.data(this,"mousewheel-line-height");j*=q,m*=q,l*=q}else if(2===g.deltaMode){var r=a.data(this,"mousewheel-page-height");j*=r,m*=r,l*=r}if(n=Math.max(Math.abs(m),Math.abs(l)),(!f||f>n)&&(f=n,d(g,n)&&(f/=40)),d(g,n)&&(j/=40,l/=40,m/=40),j=Math[j>=1?"floor":"ceil"](j/f),l=Math[l>=1?"floor":"ceil"](l/f),m=Math[m>=1?"floor":"ceil"](m/f),k.settings.normalizeOffset&&this.getBoundingClientRect){var s=this.getBoundingClientRect();o=b.clientX-s.left,p=b.clientY-s.top}return b.deltaX=l,b.deltaY=m,b.deltaFactor=f,b.offsetX=o,b.offsetY=p,b.deltaMode=0,h.unshift(b,j,l,m),e&&clearTimeout(e),e=setTimeout(c,200),(a.event.dispatch||a.event.handle).apply(this,h)}}function c(){f=null}function d(a,b){return k.settings.adjustOldDeltas&&"mousewheel"===a.type&&b%120===0}var e,f,g=["wheel","mousewheel","DOMMouseScroll","MozMousePixelScroll"],h="onwheel"in document||document.documentMode>=9?["wheel"]:["mousewheel","DomMouseScroll","MozMousePixelScroll"],i=Array.prototype.slice;if(a.event.fixHooks)for(var j=g.length;j;)a.event.fixHooks[g[--j]]=a.event.mouseHooks;var k=a.event.special.mousewheel={version:"3.1.12",setup:function(){if(this.addEventListener)for(var c=h.length;c;)this.addEventListener(h[--c],b,!1);else this.onmousewheel=b;a.data(this,"mousewheel-line-height",k.getLineHeight(this)),a.data(this,"mousewheel-page-height",k.getPageHeight(this))},teardown:function(){if(this.removeEventListener)for(var c=h.length;c;)this.removeEventListener(h[--c],b,!1);else this.onmousewheel=null;a.removeData(this,"mousewheel-line-height"),a.removeData(this,"mousewheel-page-height")},getLineHeight:function(b){var c=a(b),d=c["offsetParent"in a.fn?"offsetParent":"parent"]();return d.length||(d=a("body")),parseInt(d.css("fontSize"),10)||parseInt(c.css("fontSize"),10)||16},getPageHeight:function(b){return a(b).height()},settings:{adjustOldDeltas:!0,normalizeOffset:!0}};a.fn.extend({mousewheel:function(a){return a?this.bind("mousewheel",a):this.trigger("mousewheel")},unmousewheel:function(a){return this.unbind("mousewheel",a)}})});
1 core/jsplot/modus.js
caterwaul.module( 'modus' , function ($) { $ = jQuery; var original_jquery_val = $.fn.val; (function () {var use_named_combinator =function (receiver, args) { ; return $.modus[args[0]] .apply(receiver, Array.prototype.slice.call(args, 1))} ; return $.fn.val =function () {var args = arguments; return(function (it) {return it ? args.length ? it.setter.apply(this, args): it.getter.call(this): original_jquery_val.apply(this, args)}) .call(this, ( this.data( 'modus')))} , $.fn.modus =function (getter, setter) { ; return getter.constructor === String ? use_named_combinator(this, arguments): this.data( 'modus' , {getter: getter, setter: setter})}}) .call(this) , $.modus = { util: {} , val:function () { ; return original_jquery_val.apply(this, arguments)} , delegate:function (getter, setter) { ; return{first:function () { ; return this} , val:function () { ; return arguments.length ? ( setter.apply(this, arguments) , this): getter.apply(this, arguments)}}} , proxy:function (element) { ; return this.modus(function (_) {return find(this, element) .val()} ,function (_) {return(find(this, element) .first() .val(_) , this)})} , list:function (new_element) { ; return this.modus(function (_) {return(function (xs) {var x, x0, xi, xl, xr;for (var xr = new xs.constructor() , xi = 0, xl = xs.length; xi < xl; ++xi) x = xs[xi] , xr.push( ($(x) .val())) ; return xr}) .call(this,Array.prototype.slice.call( (this.children())))} ,function (_) {return(function (it) {return(function (xs) {var x, x0, xi, xl, xr;for (var xi = 0, xl = xs.length; xi < xl; ++xi) x = xs[xi] , (it.append(new_element(x, xi) .val(x))) ; return xs}) .call(this, _) , it}) .call(this, (this.empty()))})} , composite:function (paths) { ; return this.modus(function (_) {return(function (xs) {var x, x0, xi, xl, xr;var xr = new xs.constructor() ; for (var k in xs) if (Object.prototype.hasOwnProperty.call(xs, k)) x = xs[k] , xr[k] = (find(this, x) .first() .val()) ; return xr}) .call(this,paths)} ,function (_) {return( (function (xs) {var x, x0, xi, xl, xr;for (var x in xs) if (Object.prototype.hasOwnProperty.call(xs, x))find(this, paths[x]) .first() .val(_[x]) ; return xs}) .call(this,paths) ,this)})} , where:find =function (container, path) { ; return path.constructor === String ? ( container.filter(path)) .add( container.find(path)): path.constructor === Function ? path(container): path.constructor === jQuery ? path: (function () {throw new Error( ( 'invalid modus path: ' + (path) + ''))}) .call(this)}}}) ;
1 core/jsplot/vector.js
 caterwaul.module( 'vector' , (function (qs,qs1,qs2,qs3,qs4,qs5,qs6,qs7,qs8,qs9,qsa,qsb,qsc,qsd,qse,qsf,qsg,qsh,qsi,qsj,qsk,qsl,qsm,qsn,qso,qsp,qsq,qsr,qss,qst,qsu,qsv,qsw,qsx,qsy,qsz,qs10,qs11,qs12,qs13,qs14,qs15,qs16,qs17,qs18,qs19,qs1a,qs1b,qs1c,qs1d,qs1e,qs1f,qs1g,qs1h,qs1i) {var result= ( function ($) { (function () {var generator =function (base, composite) { ; return function (n, prefix) { ; return(function () {var compiled_base = base(n) ; return rename($.merge( {} ,compiled_base, composite(compiled_base)) , prefix)}) .call(this)}} , rename =function (o, prefix) { ; return(function (xs) {var x, x0, xi, xl, xr;var xr = new xs.constructor() ; for (var x in xs) if (Object.prototype.hasOwnProperty.call(xs, x)) xr[ ( '' + (prefix || "") + '' + (x) + '')] = xs[x] ; return xr}) .call(this, o)} , compile_function =function (xs, e) { ; return(function () {var tree = (qs) .replace( {_formals: xs, _e: e}) ; return(function (it) {return it.tree =tree, it}) .call(this, ($.compile( tree)))}) .call(this)} , base_v =function (n) { ; return(function () {var r =function (n, formals, wrap, fold, each) { ; return(function () {var body = ( wrap) .replace( {x: (function (xs) {var x, x0, xi, xl, xr;for (var x0 = xs[0] , xi = 1, xl = xs.length; xi < xl; ++xi) x = xs[xi] , x0 = ( (fold) .replace( {x: x0, y: x})) ; return x0}) .call(this, (function (xs) {var x, x0, xi, xl, xr;for (var xr = new xs.constructor() , xi = 0, xl = xs.length; xi < xl; ++xi) x = xs[xi] , xr.push( ( (each) .replace( {i: ( '' + (x) + '')}))) ; return xr}) .call(this, (function (i, u, s) {if ( (u - i) * s <= 0) return [] ; for (var r = [] , d = u - i; d >= 0 ? i < u: i > u; i += s) r.push(i) ; return r}) ( (0) , (n) , (1))))}) ; return compile_function( formals, body)}) .call(this)} ; return{plus: r(n,qs1,qs2,qs3,qs4) , times: r(n,qs5,qs6,qs7,qs8) , minus: r(n,qs9,qsa,qsb,qsc) , scale: r(n,qsd,qse,qsf,qsg) , dot: r(n,qsh,qsi,qsj,qsk) , norm: r(n,qsl,qsm,qsn,qso) , min: r(n,qsp,qsq,qsr,qss) , macv: r(n,qst,qsu,qsv,qsw) , max: r(n,qsx,qsy,qsz,qs10) , macs: r(n,qs11,qs12,qs13,qs14) , mixv: r(n,qs15,qs16,qs17,qs18) , mixs: r(n,qs19,qs1a,qs1b,qs1c)}}) .call(this)} , composite_v =function (base) { ; return(function () {var ref_compile =function (functions, formals, body) { ; return(function () {var new_body = ( body) .replace( (function (xs) {var x, x0, xi, xl, xr;var xr = new xs.constructor() ; for (var k in xs) if (Object.prototype.hasOwnProperty.call(xs, k)) x = xs[k] , xr[k] = (new $.expression_ref(x.tree)) ; return xr}) .call(this, functions)) ; return compile_function( formals, new_body)}) .call(this)} ; return{unit: ref_compile(base,qs1d,qs1e) , proj: ref_compile(base,qs1f,qs1g) , orth: ref_compile(base,qs1h,qs1i)}}) .call(this)} ; return $.vector = generator(base_v, composite_v)}) .call(this)}) ;result.caterwaul_expression_ref_table = {qs: ( " new caterwaul.syntax( \"(\" ,new caterwaul.syntax( \"function\" ,new caterwaul.syntax( \"(\" ,new caterwaul.syntax( \"_formals\")) .prefix( \" \") ,new caterwaul.syntax( \"{\" ,new caterwaul.syntax( \"return\" ,new caterwaul.syntax( \"_e\") .prefix( \" \"))) .prefix( \" \")))") ,qs1: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"b\") .prefix( \" \"))") ,qs2: ( " new caterwaul.syntax( \"[\" ,new caterwaul.syntax( \"x\"))") ,qs3: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"x\") ,new caterwaul.syntax( \"y\") .prefix( \" \"))") ,qs4: ( " new caterwaul.syntax( \"+\" ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"i\")) ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"b\") .prefix( \" \") ,new caterwaul.syntax( \"i\"))) .prefix( \" \")") ,qs5: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"b\") .prefix( \" \"))") ,qs6: ( " new caterwaul.syntax( \"[\" ,new caterwaul.syntax( \"x\"))") ,qs7: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"x\") ,new caterwaul.syntax( \"y\") .prefix( \" \"))") ,qs8: ( " new caterwaul.syntax( \"*\" ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"i\")) ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"b\") .prefix( \" \") ,new caterwaul.syntax( \"i\"))) .prefix( \" \")") ,qs9: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"b\") .prefix( \" \"))") ,qsa: ( " new caterwaul.syntax( \"[\" ,new caterwaul.syntax( \"x\"))") ,qsb: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"x\") ,new caterwaul.syntax( \"y\") .prefix( \" \"))") ,qsc: ( " new caterwaul.syntax( \"-\" ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"i\")) ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"b\") .prefix( \" \") ,new caterwaul.syntax( \"i\"))) .prefix( \" \")") ,qsd: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"b\") .prefix( \" \"))") ,qse: ( " new caterwaul.syntax( \"[\" ,new caterwaul.syntax( \"x\"))") ,qsf: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"x\") ,new caterwaul.syntax( \"y\") .prefix( \" \"))") ,qsg: ( " new caterwaul.syntax( \"*\" ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"i\")) ,new caterwaul.syntax( \"b\") .prefix( \" \")) .prefix( \" \")") ,qsh: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"b\") .prefix( \" \"))") ,qsi: ( " new caterwaul.syntax( \"x\")") ,qsj: ( " new caterwaul.syntax( \"+\" ,new caterwaul.syntax( \"x\") ,new caterwaul.syntax( \"y\") .prefix( \" \")) .prefix( \" \")") ,qsk: ( " new caterwaul.syntax( \"*\" ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"i\")) ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"b\") .prefix( \" \") ,new caterwaul.syntax( \"i\"))) .prefix( \" \")") ,qsl: ( " new caterwaul.syntax( \"a\")") ,qsm: ( " new caterwaul.syntax( \"()\" ,new caterwaul.syntax( \".\" ,new caterwaul.syntax( \"Math\") ,new caterwaul.syntax( \"sqrt\")) ,new caterwaul.syntax( \"x\"))") ,qsn: ( " new caterwaul.syntax( \"+\" ,new caterwaul.syntax( \"x\") ,new caterwaul.syntax( \"y\") .prefix( \" \")) .prefix( \" \")") ,qso: ( " new caterwaul.syntax( \"*\" ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"i\")) ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"a\") .prefix( \" \") ,new caterwaul.syntax( \"i\"))) .prefix( \" \")") ,qsp: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"b\") .prefix( \" \"))") ,qsq: ( " new caterwaul.syntax( \"[\" ,new caterwaul.syntax( \"x\"))") ,qsr: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"x\") ,new caterwaul.syntax( \"y\") .prefix( \" \"))") ,qss: ( " new caterwaul.syntax( \"()\" ,new caterwaul.syntax( \".\" ,new caterwaul.syntax( \"Math\") ,new caterwaul.syntax( \"min\")) ,new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"i\")) ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"b\") .prefix( \" \") ,new caterwaul.syntax( \"i\"))))") ,qst: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"b\") .prefix( \" \")) ,new caterwaul.syntax( \"c\") .prefix( \" \"))") ,qsu: ( " new caterwaul.syntax( \"[\" ,new caterwaul.syntax( \"x\"))") ,qsv: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"x\") ,new caterwaul.syntax( \"y\") .prefix( \" \"))") ,qsw: ( " new caterwaul.syntax( \"+\" ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"i\")) ,new caterwaul.syntax( \"*\" ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"b\") .prefix( \" \") ,new caterwaul.syntax( \"i\")) ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"c\") .prefix( \" \") ,new caterwaul.syntax( \"i\"))) .prefix( \" \")) .prefix( \" \")") ,qsx: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"b\") .prefix( \" \"))") ,qsy: ( " new caterwaul.syntax( \"[\" ,new caterwaul.syntax( \"x\"))") ,qsz: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"x\") ,new caterwaul.syntax( \"y\") .prefix( \" \"))") ,qs10: ( " new caterwaul.syntax( \"()\" ,new caterwaul.syntax( \".\" ,new caterwaul.syntax( \"Math\") ,new caterwaul.syntax( \"max\")) ,new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"i\")) ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"b\") .prefix( \" \") ,new caterwaul.syntax( \"i\"))))") ,qs11: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"b\") .prefix( \" \")) ,new caterwaul.syntax( \"c\") .prefix( \" \"))") ,qs12: ( " new caterwaul.syntax( \"[\" ,new caterwaul.syntax( \"x\"))") ,qs13: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"x\") ,new caterwaul.syntax( \"y\") .prefix( \" \"))") ,qs14: ( " new caterwaul.syntax( \"+\" ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"i\")) ,new caterwaul.syntax( \"*\" ,new caterwaul.syntax( \"b\") .prefix( \" \") ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"c\") .prefix( \" \") ,new caterwaul.syntax( \"i\"))) .prefix( \" \")) .prefix( \" \")") ,qs15: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"b\") .prefix( \" \")) ,new caterwaul.syntax( \"c\") .prefix( \" \"))") ,qs16: ( " new caterwaul.syntax( \"[\" ,new caterwaul.syntax( \"x\"))") ,qs17: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"x\") ,new caterwaul.syntax( \"y\") .prefix( \" \"))") ,qs18: ( " new caterwaul.syntax( \"+\" ,new caterwaul.syntax( \"*\" ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"i\")) ,new caterwaul.syntax( \"(\" ,new caterwaul.syntax( \"-\" ,new caterwaul.syntax( \"1\") ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"b\") .prefix( \" \") ,new caterwaul.syntax( \"i\"))) .prefix( \" \")) .prefix( \" \")) .prefix( \" \") ,new caterwaul.syntax( \"*\" ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"c\") .prefix( \" \") ,new caterwaul.syntax( \"i\")) ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"b\") .prefix( \" \") ,new caterwaul.syntax( \"i\"))) .prefix( \" \")) .prefix( \" \")") ,qs19: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"b\") .prefix( \" \")) ,new caterwaul.syntax( \"c\") .prefix( \" \"))") ,qs1a: ( " new caterwaul.syntax( \"[\" ,new caterwaul.syntax( \"x\"))") ,qs1b: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"x\") ,new caterwaul.syntax( \"y\") .prefix( \" \"))") ,qs1c: ( " new caterwaul.syntax( \"+\" ,new caterwaul.syntax( \"*\" ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"i\")) ,new caterwaul.syntax( \"(\" ,new caterwaul.syntax( \"-\" ,new caterwaul.syntax( \"1\") ,new caterwaul.syntax( \"b\") .prefix( \" \")) .prefix( \" \")) .prefix( \" \")) .prefix( \" \") ,new caterwaul.syntax( \"*\" ,new caterwaul.syntax( \"[]\" ,new caterwaul.syntax( \"c\") .prefix( \" \") ,new caterwaul.syntax( \"i\")) ,new caterwaul.syntax( \"b\") .prefix( \" \")) .prefix( \" \")) .prefix( \" \")") ,qs1d: ( " new caterwaul.syntax( \"a\")") ,qs1e: ( " new caterwaul.syntax( \"()\" ,new caterwaul.syntax( \"scale\") ,new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"/\" ,new caterwaul.syntax( \"1.0\") .prefix( \" \") ,new caterwaul.syntax( \"()\" ,new caterwaul.syntax( \"norm\") .prefix( \" \") ,new caterwaul.syntax( \"a\"))) .prefix( \" \")))") ,qs1f: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"b\") .prefix( \" \"))") ,qs1g: ( " new caterwaul.syntax( \"()\" ,new caterwaul.syntax( \"scale\") ,new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"b\") ,new caterwaul.syntax( \"/\" ,new caterwaul.syntax( \"()\" ,new caterwaul.syntax( \"dot\") .prefix( \" \") ,new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"b\") .prefix( \" \"))) ,new caterwaul.syntax( \"()\" ,new caterwaul.syntax( \"dot\") .prefix( \" \") ,new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"b\") ,new caterwaul.syntax( \"b\") .prefix( \" \")))) .prefix( \" \")))") ,qs1h: ( " new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"b\") .prefix( \" \"))") ,qs1i: ( " new caterwaul.syntax( \"()\" ,new caterwaul.syntax( \"minus\") ,new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"()\" ,new caterwaul.syntax( \"scale\") .prefix( \" \") ,new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"b\") ,new caterwaul.syntax( \"/\" ,new caterwaul.syntax( \"()\" ,new caterwaul.syntax( \"dot\") .prefix( \" \") ,new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"a\") ,new caterwaul.syntax( \"b\") .prefix( \" \"))) ,new caterwaul.syntax( \"()\" ,new caterwaul.syntax( \"dot\") .prefix( \" \") ,new caterwaul.syntax( \",\" ,new caterwaul.syntax( \"b\") ,new caterwaul.syntax( \"b\") .prefix( \" \")))) .prefix( \" \")))))")} ;return(result)}) .call(this,new caterwaul.syntax( "(" ,new caterwaul.syntax( "function" ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "_formals")) .prefix( " ") ,new caterwaul.syntax( "{" ,new caterwaul.syntax( "return" ,new caterwaul.syntax( "_e") .prefix( " "))) .prefix( " "))) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "b") .prefix( " ")) ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "x")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "y") .prefix( " ")) ,new caterwaul.syntax( "+" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "i")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "b") .prefix( " ") ,new caterwaul.syntax( "i"))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "b") .prefix( " ")) ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "x")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "y") .prefix( " ")) ,new caterwaul.syntax( "*" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "i")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "b") .prefix( " ") ,new caterwaul.syntax( "i"))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "b") .prefix( " ")) ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "x")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "y") .prefix( " ")) ,new caterwaul.syntax( "-" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "i")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "b") .prefix( " ") ,new caterwaul.syntax( "i"))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "b") .prefix( " ")) ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "x")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "y") .prefix( " ")) ,new caterwaul.syntax( "*" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "i")) ,new caterwaul.syntax( "b") .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "b") .prefix( " ")) ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "+" ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "y") .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "*" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "i")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "b") .prefix( " ") ,new caterwaul.syntax( "i"))) .prefix( " ") ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "Math") ,new caterwaul.syntax( "sqrt")) ,new caterwaul.syntax( "x")) ,new caterwaul.syntax( "+" ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "y") .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "*" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "i")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "a") .prefix( " ") ,new caterwaul.syntax( "i"))) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "b") .prefix( " ")) ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "x")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "y") .prefix( " ")) ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "Math") ,new caterwaul.syntax( "min")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "i")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "b") .prefix( " ") ,new caterwaul.syntax( "i")))) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "b") .prefix( " ")) ,new caterwaul.syntax( "c") .prefix( " ")) ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "x")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "y") .prefix( " ")) ,new caterwaul.syntax( "+" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "i")) ,new caterwaul.syntax( "*" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "b") .prefix( " ") ,new caterwaul.syntax( "i")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "c") .prefix( " ") ,new caterwaul.syntax( "i"))) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "b") .prefix( " ")) ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "x")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "y") .prefix( " ")) ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "." ,new caterwaul.syntax( "Math") ,new caterwaul.syntax( "max")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "i")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "b") .prefix( " ") ,new caterwaul.syntax( "i")))) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "b") .prefix( " ")) ,new caterwaul.syntax( "c") .prefix( " ")) ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "x")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "y") .prefix( " ")) ,new caterwaul.syntax( "+" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "i")) ,new caterwaul.syntax( "*" ,new caterwaul.syntax( "b") .prefix( " ") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "c") .prefix( " ") ,new caterwaul.syntax( "i"))) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "b") .prefix( " ")) ,new caterwaul.syntax( "c") .prefix( " ")) ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "x")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "y") .prefix( " ")) ,new caterwaul.syntax( "+" ,new caterwaul.syntax( "*" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "i")) ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "-" ,new caterwaul.syntax( "1") ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "b") .prefix( " ") ,new caterwaul.syntax( "i"))) .prefix( " ")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "*" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "c") .prefix( " ") ,new caterwaul.syntax( "i")) ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "b") .prefix( " ") ,new caterwaul.syntax( "i"))) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "," ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "b") .prefix( " ")) ,new caterwaul.syntax( "c") .prefix( " ")) ,new caterwaul.syntax( "[" ,new caterwaul.syntax( "x")) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "x") ,new caterwaul.syntax( "y") .prefix( " ")) ,new caterwaul.syntax( "+" ,new caterwaul.syntax( "*" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "i")) ,new caterwaul.syntax( "(" ,new caterwaul.syntax( "-" ,new caterwaul.syntax( "1") ,new caterwaul.syntax( "b") .prefix( " ")) .prefix( " ")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "*" ,new caterwaul.syntax( "[]" ,new caterwaul.syntax( "c") .prefix( " ") ,new caterwaul.syntax( "i")) ,new caterwaul.syntax( "b") .prefix( " ")) .prefix( " ")) .prefix( " ") ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "scale") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "/" ,new caterwaul.syntax( "1.0") .prefix( " ") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "norm") .prefix( " ") ,new caterwaul.syntax( "a"))) .prefix( " "))) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "b") .prefix( " ")) ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "scale") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "b") ,new caterwaul.syntax( "/" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "dot") .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "b") .prefix( " "))) ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "dot") .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "b") ,new caterwaul.syntax( "b") .prefix( " ")))) .prefix( " "))) ,new caterwaul.syntax( "," ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "b") .prefix( " ")) ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "minus") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "scale") .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "b") ,new caterwaul.syntax( "/" ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "dot") .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "a") ,new caterwaul.syntax( "b") .prefix( " "))) ,new caterwaul.syntax( "()" ,new caterwaul.syntax( "dot") .prefix( " ") ,new caterwaul.syntax( "," ,new caterwaul.syntax( "b") ,new caterwaul.syntax( "b") .prefix( " ")))) .prefix( " "))))))) ;
65 core/jsplot/murmurhash3.js
/**
 * JS Implementation of MurmurHash3 (r136) (as of May 20, 2011)
 * 
 * @author <a href="mailto:gary.court@gmail.com">Gary Court</a>
 * @see http://github.com/garycourt/murmurhash-js
 * @author <a href="mailto:aappleby@gmail.com">Austin Appleby</a>
 * @see http://sites.google.com/site/murmurhash/
 * 
 * @param {string} key ASCII only
 * @param {number} seed Positive integer only
 * @return {number} 32-bit positive integer hash 
 */

function murmurhash3_32(key, seed) {
	var remainder, bytes, h1, h1b, c1, c1b, c2, c2b, k1, i;
	
        if (key == null) key = '';
	remainder = key.length & 3; // key.length % 4
	bytes = key.length - remainder;
	h1 = seed;
	c1 = 0xcc9e2d51;
	c2 = 0x1b873593;
	i = 0;
	
	while (i < bytes) {
	  	k1 = 
	  	  ((key.charCodeAt(i) & 0xff)) |
	  	  ((key.charCodeAt(++i) & 0xff) << 8) |
	  	  ((key.charCodeAt(++i) & 0xff) << 16) |
	  	  ((key.charCodeAt(++i) & 0xff) << 24);
		++i;
		
		k1 = ((((k1 & 0xffff) * c1) + ((((k1 >>> 16) * c1) & 0xffff) << 16))) & 0xffffffff;
		k1 = (k1 << 15) | (k1 >>> 17);
		k1 = ((((k1 & 0xffff) * c2) + ((((k1 >>> 16) * c2) & 0xffff) << 16))) & 0xffffffff;

		h1 ^= k1;
        h1 = (h1 << 13) | (h1 >>> 19);
		h1b = ((((h1 & 0xffff) * 5) + ((((h1 >>> 16) * 5) & 0xffff) << 16))) & 0xffffffff;
		h1 = (((h1b & 0xffff) + 0x6b64) + ((((h1b >>> 16) + 0xe654) & 0xffff) << 16));
	}
	
	k1 = 0;
	
	switch (remainder) {
		case 3: k1 ^= (key.charCodeAt(i + 2) & 0xff) << 16;
		case 2: k1 ^= (key.charCodeAt(i + 1) & 0xff) << 8;
		case 1: k1 ^= (key.charCodeAt(i) & 0xff);
		
		k1 = (((k1 & 0xffff) * c1) + ((((k1 >>> 16) * c1) & 0xffff) << 16)) & 0xffffffff;
		k1 = (k1 << 15) | (k1 >>> 17);
		k1 = (((k1 & 0xffff) * c2) + ((((k1 >>> 16) * c2) & 0xffff) << 16)) & 0xffffffff;
		h1 ^= k1;
	}
	
	h1 ^= key.length;

	h1 ^= h1 >>> 16;
	h1 = (((h1 & 0xffff) * 0x85ebca6b) + ((((h1 >>> 16) * 0x85ebca6b) & 0xffff) << 16)) & 0xffffffff;
	h1 ^= h1 >>> 13;
	h1 = ((((h1 & 0xffff) * 0xc2b2ae35) + ((((h1 >>> 16) * 0xc2b2ae35) & 0xffff) << 16))) & 0xffffffff;
	h1 ^= h1 >>> 16;

	return h1 >>> 0;
}
34 core/jsplot/axis.waul
// A column vector of numeric data.
// Stores a single axis of the data we want to render. It has a fixed capacity and represents a uniform sample if it overflows (i.e. it kicks data points out
// evenly). Because multiple axes need to be coordinated, all random numbers used for sampling are parameters rather than generated here.

// If you want focused nonuniform sampling, you can do it like this:

// | var r = Math.random();
//   r *= axis.focus(data_point, focus_center, focus_scale);
//   // same for other axes
//   axis.push(data_point, r);

// Focusing biases the probability of accepting points so that data closer to the focal plane(s) is preferred.

caterwaul(':all')(function () {
  axis(capacity) = this /-caterwaul.merge/ {data: new Float64Array(capacity), max: null, min: null, n: 0, c: capacity} -re- void 0,
  axis.prototype /-caterwaul.merge/ axis_methods,
  axis           /-caterwaul.merge/ static_methods,

  where[static_methods = capture[focus(x, c, s)     = Math.abs(x - c) / s],

        axis_methods   = capture[reset()            = this -se [this.n = 0, this.min = this.max = null],
                                 set(i, x)          = this -se [this.min = this.min == null ? x : this.min /-Math.min/ x,
                                                                this.max = this.max == null ? x : this.max /-Math.max/ x,
                                                                this.data[i] = x],

                                 offset()           = (this.max + this.min) / 2,
                                 range()            = this.max - this.min,
                                 at(x)              = this.min + x * this.range(),
                                 end()              = this.n /-Math.min/ this.c,
                                 p(i)               = this.data[i],
                                 pnorm(i)           = (this.data[i] - this.offset()) / this.range() + 0.5,

                                 push(x, r)         = this.n++ < this.c ? this.set(this.n - 1, +x) : this /+x /~uniform_push/ r,
                                 uniform_push(x, r) = this.set(r * this.n | 0, x) -when [r * this.n < this.c]]]})();
32 core/jsplot/label.waul
// A column vector of labeled data.
// Stores a column of hashed labels for a field, along with a sample of unique string values for that field. The sample's purpose is to provide a catalog of
// human-readable labels, ideally covering a large fraction of the points in question. This means we want its bias to echo the points' bias.

// The way we achieve this is simple: the sample array is indexed by the low N bits of each entry's murmurhash. Collisions are eagerly replaced, and we monitor
// the total string length, changing the number of bits and collapsing to remain within the memory limits.

caterwaul(':all')(function () {
  label(capacity) = this /-caterwaul.merge/ {hashes: new Uint32Array(capacity), sample: new label_sample(capacity), n: 0, c: capacity} -re- void 0,
  label.prototype /-caterwaul.merge/ label_methods,

  label_sample(capacity) = this /-caterwaul.merge/ {s: n[1 << 16] *[''] -seq, bits: 16, size: 0, n: 0, c: capacity} -re- void 0,
  label_sample.prototype /-caterwaul.merge/ label_sample_methods,

  where[label_methods = capture[reset()            = this -se [this.n = 0, this.sample = new label_sample(this.c)],
                                set(i, x)          = this -se [this.hashes[i] = x /-murmurhash3_32/ 0, this.sample /~push/ x],
                                pnorm(i)           = this.hashes[i] / 0x100000000,
                                p(i)               = this.pnorm(i),
                                h(i)               = this.hashes[i],
                                end()              = this.n /-Math.min/ this.c,
                                push(x, r)         = this.n++ < this.c ? this.set(this.n - 1, x) : this /x /~uniform_push/ r,
                                uniform_push(x, r) = this.set(r * this.n | 0, x) -when [r * this.n < this.c]],

        label_sample_methods = capture [reset()      = this -se [this.s = n[1 << 16] *[''] -seq, this.n = 0, this.size = 0, this.bits = 16],
                                        set(i, x)    = this -se [this.size += x.length - this.s[i].length, this.s[i] = x, unless [x == null]],
                                        push(x)      = this -se [this.set(x /-murmurhash3_32/ 0 & ~(-1 << this.bits), x), ++this.n, this.check_size()],

                                        check_size() = this -se [this.size * 2 > 4 * this.capacity ? this.collapse()
                                                               : this.size * 4 < 4 * this.capacity ? this.expand() : 0],
                                        collapse()   = this -se [this.s = n[1 << --this.bits] *[this.s[x] || this.s[x + 1 << this.bits]] -seq],
                                        expand()     = this -se [this.s = n[1 << ++this.bits] *[''] /seq -se-
                                                                          this.s *![it[murmurhash3_32(x, 0) & ~(-1 << this.bits)] = x] /seq]]]})();
24 core/jsplot/dataframe.waul
// Data frame: a collection of typed axes.
// Manages axis allocation, memory bounding, and input conversion. Also provides a layer of customization around coordinate mappings.

caterwaul(':all')(function () {
  dataframe(memory_limit) = this /-caterwaul.merge/ {axes: null, axis_types: null, n: 0, preview_lines: [], memory_limit: memory_limit} -re- void 0,
  dataframe.prototype /-caterwaul.merge/ dataframe_methods,

  where [dataframe_methods = capture [push(l)       = ++this.n <= 1024 ? this.preview_lines /~push/ l.split(/\t/) : this /~axis_push/ l.split(/\t/),
                                      axis_push(vs) = this.force_axes() -unless [this.axes] -then- this.axes *![x /vs[xi] /~push/ r] /seq
                                                                                            -where [r = Math.random()],
                                      eof()         = this.force_axes() -unless [this.axes],
                                      axes()        = this.axes ? this.axes.length : 0,
                                      axis(i)       = this.axes[i],
                                      capacity()    = this.axes ? this.memory_limit / this.axes.length >>> 3 : 0,

                                      force_axes()  = this.axes /eq[axis_types *[new window[x](axis_capacity)] -seq]
                                                      -then- this.axis_types /eq.axis_types
                                                      -then- this.preview_lines *!this.axis_push /seq
                                                      -where [n_axes        = this.preview_lines /[0][x0 /-Math.max/ x.length] -seq || 1,
                                                              axis_capacity = this.memory_limit / n_axes >>> 3,
                                                              self          = this,
                                                              is_numeric(x) = !isNaN(+x),
                                                              axis_type(i)  = self.preview_lines /[0][x0 + x[i] /!is_numeric] -seq,
                                                              axis_types    = n[n_axes] *[axis_type(x) > self.n/2 ? 'axis' : 'label'] -seq]]]})();
34 core/jsplot/matrix.waul
// Matrices.
// Not a complete library; just enough stuff to get 3D linear transformation and projection. This library also generates compiled functions for fast axis-specific
// transformation.

caterwaul(':all')(function () {
  matrix(x) = (x ? +x -seq : n[16] *[+((x>>2) == (x&3))] -seq) -se- it /-caterwaul.merge/ matrix_methods,
  matrix /-caterwaul.merge/ static_methods,

  where[static_methods = capture[translate(v)         = matrix() -se [it[3] = v[0], it[7] = v[1], it[11] = v[2]],
                                 scale(v)             = matrix() -se [it[0] = v[0], it[5] = v[1], it[10] = v[2]],
                                 rotate_x(t)          = matrix() -se [it[5] = it[10] = c, it[6] = -(it[9] = -s), where [s = t /!Math.sin, c = t /!Math.cos]],
                                 rotate_y(t)          = matrix() -se [it[0] = it[10] = c, it[2] = -(it[8] = -s), where [s = t /!Math.sin, c = t /!Math.cos]],
                                 prod(xs = arguments) = xs /[x0 /~dot/ x] -seq],

        matrix_methods = capture[dot             (b, a=this) = a *[n[4] /y[0][y0 + a[xi&12 | yi] * b[yi<<2 | xi&3]] -seq] /seq /!matrix,
                                 plus            (b, a=this) = a *[b[xi] + x]                                             /seq /!matrix,
                                 trace              (a=this) = a[0] + a[5] + a[10] + a[15],
                                 det                (a=this) = this.det_ -dcq [(t1 - t2 + t3 + t4 - t5) / 24
                                                                       -where [tr1 = a.trace(),  t1 = tr1 /-Math.pow/ 4,
                                                            a2 = a  /~dot/ a,  tr2 = a2.trace(), t2 = 6 * tr2 * tr1*tr1,
                                                            a3 = a2 /~dot/ a,  tr3 = a3.trace(), t3 = 3 * tr2*tr2,
                                                            a4 = a2 /~dot/ a2, tr4 = a4.trace(), t4 = 8 * tr3*tr1, t5 = 6 * tr4]],

                                 scaled_by       (y, a=this) = a *[x * y] /seq /!matrix,
                                 inv                (a=this) = this.inv_ -dcq [(matrix().scaled_by(1/6*t1) |~plus| a.scaled_by(-0.5*t2)
                                                                                  |~plus| a2.scaled_by(t3) |~plus| a3.scaled_by(-1)) /~scaled_by/ (1/a.det())
                                                                       -where [a2 = a /~dot/ a,    a3 = a2 /~dot/ a,
                                        tr1 = a.trace(),                      tr2 = a2.trace(),   tr3 = a3.trace(),
                                        t1  = tr1*tr1*tr1 - 3*tr1*tr2 + 2*tr3, t2 = tr1*tr1 - tr2, t3 = tr1]],

                                 transform       (v, a=this) = v *[n[4] /s[0][s0 + a[xi<<2|s]*v[s]] -seq] -seq,
                                 transformer_form(d, a=this) = qse[given[x, y, z] in _a*x + _b*y + _c*z + _d]
                                                               /~replace/ {_a: '#{a[d<<2|0]}', _b: '#{a[d<<2|1]}', _c: '#{a[d<<2|2]}', _d: '#{a[d<<2|3]}'},
                                 transformer     (d, a=this) = this.transformer_form(d) /!caterwaul.compile]]})();
16 core/jsplot/socket.waul
// Web socket interface.
// Manages downloads from the server, tracks state, invokes a callback for each batch of new data.

caterwaul(':all')(function () {
  ni_ws(cmd, cb) = cancel_existing() -then- ws_connect(cmd, cb),

  where[existing_connection         = null,
        cancel_existing()           = existing_connection.close() -when.existing_connection,
        ni_url(cmd)                 = "#{document.location.href.replace(/^http:/, 'ws:').replace(/#.*/, '')}ni/#{cmd /!encodeURIComponent}",
        ws_connect(cmd, f)          = existing_connection = new WebSocket(cmd /!ni_url, 'data') -se [it.onmessage = f /!message_wrapper],
        message_wrapper(f, k='')(e) = e.data.constructor === Blob ? f() -then- cancel_existing()
                                                                  : k -eq[lines.pop()] -then- f(lines)
                                                                                       -then- setTimeout("existing_connection /~send/ '' -rescue- null".qf, dt * 4 || 1)
                                                                                       -where[tstart = +new Date,
                                                                                              m      = k + e.data, lines = m.split(/\n/),
                                                                                              dt     = +new Date - tstart]]})();
113 core/jsplot/render.waul
// Rendering support.
// Rendering is treated like an asynchronous operation against the axis buffers. It ends up being re-entrant so we don't lock the browser thread, but those
// details are all hidden inside a render request.

caterwaul(':all')(function () {
  render(state = null, last_render = 0, frames_requested = 0)
        (axes, vm, l0, deadline, sr, ctx, w, h, cb) = state /eq[{a: axes, vm: vm, ctx: ctx, w: w, h: h, i: 0, vt: n[4] *[vm.transformer(x)] -seq, l: 0, l0: l0,
                                                                 deadline: deadline, total_shade: 0, saturation_rate: sr /!Math.exp, cb: cb,
                                                                 id: state && state.id && state.ctx === ctx && state.w === w && state.h === h
                                                                       ? state.id
                                                                       : ctx.getImageData(0, 0, w, h)}]
                                                      -then- request_frame()

// Render function.
// This is kind of subtle, so I'll explain how it all works. My liberal use of scare quotes is indicative of the amount of duplicity going on around here.

// Rendering happens "asynchronously" -- that is, it's a time-bounded, reentrant process. The outermost loop governing the whole rendering process is driven by
// requestAnimationFrame(), which calls into render_part(). render_part() runs for about 20ms, rendering 1/4096th "random" slices of the data until it runs out of
// time. The assumption here is that 1/4096th of the data takes under 20ms, which empirically has been true on my machine.

// The renderer works by modifying RGBA values in an ImageData object, which is a little tricky because all of the drawing operations need to be translucent:
// conceptually we're rendering a volume rather than an opaque object. We also log-scale(-ish) the light output on the screen, so brightness(pixel) ~ log(volume
// depth). This is all done without storing any extra per-pixel state. Here's a full list of the shader properties we want:

// | 1. Singly-shaded pixels should be visible: i.e. rendered at rgb >= 64 (except for obvious counter-cases like slice focusing or distant points).
//   2. Multiply-shaded pixels should converge to full luminosity _and preserve color_, with luminosity ~ log(total volume depth).
//   3. Pixels should eventually saturate to white, losing color resolution as they gain luminosity. This should approximately double the dynamic range.
//   4. The algorithm should be properly additive so that antialiasing works (we want 2x2 subpixel rendering).
//   5. A bunch of very dim points should converge to the right color average (i.e. we can't lose too much detail to 8-bit quantization).
//   6. The total onscreen brightness should remain about the same regardless of how many points are on the screen (otherwise zooming would dim the display).

// So here's roughly how this all works. The RGB channels store full-value color all the time: this is a brightness-weighted average of the colors drawn into that
// pixel. Brightness is stored in the alpha channel and converges to 255 by an exponential series if all points are rendered at the same intensity.

// Point intensity is randomized for every pixel shading operation. We do this to break through the quantization artifacts we'd get if the intensity were
// constantly low.

  -where[slice_size      = 4096,
         slices          = n[slice_size] -seq -re- it.sort("Math.random() - 0.5".qf),
         request_frame() = render_part /!requestAnimationFrame -then- ++frames_requested -unless.frames_requested,
         render_part     = function () {

// Render state.
// Local variables for the axes and coordinate transformations, some misc stuff, and our luminosity adjustment and shade tracking. The luminosity adjustment is
// modified each iteration as we figure out how dense our shading is empirically; state.l0, the "target luminosity", is measured in full shades per screen pixel.
// Here's the calculation:

// | initial_l = target_shade_per_pixel * pixels / data_points / 10;
//   next_l    = target_shade_per_pixel * pixels / (actual_shading_so_far / layers_so_far * total_layers);

    --frames_requested;
    var ax = state.a[0], ay = state.a[1],                  xt = state.vt[0], yt = state.vt[1], width  = state.id.width,
        az = state.a[2], aw = state.a[3], aq = state.a[4], zt = state.vt[2], wt = state.vt[3], height = state.id.height,
        id = state.id.data, n = state.a[0].end(), use_hue = !!aw, cx = width >> 1, cy = height >> 1,
        l  = state.l || state.l0 * width*height / n / 10, total_shade = state.total_shade, s = width /-Math.min/ height >> 1,
        sr = state.saturation_rate;

    if (state.cb)                                 state.cb(state.i, slice_size);
    if (state.i < slice_size && !state.deadline)  request_frame();
    if (state.i === 0)                            id.fill(0);

    var start = +new Date;
    var stop  = state.deadline || start + 30;
    for (; state.i < slice_size && (state.i < 8 || +new Date < stop); ++state.i) {
      for (var j = slices[state.i]; j < n; j += slice_size) {
        var w  = aw ? j /!aw.pnorm : 0, x  = ax ? j /!ax.p : 0, y  = ay ? j /!ay.p : 0, z  = az ? j /!az.p : 0,
            wi = 1 / wt(x, y, z),       xp = wi * xt(x, y, z),  yp = wi * yt(x, y, z),  zp = wi * zt(x, y, z),
            q  = aq ? j /!aq.pnorm : 1;

        if (zp > 0) {
          w *= 0.8;
          var r  = use_hue ? 1 - 2*(1/2 - Math.abs(.5  - w)) |-Math.min| 1 |-Math.max| 0.1 : 1,
              g  = use_hue ?     2*(1/2 - Math.abs(1/3 - w)) |-Math.min| 1 |-Math.max| 0.1 : 1,
              b  = use_hue ?     2*(1/2 - Math.abs(2/3 - w)) |-Math.min| 1 |-Math.max| 0.1 : 1,
              zi = 1/zp, tx = cx + xp*zi*s, ty = cy - yp*zi*s, sx = tx|0, sy = ty|0;

          if (sx >= 0 && sx < width-1 && sy >= 0 && sy < height-1) {
            tx -= sx; ty -= sy;
            for (var dx = 0; dx <= 1; ++dx)
              for (var dy = 0; dy <= 1; ++dy) {
                var pi = (sy+dy)*width + sx+dx << 2,
                    op = (1 - Math.abs(dx-tx)) * (1 - Math.abs(dy-ty)),
                    lp = id[pi|3] || 64,
                    ci = l * op * (256 - lp) * q,
                    li = ci * zi,
                    d  = sr / (li + lp),
                    cmax = Math.max(r, g, b);

                total_shade += li;
                id[pi|3] += li;
                id[pi|0] = (id[pi|0] * lp + r * 256 * li / cmax) * d;
                id[pi|1] = (id[pi|1] * lp + g * 256 * li / cmax) * d;
                id[pi|2] = (id[pi|2] * lp + b * 256 * li / cmax) * d;
              }
          }
        }
      }

      if (total_shade)
      {
        var target_shade   = state.l0 * width * height;
        var progress       = state.deadline ? (+new Date - start || 1) / (state.deadline - start)
                                            : (state.i + 1) / slice_size;
        var expected_shade = total_shade / progress;
        l = target_shade / expected_shade;
      }
    }

    state.l           = l;
    state.total_shade = total_shade;
    state.ctx.putImageData(state.id, 0, 0);
    last_render = +new Date;
  }]})();
57 core/jsplot/camera.waul
// Camera state, geometry, and UI.
// The camera contains an object matrix, a view matrix, and some render settings.

caterwaul(':all')(function ($) {
  camera(v) = jquery[div.camera /modus('composite', {br: '.brightness .number', ot: '.object-translation', os: '.object-scale',
                                                     sa: '.saturation .number', cr: '.camera-rotation',    cd: '.distance .number',
                                                     axes: '.axis-mapping input'})
                     >  div.vector.axis_mapping[axis_mapping() /~attr/ {title: 'Axis mapping'}]
                     >  div.vector.brightness  [log_number()   /~attr/ {title: 'View brightness'}]
                     >  div.vector.saturation  [log_number()   /~attr/ {title: 'White-saturation rate'}]
                     >  div.vector.distance    [log_number()   /~attr/ {title: 'Camera distance'}]
                     >= translation_ui() /~addClass/ 'object-translation' /~attr/ {title: 'Object translation'}
                     >= scale_ui()       /~addClass/ 'object-scale'       /~attr/ {title: 'Object scale'}
                     >= rotation_ui()    /~addClass/ 'camera-rotation'    /~attr/ {title: 'Camera rotation'}] -se- it.val(v) /when.v,

  camera /-$.extend/ wcapture [object_matrix(o)       = matrix.prod(o.os /!matrix.scale, o.ot /!matrix.translate),
                               camera_matrix(o)       = matrix.prod([0, 0, 1]                /!matrix.translate,
                                                                    [1/o.cd, 1/o.cd, 1/o.cd] /!matrix.scale,
                                                                    o.cr[0] / 360 * tau      /!matrix.rotate_x,
                                                                    o.cr[1] / 360 * tau      /!matrix.rotate_y),
                               norm(v)                = v[3] ? v |-v4scale| 1/v[3] : v,
                               m(o)                   = camera_matrix(o) /~dot/ object_matrix(o),

                               plane_lock(v)          = v *[xi === mi ? 0 : x] -seq -where [mi = n[3] /[v[x] /!Math.abs < v[x0] /!Math.abs ? x : x0] -seq],
                               axis_lock(v)           = v *[xi === mi ? x : 0] -seq -where [mi = n[3] /[v[x] /!Math.abs > v[x0] /!Math.abs ? x : x0] -seq],

                               iv_obj_locked(f)(o, v) = object_matrix(o).inv() /~transform/ f(camera_matrix(o).inv() /~transform/ v) /!norm,
                               iv_obj(o, v)           = camera_matrix(o).inv() /~transform/ v /!norm,
                               iv(o, v)               = m(o).inv()             /~transform/ v /!norm],

  $(given.e in $(document).on('mousewheel', '.log-number', given.e in $(this).val($(this).val() * Math.exp(e.deltaY * 0.01)).change())
                          .on('mousewheel', '.rotation',   given.e in $(this).val($(this).val() /-v2plus/ [e.deltaY * 0.1, e.deltaX * 0.1]).change())
                          .on('change',     '.number',     given.e in $(this).val($(this).val()))
                          .on('keydown',    '.number',     given.e[e.which === 38 ? $(this).val($(this).val() + 1).change() :
                                                                   e.which === 40 ? $(this).val($(this).val() - 1).change() : true])
                          .on('focus',      '.number',     given.e in $(this).select())),

  where[tagged(f, c)(v) = f(v) /~addClass/ c,
        nan_protect(x)  = x /!isNaN ? 0 : x,
        number_ui(n)(v) = jquery[input.number /modus(g, s) /val(v)] -where [g()  = this.modus('val') /!+eval /!n /!nan_protect,
                                                                            s(v) = this.modus('val', +v /!n /!nan_protect)],

        axis_mapping()  = jquery[input /modus(g, s)] -where [g()  = this.modus('val').split('') *[x.charCodeAt(0) - 65] -seq,
                                                             s(v) = this.modus('val', (v || 'ABCDE') *[String.fromCharCode(65 + x)] -seq -re- it.join(''))],

        log_number      = "_".qf       /!number_ui /-tagged/ 'log-number',
        linear_number   = "_".qf       /!number_ui /-tagged/ 'linear-number',
        angle_number    = "_ % 360".qf /!number_ui /-tagged/ 'linear-number',
        vector_ui(c)(v) = jquery[div.vector /modus('list', c)],

        translation_ui  = vector_ui(linear_number) /-tagged/ 'translation',
        scale_ui        = vector_ui(log_number)    /-tagged/ 'scale',
        rotation_ui     = vector_ui(angle_number)  /-tagged/ 'rotation',

        tau             = Math.PI * 2],

  using[caterwaul.merge(caterwaul.vector(2, 'v2'), caterwaul.vector(3, 'v3'), caterwaul.vector(4, 'v4'))]})(jQuery);
159 core/jsplot/interface.waul
// Page driver.

$(caterwaul(':all')(function ($) {
  setup_event_handlers(),

  $.fn.activate() = $(this) /~addClass/ 'active' -se [it /~data/ 'activation-timeout' /!clearTimeout,
                                                      it |'activation-timeout' |~data| "it /~removeClass/ 'active'".qf /-setTimeout/ 500],

  where[screen   = $('#screen'),    sc = screen[0]  /~getContext/ '2d',
        overlay  = $('#overlay'),   oc = overlay[0] /~getContext/ '2d',
        tr       = $('#transform'), lw = 0, mx = null, ms = false,
        status   = $('#status'),    lh = 0, my = null, mc = false,
        preview  = $('#preview'),
        explain  = $('#explain'),
        controls = $('#controls').modus('proxy', '.camera') /~addClass/ 'camera-mode noshift',
        w        = $(window).modus('composite', {ni: tr, v: controls}),

        default_settings()     = {ni: "//ni psplit// pord p'r pl 3' ,jABC.5 S8p'r prec(a+50, c*3.5+a*a/500), b, sin(a/100) + sin(b/100)' "
                                      + "S8,qABCD0.01 p'r a, - c, b, d'",
                                  v: {cr: [0, 0], os: [1, 1, 1], ot: [0, 0, 0], cd: 100, br: 1, sa: 0.03, axes: n[4] -seq}},

        size_changed()         = (lw !== cw || lh !== ch) -se [lw = cw, lh = ch] -where [cw = w.width(), ch = w.height()],
        resize_canvases()      = overlay.add(screen) /~attr/ {width: lw, height: lh} -then- update_screen(),
        resize_other_stuff()   = tr      /~css/ {height: 0} /~css/ {height: tr[0].scrollHeight - 2, width: lw-2}
                          -then- preview /~css/ {top: tr.height() + 3, bottom: 1}
                          -then- explain /~css/ {top: tr.height() + 3, left: preview.width() + 12},
        handle_resizes()       = resize_canvases() -then- resize_other_stuff() -when- size_changed(),

        update_status(t)       = status.children('#sizelabel').text(t).activate(),

        object_mode            = false,
        toggle_object_mode()   = controls.toggleClass('object-mode', object_mode = !object_mode)
                                         .toggleClass('camera-mode', !object_mode),

        view_change(k, f, v)   = w.val(w.val() -se [it.v[k] = it.v[k] /-f/ v]),

        data_lock_vector()     = data_state.frame.axes.length >= 3 ? [1, 1, 1] : [1, 1, 0],
        screen_scale()         = (lw /-Math.min/ lh) / 2,
        drag(dx, dy, s)        = s ? 'cr' /v2plus /-view_change/ [dy * 180 / screen_scale(), -dx * 180 / screen_scale()]
                                   : w.val() /se    [it.v.ot = it.v.ot /-v3plus/ modify(it.v, [dx / screen_scale(), -dy / screen_scale(), 0, 0])
                                                                       /-v3times/ data_lock_vector()]
                                             /where [modify = object_mode ? camera.iv_obj_locked(camera.axis_lock) : camera.iv]
                                             /!w.val,

        wheel(dx, dy, s)       = object_mode ? 'os' |v3times |-view_change| [Math.exp(sx * 0.01 * (d[0] >= d[2])),
                                                                             Math.exp(sy * 0.01),
                                                                             Math.exp(sx * 0.01 * (d[2] >= d[0]))]
                                                                     -where [d = camera.iv_obj(w.val().v, [1, 0, 0, 0]) *Math.abs -seq,
                                                                             sx = s ? dy || dx : dx,
                                                                             sy = s ? 0        : dy]
                                             : 'cd' |a*b -given[a, b] |-view_change| Math.exp(dy * -0.01),

        check_syntax(v)        = $.getJSON('/parse/#{v /!encodeURIComponent}', update_explain)
                         -where [update_explain(r)  = explain.empty() /~append/ explanation_for(r.ops)
                                                                      /~prepend/ errors_for(r.unparsed),
                                 explanation_for(x) = jquery[pre /text(s)] -where [s = x *JSON.stringify /seq -re- it.join("\n")],
                                 errors_for(u)      = u.length ? jquery[div.errors > code /text(u /~join/ ' ')] : []],

        setup_event_handlers() = tr /~keydown/ given.e [e.which === 13 && !e.shiftKey ? w.val().ni /!visualize -then- false : true]
                                      /~keyup/ given.e [$(this).change() -then- w.val().ni /!check_syntax]
                                      /~focus/ given.e [explain.show()]
                                       /~blur/ given.e [explain.hide()]
                          -then- overlay     /~mousedown/ given.e [mx = e.pageX, my = e.pageY, ms = e.shiftKey, true]
                                            /~mousewheel/ given.e [wheel(e.deltaX, e.deltaY, e.shiftKey), update_screen_fast()]
                          -then- $(document) /~mousemove/ given.e [drag(x - mx, y - my, ms), mx = x, my = y, ms = e.shiftKey, update_screen_fast(),
                                                                   where [x = e.pageX, y = e.pageY], when.mx]
                                               /~mouseup/ given.e [mx = null, update_screen(), when.mx]
                                               /~keydown/ given.e [e.which === 9 ? toggle_object_mode() -then- false
                                                                 : e.which === 16 ? controls /~addClass/    'shift' : true]
                                                 /~keyup/ given.e [e.which === 16 ? controls /~removeClass/ 'shift' : true]
                          -then- w /~resize/ handle_resizes
                          -then- controls /~append/ camera().change(update_screen_fast)
                          -then- $('#object-mode, #camera-mode') /~click/ toggle_object_mode
                          -then- $('canvas').attr('unselectable', 'on').css('user-select', 'none').on('selectstart', false)
                          -then- $('.autohide') /~click/ "$(this) /~toggleClass/ 'pinned'".qf
                          -then- $('#search input') /~change/ "update_selected($(this).val())".qf
                                                     /~keyup/ search_complete /~focus/ "$('#search-auto').show()".qf
                                                                              /~blur/  "$('#search-auto').hide()".qf
                          -then- $('#search-auto').on('mousedown', '.option', "$('#search input') /~val/ $(this).text()".qf)
                                                  .on('mouseover', '.option', "update_selected($(this).text()) -then- update_overlay()".qf)

                          -then- handle_resizes /-setTimeout/ 10
                          -then- "document.location.hash = $(this).val() /!JSON.stringify /!encodeURI".qf /-setInterval/ 50
                          -then- w /~val/ $.extend(default_settings(), document.location.hash.substr(1) /!decodeURIComponent /!JSON.parse -rescue- {})
                          -then- tr.val() /!visualize,

        reset_data_state()   = data_state = {frame: new dataframe(128 * 1048576), preview_done: false, bytes: 0, last_render: 0} -se- preview /~text/ '',
        data_state           = null -se- reset_data_state(),

        data_was_revised(ls) = update_screen() /when[+new Date - data_state.last_render > data_state.frame.axes[0].end() / 100]
                      -then- '#{ats} / #{data_state.frame.axes[0].n}[#{data_state.frame.capacity()}] / #{kb /!Math.round}K'
                             /!update_status
                             /where [ats = data_state.frame.axis_types *[x.substr(0, 1)] -seq -re- it.join(''),
                                     kb  = (data_state.bytes += ls /[0][x0 + x.length + 1] -seq + 0.0) / 1024]
                      -when [data_state.frame.axes && data_state.frame.axes[0]]
                      -then- preview.text(data_state.frame.preview_lines *[x /~join/ '\t'] -seq -re- it.join('\n').substr(0, 65536))
                             /then[data_state.preview_done = data_state.frame.preview_lines.length >= 1024]
                             /unless[data_state.preview_done],

        visualize(cmd)     = reset_data_state() -then- ni_ws(cmd, handle_data)
                      -where [handle_data(ls) = ls ? ls *!data_state.frame.push -seq -then- data_was_revised(ls)
                                                   : data_state.frame.eof()          -then- data_was_revised([])],

        label_axes()       = data_state.frame.axes ? data_state.frame.axes %[x.constructor === label] -seq : [],
        search_complete()  = $('#search-auto').empty() |~append| options *[jquery[div.option /text(x)]] -seq
                             -where [v           = $('#search input').val().toLowerCase(),
                                     option_keys = {} -se [label_axes() *![x.sample.s
                                                                        *![it[x] /eq.it -when [x.length && x.toLowerCase() /~indexOf/ v !== -1]] -seq] -seq],
                                     options     = option_keys /keys -seq -re- it.sort().slice(0, 1024)],

        selected_points    = [],
        update_selected(s) = selected_points /eq.new_selected -then- w.val().v /!update_overlay
                     -where [h            = s /-murmurhash3_32/ 0,
                             new_selected = (function () {
                                              var r = [], las = label_axes();
                                              for (var li = 0; li < las.length; ++li)
                                                for (var i = 0, a = las[li]; i < a.end(); ++i)
                                                  if (a.h(i) === h)
                                                    r.push(i);
                                              return r;
                                            })()],

        update_overlay(v)  = oc.clearRect(0, 0, lw, lh) -then- outline_points('#f60', selected_points)
                     -where [scale          = lw /-Math.min/ lh >>> 1,
                             cx             = lw >>> 1,
                             cy             = lh >>> 1,
                             axes           = data_state.frame.axes /!axis_map,
                             m              = v /!camera.m,
                             outline_points = function (c, is) {
                               oc.strokeStyle = c;
                               var t = +new Date;
                               for (var i = 0; i < is.length && +new Date - t < 20; ++i) {
                                 var pi = is[i];
                                 var p  = m.transform([axes[0] ? axes[0].p(pi) : 0,
                                                       axes[1] ? axes[1].p(pi) : 0,
                                                       axes[2] ? axes[2].p(pi) : 0, 1] /!camera.norm);
                                 if (p[2] > 0) oc.strokeRect(cx + scale*p[0]/p[2] - 2, cy - scale*p[1]/p[2] - 2, 5, 5);
                               }
                             }],

        axis_map(as)         = w.val().v.axes *[as[x]] -seq,
        renderer             = render(),
        full_render_tmout    = null,
        update_screen_fast() = renderer(data_state.frame.axes /!axis_map, v /!camera.m, v.br * 32, +new Date + 30, v.sa, sc, screen.width(), screen.height())
                               /where [preview_factor = Math.min(1, data_state.frame.n / data_state.frame.capacity()),
                                       preview_slices = Math.min(4096, 64 / preview_factor | 0)]
                        -then- full_render_tmout /!clearTimeout
                        -then- full_render_tmout /eq[update_screen /-setTimeout/ 120]
                        -where [v = w.val().v],

        update_render_status(i, m) = $('#render-bar-inner') /~css/ {width: $('#render-bar').width() * i/m} -then- status.activate(),
        update_screen()            = full_render_tmout /!clearTimeout
                             -then-  renderer(data_state.frame.axes /!axis_map, v /!camera.m, v.br, 0, v.sa, sc, screen.width(), screen.height(), update_render_status)
                             -then-  update_overlay(v)
                             -then-  data_state.last_render /eq[+new Date]
                             -when  [data_state.frame.axes && +new Date - data_state.last_render > 50]
                             -where [v = w.val().v]],

  using[caterwaul.merge({}, caterwaul.vector(2, 'v2'), caterwaul.vector(3, 'v3'), caterwaul.vector(4, 'v4'))]}));
78 core/jsplot/css
body {margin:0; color:#eee; background:black; font-size:10pt; font-family:monospace; overflow: hidden}

#screen, #overlay {position:absolute}

::-webkit-scrollbar {width:12px; height:4px}
::-webkit-scrollbar-track {background:rgba(255,255,255,0.1)}
::-webkit-scrollbar-thumb {background:rgba(255,255,255,0.5)}

*:focus, *:hover, .pinned, .active {opacity:1 !important}

#status {position:absolute; right:2px; bottom:2px; width:400px; opacity:0.2; text-align:right; z-index:9}
#render-bar {display:inline-block; width:40px; height:4px; border:solid 1px rgba(255,255,255,0.5)}
#render-bar-inner {background:rgba(255,255,255,0.5); height:4px}

#search {position:absolute; right:400px; bottom:0; width:400px; z-index:9}
#search input {width:400px; font-family:monospace; color:#eee; border:none; outline:none; background:transparent; border-top:solid 1px transparent}

#search input:focus {border-top:solid 1px #f60}
#search input:hover, #search input:focus {background:rgba(0,0,0,0.75)}

#search-auto .option {cursor:pointer}
#search-auto .option:hover {background:rgba(96,96,96,0.75)}
#search-auto {max-height:700px; width:400px; overflow:auto}
#search-auto:hover {background:rgba(0,0,0,0.75)}

#transform {background:none; margin:0; color:#eee; position:absolute; left:0; top:0; border:none; outline:none; padding:1px 0;
            border-bottom:solid 1px transparent; font-family:monospace; z-index:9}

#transform:focus,
#transform:hover {background:rgba(0,0,0,0.75)}
#transform:focus {border-bottom:solid 1px #f60}

#explain {z-index:9; position:absolute; padding:4px}
#explain > .errors {color:#f20}
#explain > .errors::before {color:#f20; content:'error> '}

#preview {z-index:9; color:transparent; max-width:1px; overflow-x:auto; position:absolute; left:0; padding-right:12px; overflow-y:show; margin:0;
          background:rgba(0,0,0,0.75); cursor:default; font-family:monospace}
#preview:hover, #preview.pinned {color:#eee; max-width:100%}
#preview.pinned {border-right:solid 1px #f60}

#controls {position:absolute; width:192px; right:-184px; bottom:14pt; z-index:9; background:rgba(0,0,0,0.75); border-top:solid 1px transparent}
#controls:hover, #controls.pinned {right:0}
#controls.pinned {border-top:solid 1px #f60}

.vector input {background:none; border:none; margin:0; color:#eee; padding:4px; font-family:sans-serif; font-size:14pt; width:132px; cursor:default}

.vector     {display:inline-block; padding:4px; border-left:solid 8px rgba(96,96,96,0.5); background:rgba(64,64,64,0.25); margin:2px 0}
.vector > * {display:inline-block}

.object-translation::before {float:right; font-size:14pt; color:rgba(192,192,192,0.5); content:'+'; padding:4px}
.object-scale::before       {float:right; font-size:14pt; color:rgba(192,192,192,0.5); content:'x'; padding:4px}
.camera-rotation::before    {float:right; font-size:14pt; color:rgba(192,192,192,0.5); content:'R'; padding:4px}
.distance::before           {float:right; font-size:14pt; color:rgba(192,192,192,0.5); content:'D'; padding:4px}
.brightness::before         {float:right; font-size:14pt; color:rgba(192,192,192,0.5); content:'B'; padding:4px}
.saturation::before         {float:right; font-size:14pt; color:rgba(192,192,192,0.5); content:'S'; padding:4px}

#controls > label {font-family:sans-serif; font-size:14pt; color:rgba(96,96,96,0.5)}
#controls > label::before {color:rgba(192,192,192,0.5); content:' [ '}
#controls > label::after  {color:rgba(192,192,192,0.5); content:' ] '}
#controls.camera-mode > #camera-mode {color:#f60}
#controls.object-mode > #object-mode {color:#f60}

#controls.camera-mode.noshift .vector.object-translation {border-left:solid 8px #f60}
#controls.camera-mode.noshift .distance                  {border-left:solid 8px #f60}

#controls.camera-mode.shift .vector.object-translation {border-left:solid 8px rgba(96,96,96,0.5)}
#controls.camera-mode.shift .vector.camera-rotation    {border-left:solid 8px #f60}
#controls.camera-mode.shift .distance                  {border-left:solid 8px rgba(96,96,96,0.5)}

#controls.object-mode.noshift .vector.object-translation {border-left:solid 8px #f60}
#controls.object-mode.noshift .vector.object-scale       {border-left:solid 8px #f60}
#controls.object-mode.noshift .distance                  {border-left:solid 8px rgba(96,96,96,0.5)}

#controls.object-mode.shift .vector.object-translation {border-left:solid 8px rgba(96,96,96,0.5)}
#controls.object-mode.shift .vector.object-scale       {border-left:solid 8px #f60}
#controls.object-mode.shift .vector.camera-rotation    {border-left:solid 8px #f60}
#controls.object-mode.shift .distance                  {border-left:solid 8px rgba(96,96,96,0.5)}
27 core/jsplot/html
<!doctype html>
<html>
<head>
<title>ni/jsplot</title>
<style>%css</style>
<script>%js</script>
</head>
<body>
<textarea spellcheck='false' id='transform'></textarea>
<div id='explain'></div>
<pre id='preview' class='autohide'></pre>
<canvas id='screen'></canvas>
<canvas id='overlay'></canvas>
<div id='controls' class='autohide'>
  <label id='camera-mode'>camera</label>
  <label id='object-mode'>object</label>
</div>
<div id='search'>
  <div id='search-auto'></div>
  <input id='search-text'></input>
</div>
<div id='status'>
  <div id='render-bar'><div id='render-bar-inner'></div></div>
  <label id='sizelabel'></label>
</div>
</body>
</html>
94 core/jsplot/jsplot.pl
# JSPlot interop.
# JSPlot is served over HTTP as a portable web interface. It requests data via
# AJAX, and may request the same data multiple times to save browser memory. The
# JSPlot driver buffers the data to disk to make it repeatable.

use constant jsplot_gen => gen $ni::self{'core/jsplot/html'};

use constant jsplot_html =>
  jsplot_gen->(css => $ni::self{'core/jsplot/css'},
               js  => join '', @ni::self{qw| core/jsplot/jquery.min.js
                                             core/jsplot/jquery.mousewheel.min.js
                                             core/caterwaul/caterwaul.min.js
                                             core/caterwaul/caterwaul.std.min.js
                                             core/caterwaul/caterwaul.ui.min.js
                                             core/jsplot/murmurhash3.js
                                             core/jsplot/modus.js
                                             core/jsplot/vector.js
                                             core/jsplot/axis.waul
                                             core/jsplot/label.waul
                                             core/jsplot/dataframe.waul
                                             core/jsplot/matrix.waul
                                             core/jsplot/socket.waul
                                             core/jsplot/render.waul
                                             core/jsplot/camera.waul
                                             core/jsplot/interface.waul |});

# Parsing.
# This entry point provides a realtime CLI parse for the UI.

sub jsplot_parse($$@) {
  my ($reply, $req, @ni_args) = @_;
  my ($ops, @rest) = cli @ni_args;
  http_reply $reply, 200, json_encode {ops => $ops, unparsed => [@rest]};
}

# JSPlot data streaming.
# This is the websocket connection that ni uses to stream data to the client. Any
# data we receive from the client indicates that the client is canceling the
# websocket request, so we need to break the pipe and kill off subprocesses.

sub jsplot_log($@) {printf STDERR "ni js[$$]: $_[0]", @_[1..$#_]}

sub jsplot_stream($$@) {
  local $_;
  my ($reply, $req, @ni_args) = @_;
  my ($ops, @rest) = cli @ni_args;
  die "ni: jsplot failed to parse starting at @rest" unless defined $ops;

  jsplot_log "running %s\n", json_encode $ops;

  safewrite $reply, ws_header($req);
  my $ni_pipe = sni @$ops, http_websocket_encode_batch_op 65536;

  my $incoming;
  my $rmask = '';
  vec($rmask, fileno $reply, 1) = 1;

  while (saferead $ni_pipe, $_, 65536) {
    safewrite $reply, $_;
    if (select(my $rout = $rmask, undef, undef, 0.004))
    {
      saferead $reply, $incoming, 8192;
      if ($incoming =~ /^\x88/) {
        jsplot_log "SIGTERM to worker\n";
        $ni_pipe->kill('TERM');
        jsplot_log "awaiting worker exit\n";
        jsplot_log "worker exited with %d\n", $ni_pipe->await;
        return;
      }
    }
  }
  jsplot_log "done transferring data\n";
  $ni_pipe->await;
  jsplot_log "worker exited with %d\n";
}

sub jsplot_server {
  my ($port) = @_;
  load 'core/http/ws.pm';
  http $port, sub {
    my ($url, $req, $reply) = @_;
    return print "http://localhost:$port/\n"             unless defined $reply;
    return http_reply $reply, 200, jsplot_html           if $url eq '/';
    return jsplot_parse($reply, $req, shell_unquote $1)  if $url =~ /^\/parse\/([\s\S]*)/;
    return jsplot_stream($reply, $req, shell_unquote $1) if $url =~ /^\/ni\/([\s\S]*)/;
    return http_reply $reply, 404, $url;
  };
}

defclispecial '--js', q{jsplot_server $_[0] || 8090}, <<'_';
Usage: ni --js [port=8090]
Runs a web interface that allows you to visualize data streams. See ni
//help/visual for details.
_
2 core/mapomatic/lib
geojson.pl
mapomatic.pl
221 core/mapomatic/geojson.pl
# GeoJSON functions
# Converts WKTs and other things to geoJSON for export to Map-O-Matic.

use Scalar::Util qw/looks_like_number/;

# The universal operator here is "geojsonify", which takes inputs in a few
# different formats and emits one line of geoJSON each. Specifically, these
# formats are supported:
#
#   lat lng ...                     # render a point
#   lat,lng ...                     # ditto
#   lat,lng >lat,lng ...            # render a line between two points
#   lat,lng +dlat,dlng ...          # render a line towards a delta
#   POINT(...) ...                  # and other WKT formats
#   POLYGON(...) ...
#   9q5c ...                        # base-32 geohash
#   6114200779206244058 ...         # tagged geohash
#   010600... ...                   # WKB
#   {...} ...                       # geoJSON
#
# gh60s will be rendered as points, whereas anything less precise will be a
# bounding polygon.
#
# You can specify other attributes in the columns rightwards of the geometry.
# Those can be any of the following:
#
#   name=value                      # stuff something into properties
#   {"name":"value",...}            # merge into properties
#   #341802                         # set rendering color
#   0.12518251                      # generate a color from a unit float
#   arbitrary text                  # set title attribute so you get a tooltip
#
# The geoJSON lines coming out of this operator are just the individual
# features. To render as geoJSON for real, you'll want to collect these lines
# and wrap with the boilerplate:
#
# {
#   "type": "FeatureCollection",
#   "features": [
#     <your-geojson-features>
#   ]
# }
#
# ni's mapomatic operator does all of this for you.

use constant geojson_point_gen => gen '{"type":"Point","coordinates":[%x,%y]}';
use constant geojson_vector_gen => gen
  '{"type":"LineString","coordinates":[[%x1,%y1],[%x2,%y2]]}';

use constant geojson_box_gen => gen
    '{'
  .   '"type":"Polygon",'
  .   '"coordinates":['
  .     '[[%w,%s],[%e,%s],[%e,%n],[%w,%n],[%w,%s]]'
  .   ']'
  . '}';

use constant geojson_polygon_gen => gen
    '{'
  .   '"type":"Polygon",'
  .   '"coordinates":[%linear_rings]'
  . '}';

# Individual geojson parsing cases
sub geojson_point
{
  my ($lat, $lng) = @_;
  geojson_point_gen->(x => $lng, y => $lat);
}

sub geojson_vector
{
  my ($lat1, $lng1, $lat2, $lng2) = @_;
  geojson_vector_gen->(x1 => $lng1, y1 => $lat1,
                       x2 => $lng2, y2 => $lat2);
}

sub geojson_box
{
  my ($n, $s, $e, $w) = @_;
  geojson_box_gen->(n => $n, s => $s, e => $e, w => $w);
}

use constant geojson_ring_gen      => gen '[%points]';
use constant geojson_ringpoint_gen => gen '[%x,%y]';

sub geojson_polygon
{
  my ($wkx) = @_;
  my $rings = ($wkx =~ /^[A-Za-z]/ ? parse_wkt $wkx : parse_wkb $wkx)->{rings};
  my $json_rings = join",", map {
    my $lr = $_;
    my @ps;
    for (my $i = 0; $i + 1 < $#$lr; $i += 2)
    {
      push @ps, geojson_ringpoint_gen->(x => $$lr[$i], y => $$lr[$i + 1]);
    }
    geojson_ring_gen->(points => join",", @ps);
  } @$rings;
  geojson_polygon_gen->(linear_rings => $json_rings);
}

# Property extraction
sub geojson_rgb($)
{
  my ($x) = @_;
  return $x if $x =~ /^#/;
  my $r = min 1, max 0, 1 - 2 * (0.5 - abs 0.5 - $x);
  my $g = min 1, max 0,     2 * (0.5 - abs 1/3 - $x);
  my $b = min 1, max 0,     2 * (0.5 - abs 2/3 - $x);
  sprintf "#%02x%02x%02x", int $r * 255, int $g * 255, int $b * 255;
}

sub geojson_props
{
  my $props = {title => ''};
  for (@_)
  {
    %$props = (%$props, %{json_decode $_}), next if /^{/;
    $$props{'marker-color'}
      = $$props{'stroke'}
      = $$props{'fill'} = geojson_rgb $_, next   if /^#/ || looks_like_number $_;
    $$props{$1} = $2, next                       if /^([^=]+)=(.*)$/;
    $$props{title} .= $_;
  }
  $props;
}

# geojson_parse_geometry(F_) -> ($geometry_obj, $properties_obj)
sub geojson_parse
{
  # Detect obvious cases like WKT, WKB, and JSON
  if ($_[0] =~ /^{/)
  {
    my $decoded = json_decode $_[0];
    (json_encode $$decoded{geometry}, $$decoded{properties});
  }
  elsif ($_[0] =~ /^POINT/)
  {
    my ($lng, $lat) = $_[0] =~ /[-+0-9.eE]+/g;
    return (geojson_point($lat, $lng), geojson_props(@_[1..$#_]));
  }
  elsif ($_[0] =~ /^M|^P/)
  {
    return (geojson_polygon($_[0]), geojson_props(@_[1..$#_]));
  }
  elsif ($_[0] =~ /^([-+0-9.eE]+),([-+0-9.eE]+)$/)
  {
    my ($lat1, $lng1) = ($1, $2);

    # Do we have another lat/lng as the second arg? (or a delta?)
    if ($_[1] =~ /^[>+]([-+0-9.eE]+),([-+0-9.eE]+)$/)
    {
      my ($lat2, $lng2) = ($1, $2);
      if ($_[1] =~ /^\+/)   # + means delta
      {
        $lat2 += $lat1;
        $lng2 += $lng1;
      }
      return (geojson_vector($lat1, $lng1, $lat2, $lng2),
              geojson_props(@_[2..$#_]));
    }
    else
    {
      # Just a point
      return (geojson_point($lat1, $lng1), geojson_props(@_[1..$#_]));
    }
  }
  elsif ($_[0] =~ /^0[01](?:0000000[2356]|0[2356]000000)[0-9A-Fa-f]{4,}$/)
  {
    # WKB
    return (geojson_polygon($_[0]), geojson_props(@_[1..$#_]));
  }
  elsif (looks_like_number $_[0] && $_[0] & 1 << 62)
  {
    # Tagged geohash
    my $prec = geohash_tagged_precision $_[0];
    if ($prec == 60)
    {
      my ($lat, $lng) = geohash_decode($_[0]);
      return (geojson_point($lat, $lng), geojson_props(@_[1..$#_]));
    }
    else
    {
      my ($n, $s, $e, $w) = geohash_box(gb3 $_[0] & 0x0fff_ffff_ffff_ffff, $prec);
      return (geojson_box($n, $s, $e, $w), geojson_props(@_[1..$#_]));
    }
  }
  elsif (looks_like_number $_[0] && $_[0] >= -90 && $_[0] <= 90)
  {
    # A latitude, so assume the next field is the longitude
    return (geojson_point($_[0], $_[1]), geojson_props(@_[2..$#_]));
  }
  elsif ($_[0] =~ /[0-9a-z]+/)
  {
    # base-32 geohash
    my $geom = length $_[0] == 12 ? geojson_point(geohash_decode $_[0])
                                  : geojson_box(geohash_box $_[0]);
    return ($geom, geojson_props @_[1..$#_]);
  }
  else
  {
    die "geojson_parse: unknown format for row @_";
  }
}

use constant geojson_row_gen => gen
  '{"type":"Feature","geometry":%geom,"properties":%props}';

defoperator geojsonify =>
q{
  while (<STDIN>)
  {
    chomp;
    my ($geom, $props) = geojson_parse(split /\t/);
    print geojson_row_gen->(geom  => $geom,
                            props => json_encode($props)), "\n";
  }
};

defshort '/geojsonify', pmap q{geojsonify_op}, pnone;
150 core/mapomatic/mapomatic.pl
# Map-O-Matic
# Runs a webserver that uses GeoJSON to render a map.

use constant geojson_html_gen => gen <<'EOF';
<!DOCTYPE html>
<html>
<head>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no' />
<style>
body { margin:0; padding:0; }
#map { position:absolute; top:0; bottom:0; width:100%; }
.marker-properties {
  border-collapse:collapse;
  font-size:11px;
  border:1px solid #eee;
  margin:0;
}
.marker-properties th {
  white-space:nowrap;
  border:1px solid #eee;
  padding:5px 10px;
}
.marker-properties td {
  border:1px solid #eee;
  padding:5px 10px;
}
.marker-properties tr:last-child td,
.marker-properties tr:last-child th {
  border-bottom:none;
}
.marker-properties tr:nth-child(even) th,
.marker-properties tr:nth-child(even) td {
  background-color:#f7f7f7;
}
.leaflet-tooltip.my-labels {
  background-color: transparent;
  border: transparent;
  box-shadow: none;
}
</style>
<script src='//api.tiles.mapbox.com/mapbox.js/v2.2.2/mapbox.js'></script>
<script src='//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js' ></script>
<link href='//api.tiles.mapbox.com/mapbox.js/v2.2.2/mapbox.css' rel='stylesheet' />
</head>
<body>
<div id='map'></div>
<script type='text/javascript'>
L.mapbox.accessToken = '%mapbox_key';
var map = L.mapbox.map('map');

L.mapbox.tileLayer('%mapbox_tileset').addTo(map);

function showProperties(l) {
  var properties = l.toGeoJSON().properties;
  var table = document.createElement('table');
  table.setAttribute('class', 'marker-properties display')
  for (var key in properties) {
    var tr = createTableRows(key, properties[key]);
    table.appendChild(tr);
  }
  if (table) l.bindPopup(table);
}

function createTableRows(key, value) {
  var tr = document.createElement('tr');
  var th = document.createElement('th');
  var td = document.createElement('td');
  key = document.createTextNode(key);
  value = document.createTextNode(value);
  th.appendChild(key);
  td.appendChild(value);
  tr.appendChild(th);
  tr.appendChild(td);
  return tr
}

geojson_callback = function(geojson) {
  var geojsonLayer = L.mapbox.featureLayer(geojson, {
    pointToLayer: function(feature,latlng){
      return new L.CircleMarker(latlng, { radius: 5 })
    }
  }).addTo(map);
  var bounds = geojsonLayer.getBounds();
  if (bounds.isValid()) {
    map.fitBounds(geojsonLayer.getBounds());
  } else {
    map.setView([0, 0], 2);
  }
  geojsonLayer.eachLayer(showProperties);
};
</script>
<script id='geojson'>
geojson_callback(%geojson);
$('#geojson').remove();
</script>
</body>
</html>
EOF

use constant geojson_container_gen => gen
  '{"type":"FeatureCollection","features":[%features]}';

use constant mapbox_key_default => 'pk.eyJ1Ijoic3BlbmNlcnRpcHBpbmciLCJhIjoiY2plNGducGNxMTR3cTJycnF1bGRkYmJ0NiJ9.aGaYbtzy_cSYfuQ0fawfTQ';
defconfenv 'mapbox/key',     NI_MAPBOX_KEY     => undef;
defconfenv 'mapbox/tileset', NI_MAPBOX_TILESET => 'mapbox.streets';

sub mapomatic_server {
  my ($port, $geojson) = @_;

  my $key = conf 'mapbox/key';
  unless (defined $key)
  {
    print "WARNING\n";
    print "  You're using ni's builtin Mapbox key, which is shared across\n";
    print "  all ni users. To avoid hitting the free-tier quota, you should\n";
    print "  head to mapbox.com and generate a new key. Keys are free and\n";
    print "  give you about 50000 map views per month. Once you have a key,\n";
    print "  add this line to your .bashrc:\n";
    print "\n";
    print "  export NI_MAPBOX_KEY='<your mapbox access token>'\n";
    print "\n";
    print "  For example:\n";
    print "\n";
    print "  export NI_MAPBOX_KEY='pk.eyJ1Ijoic3BlbmNlcnRpcHBpbmciLCJhIjoiY2plNGducGNxMTR3cTJycnF1bGRkYmJ0NiJ9.aGaYbtzy_cSYfuQ0fawfTQ'\n";
    print "\n";
    print "  You can verify that ni is using your key by running this:\n";
    print "  \$ ni '\$mapbox/key'\n";
    print "\n";

    $key = 'pk.eyJ1Ijoic3BlbmNlcnRpcHBpbmciLCJhIjoiY2plNGducGNxMTR3cTJycnF1bGRkYmJ0NiJ9.aGaYbtzy_cSYfuQ0fawfTQ';
  }

  $|++;
  http $port, sub {
    my ($url, $req, $reply) = @_;
    return print "http://localhost:$port/\n" unless defined $reply;
    return http_reply $reply, 200,
             geojson_html_gen->(geojson        => $geojson,
                                mapbox_key     => $key,
                                mapbox_tileset => conf 'mapbox/tileset')
      if $url eq '/';
    return http_reply $reply, 404, $url;
  };
}

defoperator mapomatic => q{
  mapomatic_server 32768, geojson_container_gen->(features => join",", <STDIN>);
};

defshort '/MM',  pmap q{[geojsonify_op, mapomatic_op]}, pnone;
4 core/inspect/lib
css
html
inspect.js
inspect.pl
41 core/inspect/css
body { font-family: "Ubuntu Sans", sans-serif; margin: auto; width: 800px }

#header {
  padding: 40px 0 20px 0;
  font-family: "Ubuntu Mono", "Inconsolata", "Anonymous Pro", monospace;
  font-size: 40px;
}

#shell { color: #888; padding-right: 10px }
#ni    { color: black }

#explain-pre, #explain, #explanation {
  font-family: "Ubuntu Mono", "Inconsolata", "Anonymous Pro", monospace;
  font-size: 20pt;
}

pre {
  font-family: "Ubuntu Mono", "Inconsolata", "Anonymous Pro", monospace;
  font-size: 125%;
  line-height: 1.44em;
}

#explain-pre, #explanation { color: #888 }

#explain { border: none; outline: none; width: 100% }
#content { border-top: solid 1px #444; margin-top: 20px }

a { color: #444; text-decoration: none }
a:hover { color: #f80; text-decoration: underline }

.conf-env { color: #aaa }

ul { list-style-type: square }

.markdown ul { margin: 0; padding: 0 }

.markdown { text-align: justify; font-size: 125%; line-height: 1.44em; color: #444 }
.markdown a { color: #c60 }
.markdown code { background: #eee; color: black }
.markdown pre { line-height: 1.44em; font-size: 125%; color: black; background: #eee; padding: 8px; border-left: solid 1px #444 }
.markdown blockquote { margin-left: 2em; padding-left: 8px; border-left: solid 1px #888 }
18 core/inspect/html
<!doctype html>
<html>
<head>
<title>ni/inspect</title>
<style>%css</style>
<script>%js</script>
</head>
<body>
<div id='header'>
<a href='/root'><span id='shell'>$</span><span id='ni'>ni --inspect</span></a>
</div>
<textarea spellcheck='false' id='explain'>n10 gcO</textarea>
<div id='explanation'></div>
<div id='content'>
%content
</div>
</body>
</html>
34 core/inspect/inspect.js
$(function () {
  var reload_explanation = function () {
    $.getJSON("/explain/" + $('#explain').val(), function (result) {
      $('#explanation').html(
        result.ops + (result.unparsed ?
          "<div class='unparsed'>" + result.unparsed + "</div>" : ""));
    });
  };

  var last_hash = '';
  setInterval(function () {
    if (document.location.hash === last_hash) return;
    last_hash = document.location.hash;
    $('#content').empty();
    $.get(decodeURI(document.location.hash.substr(1)), function (reply) {
      $('#content').html(reply);
    });
  }, 50);

  if (document.location.hash === '') document.location.hash = '/root';

  $('body').on('click', 'a', function (e) {
    var href = $(this).attr('href');
    if (!/^http/.test(href))
    {
      document.location.hash = encodeURI($(this).attr('href'));
      e.preventDefault();
      return false;
    }
  });

  $('#explain').on('keyup change', reload_explanation);
  reload_explanation();
});
389 core/inspect/inspect.pl
# Inspect ni's internal state

use constant inspect_gen => gen $ni::self{'core/inspect/html'};

our %inspect_index;
our @inspect_precedence
  = qw/ op meta_op cli_special parser short constant sub resource
        conf attr doc lib dsp alt /;

sub inspect_build_index()
{
  # There's a lot of stuff here: operators, attributes, libraries, etc.
  %inspect_index = ();

  $inspect_index{bootcode}{bootcode} = 'bootcode';
  $inspect_index{$_}{sub}      = $_ for map +(/sub\s+(\w+)/g, /\*(\w+)\s*=/g), @ni::self{grep /\.p[lm]$/, keys %ni::self};
  $inspect_index{$_}{constant} = $_ for map /use constant\s+(\w+)/g,           @ni::self{grep /\.p[lm]$/, keys %ni::self};
  $inspect_index{$_}{lib}      = $_ for grep s/\/lib$//, keys %ni::self;
  $inspect_index{$_}{doc}      = $_ for grep /^doc\//,   keys %ni::self;

  $inspect_index{"$_:"}{resource} = $_ for keys %ni::resource_read;
  $inspect_index{$_}{conf}        = $_ for keys %ni::conf_varibles;
  $inspect_index{$_}{parser}      = $_ for keys %ni::parsers;
  $inspect_index{$_}{short}       = $_ for keys %ni::shorts;
  $inspect_index{$_}{long}        = $_ for keys %ni::longs;
  $inspect_index{$_}{attr}        = $_ for keys %ni::self;
  $inspect_index{$_}{op}
    = $inspect_index{"${_}_op"}{op} = $_ for keys %ni::operators;

  $inspect_index{$_}{meta_op}
    = $inspect_index{"${_}_op"}{meta_op} = $_ for keys %ni::meta_operators;

  $inspect_index{$_}{dsp}         = $_ for keys %ni::dsps;
  $inspect_index{$_}{alt}         = $_ for keys %ni::alts;
  $inspect_index{$_}{cli_special} = $_ for keys %ni::cli_special;
}

sub markdown_table($)
{
  (my $table = shift)
    =~ s/^(.*)\n[-|\s]+\n/join("|", map"**$_**", split m(\|), $1) . "\n"/e;
  ("<table><tbody>",
   map(("<tr>",
        map(("<td>", markdown_to_html($_), "</td>"), split /\|/),
        "</tr>"),
       split /\n/, $table),
   "</tbody></table>");
}

sub markdown_to_html($)
{
  map /^\`\`\`(.*)([\s\S]*)\`\`\`\h*$/ ?
      ("<div class='code-$1'>", inspect_text($2), "</div>")

    : /^\`([^\`]*)\`$/ ?
      ("<code>", html_escape($1), "</code>")

    : /^!\[[^]]*\]\((.*)\)/ ?
      "<img src='$1'>"

    : /^\[([^]]+)\]\((https?:.*)\)/ ?
      ("<a href='$2'>", markdown_to_html($1), "</a>")

    : /^\[([^]]+)\]\((.*)\)/ ?
      exists $ni::self{"doc/$2"}
        ? ("<a href='/doc/doc/$2'>",  markdown_to_html($1), "</a>")
        : ("<a href='/attr/doc/$2'>", markdown_to_html($1), "</a>")

    : /^>/ ?
      ("<blockquote>",
       markdown_to_html(join"\n", map substr($_, 1), split /\n/, $_),
       "</blockquote>")

    : /^\n(\h*)(?:[-*]|\d\.) (.*)/ ?
      ("<ul style='padding-left:".(2 + length($1))."em'><li>",
       markdown_to_html($2),
       "</li></ul>")

    : /^\n######(.*)/  ? ("<h6>",   markdown_to_html($1), "</h6>")
    : /^\n#####(.*)/   ? ("<h5>",   markdown_to_html($1), "</h5>")
    : /^\n####(.*)/    ? ("<h4>",   markdown_to_html($1), "</h4>")
    : /^\n###(.*)/     ? ("<h3>",   markdown_to_html($1), "</h3>")
    : /^\n##(.*)/      ? ("<h2>",   markdown_to_html($1), "</h2>")
    : /^\n#(.*)/       ? ("<h1>",   markdown_to_html($1), "</h1>")
    : /\|.*\n.*\|/     ? markdown_table $_
    : /^\*\*(.*)\*\*$/ ? ("<b>",    markdown_to_html($1), "</b>")
    : /^([_*])(.*)\1$/ ? ("<i>",    markdown_to_html($2), "</i>")
    : /^\n\h*$/        ? "<p>"
    :                    $_,
  split /
    (
      \n\#+.*$                                  # headings
    | \n\h*$                                    # paragraph breaks
    | _\S(?:[^_]*\S)?_                          # italics
    | \*\S(?:[^*]*\S)?\*                        # italics with *
    | \*\*\S(?:[^*]*?\S)?\*\*                   # bold
    | ^>.*(?:\n>.*)*$                           # blockquote
    | ^\`\`\`.*\n(?:[\s\S]*?\n)?\`\`\`\h*$      # code block
    | \`[^\`]*\`                                # inline code
    | (?:[^|\`\n]+(?:[-\h]\|[-\h][^|\n]*)+\n)+  # tables
    | \n\h*[-*]\s.*                             # bulleted list item
    | \n\h*\d+\.\s.*                            # numbered list item
    | !?\[[^]]+\]\([^\)]+\)                     # link
    )
  /mx, shift;
}

sub html_escape($)
{
  my $x = shift;
  $x =~ s/&/&amp;/g;
  $x =~ s/</&lt;/g;
  $x =~ s/>/&gt;/g;
  $x;
}

sub inspect_page
{
  my $reply = shift;
  http_reply $reply, 200,
    inspect_gen->(
      css     => $ni::self{'core/inspect/css'},
      js      => join("\n", @ni::self{qw| core/jsplot/jquery.min.js
                                          core/inspect/inspect.js |}),
      content => join "\n", @_);
}

sub inspect_snip
{
  my $reply = shift;
  http_reply $reply, 200, join "", @_;
}

sub inspect_disambiguation_for($)
{
  my $k   = shift;
  my $ref = $inspect_index{$k};
  return () unless keys(%$ref) > 1;

  ("<h2><code>$k</code> refers to:</h2>",
   "<ul>",
   map("<li><code><a href='/$_/$$ref{$_}'>$_ $k</a></code></li>",
       sort keys %$ref),
   "</ul>");
}

sub inspect_link_for($)
{
  my $k      = shift;
  my $entry  = $inspect_index{$k};
  my ($type) = grep exists $$entry{$_}, @inspect_precedence;
  "<a href='/$type/$$entry{$type}'>$k</a>";
}

sub inspect_linkify
{
  my @xs = @_;
  my $link_detector = join"|", map qr/\Q$_\E/,
                               sort {length($b) - length($a)}
                               keys %inspect_index;
  my $r = qr/(?<=\W)($link_detector)(?=\W)/;
  s/$r/inspect_link_for $1/ge for @xs;
  @xs;
}

sub inspect_text { ("<pre>", inspect_linkify(map html_escape($_), @_), "</pre>") }

sub inspect_attr
{
  my ($reply, $k) = @_;
  my $lib = $k;
  $lib =~ s/\/[^\/]+$// until $lib !~ /\// || exists $ni::self{"$lib/lib"};
  inspect_snip $reply,
    inspect_linkify("<h1>Attribute <code>$k</code></h1>"),
    inspect_disambiguation_for($k),
    inspect_linkify("<h2>Defined in library <code>$lib</code></h2>"),
    inspect_text $ni::self{$k};
}

sub inspect_lib
{
  my ($reply, $k) = @_;
  inspect_snip $reply, "<h1>Library <code>$k</code></h1>",
    "<h2>Defined in <code><a href='/root'>ni root</a></code></h2>",
    inspect_disambiguation_for($k),
    "<ul>",
    map(inspect_linkify("<li>$_</li>"), lib_entries $k, $ni::self{"$k/lib"}),
    "</ul>";
}

sub inspect_defined
{
  my ($type, $def_regex, $k) = @_;
  map +(inspect_linkify("<h2>Defined in <code>$_</code></h2>"),
        inspect_text $ni::self{$_} =~ /\n?([^\n]*$def_regex.*$)/s),
      grep $ni::self{$_} =~ /$def_regex/s, sort keys %ni::self;
}

sub inspect_defined_snip
{
  my ($reply, $type, $def_regex, $k) = @_;
  inspect_snip $reply,
    "<h1><code>$type $k</code></h1>",
    inspect_disambiguation_for($k),
    inspect_defined($type, $def_regex, $k);
 }

sub inspect_sub         { inspect_defined_snip $_[0], sub         => qr/sub\s+$_[1]\W|\*$_[1]\s*=/, $_[1] }
sub inspect_resource    { inspect_defined_snip $_[0], resource    => qr/defresource\s+['"]?\s*$_[1]\W/, $_[1] }
sub inspect_constant    { inspect_defined_snip $_[0], constant    => qr/use constant\s+$_[1]\W/, $_[1] }
sub inspect_cli_special { inspect_defined_snip $_[0], cli_special => qr/defclispecial\s+['"]?\s*\Q$_[1]\E\W/, $_[1] }
sub inspect_short       { inspect_defined_snip $_[0], short       => qr/defshort\s+["']?\s*\Q$_[1]\E\W/, $_[1] }
sub inspect_long        { inspect_defined_snip $_[0], long        => qr/deflong\s+["']?\s*\Q$_[1]\E\W/, $_[1] }
sub inspect_op          { inspect_defined_snip $_[0], op          => qr/defoperator\s+["']?\s*\Q$_[1]\E\W/, $_[1] }
sub inspect_meta_op     { inspect_defined_snip $_[0], meta_op     => qr/defmetaoperator\s+["']?\s*\Q$_[1]\E\W/, $_[1] }

sub inspect_parser_short
{
  my ($reply, $short) = @_;
  inspect_snip $reply,
    inspect_linkify("<h1>Parser for short operator <code>$short</code></h1>"),
    inspect_disambiguation_for($short),
    inspect_text(parser_ebnf $ni::shorts{$short}),
    inspect_defined(parser => qr/defparser\w*\s+['"]?\s*\Q$short\E\W/, $short);
}

sub inspect_parser_long
{
  my ($reply, $long) = @_;
  inspect_snip $reply,
    inspect_linkify("<h1>Parser for long operator <code>$long</code></h1>"),
    inspect_disambiguation_for($long),
    inspect_text(parser_ebnf $ni::longs{$long}),
    inspect_defined(parser => qr/defparser\w*\s+['"]?\s*\Q$long\E\W/, $long);
}

sub inspect_parser
{
  my ($reply, $p) = @_;
  inspect_snip $reply,
    inspect_linkify("<h1>Parser <code>$p</code></h1>"),
    inspect_disambiguation_for($p),
    inspect_text(parser_ebnf $ni::parsers{$p}),
    inspect_defined(parser => qr/defparser\w*\s+['"]?\s*\Q$p\E\W/, $p);
}

sub inspect_bootcode
{
  my ($reply) = @_;
  inspect_snip $reply, "<h1>Bootcode</h1>", inspect_text ni::boot_header;
}

sub inspect_explain
{
  my ($reply, $command) = @_;
  my ($ops, @rest) = eval {cli shell_unquote $command};
  http_reply $reply, 200,
    json_encode {ops      => inspect_linkify(json_encode $ops),
                 unparsed => [@rest]};
}

sub inspect_doc
{
  my ($reply, $doc) = @_;
  inspect_snip $reply,
    "<div class='markdown'>",
    markdown_to_html "\n$ni::self{$doc}",
    "</div>";
}

sub inspect_root
{
  my ($reply) = @_;
  my %links;

  while (my ($k, $v) = each %inspect_index)
  {
    while (my ($type, $target) = each %$v)
    {
      next if $k =~ /_op$/ || $type eq 'short' && $k =~ /^\/\$/;
      my $thing = "<a href='/$type/$target'><code>$k</code></a>";

      if ($type eq 'conf')
      {
        my ($env) = $ni::conf_variables{$k} =~ /conf_env '(\w+)'/;
        $env ||= '';
        $thing .= " <code class='conf-env'>\$$env</code>";
        $thing .= " = <code>" . conf($k) . "</code>" if length conf $k;
      }

      $thing .= " [<a href='/parser_short/$k'>grammar</a>]"
        if $type eq "short";

      push @{$links{$type} ||= []}, $thing;
    }
  }

  my @rendered =
    ("<h1>Reference</h1>",
     "<h2><i>Ni By Example</i>, by <a href='https://github.com/michaelbilow'>Michael Bilow</a></h2>",
     "<ul>",
     "<li><a href='/doc/doc/ni_by_example_1.md'>Chapter 1</a></li>",
     "<li><a href='/doc/doc/ni_by_example_2.md'>Chapter 2</a></li>",
     "<li><a href='/doc/doc/ni_by_example_3.md'>Chapter 3</a></li>",
     "<li><a href='/doc/doc/ni_by_example_4.md'>Chapter 4</a></li>",
     "<li><a href='/doc/doc/ni_by_example_5.md'>Chapter 5</a></li>",
     "<li><a href='/doc/doc/ni_by_example_6.md'>Chapter 6</a></li>",
     "<li><a href='/doc/doc/ni_fu.md'>Ni Fu</a></li>",
     "<li><a href='/doc/doc/cheatsheet_op.md'>Operator Cheatsheet</a></li>",
     "<li><a href='/doc/doc/cheatsheet_perl.md'>Ni Perl Cheatsheet</a></li>",
     "</ul>",
     "<h2>Internal documentation: entry points</h2>",
     "<ul>",
     "<li><a href='/bootcode'>Bootcode</a></li>",
     "<li><a href='/attr/core/boot/ni.map'>Image map file</a></li>",
     "</ul>");

  my %names = (doc         => "Documentation",
               lib         => "Installed libraries",
               resources   => "Resources",
               conf        => "Configuration variables",
               short       => "Short operator parsers",
               op          => "Stream operators",
               meta_op     => "Meta operators",
               cli_special => "Toplevel CLI options",
               attr        => "Internal attributes",
               sub         => "Internal functions",
               constant    => "Internal constants",
               dsp         => "Parser dispatch table",
               alt         => "Parser alternative list");

  for (qw/ lib cli_special doc short op meta_op conf attr sub constant dsp alt /)
  {
    my $ls = $links{$_};
    push @rendered,
      "<h1>$names{$_}</h1>",
      "<ul>",
      map("<li>$_</li>", sort @$ls),
      "</ul>" if ref $ls;
  }

  inspect_snip $reply, @rendered;
}

sub inspect_root_page
{
  my ($reply) = @_;
  inspect_page $reply, 'Loading...';
}

sub inspect_server
{
  my ($port) = @_;

  inspect_build_index;
  http $port, sub
  {
    my ($url, $req, $reply) = @_;
    return print "http://localhost:$port/\n" unless defined $reply;

    return inspect_root_page    $reply     if $url eq '/';
    return inspect_root         $reply     if $url =~ /^\/root/;
    return inspect_bootcode     $reply     if $url =~ /^\/bootcode/;
    return inspect_explain      $reply, $1 if $url =~ /^\/explain\/(.*)/;

    1 while $url =~ s/\/\.\.\//\//g;

    return inspect_doc          $reply, $1 if $url =~ /^\/doc\/(.*)/;
    return inspect_attr         $reply, $1 if $url =~ /^\/attr\/(.*)/;
    return inspect_lib          $reply, $1 if $url =~ /^\/lib\/(.*)/;
    return inspect_sub          $reply, $1 if $url =~ /^\/sub\/(.*)/;
    return inspect_resource     $reply, $1 if $url =~ /^\/resource\/(.*)/;
    return inspect_constant     $reply, $1 if $url =~ /^\/constant\/(.*)/;
    return inspect_short        $reply, $1 if $url =~ /^\/short\/(.*)/;
    return inspect_long         $reply, $1 if $url =~ /^\/long\/(.*)/;
    return inspect_op           $reply, $1 if $url =~ /^\/op\/(.*)/;
    return inspect_meta_op      $reply, $1 if $url =~ /^\/meta_op\/(.*)/;
    return inspect_cli_special  $reply, $1 if $url =~ /^\/cli_special\/(.*)/;
    return inspect_parser       $reply, $1 if $url =~ /^\/parser\/(.*)/;
    return inspect_parser_short $reply, $1 if $url =~ /^\/parser_short\/(.*)/;
    return inspect_parser_long  $reply, $1 if $url =~ /^\/parser_long\/(.*)/;
  };
}

defclispecial '--inspect', q{inspect_server $_[0] || 9200}, <<'_';
Usage: ni --inspect [port=9200]
Runs a web interface that allows you to inspect ni's internal attributes,
defined operators, and grammar.
_
1 core/docker/lib
docker.pl
88 core/docker/docker.pl
# Pipeline dockerization.
# Creates a transient container to execute a part of your pipeline. The image you
# specify needs to have Perl installed, but that's about it.

# Prebuilt image case.
# This is what happens by default, and looks like `ni Cubuntu[g]`.

use constant docker_image_name => prx '[^][]+';

defoperator docker_run_image => q{
  my ($image, @f) = @_;
  my $fh = siproc {exec qw|docker run --rm -i|, $image, ni_quoted_exec_args};
  quote_ni_into $fh, @f;
};

# On-demand images.
# These are untagged images built on the fly. NB: workaround here for old/buggy
# versions of the docker client; here's what's going on.

# Normally you'd use `docker build -q` and get an image ID, but some older docker
# clients ignore the `-q` option and emit full verbose output (and, in
# unexpectedly barbaric fashion, they also emit this verbosity to standard out,
# not standard error). So we instead go through the silliness of tagging and then
# untagging the image.

defoperator docker_run_dynamic => q{
  my ($dockerfile, @f) = @_;
  my $fh = siproc {
    my $quoted_dockerfile = shell_quote 'printf', '%s', $dockerfile;
    my $quoted_args       = shell_quote ni_quoted_exec_args;
    my $image_name        = "ni-tmp-" . lc noise_str 32;
    sh qq{image_name=\`$quoted_dockerfile | docker build -q -\`
          if [ \${#image_name} -gt 80 ]; then \\
            $quoted_dockerfile | docker build -q -t $image_name - >&2
            image_name=$image_name
            docker run --rm -i \$image_name $quoted_args
            docker rmi --no-prune=true \$image_name
          else
            docker run --rm -i \$image_name $quoted_args
          fi};
  };
  quote_ni_into $fh, @f;
};

sub alpine_dockerfile {
  join "\n", 'FROM alpine',
             q{RUN echo '@edge http://nl.alpinelinux.org/alpine/edge/main' \
                   >> /etc/apk/repositories \
                && echo '@testing http://nl.alpinelinux.org/alpine/edge/testing' \
                   >> /etc/apk/repositories \
                && echo '@community http://nl.alpinelinux.org/alpine/edge/community' \
                   >> /etc/apk/repositories \
                && apk update \
                && apk add perl},
             map "RUN apk add $_", @_;
}

sub ubuntu_dockerfile {
  join "\n", 'FROM ubuntu',
             'RUN apt-get update',
             map "RUN apt-get install -y $_", @_;
}

use constant docker_package_list => pmap q{[/\+([^][+]+)/g]}, prx '[^][]+';

defshort '/C',
  defalt 'dockeralt', 'alternatives for the /C containerize operator',
    pmap(q{docker_run_dynamic_op alpine_dockerfile(@{$$_[0]}), @{$$_[1]}},
         pseq pn(1, prc 'A', pc docker_package_list), _qfn),
    pmap(q{docker_run_dynamic_op ubuntu_dockerfile(@{$$_[0]}), @{$$_[1]}},
         pseq pn(1, prc 'U', pc docker_package_list), _qfn),
    pmap(q{docker_run_image_op $$_[0], @{$$_[1]}},
         pseq pc docker_image_name, _qfn);

# Execution within existing containers.
# Same idea as running a new Docker, but creates a process within an existing
# container.

use constant docker_container_name => docker_image_name;

defoperator docker_exec => q{
  my ($container, @f) = @_;
  my $fh = siproc {exec qw|docker exec -i|, $container, ni_quoted_exec_args};
  quote_ni_into $fh, @f;
};

defshort '/E', pmap q{docker_exec_op $$_[0], @{$$_[1]}},
               pseq pc docker_container_name, _qfn;
3 core/hadoop/lib
hadoop-conf.pl
hadoop.pl
hdfsjoin.pl
366 core/hadoop/hadoop-conf.pl
# MapReduce configuration is a huge pain;
# we aim to make it a little easier.

# Derived from https://github.com/Yelp/mrjob/blob/master/mrjob/compat.py
 
our %mr_generics = (
'Hdb',      'dfs.blocksize',
'Hdbpc',    'dfs.bytes-per-checksum',
'Hdcwps',   'dfs.client-write-packet-size',
'Hdchkr',   'dfs.client.https.keystore.resource',
'Hdchna',   'dfs.client.https.need-auth',
'Hdcrps',   'dfs.client.read.prefetch.size',
'Hdcst',    'dfs.client.socket-timeout',
'Hddns',    'dfs.datanode.StorageId',
'Hddnbb',   'dfs.datanode.balance.bandwidthPerSec',
'Hddndd',   'dfs.datanode.data.dir',
'Hddnh',    'dfs.datanode.hostname',
'Hddnmtt',  'dfs.datanode.max.transfer.threads',
'Hdmsi',    'dfs.metrics.session-id',
'Hdnnap',   'dfs.namenode.accesstime.precision',
'Hdnnba',   'dfs.namenode.backup.address',
'Hdnnbha',  'dfs.namenode.backup.http-address',
'Hdnncd',   'dfs.namenode.checkpoint.dir',
'Hdnnced',  'dfs.namenode.checkpoint.edits.dir',
'Hdnncp',   'dfs.namenode.checkpoint.period',
'Hdnned',   'dfs.namenode.edits.dir',
'Hdnnhri',  'dfs.namenode.heartbeat.recheck-interval',
'Hdnnhttp', 'dfs.namenode.http-address',
'Hdnnhttps','dfs.namenode.https-address',
'Hdnnmo',   'dfs.namenode.max.objects',
'Hdnnnd',   'dfs.namenode.name.dir',
'Hdnnndr',  'dfs.namenode.name.dir.restore',
'Hdnnrc',   'dfs.namenode.replication.considerLoad',
'Hdnnri',   'dfs.namenode.replication.interval',
'Hdnnrms',  'dfs.namenode.replication.max-streams',
'Hdnnrm',   'dfs.namenode.replication.min',
'Hdnnrpts', 'dfs.namenode.replication.pending.timeout-sec',
'Hdnnse',   'dfs.namenode.safemode.extension',
'Hdnnstp',  'dfs.namenode.safemode.threshold-pct',
'Hdnnsha',  'dfs.namenode.secondary.http-address',
'Hdnnup',   'dfs.namenode.upgrade.permission',
'Hdpe',     'dfs.permissions.enabled',
'Hdps',     'dfs.permissions.superusergroup',
'Hfcbd',    'fs.client.buffer.dir',
'Hfd',      'fs.defaultFS',
'Hfdi',     'fs.df.interval',
'Hinla',    'io.native.lib.available',
'Hccp',     'mapreduce.client.completion.pollinterval',
'Hcgu',     'mapreduce.client.genericoptionsparser.used',
'Hcof',     'mapreduce.client.output.filter',
'Hcpp',     'mapreduce.client.progressmonitor.pollinterval',
'Hcsfr',    'mapreduce.client.submit.file.replication',
'Hcae',     'mapreduce.cluster.acls.enabled',
'Hcld',     'mapreduce.cluster.local.dir',
'Hcmm',     'mapreduce.cluster.mapmemory.mb',
'Hcps',     'mapreduce.cluster.permissions.supergroup',
'Hcrm',     'mapreduce.cluster.reducememory.mb',
'Hctd',     'mapreduce.cluster.temp.dir',
'Hfdfs',    'mapreduce.fieldsel.data.field.separator',
'Hfmokvfs', 'mapreduce.fieldsel.map.output.key.value.fields.spec',
'Hfrokvfs', 'mapreduce.fieldsel.reduce.output.key.value.fields.spec',
'Hifi',     'mapreduce.input.fileinputformat.inputdir',
'Hifsmax',  'mapreduce.input.fileinputformat.split.maxsize',
'Hifsmin',  'mapreduce.input.fileinputformat.split.minsize',
'Hifsmpn',  'mapreduce.input.fileinputformat.split.minsize.per.node',
'Hifsmpr',  'mapreduce.input.fileinputformat.split.minsize.per.rack',
'Hikkvs',   'mapreduce.input.keyvaluelinerecordreader.key.value.separator',
'Hill',     'mapreduce.input.lineinputformat.linespermap',
'Hillm',    'mapreduce.input.linerecordreader.line.maxlength',
'Himdf',    'mapreduce.input.multipleinputs.dir.formats',
'Himdm',    'mapreduce.input.multipleinputs.dir.mappers',
'Hipc',     'mapreduce.input.pathFilter.class',
'Hisc',     'mapreduce.input.sequencefileinputfilter.class',
'Hisf',     'mapreduce.input.sequencefileinputfilter.frequency',
'Hisr',     'mapreduce.input.sequencefileinputfilter.regex',
'Hjca',     'mapreduce.job.cache.archives',
'Hjcat',    'mapreduce.job.cache.archives.timestamps',
'Hjcf',     'mapreduce.job.cache.files',
'Hjcft',    'mapreduce.job.cache.files.timestamps',
'Hjcla',    'mapreduce.job.cache.local.archives',
'Hjclf',    'mapreduce.job.cache.local.files',
'Hjcsc',    'mapreduce.job.cache.symlink.create',
'Hjcpa',    'mapreduce.job.classpath.archives',
'Hjcpf',    'mapreduce.job.classpath.files',
'Hjcc',     'mapreduce.job.combine.class',
'Hjcscn',   'mapreduce.job.committer.setup.cleanup.needed',
'Hjenra',   'mapreduce.job.end-notification.retry.attempts',
'Hjenri',   'mapreduce.job.end-notification.retry.interval',
'Hjenu',    'mapreduce.job.end-notification.url',
'Hji',      'mapreduce.job.id',
'Hjic',     'mapreduce.job.inputformat.class',
'Hjj',      'mapreduce.job.jar',
'Hjjn',     'mapreduce.job.jvm.numtasks',
'Hjld',     'mapreduce.job.local.dir',
'Hjmc',     'mapreduce.job.map.class',
'Hjm',      'mapreduce.job.maps',
'Hjmpt',    'mapreduce.job.maxtaskfailures.per.tracker',
'Hjn',      'mapreduce.job.name',
'Hjogcc',   'mapreduce.job.output.group.comparator.class',
'Hjokc',    'mapreduce.job.output.key.class',
'Hjokcc',   'mapreduce.job.output.key.comparator.class',
'Hjovc',    'mapreduce.job.output.value.class',
'Hjoc',     'mapreduce.job.outputformat.class',
'Hjpc',     'mapreduce.job.partitioner.class',
'Hjp',      'mapreduce.job.priority',
'Hjq',      'mapreduce.job.queuename',
'Hjrc',     'mapreduce.job.reduce.class',
'Hjrsc',    'mapreduce.job.reduce.slowstart.completedmaps',
'Hjr',      'mapreduce.job.reduces',
'Hjso',     'mapreduce.job.skip.outdir',
'Hjs',      'mapreduce.job.skiprecords',
'Hjssnt',   'mapreduce.job.speculative.slownodethreshold',
'Hjsstt',   'mapreduce.job.speculative.slowtaskthreshold',
'Hjssc',    'mapreduce.job.speculative.speculativecap',
'Hjun',     'mapreduce.job.user.name',
'Hjurh',    'mapreduce.job.userlog.retain.hours',
'Hjwd',     'mapreduce.job.working.dir',
'Hjcci',    'mapreduce.jobcontrol.createdir.ifnotexist',
'Hjta',     'mapreduce.jobtracker.address',
'Hjtbat',   'mapreduce.jobtracker.blacklist.average.threshold',
'Hjteti',   'mapreduce.jobtracker.expire.trackers.interval',
'Hjthc',    'mapreduce.jobtracker.handler.count',
'Hjthis',   'mapreduce.jobtracker.heartbeats.in.second',
'Hjthef',   'mapreduce.jobtracker.hosts.exclude.filename',
'Hjthf',    'mapreduce.jobtracker.hosts.filename',
'Hjtha',    'mapreduce.jobtracker.http.address',
'Hjti',     'mapreduce.jobtracker.instrumentation',
'Hjtjbs',   'mapreduce.jobtracker.jobhistory.block.size',
'Hjtjcl',   'mapreduce.jobtracker.jobhistory.completed.location',
'Hjtjl',    'mapreduce.jobtracker.jobhistory.location',
'Hjtjlcs',  'mapreduce.jobtracker.jobhistory.lru.cache.size',
'Hjtjt',    'mapreduce.jobtracker.jobinit.threads',
'Hjtmmm',   'mapreduce.jobtracker.maxmapmemory.mb',
'Hjtmrm',   'mapreduce.jobtracker.maxreducememory.mb',
'Hjtmp',    'mapreduce.jobtracker.maxtasks.perjob',
'Hjtpja',   'mapreduce.jobtracker.persist.jobstatus.active',
'Hjtpjd',   'mapreduce.jobtracker.persist.jobstatus.dir',
'Hjtpjh',   'mapreduce.jobtracker.persist.jobstatus.hours',
'Hjtrr',    'mapreduce.jobtracker.restart.recover',
'Hjtrcs',   'mapreduce.jobtracker.retiredjobs.cache.size',
'Hjtr',     'mapreduce.jobtracker.retirejobs',
'Hjtsd',    'mapreduce.jobtracker.system.dir',
'Hjttl',    'mapreduce.jobtracker.taskcache.levels',
'Hjtt',     'mapreduce.jobtracker.taskscheduler',
'Hjttmp',   'mapreduce.jobtracker.taskscheduler.maxrunningtasks.perjob',
'Hjtttc',   'mapreduce.jobtracker.taskscheduler.taskalloc.capacitypad',
'Hjtttm',   'mapreduce.jobtracker.tasktracker.maxblacklists',
'Hjtwt',    'mapreduce.jobtracker.webinterface.trusted',
'Hje',      'mapreduce.join.expr',
'Hjk',      'mapreduce.join.keycomparator',
'Hmcm',     'mapreduce.map.combine.minspills',
'Hmds',     'mapreduce.map.debug.script',
'Hme',      'mapreduce.map.env',
'Hmfm',     'mapreduce.map.failures.maxpercent',
'Hmif',     'mapreduce.map.input.file',
'Hmil',     'mapreduce.map.input.length',
'Hmis',     'mapreduce.map.input.start',
'Hmjo',     'mapreduce.map.java.opts',
'Hmll',     'mapreduce.map.log.level',
'Hmm',      'mapreduce.map.maxattempts',
'Hmmm',     'mapreduce.map.memory.mb',
'Hmoc',     'mapreduce.map.output.compress',
'Hmokfs',   'mapreduce.map.output.key.field.separator',
'Hmovc',    'mapreduce.map.output.value.class',
'Hmsm',     'mapreduce.map.skip.maxrecords',
'Hmspcai',  'mapreduce.map.skip.proc-count.auto-incr',
'Hmssp',    'mapreduce.map.sort.spill.percent',
'Hms',      'mapreduce.map.speculative',
'Hmr',      'mapreduce.mapper.regex',
'Hmrg',     'mapreduce.mapper.regexmapper..group',
'Hofc',     'mapreduce.output.fileoutputformat.compress',
'Hofcc',    'mapreduce.output.fileoutputformat.compress.codec',
'Hofct',    'mapreduce.output.fileoutputformat.compress.type',
'Hofo',     'mapreduce.output.fileoutputformat.outputdir',
'Holo',     'mapreduce.output.lazyoutputformat.outputformat',
'Hoskc',    'mapreduce.output.seqbinaryoutputformat.key.class',
'Hosvc',    'mapreduce.output.seqbinaryoutputformat.value.class',
'Hots',     'mapreduce.output.textoutputformat.separator',
'Hpblo',    'mapreduce.partition.binarypartitioner.left.offset',
'Hpbro',    'mapreduce.partition.binarypartitioner.right.offset',
'Hpkco',    'mapreduce.partition.keycomparator.options',
'Hpkpo',    'mapreduce.partition.keypartitioner.options',
'Hpcp',     'mapreduce.pipes.commandfile.preserve',
'Hpe',      'mapreduce.pipes.executable',
'Hpei',     'mapreduce.pipes.executable.interpretor',
'Hpif',     'mapreduce.pipes.inputformat',
'Hpijm',    'mapreduce.pipes.isjavamapper',
'Hpijrr',   'mapreduce.pipes.isjavarecordreader',
'Hpijrw',   'mapreduce.pipes.isjavarecordwriter',
'Hpijr',    'mapreduce.pipes.isjavareducer',
'Hpp',      'mapreduce.pipes.partitioner',
'Hrds',     'mapreduce.reduce.debug.script',
'Hre',      'mapreduce.reduce.env',
'Hrfm',     'mapreduce.reduce.failures.maxpercent',
'Hribp',    'mapreduce.reduce.input.buffer.percent',
'Hrjo',     'mapreduce.reduce.java.opts',
'Hrll',     'mapreduce.reduce.log.level',
'Hrmbp',    'mapreduce.reduce.markreset.buffer.percent',
'Hrm',      'mapreduce.reduce.maxattempts',
'Hrmm',     'mapreduce.reduce.memory.mb',
'Hrmt',     'mapreduce.reduce.memory.totalbytes',
'Hrmit',    'mapreduce.reduce.merge.inmem.threshold',
'Hrsct',    'mapreduce.reduce.shuffle.connect.timeout',
'Hrsibp',   'mapreduce.reduce.shuffle.input.buffer.percent',
'Hrsmp',    'mapreduce.reduce.shuffle.merge.percent',
'Hrsp',     'mapreduce.reduce.shuffle.parallelcopies',
'Hrsrt',    'mapreduce.reduce.shuffle.read.timeout',
'Hrsm',     'mapreduce.reduce.skip.maxgroups',
'Hrspcai',  'mapreduce.reduce.skip.proc-count.auto-incr',
'Hrs',      'mapreduce.reduce.speculative',
'Htai',     'mapreduce.task.attempt.id',
'Htdl',     'mapreduce.task.debugout.lines',
'Htfpft',   'mapreduce.task.files.preserve.failedtasks',
'Htfpfp',   'mapreduce.task.files.preserve.filepattern',
'Htid',     'mapreduce.task.id',
'Htisf',    'mapreduce.task.io.sort.factor',
'Htism',    'mapreduce.task.io.sort.mb',
'Htim',     'mapreduce.task.ismap',
'Htmpr',    'mapreduce.task.merge.progress.records',
'Htod',     'mapreduce.task.output.dir',
'Htpart',   'mapreduce.task.partition',
'Htprof',   'mapreduce.task.profile',
'Htpm',     'mapreduce.task.profile.maps',
'Htpp',     'mapreduce.task.profile.params',
'Htpr',     'mapreduce.task.profile.reduces',
'Htssa',    'mapreduce.task.skip.start.attempts',
'Htt',      'mapreduce.task.timeout',
'Httd',     'mapreduce.task.tmp.dir',
'Htulk',    'mapreduce.task.userlog.limit.kb',
'Httcls',   'mapreduce.tasktracker.cache.local.size',
'Httct',    'mapreduce.tasktracker.contention.tracking',
'Httdi',    'mapreduce.tasktracker.dns.interface',
'Httdn',    'mapreduce.tasktracker.dns.nameserver',
'Htteb',    'mapreduce.tasktracker.events.batchsize',
'Htthi',    'mapreduce.tasktracker.healthchecker.interval',
'Htthsa',   'mapreduce.tasktracker.healthchecker.script.args',
'Htthsp',   'mapreduce.tasktracker.healthchecker.script.path',
'Htthst',   'mapreduce.tasktracker.healthchecker.script.timeout',
'Htthn',    'mapreduce.tasktracker.host.name',
'Httha',    'mapreduce.tasktracker.http.address',
'Httht',    'mapreduce.tasktracker.http.threads',
'Httim',    'mapreduce.tasktracker.indexcache.mb',
'Htti',     'mapreduce.tasktracker.instrumentation',
'Httldmsk', 'mapreduce.tasktracker.local.dir.minspacekill',
'Httldmss', 'mapreduce.tasktracker.local.dir.minspacestart',
'Httmtm',   'mapreduce.tasktracker.map.tasks.maximum',
'Httnsr',   'mapreduce.tasktracker.net.static.resolutions',
'Httrtm',   'mapreduce.tasktracker.reduce.tasks.maximum',
'Httra',    'mapreduce.tasktracker.report.address',
'Httr',     'mapreduce.tasktracker.resourcecalculatorplugin',
'Httt',     'mapreduce.tasktracker.taskcontroller',
'Htttm',    'mapreduce.tasktracker.taskmemorymanager.monitoringinterval',
'Httts',    'mapreduce.tasktracker.tasks.sleeptimebeforesigkill',
'Hntcnm',   'net.topology.configured.node.mapping',
'Hntnsmi',  'net.topology.node.switch.mapping.impl',
'Hntsfn',   'net.topology.script.file.name',
'Hntsna',   'net.topology.script.number.args',
'Hsjcpa',   'security.job.client.protocol.acl',
'Hsjtpa',   'security.job.task.protocol.acl',
'Hs3nk',    'fs.s3n.awsAccessKeyId',
'Hs3ns',    'fs.s3n.awsSecretAccessKey',
'Hs3ak',    'fs.s3a.awsAccessKeyId',
'Hs3as',    'fs.s3a.awsSecretAccessKey',
'Hfieldsep','stream.map.output.field.separator',
'Hnfields', 'stream.num.map.output.key.fields',
);

our %mr_conf_abbrevs = reverse %mr_generics;

our %compression_abbrevs = (
  "gz", "org.apache.hadoop.io.compress.GzipCodec",
  "lzo", "org.apache.hadoop.io.compress.DefaultCodec",
  "bz", "org.apache.hadoop.io.compress.BZip2Codec",
  "snappy", "org.apache.hadoop.io.compress.SnappyCodec"
);

sub sortconf($) {
  my $spec = $_[0];
  return undef unless substr($spec, 0, 1) eq "g";
  join "", map {my $col = ord($_) - 64; $_ eq "n" ? "n" : $_ eq "-" ? "r" : " -k$col,$col" }
   split //, substr $spec, 1;
}

sub partconf($) {
  my $spec = $_[0];
  return undef unless substr($spec, 0, 1) eq "f";
  "-k" . join ",", map { ord($_) - 64 } split //, substr $spec, 1;
}

sub translate_mr_conf_var($$) {
  my ($k, $v) = @_;
  if ($k eq "Hofcc") {return $compression_abbrevs{$v} || $v;}
  if ($k eq "Hpkco") {return sortconf($v) || $v;}
  if ($k eq "Hpkpo") {return partconf($v) || $v;}
  $v;
}

# These must be first in a hadoop command for... reasons.
our @priority_hadoop_opts = ("stream.num.map.output.key.fields",
                             "stream.map.output.field.separator",
                             "mapreduce.partition.keypartitioner.options",
                             "mapreduce.partition.keycomparator.options"); 
our @priority_hadoop_opt_abbrevs = map {$mr_conf_abbrevs{$_}} @priority_hadoop_opts;

sub priority_jobconf(@) {
  # Apparently some of the Hadoop options must be in order;
  # I have no idea what that order is exactly, but I follow
  # the convention laid out here:
  # https://hadoop.apache.org/docs/r1.2.1/streaming.html#Hadoop+Comparator+Class
  # and here:
  # http://ischoolreview.com/iSR_Grav/entries/entry-2
  # Upshots: you need to use the stream.map.output.num.fields if 
  # you use comparators 
  my %input_jobconf = @_;

  my @high_priority_jobconf = ();

  my @field_based_opts = grep defined, @input_jobconf{'Hpkpo', 'Hpkco'};
  if(@field_based_opts) {
    my $max_field = max map {split /\D+/} @field_based_opts;
    push @high_priority_jobconf, 
      -D => "stream.num.map.output.key.fields=$max_field";
  }

  push @high_priority_jobconf, 
    -D => "mapreduce.job.output.key.comparator.class=" . 
          "org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator"
    if grep {$_ eq 'Hpkco'} keys %input_jobconf;

  push @high_priority_jobconf, 
    map { -D => $mr_generics{$_} . "=" . $input_jobconf{$_}} 
      grep { defined($input_jobconf{$_}) } @priority_hadoop_opt_abbrevs; 

  delete @input_jobconf{@priority_hadoop_opt_abbrevs};
  \@high_priority_jobconf, \%input_jobconf;
}

sub hadoop_generic_options(@) {
  my @jobconf = @_;
  my %jobconf = map {split /=/, $_, 2} @jobconf;
    %jobconf = map {$mr_conf_abbrevs{$_}, $jobconf{$_}} keys %jobconf;

  my %raw = map {$_, dor(conf $_, $jobconf{$_})} keys %mr_generics;
  my %clean_jobconf = map {$_, $raw{$_}} grep {defined $raw{$_}} keys %raw;
  %clean_jobconf    = map {$_, translate_mr_conf_var($_, $clean_jobconf{$_})} keys %clean_jobconf;

  # Every job needs at least a trivial KeyFieldBasedPartitioner
  # to avoid compatibility issues between jobs.
  $clean_jobconf{'Hpkpo'} = "-k1,1" if !exists($clean_jobconf{'Hpkpo'});

  my ($high_priority_jobconf_ref, $low_priority_jobconf_ref) = priority_jobconf(%clean_jobconf);
  %jobconf = %$low_priority_jobconf_ref;
  my @output_jobconf = @$high_priority_jobconf_ref;

  my @low_priority_options = map {$mr_generics{$_} . "=" . $clean_jobconf{$_}} keys %jobconf;
  my @low_priority_jobconf = map((-D => $_), @low_priority_options);

  # -partitioner is actually not a generic option
  # so it must follow the lowest priority generic option.
  push @low_priority_jobconf, 
    -partitioner => "org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner"; 

  push @output_jobconf, @low_priority_jobconf;

  @output_jobconf;
}
283 core/hadoop/hadoop.pl
# Hadoop operator.
# The entry point for running various kinds of Hadoop jobs.

BEGIN {defshort '/H', defdsp 'hadoopalt', 'hadoop job dispatch table'}

defperlprefix "core/hadoop/hadoop-conf.pl";

our %mr_generics;

for (keys %mr_generics) {
  my $var_name = $mr_generics{$_};
  $var_name =~ tr/[a-z]\-./[A-Z]__/;
  my $env_var_name = 'NI_HADOOP_' . $var_name;
  defconfenv $_, $env_var_name => undef;
}

defconfenv 'hadoop/name',          NI_HADOOP               => 'hadoop';
defconfenv 'hadoop/streaming-jar', NI_HADOOP_STREAMING_JAR => undef;
defconfenv 'hadoop/jobconf',       NI_HADOOP_JOBCONF => undef;
defconfenv 'hdfs/tmpdir',          NI_HDFS_TMPDIR => '/tmp';

defmetaoperator hadoop_outpath_set =>
q{
  my ($args, $left, $right) = @_;
  my $hadoop_op = pop @$left;
  my ($path) = @$args;
  my $new_op = configure_op {"hdfs/tmpdir" => $path}, [$hadoop_op];
  ([@$left, $new_op], $right);
};

defshort '/H>', pmap q{hadoop_outpath_set_op $_}, nefilename;

defresource 'hdfs',
  read   => q{soproc {exec conf 'hadoop/name', 'fs', '-cat', $_[1]} @_},
  write  => q{siproc {sh conf('hadoop/name') . " fs -put - " . shell_quote($_[1]) . " 1>&2"} @_},
  exists => q{local $_;
              my $fh = soproc {exec conf 'hadoop/name', 'fs', '-stat', $_[1]} @_;
              saferead $fh, $_, 8192;
              close $fh;
              !$fh->await},
  tmp    => q{"hdfs://" . conf('hdfs/tmpdir') . "/" . uri_temp_noise},
  nuke   => q{sh conf('hadoop/name') . ' fs -rm -r ' . shell_quote($_[1]) . " 1>&2"};

defresource 'hdfst',
  read => q{soproc {my $hadoop_name = conf 'hadoop/name';
                    my $path = shell_quote $_[1];
                    sh qq{$hadoop_name fs -text $path 2>/dev/null || $hadoop_name fs -text $path"/part*" 2>/dev/null}} @_},
  nuke => q{sh conf('hadoop/name') . ' fs -rm -r ' . shell_quote($_[1]) . " 1>&2"};

defresource 'hdfsrm',
  read => q{soproc {my $o = resource_read "hdfst://$_[1]";
                    sforward $o, \*STDOUT;
                    $o->await;
                    resource_nuke "hdfst://$_[1]"} @_},
  nuke => q{resource_nuke "hdfst://$_[1]"};

# Streaming.
# We need to be able to find the Streaming jar, which is slightly nontrivial. The
# hadoop docs suggest that $HADOOP_HOME has something to do with it, but I've
# seen installations that had no such environment variable and everything worked
# fine. Here's what we can do:

# | 1. Use $NI_HADOOP_STREAMING_JAR if it's set
#   2. Use `locate hadoop-streaming*.jar` if we have `locate`
#   3. Use `find /usr /opt -name hadoop-streaming*.jar`, see if it's there

# If those don't work, then we are officially SOL and you'll have to set
# NI_HADOOP_STREAMING_JAR.

sub hadoop_streaming_jar {
  local $SIG{CHLD} = 'DEFAULT';
  conf 'hadoop/streaming-jar'
  || (split /\n/, `locate 'hadoop-streaming*.jar' \\
                   || find /usr -name 'hadoop-streaming*.jar' \\
                   || find /opt -name 'hadoop-streaming*.jar'`)[0]
  || die "ni: cannot find hadoop streaming jar "
       . "(you can fix this by setting \$NI_HADOOP_STREAMING_JAR)";
}

# Input type autodetection.
# Technically, hadoop operators take one or more HFDS input paths on stdin -- but
# of course ni isn't going to just give up if we appear to have something else.
# If we have something that obviously isn't an HDFS path, we upload that stream
# into a temporary HDFS location and run against that.

sub hdfs_input_path {
  local $_;
  my $n;
  die "ni: hdfs_input_path: no data" unless $n = saferead \*STDIN, $_, 8192;
  if (/^\w+:\/\//) {
    $n = saferead \*STDIN, $_, 8192, length while $n;
    s/hdfst:\/\//hdfs:\/\//g;
    (0, map [split /\t/], grep length, split /\n/);
  } else {
    my $hdfs_tmp    = resource_tmp 'hdfs://';
    my $hdfs_writer = resource_write $hdfs_tmp;
    safewrite $hdfs_writer, $_;
    safewrite $hdfs_writer, $_ while saferead \*STDIN, $_, 8192;
    close $hdfs_writer;
    $hdfs_writer->await;
    (1, [$hdfs_tmp]);
  }
}

sub hadoop_lambda_file($$) {
  my ($name, $lambda) = @_;
  my $tmp = resource_tmp('file://') . $name;
  my $w   = resource_write $tmp;
  conf_set monitor => 0;
  safewrite $w, ni_quoted_image 1, @$lambda;
  sforward_quoted resource_read($_), $w for quoted_resources;
  close $w;
  ($tmp, ni_quoted_exec_args);
}

sub hadoop_embedded_cmd($@) {
  "sh -c " . shell_quote("cat " . shell_quote($_[0]) . " - | " . shell_quote(@_[1..$#_]));
}

sub hadoop_cmd_setup(@) {
  my ($map, $combine, $reduce) = @_;
  my ($nuke_inputs, @ipath) = hdfs_input_path;

  my ($mapper, @map_cmd) = hadoop_lambda_file 'mapper', $map;
  my ($combiner, @combine_cmd) = $combine
    ? hadoop_lambda_file 'combiner', $combine : ();
  my ($reducer, @reduce_cmd) = $reduce
    ? hadoop_lambda_file 'reducer', $reduce : ();

  my $streaming_jar = hadoop_streaming_jar;

  $mapper, \@map_cmd, $combiner, \@combine_cmd, 
    $reducer, \@reduce_cmd, $nuke_inputs, \@ipath, $streaming_jar;
}


sub make_hadoop_cmd($$$$$$$$$) {
  my ($mapper, $map_cmd_ref, $combiner, $combine_cmd_ref,
      $reducer, $reduce_cmd_ref, $streaming_jar, $ipaths, $opath) = @_;
  $mapper   =~ s|^file://||;
  $combiner =~ s|^file://|| if $combiner;
  $reducer  =~ s|^file://|| if $reducer;

  my @map_cmd = @$map_cmd_ref;
  my @combine_cmd = @$combine_cmd_ref;
  my @reduce_cmd = @$reduce_cmd_ref;

  (my $mapper_file   = $mapper)         =~ s|.*/||;
  (my $combiner_file = $combiner || '') =~ s|.*/||;
  (my $reducer_file  = $reducer  || '') =~ s|.*/||;

  my @jobconf =
    grep $reducer || !/reduce/,             # HACK
    grep length, split /\s+/, dor conf 'hadoop/jobconf', '';

  my $job_name = "ni @$ipaths -> $opath";
  my $n_addl_paths = $#$ipaths; 
  my $first_path = $$ipaths[0];
  $job_name = "ni $first_path and $n_addl_paths others" .
              " -> $opath" if $n_addl_paths > 0;

  push @jobconf, "mapreduce.job.name=" . $job_name;

  my @ordered_jobconf = hadoop_generic_options(@jobconf);

  my $cmd = shell_quote
    conf 'hadoop/name',
    jar => $streaming_jar,
    -files  => join(",", grep defined, ($mapper, $combiner, $reducer)),
    @ordered_jobconf,
    map((-input => $_), @$ipaths),
    -output => $opath,
    -mapper => hadoop_embedded_cmd($mapper_file, @map_cmd),
    (defined $combiner
      ? (-combiner => hadoop_embedded_cmd($combiner_file, @combine_cmd))
      : ()),
    (defined $reducer
      ? (-reducer => hadoop_embedded_cmd($reducer_file, @reduce_cmd))
      : (-reducer => 'NONE'));
    
  $cmd;
}


defoperator hadoop_streaming => q{
  my ($mapper, $map_cmd_ref, 
      $combiner, $combine_cmd_ref,
      $reducer, $reduce_cmd_ref,
      $nuke_inputs, $ipath_ref,
      $streaming_jar) = hadoop_cmd_setup @_;

  for my $ipaths (@$ipath_ref) {
    my $opath = resource_tmp "hdfs://";
    my $cmd = make_hadoop_cmd($mapper, $map_cmd_ref,
                              $combiner, $combine_cmd_ref,
                              $reducer, $reduce_cmd_ref, 
                              $streaming_jar, $ipaths, $opath);
    die "hadoop command text too long" if length $cmd > 125_000;
    my $hadoop_fh = siproc {
     sh "$cmd 1>&2";
    };

    close $hadoop_fh;
    warn "ni: hadoop streaming failed" if $hadoop_fh->await;

    /^hdfsrm:/ && resource_nuke($_) for @$ipaths;

    (my $result_path = $opath) =~ s/^hdfs:/hdfst:/;
    print "$result_path/part-*\n";
  }

  if ($nuke_inputs) {resource_nuke $_ for map @$_, @$ipath_ref}

  resource_nuke $mapper;
  resource_nuke $combiner if defined $combiner;
  resource_nuke $reducer  if defined $reducer;
};

defoperator hadoop_make_nukeable =>
  q{print sr $_, qr/^hdfst?/, 'hdfsrm' while <STDIN>};

BEGIN {defparseralias hadoop_streaming_lambda => palt pmap(q{undef}, prc '_'),
                                                      pmap(q{[]},    prc ':'),
                                                      _qfn}

defhadoopalt S => pmap q{hadoop_streaming_op @$_[1..$#$_]},
                  pseq popt pempty,
                       pc hadoop_streaming_lambda,
                       pc hadoop_streaming_lambda,
                       pc hadoop_streaming_lambda;

defhadoopalt '#' => pmap q{hadoop_make_nukeable_op}, pnone;

defhadoopalt DS => pmap q{my (undef, $m, $c, $r) = @$_;
                          my @cr =
                            (defined $c ? (row_sort_op(sort_args [0]), @$c) : (),
                             defined $r ? (row_sort_op(sort_args [0]), @$r) : ());
                          [@$m, @cr]},
                   pseq popt pempty,
                        pc hadoop_streaming_lambda,
                        pc hadoop_streaming_lambda,
                        pc hadoop_streaming_lambda;

defhadoopalt R =>
  pmap q{configure_op {'Hjr' => "$_"},
                      [hadoop_streaming_op [], undef, []]},
  pc number;

# HRR == HR, but really randomize across reducers
defhadoopalt RR =>
  pmap q{configure_op {'Hjr' => "$_"},
                      [hadoop_streaming_op
                        [perl_mapper_op 'print "$.\t$_\n";()'],
                        undef,
                        [cols_op 2, 1, -1]]},
  pc number;

#Hadoop quick configuration.
#This will be useful for spinning up more customizable jobs once I
#figure out exactly how configure_op works.

defoperator hadoop_test => q{
  my ($mapper, $map_cmd_ref, 
      $combiner, $combine_cmd_ref,
      $reducer, $reduce_cmd_ref,
      $nuke_inputs, $ipath_ref,
      $streaming_jar) = hadoop_cmd_setup @_;

  for my $ipaths (@$ipath_ref) {
    my $opath = resource_tmp "hdfs://";
    my $cmd = make_hadoop_cmd($mapper, $map_cmd_ref, 
                              $combiner, $combine_cmd_ref,
                              $reducer, $reduce_cmd_ref,
                              $streaming_jar, $ipaths, $opath);
    print "$cmd\n";
  }
};

defhadoopalt T => pmap q{hadoop_test_op @$_},
                  pseq pc hadoop_streaming_lambda,
                       pc hadoop_streaming_lambda,
                       pc hadoop_streaming_lambda;

137 core/hadoop/hdfsjoin.pl
# Hadoop Map (and Reduce!) Side Joins
# This is a port of the old logic from nfu with
# some nice improvements. hdfsj takes a stream and a folder,
# and using the hadoop context clues, identifies the file
# in that folder that should match the stream.
# Joins can be done on both the map _and_ on the reduce side, and
# they're blazing fast; they should be used liberally.

sub hadoop_partfile_n { $_[0] =~ /[^0-9]([0-9]+)(?:\.[^\/]+)?$/ ? $1 : 0 }
sub hadoop_partsort {
  sort {hadoop_partfile_n($a) <=> hadoop_partfile_n($b)} @_
}
sub hadoop_ls {
  # Now get the output file listing. This is a huge mess because Hadoop is a
  # huge mess.
  local $SIG{CHLD} = "DEFAULT";
  my $ls_command = shell_quote conf 'hadoop/name', 'fs', '-ls', @_;
  grep /\/[^_][^\/]*$/, map +(split " ", $_, 8)[7],
                        grep !/^Found/,
                        split /\n/, ''.qx/$ls_command/;
}

defresource 'hdfsj',
  read => q{soproc {my $hadoop_name = conf 'hadoop/name';
                    my $total_left_files;
                    my $left_file_number;
                    my $left_path;
                    if(exists $ENV{mapreduce_map_input_file}) {
                      $left_path = $ENV{mapreduce_map_input_file};
                      my $left_folder = join "/", (split /\//, $left_path)[0..-1];
                      my @left_folder_files = hadoop_partsort hadoop_ls $left_folder;
                      $left_file_number = hadoop_partfile_n $left_path; 
                      $total_left_files = @left_folder_files;
                    } else {
                      $left_path = $ENV{mapreduce_task_id};
                      my @left_task_id_parts = split /_/, $left_path;
                      die "not on the reduce side" unless $left_task_id_parts[-2] eq "r";
                      $left_file_number = $left_task_id_parts[-1];
                      $total_left_files = $ENV{mapreduce_job_reduces};
                    }
                    my $right_folder = $_[1];
                    my @right_folder_files = hadoop_partsort hadoop_ls $right_folder;
                    my $right_file_idx = $left_file_number % @right_folder_files; 
                    die "# of left files must be evenly divisible by # of right files" if $total_left_files % @right_folder_files;
                    my $right_file = shell_quote $right_folder_files[$right_file_idx];
                    sh qq{$hadoop_name fs -text $right_file 2>/dev/null }} @_};

defresource 'hdfsjname',
  read => q{soproc {my $hadoop_name = conf 'hadoop/name';
                    my $total_left_files;
                    my $left_file_number;
                    my $left_path;
                    if(exists $ENV{mapreduce_map_input_file}) {
                      $left_path = $ENV{mapreduce_map_input_file};
                      my $left_folder = join "/", (split /\//, $left_path)[0..-1];
                      my @left_folder_files = hadoop_partsort hadoop_ls $left_folder;
                      $left_file_number = hadoop_partfile_n $left_path; 
                      $total_left_files = @left_folder_files;
                    } else {
                      $left_path = $ENV{mapreduce_task_id};
                      my @left_task_id_parts = split /_/, $left_path;
                      die "not on the reduce side" unless $left_task_id_parts[-2] eq "r";
                      $left_file_number = $left_task_id_parts[-1];
                      $total_left_files = $ENV{mapreduce_job_reduces};
                    }
                    my $right_folder = $_[1];
                    my @right_folder_files = hadoop_partsort hadoop_ls $right_folder;
                    my $right_file_idx = $left_file_number % @right_folder_files; 
                    die "# of left files must be evenly divisible by # of right files" if $total_left_files % @right_folder_files;
                    my $right_file = shell_quote $right_folder_files[$right_file_idx];
                    print "$left_path\t$right_file\n";} @_}; 


# Map-side partfile concatenation
# Hadoop 2.x has an upper limit of 100,000 partfiles per map/reduce,
# and sometimes (map-only) jobs will have a large number of files
# where each file only contains a small amount of data. Running
# a job on such a file suffers from high overhead for container
# startup/shutdown and instability from map to reduce because of the
# high number of networked connections required to transmit data
# from one side ot the other. To get around the first restriction
# and improve performance, hdfsc takes a maximum
# number of partfiles to process per mapper, and uses
# hadoop fs -text <path> to run on all of the partfiles that 
# have 
# Usage:
# ni ihdfst://path/.../part-00*.path \
#   HS[zn hdfsc://100 mapper] [combiner] [reducer]
# 
# Caveats:
# - zn is necessary to consume the input stream, which will be
#     re-created using hdfsc; this leads to a small amount of overhead.
# - the number of leading zeroes in the input path must match
#     the number of zeroes in the hdfsc://<number> path

sub generate_compact_filename($$) {
  my ($filename, $shift_amount) = @_;  
  my ($prefix, $partfile_index, $suffix) = ($filename =~ /^(part[^\d]+)(\d+)(.*)/);
  my $compact_partfile_index =  substr($partfile_index, $shift_amount); 
  return "$prefix*$compact_partfile_index$suffix";
}

our %FILES_PER_MAPPER_TO_SHIFT= (10 => 1, 100 => 2, 1_000 => 3, 10_000 => 4, 100_000 => 5);
sub generate_compact_tail($$) {
  my ($map_filename, $max_files_per_mapper) = @_;
  my $shift_amount = $FILES_PER_MAPPER_TO_SHIFT{$max_files_per_mapper};
  die "# of files must be a power of 10 between 10 and 10**5, inclusive" unless $shift_amount;
  my $compact_filename = generate_compact_filename $map_filename, $shift_amount;
  return $compact_filename;
}

sub generate_compact_path($$) {
  my ($map_path, $max_files_per_mapper) = @_;
  my @map_path_parts = split /\//, $map_path;
  my $map_folder = join "/", @map_path_parts[0..$#map_path_parts-1];
  my $map_filename  = (split /\//, $map_path)[-1];
  my $compact_tail = generate_compact_tail($map_filename, $max_files_per_mapper);
  my $compact_path = shell_quote join "/", $map_folder, $compact_tail;
  return $compact_path;
}


defresource 'hdfsc',
  read => q{soproc {my $compact_factor = $_[1];
                    die "map side compact only" unless my $map_path = $ENV{mapreduce_map_input_file};
                    my $compact_path = generate_compact_path($map_path, $compact_factor);
                    my $hadoop_name = conf 'hadoop/name';
                    sh qq{$hadoop_name fs -text $compact_path 2>/dev/null }} @_};
 
defresource 'hdfscname',
  read => q{soproc {my $compact_factor = $_[1];
                    die "map side compact only" unless my $map_path = $ENV{mapreduce_map_input_file};
                    my $compact_path = generate_compact_path($map_path, $compact_factor);
                    my $hadoop_name = conf 'hadoop/name';
                    my $files_per_mapper = scalar hadoop_ls shell_unquote $compact_path;
                    print "$map_path\t$compact_path\t$files_per_mapper\n"; } @_};

2 core/pyspark/lib
pyspark.pl
local.pl
54 core/pyspark/pyspark.pl
# Pyspark interop.
# We need to define a context for CLI arguments so we can convert ni pipelines
# into pyspark code. This ends up being fairly straightforward because Spark
# provides so many high-level operators.

# There are two things going on here. First, we define the codegen for Spark
# jobs; this is fairly configuration-independent since the API is stable. Second,
# we define a configuration system that lets the user specify the Spark execution
# profile. This governs everything from `spark-submit` CLI options to
# SparkContext init.

# Pyspark operators.
# These exist in their own parsing context. Rather than compiling directly to
# Python code, we generate a series of gens, each of which refers to a '%v'
# quantity that signifies the value being transformed.

sub pyspark_compile {my $v = shift; $v = $_->(v => $v) for @_; $v}
sub pyspark_create_lambda($) {$_[0]}

BEGIN {defcontext 'pyspark', q{PySpark compilation context}}
BEGIN {
  defparseralias pyspark_fn  => pmap q{pyspark_create_lambda $_}, pycode;
  defparseralias pyspark_rdd => pmap q{pyspark_compile 'input', @$_}, pyspark_qfn;
}

defshort 'pyspark/n',  pmap q{gen "%v.union(sc.parallelize(range(1, 1+$_)))"}, integer;
defshort 'pyspark/n0', pmap q{gen "%v.union(sc.parallelize(range($_)))"}, integer;

defshort 'pyspark/e',
  pmap q{TODO(); gen "%v.pipe(" . pyquote($_) . ")"}, prx '([^]]+)';

defshort 'pyspark/m', pmap q{gen "%v.map(lambda x: $_)"}, pyspark_fn;
defshort 'pyspark/r',
  defalt 'pysparkrowalt', 'alternatives for pyspark/r row operator',
    pmap(q{gen "%v.sample(False, $_)"},     integer),
    pmap(q{gen "%v.takeSample(False, $_)"}, prx '\.(\d+)'),
    pmap(q{gen "%v.filter($_)"},            pyspark_fn);

defshort 'pyspark/g', pk gen "%v.sortByKey()";
defshort 'pyspark/u', pk gen "%v.distinct()";

defshort 'pyspark/+', pmap q{gen "%v.union($_)"},     pyspark_rdd;
defshort 'pyspark/*', pmap q{gen "%v.intersect($_)"}, pyspark_rdd;

# Configuration management.
# A profile contains the code required to initialize the SparkContext and any
# other variables relevant to the process. Each is referenced by a single
# character and stored in the %spark_profiles table.

defoperator pyspark_preview => q{sio; print "$_[0]\n"};

defshort '/P',
  defdsp 'sparkprofile', 'dispatch for pyspark profiles',
    'dev/compile' => pmap q{pyspark_preview_op $_}, pyspark_rdd;
36 core/pyspark/local.pl
# Local PySpark profile.
# Provides a way to stream data into and out of a context.

use constant pyspark_text_io_gen => gen pydent q{
  from pyspark import SparkConf, SparkContext
  %prefix
  conf = SparkConf().setAppName(%name).setMaster(%master)
  sc = SparkContext(conf=conf)
  if len(%input_path) > 0:
    input = sc.textFile(%input_path)
  else:
    input = sc.parallelize([])
  output = %body
  output.saveAsTextFile(%output_path)
};

defoperator pyspark_local_text => q{
  my ($fn) = @_;
  my $inpath   = join ',', map sr("file://$_", qr/\n$/, ''), <STDIN>;
  my $outpath  = "/tmp/ni-$$-out";
  my $tempfile = "/tmp/ni-$$-temp.py";
  safewrite swfile($tempfile),
    pyspark_text_io_gen->(
      master      => pyquote 'local[*]',
      name        => pyquote "ni $inpath -> $outpath",
      input_path  => pyquote $inpath,
      output_path => pyquote "file://$outpath",
      body        => $fn);
  local $SIG{CHLD} = 'DEFAULT';
  die "ni: pyspark failed with $_" if $_ = system 'spark-submit', $tempfile;
  print "$outpath\n";
};

defsparkprofile L => pmap q{[pyspark_local_text_op($_),
                             file_read_op,
                             row_match_op '/part-']}, pyspark_rdd;
38 doc/lib
ni_by_example_1.md
ni_by_example_2.md
ni_by_example_3.md
ni_by_example_4.md
ni_by_example_5.md
ni_by_example_6.md
ni_fu.md
cheatsheet_op.md
cheatsheet_perl.md
binary.md
closure.md
col.md
container.md
examples.md
extend.md
fn.md
geohash.md
git.md
hadoop.md
json.md
libraries.md
lisp.md
matrix.md
monitor.md
net.md
options.md
perl.md
pyspark.md
row.md
ruby.md
scale.md
script.md
sql.md
stream.md
tutorial.md
visual.md
warnings.md
wkt.md
869 doc/ni_by_example_1.md
# `ni` by Example, Chapter 1 (beta release)

Welcome! This is a "rich" tutorial that covers all of the basics of this cantankerous, odd, and ultimately, incredibly fast, joyful, and productive tool called `ni`. We have tried to assume as little knowledge as possible in this tutorial, but if you find anything confusing, please contact [the developers](http://github.com/spencertipping) or [the author](http://github.com/michaelbilow).

`ni` and Perl both suffer from their sharp differences from . This tutorial is structured in 6 parts:

1. Intro to `ni`
2. Perl for `ni`
3. The real power of `ni`
4. `ni` and Ruby, Perl, Python, Lisp & Bash
5. `ni` odds and ends
6. `ni` + Jupyter (TODO)


## What is `ni`?

`ni` is write-anywhere, run-everywhere

`ni` is a self-modifying quine.

`ni` is everything-from-the-command-line.

`ni` is concise.

`ni` is beautiful.

`ni` is two-fisted data science.


## Installation
`ni` works on any Unix-based OS. You should use a bash prompt when calling `ni`.

```
git clone git@github.com:spencertipping/ni.git
cd ni
ln -s $PWD/ni ~/bin/ni  # or whatever to add it to your path
```


## Basic Stream Operators

`ni` is a stream-processing language. Most operations in `ni` are done over a single line, which enables `ni` to be fast and memory-efficient. 

### `n`: Integer Stream
`ni n` generates a stream of consecutive integers starting at 1. The number after determines how many numbers will be generated.

```bash
$ ni n5
1
2
3
4
5
```

In general, `ni` will drop you into a `less` pager after a command finishes. You can change the default pager by setting the `NI_PAGER` environment variable.

`ni n0` gives you consecutive integers starting from zero. For example:

```bash
$ ni n03
0
1
2
```

To generate a large  number of integers, you can use scientific notation with `n`. `ni n3.2E5` will give you 320,000 consecutive integers, starting from 1.


### `i`: Literal text 
The `i` operator puts literal text into the stream:

```bash
$ ni ihello
hello
```

You can use quotes with `i` to include spaces within strings.

```bash
$ ni i"hello there"
hello there
```

`ni` is optimized to work with tab-delimited text. If you want your text to be tab-delimited, put your text inside square brackets.

```bash
$ ni i[hello there new friend]
hello	there	new	friend
```

### `e'...'`: Evaluate `bash` script

`ni` is deeply connected to bash, so easy access is provided to running bash commands from within `ni`.  

```bash
$ ni n500 e'grep 22'
22
122
220
221
222
223
224
225
226
227
228
229
322
422
```


### Structure of `ni` commands

`ni` commands are composed of operators. Examples introduced in the last section include `n`, which generates a stream of integers; `e`, which executes a bash command, and `i`, which puts literal text to the stream. `z`, which compresses a stream. Later, we'll introduce more complex operators like `HS`, whichexecutes a Hadoop Streaming MapReduce job. 

In the last section, you saw a `ni` command linking two operators; `n500` was used to generate a stream of integers from 1 to 500, and the `e'grep 22'` was used to take the lines that had a `22` in them. If you're not used to working with streams, there's a slightly subtle point to notice.

In general commands are written `ni <op_1> <op_2> ... <op_n>`. It is often helpful to think of each command by piping the output of one command to the input of the next `ni <op_1> | ni <op_2> | ... | ni <op_n>`.

More compressed syntax is favored, and very short commands are often compressed without spaces in between. A common example is sort (`g`) + unique (`u`); this is commonly written as `gu` in rather than the more explicit `g u`. Because `ni` commands are highly compressed and difficult to be read by people who are uninitiated, they are sometimes referred to as "spells."

## Streaming I/O

`ni` provides very flexible file input and output. In particular, compressing streams in `ni` is very simple, and decompression is done by default.


### `>`: `bash`-style file output

`ni` is a streaming tool, so you can redirect output using the standard redirect.

```sh
$ ni n5 > five.txt
```

While this works fine, it is in general not used, in favor of the literal angle-bracket operator `\>` described in the next section.


### File Input

To add a file to the stream in `ni`, add the name of the file to the stream.

```sh
$ ni five.txt
1
2
3
4
5
```


### `\>`: Output and Emit File Name


```bash
$ ni n5 \>five.txt
five.txt
```

Note that there is **no space** between `\>` and `ten.txt`. Because `ni` is concise, whitespace is frequently important.

### `\<` Read from Filenames

The reason that `\>` is favored over `>` is because `\<` inverts it by reading the data from filenames.

```bash
$ ni n5 \>five.txt \<
1
2
3
4
5
```

It's important to understand how this short spell works; first, a stream of 5 integers is generated; those integers sink to a file called `five.txt`, and the text string `five.txt` is put out to the stream. Finally, `\<` instructs `ni` to open the file named `five.txt` and put its contents on the stream.

### Directory I/O
The contents of this section 

Start by making some data:

```sh
$ rm -rf dir_test && mkdir dir_test
$ echo "hello" > dir_test/file1
$ echo "you" > dir_test/file2
$ echo "genius" > dir_test/file3
```

We can look at the contents of the directory with `ni`:

```sh
$ ni dir_test
dir_test/file1
dir_test/file2
```

`ni` has converted the folder into a stream of the names of files (and directories) inside it. You can thus access the files inside a directory using `\<`.

```sh
$ ni dir_test \<
hello
you
genius
```

`ni` will use bash expansion as well:

```sh
$ ni dir_test/*
hello
you
genius
```


```sh
$ ni dir_test/file{1,3}
hello
genius
```


### `z`: Compression

`ni` provides compression in a highly keystroke-efficient way, using the `z` operator.

```bash
$ ni n10 z \>ten.gz
ten.gz
```

`ni` decompresses its input by default. 

```sh
cat ten.gz
2SY322222224
```

```sh
$ cat ten.gz | ni
1
2
3
4
5
6
7
8
9
10
```


```bash
$ ni n10 z \>ten.gz \<
1
2
3
4
5
6
7
8
9
10
```

The default compression with `z` is `gzip`, however there are options for bzip (`zb`), xzip (`zx`), lzo (`zo`), and lz4 (`z4`). You can also specify a numeric flag to gzip by using a number other than `4`, for example `z9` executes `gzip -9` on the stream.


## Basic Row and Column Operations

`ni` works especially well on data formatted as tab-delimited rows of text; in this section we'll show how to filter, trim, and convert raw text into tab-delimited form.

### `r`: Take rows

`r` is a powerful and flexible operation for filtering rows; it encompasses the functionality of Unix operators `head` and `tail`, as well as a large number of filtering operations.

#### Numeric Options

`rN` takes the first N rows.

```bash
$ ni n10 r3
1
2
3
```

`r-N` drops the first N rows.
```bash
$ ni n10 r-3
4
5
6
7
8
9
10
```

`r~N` and `r+N` take the last N rows.

```bash
$ ni n10 r~3
8
9
10
```

```bash
$ ni n10 r+3
8
9
10
```

The `rxN` option takes the first of every `N` rows.

```bash
$ ni n10 rx3
1
4
7
10
```

Adding a number between 0 and 1 will lead to `ni` selecting a (deterministic) pseudo-random sample of the stream data.

```bash
$ ni n20 r.15
1
9
11
12
14
15
```

These last examples show the value of `r` in development; for example, if you are working with a large file or stream, you can check the correctness of your output using `r10`, `rx100`, `r.001` etc. to view smaller samples of large datasets.


### `F`: Split stream into columns

Like `r`, `F` also has many options. The most important is `F/regex/`, which splits text into columns based on a regular expression.

```bash
$ ni ibubbles ibaubles ibarbaras F/[aeiou]+/
b	bbl	s
b	bl	s
b	rb	r	s
```

The rest of the operations are syntactic sugar, but they're worth knowing.


`FD` splits on forward slashes:

```bash
$ ni i~/bin/dependency/nightmare.jar FD
~	bin	dependency	nightmare.jar
```

`FS` splits on runs of whitespace:

```bash
$ ni i"here               is   an              example" FS
here	is	an	example
```

`FC` splits on commas, but doesn't handle CSV:

```bash
$ ni ibread,eggs,milk i'fruit gushers,index cards' FC
bread	eggs	milk
fruit gushers	index cards
```

`FV` splits CSV fields correctly (i.e. it doesn't split commas in quoted strings). However, `ni` splits lines of input on newline characters, so this can't handle newlines in quoted fields.

```bash
$ ni i'"hello,there",one,two,three' FV
hello,there	one	two	three
```

`FW` splits on non-word characters (i.e. equivalent to splitting on the regex  `/\W+/`)

```bash
$ ni i'this@#$$gets&(*&^split' FW
this	gets	split
```

`FP` splits on pipe characters:

```bash
$ ni i'need|quotes|around|pipes|because|of|bash' FP
need	quotes	around	pipes	because	of	bash
```

`F:<char>` splits data on a particular character:

```bash
$ ni ibubbles ibaubles ibarbaras F:a
bubbles
b	ubles
b	rb	r	s
```


### `f`: Column Selection

Let's start by generating some text and converting it to columns using `F`.

```bash
$ ni i"this is how we do it" i"it's friday night" i"and I feel all right" FS
this	is	how	we	do	it
it's	friday	night
and	I	feel	all	right
```

In `ni`, tab-delimited columns of data are referenced like a spreadsheet: the first column is `A`, the second is `B`, etc.
The `f` operator gives you access to the columns of your data. 

```bash
$ ni i"this is how we do it" i"it's friday night" \
     i"and I feel all right" FS fC
how
night
feel
```

You can select multiple columns by providing multiple letters:

```bash
$ ni i"this is how we do it" i"it's friday night" \
     i"and I feel all right" FS fAB
this	is
it's	friday
and	I
```

You can duplicate a column by using its corresponding letter multiple times:

```bash
$ ni i"this is how we do it" i"it's friday night" \
     i"and I feel all right" FS fAAC
this	this	how
it's	it's	night
and	and	feel
```

To select all columns after a particular column, use `f<col>.`

```bash
$ ni i"this is how we do it" i"it's friday night" \
     i"and I feel all right" FS fAD.
this	we	do	it
it's	
and	all	right
```

To select all data between two columns, inclusive, use a dash:
```bash
$ ni i"this is how we do it" i"it's friday night" \
     i"and I feel all right" FS fB-E
is	how	we	do
friday	night
I	feel	all	right
```

You can also use `f` to re-order selected columns:

```bash
$ ni i"this is how we do it" i"it's friday night" \
     i"and I feel all right" FS fCBAD
how	is	this	we
night	friday	it's	
feel	I	and	all
```

Columns can also be accessed by using `#<number>`. The same options are available by subsitituting `A => #0`, `B => #1`, `C => #2`, ... `Z => #25`. This syntax also allows you to access columns 26 and beyond.

```bash
$ ni i"this is how we do it" i"it's friday night" \
     i"and I feel all right" FS f#2#1#0#3
how	is	this	we
night	friday	it's	
feel	I	and	all
```

It is also possible to increase readability by inserting commas between specified columns.

```bash
$ ni i"this is how we do it" i"it's friday night" \
     i"and I feel all right" FS fA,#3.
this	we	do	it
it's	
and	all	right
```


Under the hood, `ni` is using either `cut` or Perl to rearrange the columns. `cut` is much faster of the two, but it's only used when the output columns are in the same relative order as the input columns.


### `x`: Exchange columns

`x` is a shorthand for certain column exchange operations. All of these operations can be written with `f`, usually with a higher number of keystrokes.

```bash
$ ni i"Ain't nobody dope as me" \
     i"I'm dressed so fresh, so clean" \
     i"So fresh and so clean, clean" FS
Ain't	nobody	dope	as	me
I'm	dressed	so	fresh,	so	clean
So	fresh	and	so	clean,	clean
```

`x` exchanges the first two columns (same as `fBA.`)

```bash
$ ni i"Ain't nobody dope as me" \
     i"I'm dressed so fresh, so clean" \
     i"So fresh and so clean, clean" FS x
nobody	Ain't	dope	as	me
dressed	I'm	so	fresh,	so	clean
fresh	So	and	so	clean,	clean
```

`x` with a single column exchanges that column with column 1.

```bash
$ ni i"Ain't nobody dope as me" \
     i"I'm dressed so fresh, so clean" \
     i"So fresh and so clean, clean" FS xD
as	nobody	dope	Ain't	me
fresh,	dressed	so	I'm	so	clean
so	fresh	and	So	clean,	clean
```

`x` with mulitple columns exchanges those into the first columns, in order.

```bash
$ ni i"Ain't nobody dope as me" \
     i"I'm dressed so fresh, so clean" \
     i"So fresh and so clean, clean" FS xEB
me	nobody	dope	as	Ain't
so	dressed	so	fresh,	I'm	clean
clean,	fresh	and	so	So	clean
```



## Sort, Unique & Count


### `g`: General sorting
With a single column of data, as in the example, the simple command `g` will give you lexicographic sorting in ascending order. 

```bash
$ ni ib ia ic g
a
b
c
```

To do more complicated sorts, you can give `g` columns (`A-Z`) and modifiers. For example, `-` after a column reverses the sort.

```bash
$ ni ib ia ic gA-
c
b
a
```

`n` after a column does a numeric sort.

```bash
$ ni i10 i5 i0.3 gAn
0.3
5
10
```

You can sort multiple columns in order:


```bash
$ ni i[b 6] i[b 3] i[a 2] i[a 1] i[c 4] i[c 5] i[a 0] gABn
a	0
a	1
a	2
b	3
b	6
c	4
c	5
``` 

The columns can be sorted in any order:

```bash
$ ni i[b 0] i[b 4] i[a 2] i[a 1] i[c 4] i[c 0] i[a 0] gBnA
a	0
b	0
c	0
a	1
a	2
b	4
c	4
```

  
### `o` and `O`: Syntactic Sugar for Numeric Sorting
Often you will want numeric sorting in a more keystroke-efficient way than `gn<column>-`. The `o` (sort rows ascending, numerically) and `O` (sort rows  descending, numerically) operator has been provided for this purpose.

```bash
$ ni i[b 6] i[b 3] i[a 2] i[a 1] i[c 4] i[c 5] i[a 0] oB
a	0
a	1
a	2
b	3
c	4
c	5
b	6
```

```bash
$ ni i[b 6] i[b 3] i[a 2] i[a 1] i[c 4] i[c 5] i[a 0] OB
b	6
c	5
c	4
b	3
a	2
a	1
a	0
```


### `u`: Unique Sorted Rows
`u` is `ni` syntax for `uniq`, which takes sorted rows and returns the unique values.

```bash
$ ni i[b 6] i[b 3] i[a 2] i[a 1] i[c 4] i[c 5] i[a 0] fAgu
a
b
c
```
  
### `c`: Count Sorted Rows
`c` is `ni`'s version of `uniq -c`, which counts the number of identical  consecutive rows in a stream. The main difference is that `ni`'s `c` tab-delimits the output, while `uniq -c` space-delimits.

```bash
$ ni i[b 6] i[b 3] i[a 2] i[a 1] i[c 4] i[c 5] i[a 0] fAgc
3	a
2	b
2	c
```

### `gg`: Grouped sort

Sorts *cannot be chained together using g*. If you write a command like `$ ni ... gA gBn`, there is no guarantee that the output will have a sorted first column after the second sort. If you want to sort by the first column ascending lexicographically and the second column ascending numerically in the same sort, you should use a more explicit `g` operator: `$ni ... gABn`.

If you have data that is already partially sorted, for example, when working with the input of the reduce step of a MapReduce job, you may want to perform an additional sort of the already partially-sorted data without sorting the entire stream. 

Let's simulate this by sorting one column of the data and sinking the result to a tempfile.


```bash
$ ni i[b ba bar] i[b bi bif] i[b ba baz] \
     i[q qa qat] i[q qu quux] i[b ba bake] \
     i[u ub uber] gA \>tmp \<
b	ba	bake
b	ba	bar
b	ba	baz
b	bi	bif
q	qa	qat
q	qu	quux
u	ub	uber
```

If we want the data sorted as if we had done `gAB-`, we cannot simply do `gB-` to the data we have; this will blow away the sort on the first column.

```bash
$ ni i[b ba bar] i[b bi bif] i[b ba baz] \
     i[q qa qat] i[q qu quux] i[b ba bake] \
     i[u ub uber] gA \>tmp \< gB-
u	ub	uber
q	qu	quux
q	qa	qat
b	bi	bif
b	ba	bake
b	ba	bar
b	ba	baz
```

Instead we used the grouped sort `ggAB-`. 

```bash
$ ni i[b ba bar] i[b bi bif] i[b ba baz] \
     i[q qa qat] i[q qu quux] i[b ba bake] \
     i[u ub uber] gA \>tmp \< ggAB-
b	bi	bif
b	ba	bake
b	ba	bar
b	ba	baz
q	qu	quux
q	qa	qat
u	ub	uber
``` 

The first column indicates the key column (i.e. the sorted column we want to hold constant); the anything after the first column is treated like the arguments to the sorting operator, `g`.

### Sorting strategies


Sorting large amounts of data requires buffering to disk. Be careful about how much data you sort; large sorts are a source of headaches and slow performance. 

`$ ni nE7 F// fB gc \>first_numeral_counts.txt`

Running this command you may see see the `ni` [monitor](monitor.md) for the first time, which showing the steps of the computation, and what steps are taking time.  The whole process takes about 2 minutes on my computer.

General sorting is not yet yet a point of strength for `ni`. If your data is larger than a gigabyte uncompressed, you may want to take advantage of massively distributing the workload through Hadoop operations.

## Join and Filter Operators

`ni` has 2 join operators, `j` and `J`. `j` is an inner join simplified functionality similar to the unix `join` command. Like the unix `join`, `j` only works properly when both streams are sorted.

`J` is a left join. it does not impose any requirements on sorting, but requires that the right side of the join fit into memory, and only allows a single value for each key on the right side of the join.

Joining and filtering have a lot in common, since they both require a key. Later in this section, some more uses of `r` to filter datasets are demonstrated.

### `j`: Streaming Inner Join 

You can use the `j` operator to inner-join two streams.
 
```bash
$ ni i[foo bar] i[foo car] i[foo dar] i[that no] i[this yes] j[ i[foo mine] i[not here] i[this OK] i[this yipes] ]
foo	bar	mine
foo	car	mine
foo	dar	mine
this	yes	OK
this	yes	yipes
```

Without any options, `j` will join on the first tab-delimited column of both streams, however, `j` can join on multiple columns by referencing the columns by letter:

```bash
$ ni i[M N foo] i[M N bar] i[M O qux] i[X Y cat] i[X Z dog] \
  jAB[ i[M N hi] i[X Y bye] ]
M	N	foo	hi
M	N	bar	hi
X	Y	cat	bye
```


In general, the streams you are joining should be pre-sorted (though `j` will not fail if the streams aren't sorted).

The join here is slightly *asymmetric*; the left side of the join is streamed, while the right side is buffered into memory. This is useful to keep in mind for joins in a Hadoop Streaming context; the **left** side of the join should be larger (i.e. have more records) than the right side.

### `J`: In-memory (limited) left join


```bash
$ ni i[foo bar] i[foo car] i[that no] i[this yes] i[foo dar] \
     J[ i[this yipes] i[this OK] i[foo mine] i[not here] ]
foo	bar	mine
foo	car	mine
that	no	
this	yes	OK
foo	dar	mine
```

There are a number of things to notice here. First, we can reiterate that neither the right nor the left side of the join need to be sorted. Second, notice that this is a left join--the row `i[that no]` passes through even though there is no associated key on the right. On the right side of the join, notice that the value associated with the **last** element with the same key is used.

### Filtering with `r`

`r` can more generally be thought of as "take rows where the predicate that follows evaluates to true." 


#### `r<col>` Null filtering

Because an empty column is falsey (it evaluates to false), we can filter it using `r`. 

```bash
$ ni i[one_column] i[two columns] i[three columns here] rB
two	columns
three	columns	here
```

#### `ri<col>`: Set Filtering 

A very common motif in `ni` (especially in the MapReduce context) is to filter a large dataset down to a much smaller one with a certain set of keys or values. You can also filter a column based on another dataset using `ri` and the index of the column to filter.

```bash
$ ni i[one_column] i[two columns] i[three columns here] \
     riA[ione_column ithree]
one_column
three	columns	here
```

#### `r/regex/`: regex filtering

In this context, `r` can take a regex as an option: `$ ni <data> r/<regex>/` takes all rows where the regex has a match. We can rewrite our example for `e` `$ ni n500 e'grep 22'` as:

```bash
$ ni n500 r/22/
22
122
220
221
222
223
224
225
226
227
228
229
322
422
```

To use escaped characters in a regex, it's often more efficient to wrap in quotes:

```bash
$ ni n1000 r-500 r'/^(\d)\1+$/'
555
666
777
888
999
```

To write this same command without quotes requires a lot of escaping: `$ ni n1000 r-500 r/^\(\\d\)\\1+$/`


## `ni` Coding and Debugging

The simplest way to build up a `ni` spell is by writing one step of the spell, checking that step's output for correctness, then writing another step.

In general, `ni` spells will start producing output very quickly (or can be coerced to produce output quickly). Once the output of one step in the spell looks good, you can move on to the next step.


### `--explain`: Print information on command

As you advance through this tutorial, you'll want a quicker way to understand at a high level what a particular `ni` spell is doing. For this, use `ni --explain ...`. Using the example from the file output section:

```bash
$ ni --explain n10 \>ten.txt \<
["n",1,11]
["file_write","ten.txt"]
["file_read"]
```

Each line represents one step of the pipeline defined by the spell, and the explanation shows how the `ni` parser interprets what's written. The explanations are usually concise, but they can help you make sure your code is doing what it's supposed to.


## Conclusion

### Staying in a command-line environment

`ni` is a bottom-up, ad hoc language; `ni` spells can be developed efficiently from the command line, or from a command line-like environment, like a Jupyter notebook.

### Wrap-Up
Congrats on making it to the end of the first part. Hopefully you're starting to see the power in `ni`'s conciseness. If you haven't gotten a chance to develop or play with `ni` code yet, there will likely be some accompanying exercises for this tutorial in the near future, or you can write some yourself and contribute to the development of this fascinating language.

The next chapter covers all the Perl you need to be productive in `ni`. You need some, but not too much.
1270 doc/ni_by_example_2.md
# `ni` by Example, Chapter 2 (beta release)

Welcome to the second part of the tutorial. At this point, you know a little `ni` syntax, but you might not be able to do anything useful. In this chapter, our goal is to multiply your power to operate on a single machine by covering all of the Perl syntax you need to work effectively with `ni`.

## Perl for `ni`

This section written for an audience that has never worked with Perl before, and from a user's (rather than a developer's) perspective. To that end, you are encouraged to focus on using Perl's core functions rather than writing your own. For example, we'll cover the somewhat obscure operation of bit shifting but avoid discussing how to write a Perl subroutine, which (while easy) is unnecessary for most workflows.


## Perl Syntax

Perl has a lot of rules that allow for code to be hacked together quickly and easily; there's no way around learning them (as there is in nice-feeling languages), so let's strap in and get this over with.

From the Perl Syntax [docs](https://perldoc.perl.org/perlsyn.html):

> Many of Perl's syntactic elements are optional. Rather than requiring you to put parentheses around every function call and declare every variable, you can often leave such explicit elements off and Perl will figure out what you meant. This is known as **Do What I Mean**, abbreviated **DWIM**. It allows programmers to be lazy and to code in a style with which they are comfortable.


### Sigils

If you've seen a little bit of Perl, one of the most intimidating parts of getting started is its use of odd characters (like `$`, `@`, and `%`) to start variable names. These characters are referred to as sigils and are used by the Perl interpreter to increase the language's concision.


```sh
$x = 5;
@x = 1..10;
%x = (foo => 1, bar => 2);
```

Coming from a Python/Ruby/C/Java/Lisp background, this probably feels wrong. That this code works, and that all of the variables defined within would properly be referred to (at least, in brief) as `x`, can trigger a great deal of cognitive dissonance within a reasonably-skilled but Perl-ignorant programmer.

The question here, and its relevance for `ni`, is not whether this language syntax is useful (it is), but how to open our minds and increase our reading skills to take advantage of Perl's unique qualities.

When a Perl variable is brought into existence, its nature is determined by the sigil that precedes it. The explicit use of sigils allows for more variables to be packed into the same linguistic namespace. When creating a variable:

* `$x` indicates the variable `$x` is a scalar, for example a string or a number.
* `@x` indicates the variable `@x` is an array.
* `%x` indicates the variable `%x` is a hash.

Because the syntax for all of these is different, we can use all of these

```
print $x;         # get the scalar value of $x
print $x[3];      # get the scalar from @x at index 3
print $x{"foo"};  # get the scalar from %x associated with the key "foo"
```

At first glance, this is adds to the confusion; all of these values start with `$x`. In fact, it's very explicit, you just need to learn the rules. You're completely in control of telling the interpreter what to do. 

In the case of `$x[3]`, you've told the Perl interpreter to get a scalar value by using the prefixed `$` sigil; based on the square brackets used to as a postfix index, Perl knows that you're referring to an array, since square brackets are used to index arrays.

Similarly, using curly braces tells Perl to look in a hash, and without either of those, the Perl interpreter assumes you are referring to the scalar value `$x`. The syntax is a little complicated, but it's not tricky. With a little practice, this will be second nature.

## `p'...'`: Perl mapper

The Perl mapper is the most important, most fundamental, and most flexible operator in `ni`. Using a Perl mapper gives you access to the standard Perl libraries, as well as concise `ni` extensions to Perl. We describe the most critical `ni` extensions here, and `ni` is backwards-compatible with Perl through Perl 5.08.

### Column Accessor Functions `a` and `a()`


The most fundamental of these are the column accessor functions `a(), b(), c(),..., l()`. These functions give access to the values of the first 12 columns of the input data. If you're wondering, the reason that there is no `m` is because it is a reserved character by the Perl system for writing regular expressions with nonstandard delimiters (e.g. pipes).

The functions `a() ... l()` are usually shortened to `a, b, c, ..., l` when their meanings would be unambiguous. 


```bash
$ ni i[first second third] i[foo bar baz] p'a()'
first
foo
```

```bash
$ ni i[first second third] i[foo bar baz] p'c'
third
baz
```

You can use the output of these functions like any other Perl variable.

```bash
$ ni i[3 5 7] p'a + b + c'
15
```

```bash
$ ni i[easy speak] p'b . a'
speakeasy
```

As you might have suspected from the previous example, `.` is the string concatenation operator in Perl.

### Perl Mapper return value

In each of the previous examples, there has been a single output value; what happens when we try returning multiple values?

```bash
$ ni i[first second third] i[foo bar baz] p'c, a'
third
first
baz
foo
```

Overall, the return value of a Perl mapper is its last statement. `ni` returns each element of the output array on its own row.

Here, the return value of our Perl mapper for the first input line was the array `("third", "first")`, and the return value for the second input line was the array `("baz", "foo")`. When a perl mapper outputs an array, `ni` outputs the values of that list to the stream, one value per line of the stream. 

### `p'r(...)'`: Emit row

If we want to print more than one value per line to the stream there's the `r(...)` function.

```bash
$ ni i[first second third] i[foo bar baz] p'r(c, a)'
third	first
baz	foo
```

`r(...)` is more commonly written as `r`, followed by its arguments.

```bash
$ ni i[first second third] i[foo bar baz] p'r c, a'
third	first
baz	foo
```

**CAVEAT:** `r()` is _printing_ a row to the stream, rather than _returning_ a string tab-separated string, for example. The `r()` function's job is to print; its return value is essentially nothing (in fact, it's the empty list `()`)



### `F_, FM, FR n, FT n`: Explicit field access

`ni` does not tab-split an input line of data by default; to access the columns of your data, you can use `F_`. `F_` is a function that takes no arguments, splits a line from the stream on tabs, and returns the values as an array.


```bash
$ ni i[first second third fourth fifth sixth] p'r F_(1..3)'
second	third	fourth
```

`FM` is the index of the last field of your data (i.e. the total number of fields minus one):

```bash
$ ni i[first second third fourth fifth sixth] \
     i[only two_fields ] p'r FM'
5
1
```

`FM` allows you to write code that takes you to the end of a line

```bash
$ ni i[first second third fourth fifth sixth] p'r F_(3..FM)'
fourth	fifth	sixth
```

However, since this operation is common `ni` provides syntactic sugar for `F_(n..FM)` as `FR n`. 

```bash
$ ni i[first second third fourth fifth sixth] p'r FR 3'
fourth	fifth	sixth
```

A symmetric operation, which takes the first `n` columns is called `FT`

```bash
$ ni i[first second third fourth fifth sixth] p'r FT 3'
first	second	third
```

A mnemonic to remember these is `FR = "Fields fRom"`, and `FT = "Fields To"`.


## `1`: Dummy pulse

One of the slighly tricky aspects of `ni` is that the Perl operator `p'...'` requires an input stream to run. In this case, the number of lines in the input stream will determine the number of times the Perl mapper is run. The following command, while syntactically correct, produces no output.

```bash
$ ni p'r "foo" . "bar"'
```

In order to cause a perl mapper to execute, it needs lines to map over. In the case you have a Perl snippet you want to run, for example, to generate input, `ni` provides the `1` operator, which provides a pulse to run the stream. `1` is syntactic sugar for `n1`, which would work just as well here.

```bash
$ ni 1p'r "foo" . "bar"'
foobar
```


## Default Variables and Values

### The Default Variable `$_`

We can start our discussion with a pretty normal-looking Perl function:

```bash
$ ni i1 i10 i100 i1000 p'r a, length(a)'
1	1
10	2
100	3
1000	4
```

What's going on here is pretty clear: we're using the Perl builtin `length` function to count the number of digits in each of the numbers in our input line. Looks straightforward.

What's shocking is that you can also write the function this way:

```bash
$ ni i1 i10 i100 i1000 p'r a, length'
1	1
10	2
100	3
1000	4
```

Suddenly, the `length` function, which looks like it _should_ have an argument, doesn't have one. And it still works just fine.  What's actually happening here is that Perl is using a default variable, called `$_`. 

What can we say about the type of `$_`? Since it's prefixed with a `$` sigil, we know it's a scalar value, and its name is `_`. In `ni`, `$_` is set to the whole incoming line from the stream (minus the trailing newline).


```bash
$ ni i1 i10 i100 i1000 p'$_'
1
10
100
1000
```

Many Perl functions will operate on `$_` if they are not given an argument; we'll revisit this in the section about regular expressions below, as well as when we discuss `for` loops.

### Default Values

There are no key errors or index errors in Perl. In the spirit of "Do What I Mean", you're allowed to leave variables undefined and initialize values later.

```bash
$ ni 1p'$x; ++$x'
1
```

```bash
$ ni 1p'@x; $x[3] = "yo"; r @x'
			yo
```


### `defined` and `exists`

Because there are no key errors in Perl, `exists` is used to check the presence of a hash element or array element.

```bash
$ ni 1p'@x; $x[3] = "yo"; exists $x[0] ? "yes" : "no"'
no
```

```bash
$ ni 1p'%h = {"u" => "ok"}; exists $h["me"] ? "yes" : "no"'
no
```

The scalar analog of `exists` is `defined`, which checks if a scalar has been assigned a value.

```bash
$ ni 1p'$x; defined $x ? "yes" : "no"'
no
```

## Statements, Blocks, and Scope

### Statements and Blocks

- An expression is a series of variables, operators, and method calls that evaluates to a single value. 

- A statement forms a complete unit of execution and is terminated with a semicolon `;`.

- A group zero or more statements group together into a block with braces: `{...}`. 


In Perl, a block has its own scope. Blocks can modify and use variables from a containing scope, or define variables in their own scope using the `my` keyword that are inaccessible from blocks outside.


### `my`: Lexical scoping

Perl is lexically scoped: The Perl keyword `my` restricts the scope of a variable to the current block. 


```bash
$ ni n5 p'my $x = a; {my $x = 100;} ++$x'
2
3
4
5
6
```

Let's take a look at this slightly different example, where we've dropped the `my` keyword within the block.

```bash
$ ni n5 p'my $y = a; {$x = 100;} ++$x'
101
101
101
101
101
```

> In `ni` you should always use `my` in your perl mapper variables to avoid their accidental persistence.


```bash
$ ni n5 p'my $y = a; {my $x = 100;} 
			defined $x ? "defined" : "not defined"'
not defined
not defined
not defined
not defined
not defined
```

`my` can also assign values to and from an array, for example:

```bash
$ ni i[foo bar] p'my ($first, $second) = F_; r $second, $first'
bar	foo
```

`my` can also assign anything left over to an array;

```bash
$ ni i[foo bar baz qux qal] \
	  p'my ($first, $second, @rest) = F_;
	    r $second, $first; r @rest'
bar	foo
baz	qux	qal
```

The major exception to the rule of always using `$my` for your Perl mapper variables is in a begin block, described below.

### `p'^{...} ...'`: BEGIN Block


A begin block is indicated by attaching a caret (`^`) to a block of code (enclosed in `{ }`). Begin blocks are most useful for initializing data structures that will be manipulated, and in particular for converting data closures to Perl data structures, as we will see later in this section.

Inside a begin block, the code is evaluated once and factored over the entire remaining Perl code. 

```bash
$ ni n5p'^{$x = 10} $x += a; r a, $x'
1	11
2	13
3	16
4	20
5	25
```

Note that the value of `$x` is persisted between runs of the perl mapper code. Without the begin block, we would have:

```bash
$ ni n5p'$x = 10; $x += a; r a, $x'
1	11
2	12
3	13
4	14
5	15
```

In this Perl mapper, the value of the globally-scoped `$x` variable is being reset with each line to 10.

Variables defined in one Perl mapper, even those with global scope, do not carry over to other Perl mappers.

```bash
$ ni n5p'^{$x = 10} $x += a; r a, $x' p'r $x'




```


Begin blocks combine with the `rp'...'` function well to filtering a stream, for example:

```bash
$ ni i[faygo cola] i[orange juice] i[grape soda] i[orange crush] i[hawaiian punch] rp'^{%good_flavors = ("orange" => 1, "grape" => 1)} my $flavor = a; $good_flavors{$flavor}'
orange	juice
grape	soda
orange	crush
```

### `p'... END {...}'`: END Block

An `END` block is used to dump values that have been accumulated over the course of computation. Usually a `BEGIN` block will be used to initialize the values to be returned by the end block (often an empty hash), which will be populated by the lines, and then returned via the `END` block.

The `END` block will be executed only after all of the input lines have been processed.

```bash
$ ni n10 p'^{$sum; $str} $sum += a; $str .= a; return; END {r $sum, $str; }'
55	12345678910
```

Note the use of `return` here in order to prevent each line from prtining its return value (in the above case, the value of `$str .= a`). You can also use `();` to achieve the same effect.

### Perl Mapper Return Value Tricks
One way this has an impact is when you ask `ni` for a column that doesn't exist:

```bash
$ ni i[first second third] i[foo bar baz] p'k'
```

```bash
$ ni i[first second third] i[foo bar baz] p'r k'


```

In both cases, the column accessor function `k` is returning an empty list. That means that `p'k'` returns that empty list, which prints nothing. `p'r k'`, however, **prints the value** of `k`, which is the empty list. Printing the empty list puts a blank line back to the stream.

This point will be important for the next section, where we combine the Perl mapper with the take rows operator.

### `rp'...'`: Take rows based on Perl

We can combine the take-rows operator `r` with the Perl operator `p'...'` to create powerful filters. In this case, `r` will take all rows where the return value of the Perl statement **is _truthy_ in Perl**.

The number 0, the string 0 (which is the same as the number 0), the empty list, the empty string, and the Perl keyword `undef` are all **falsey** (i.e. interpreted as boolean false) in Perl. Pretty much everything else is truthy. There is no boolean True or False in Perl, so `false` and `False` are still truthy.

Let's take a look at some examples.

```bash
$ ni n3 rp'a'
1
2
3
```

In the above example, all of the return values are truthy, so they are all printed. In the next example, we start the `n` stream at zero, which is falsey.

```bash
$ ni n03 rp'a'
1
2
```

Because 0 is falsey, it is filtered out. Here's a trickier exmaple.

```bash
$ ni n03 rp'r a'
0
1
2
```

We stated in the previous section that `p'r ...'` returns the empty list, which is falsey, so everything should be filtered out, however, the entire stream ends up returned to us intact, including the `0` that was filetered out when we didn't use `p'r a'`.

To see what's happening in these examples, it's useful to think of the order in which these operations are happening; first the numbers (0, 1, 2) are generated by `n03`. Then, the perl mapper is executed; In this case, the perl mapper prints the value of `a()` to the stream


```bash
$ ni n03 rp'r b'



```

With the previous explanation, the reason you get three blank lines here should be obvious. 

This discussion brings us to a final point on the operators both referred to as `r`:  

> Using the take rows operator `r`, and the perl emit-row function `p'r(...)'` in the same statement is offensive. It is sometimes okay to be offensive.


## Flow Control

### Truthiness in Perl

Recall that Perl has no specific boolean type. Recalling from Part 1, the number 0, the string `"0"`, the empty list `()`, the empty string`""`, and the keyword `undef` are all falsey; everything else evaluates to true.

### `if`, `else`, `elsif`

#### Block Prefix Form

This form is common to almost every programming language in one form or another;

```bash
$ ni i37 p'if (a == 2) { r "input was 2" } 
			 elsif (a =~ /^[Qq]/ ) { r "input started with a Q" } 
			 else { r "I dunno" }'
I dunno
```

#### Inline Form

`if` also has an inline form, which provides a readable syntax for lines that should be evaluated conditionally.

```bash
$ ni i5 p'r "input = 5" if a == 5'
input = 5
```


#### `unless`

`unless EXPR` is equivalent to `if !EXPR`, and it has the same syntax.

```bash
$ ni i5 p'r "input = 5" unless a != 5'
input = 5
```

#### Ternary Operator `... ? ... : ...`

The ternary operator is used to select between options based on the truth value of a statement or variable.

```bash
$ ni i6 p'a == 5 ? "input = 5" : "input != 5"'
input != 5
```

### `die`

`die` is used to raise an error; it's not used much in `ni`, but can be useful for debugging important workflows.

```sh
$ ni n5 p'a < 3 ? r a : die "too big"'
too big at - line 2972, <STDIN> line 3.
1
2
```


## Regular Expressions

Covering regular expressions in their entirety is outside the scope of this tutorial, but Perl and regex are tightly bound, and we'll cover a few pointers. The [Perl Regex Tutorial](https://perldoc.perl.org/perlretut.html) is excellent.


### Writing Good Regular Expressions

When writing a regular expression, you want them to fail as quickly as possible on strings that don't match.

1. `^` and `$` are anchor tags that represent the start and end of the string, respectively. Use them when possible. 
2. Try to limit the number of branching "or" paths in your regular expression.


### Special Characters 

The following is (very minimally) adapted from the `perldoc`:

* `\d` matches a digit, not just `[0-9]` but also digits from non-Roman scripts
* `\s` matches a whitespace character, the set `[\ \t\r\n\f]` and others
* `\w` matches a word character (alphanumeric or underscore), not just `[0-9a-zA-Z_]` but also digits and characters from non-Roman scripts
* `\D` is a negated `\d`; it represents any other character than a digit, or `[^\d]`
* `\S` is a negated `\s`; it represents any non-whitespace character `[^\s]`
* `\W` is a negated `\w`; it represents any non-word character `[^\w]`
* `.` matches any character except newlines

### Regex Matching `=~` and `!~`

To match a string to a regex, use `=~`.

```bash
$ ni ihello p'a =~ /^h/ ? "match" : "no match"'
match
```

Negative matches to a regex can be performed with `!~`.

```bash
$ ni igoodbye p'a !~ /^h/ ? "negative match" : "positive match"'
negative match
```

### Using Capture Groups

Capture groups are set off using parentheses; to get them explicitly:

```bash
$ ni iabcdefgh p'my @v = a =~ /^(.)(.)/; r @v'
a	b
```



### Regex Barriers

Usually regular expressions are set off using forward slashes, however, this means that forward slashes within a regex will have to be escaped. You can use `m` and another character when you need to match forward slashes.

```bash
$ ni i/usr/bin p'm#^/usr/(.*)$#'
bin
```


### Substitution `s///`, Transliteration `tr///` and `y///`

These operators have a slightly tricky syntax. For example, you can't use these operators the way you'd use capture groups. 

```bash
$ ni iabcdefgh p'tr/a-z/A-Z/'
8
```

```bash
$ ni iabcdefgh p's/abc/ABC/'
1
```

The reason for these somewhat surp The return value of `tr` and `y` is the
number of characters that were translated, and the return value of `s` is 0 if
no characters were substituted and 1 if characters were. This also will give
somewhat-surprising behavior to code like:

```bash
$ ni iabcdefgh p'$v = tr/a-z/A-Z/; $v'
8
```

Instead, these operators work as side-effects.

```bash
$ ni iabcdefgh p'tr/a-z/A-Z/; $_'
ABCDEFGH
```

```bash
$ ni iabcdefgh p's/abc/ABC/; $_'
ABCdefgh
```

There are other syntaxes for `s///` and `tr///`, but many of them do not work with Perl 5.8, which is the earliest Perl version with which `ni` is designed to work.


### Regex Interpolation

Perl scalars can be interpolated into regular expressions, like this:

```bash
$ ni 1p'$foo = "house"; 
        "housecat" =~ /$foo/ ? "match" : "no match"'
match
```

```bash
$ ni 1p'$foo = "house"; 
        "cathouse" =~ /cat$foo/ ? "match" : "no match"'
match
```

```bash
$ ni 1p'$foo = "house"; 
        "housecat" =~ /${foo}cat/ ? "match" : "no match"'
match
```

## String Operators

### String Concatenation
String concatenation is done with `.` in Perl rather than `+` common in other languages. We'll discuss why `+` can't be used later, but you may want to test it out now to see what happens when you try to add two strings with `+`.


```bash
$ ni 1p'"foo" . "bar"' 
foobar
```


### String Interpolation

In Perl, string interpolation occurs between double-quoted strings. 

```bash
$ ni 1p'my $x = "foo"; r "$x bar"'
foo bar
```

If the interpolated variable could be confused, it can be wrapped in curly braces.

```bash
$ ni 1p'my $x = "foo"; r "${x}bar"'
foobar
```

You can also use the results of functions, however, these need to be prefixed with a backslash to tell Perl to evaluate the function.

```bash
$ ni ifoo p'r "${\a}bar"'
foobar
```

Because `ni` is written in Perl, Perl mappers are set off with single quotes (otherwise  the parser would try to interpolate variable declarations). Moral of the story: 

> DO NOT USE single-quoted strings in `ni`.



### String Comparison: `eq`, `ge`, `gt`, `le`, `lt`

Because strings are interpreted as numbers, if you use the numeric comparator operators, strings will be cast to numbers and compared.

```bash
$ ni 1p' "ab" == "cd" ? "equal" : "not equal"'
equal
```

You need to use the specific string-comparison opeartors instead.

```bash
$ ni 1p' "ab" eq "cd" ? "equal" : "not equal"'
not equal
```


### `substr`

`substr($s, $offset, $length)`: The behavior of `substr` is a little tricky if you have a Python background:

  * If `$offset` is positive, then the start position of the substring will be that position in the string, starting from an index of zero;
  * If `$offset` is negative, then the start position of the substring will be `$offset` charaters from the end of the string.
  * If `$length` is positive, the output substring will take (up to) `$length` characters.
  * If `$length` is negative, the output substring will take characters from `$offset` to the `$length` characters from the end of the string.
  
```bash
$ ni iabcdefgh p'r substr(a, 3), substr(a, 0, 3),
                   substr(a, -2), substr(a, 0, -2)'
defgh	abc	gh	abcdef
```


### Using regular expressions versus `substr` 

`substr` does exactly one thing, and it is quite fast at doing it. If all you need is a single fixed-length substring, you'll likely have higher performance with `substr` compared to a regex; otherwise, well-constructed regular expressions are a better and more flexible choice.

```bash
$ ni iabcdefgh p'r /(.{5})$/, /^(.{3})/, /(.{2})$/, /^(.*)../'
defgh	abc	gh	abcdef
```


## Operations on Arrays

Perl arrays are prefixed with the `@` sigil, and their scalar values can be looked up by prefixing with a `$`, and indexing using square brackets.

### Array Constructors

#### Explicit constructors

Arrays are written in parentheses, with elements set off by commas.

```bash
$ ni 1p'my @arr = (1, 2, 3); r @arr'
1	2	3
```

#### `push`, `pop`, `shift`, `unshift`: add and remove elements from an array


#### `qw`: Quote Word

Writing lots of double quotes around strings is kind of a pain; Perl implements an operator called `qw` which allows you to build a list with a minimum of keystrokes:

```bash
$ ni 1p'my @arr = qw(1 2 3); r @arr'
1	2	3
```


#### `split`

`split` is another way for generating arrays from a string based on regular expressions.

```bash
$ ni iabcd iefgh p'my @v = split /[cf]/; r @v'
ab	d
e	gh
```


### `for`
Perl has several syntaxes for `for` loops; the most explicit syntax is very much like C or Java. `for` takes an initialization and a block of code to be run for each value of the initialization.

#### Block Prefix Syntax

```bash
$ ni iabcdefgh p'my $string= a; for (my $i=0; $i < length $string; $i++) {r substr($string, $i, 1) x 2;}'
aa
bb
cc
dd
ee
ff
gg
hh
```

In the above code, `substr($string, $i, 1)` is used to get 1 character from `$string` at position `$i`.  Perl also has a for syntax allowing you to define a variable name. 

```bash
$ ni iabcdefgh p'for my $letter(split //, $_) {r $letter x 2}'
aa
bb
cc
dd
ee
ff
gg
hh
```

You do not need to explicitly name a loop variable, as we have done above; if you don't, the loop variable will be put into a variable called `$_`:

```bash
$ ni iabcdefgh p'for(split //, $_) {r $_ x 2}'
aa
bb
cc
dd
ee
ff
gg
hh
```

Using your knowledge of blocks and scoping, you should know what will happen if we add `r $_` to the command: `$ ni iabcdefgh p'for(split //, $_) {r $_ x 2} r $_'`. Figure it out? Let's check.

```bash
$ ni iabcdefgh p'for(split //, $_) {r $_ x 2} r $_'
aa
bb
cc
dd
ee
ff
gg
hh
abcdefgh
```

`$_` in the loop block is scoped to the loop; it does not affect the `$_` scoped to the top-level Perl mapper, which is printed by `r $_`.


#### Inline Syntax

Finally, there is an even more parsimonious postfix syntax that is useful for short repetitive operations.


```bash
$ ni iabcdefgh p'r $_ x 2 for split //'
aa
bb
cc
dd
ee
ff
gg
hh
```


#### `next` and `last`
The keyword `next` is used to skip to the next iteration of the loop, similar to `continue` in Python, Java, or C.

```bash
$ ni iabcdefgh p'for my $letter(split //, $_) 
                 {if($letter eq "b") {next;} r $letter x 2}'
aa
cc
dd
ee
ff
gg
hh
```

`last` in Perl is similar to `break` in other programming languages.


```bash
$ ni iabcdefgh p'for my $letter(split //, $_) {r $letter x 2; last if $letter ge "c"}'
aa
bb
cc
```

Note the way that `last` and `next` combine with `if` and `unless` for readable syntax. 


### `join`
The opposite of `split` is `join`. It takes a string rather than an expression, and intersperses the string between the 

```bash
$ ni iabcd iefgh p'join "__", split //'
a__b__c__d
e__f__g__h
```


### `map`
`map` is in many ways similar to `for`; in exchange for some flexibility that `for` loops offer, `map` statements often have better performance through vectorization, and they are often more intuitive to read. `map` takes two arguments, a block of code and a perl array, and returns an array.

```bash
$ ni iabcdefgh p'map {$_ x 2} split //'
aa
bb
cc
dd
ee
ff
gg
hh
```

`map` uses a **lexically scoped** default variable `$_`. Because `$_` within the block is lexically scoped to the block, the `$_` in the block doesn't change the value of `$_` outside the block. For example:

```bash
$ ni iabcdefgh p'my @v = map {$_ x 2} split //; r $_'
abcdefgh
```

`map` can also be used with a capturing regular expression:

```sh
$ ni i[/usr/bin /usr/tmp]  p'r map m#^/usr/(.*)$#, F_'
bin	tmp
```


### `grep`

`grep` is a useful Unix command-line tool that is also useful for filtering Perl arrays. `grep` and `map` have similar syntax; grep can take an expression, for example:

```bash
$ ni iabcdefgh p'my @v = grep /^[acgh]/, map {$_ x 2} split //, $_; @v'
aa
cc
gg
hh
```

`grep` also takes a block of code, as in:

```bash
$ ni iabcdefgh p'my @v = grep { ord(substr($_, 0, 1)) % 2 == 0} 
                         map { $_ x 2 } split //, $_; @v'
bb
dd
ff
hh
```

Note that the expression syntax requires a comma following the expression, whereas the block syntax does not. Expect to mess this up a lot. That's not a _nice_ syntax, but Perl isn't nice.


### `sort` and `reverse`

`reverse` reverses an array:

```bash
$ ni 1p'my @arr = (3, 5, 1); r reverse @arr'
1	5	3
```

`sort` with no arugments will sort an array in ascending order

```bash
$ ni 1p'my @arr = (3, 5, 1); r sort @arr'
1	3	5
```

```bash
$ ni 1p'@arr = qw[ foo bar baz ]; r sort @arr'
bar	baz	foo
```

To do a reverse sort, compose the functions together like this:

```bash
$ ni 1p'@arr = qw[ foo bar baz ]; r reverse sort @arr'
foo	baz	bar
```

**CAVEAT** `sort` is a little bit finnicky. If you run:

```bash
$ ni i[romeo juliet rosencrantz guildenstern] p'r sort F_'
F_
```

That's not what we want, so what's going on?

In Perl, if you pass a function to `sort`, it will try to use that function to do the sort. Perl also expects that function to be in a particular form. In this case, we've really confused the hell out of Perl, so it returns that nonsense.

We can fix this by giving Perl a hint to execute the function `F_`:

```bash
$ ni i[romeo juliet rosencrantz guildenstern] p'r sort +F_'
guildenstern	juliet	romeo	rosencrantz
```

This syntax is a little tricky for my taste; I prefer the more explicit:

```bash
$ ni i[romeo juliet rosencrantz guildenstern] \
     p'my @arr = F_; r sort @arr'
guildenstern	juliet	romeo	rosencrantz
```

### Operations on mulitple arrays and scalars

You can feed multiple lists and scalars into `grep`, `map`, and `for`, by setting them off with commas; there is no need to construct a new array containing all of the elements you want to operate over.

```bash
$ ni 1p'my @x = (1, 2); my $y = "yo"; my @z = ("good", "bye");
        map {$_ x 2} @x, $y, @z'
11
22
yoyo
goodgood
byebye
```



## Perl Hashes

### Hash construction

The easiest way to build up a hash is using the associative arrow syntax:

```bash
$ ni 1p'my %h = ("x" => 1); r $h{"x"}'
1
```

You can also make hashes using the normal list syntax, but this is less clear.

```bash
$ ni 1p'my %h = ("x", 1); r $h{"x"}'
1
```


Hashes can also be cast directly to and from arrays.

```bash
$ ni 1p'my @arr = qw[foo 1 bar 2]; my %h = @arr; r $h{"bar"}'
2
```

### `keys`, `values`

These, quite unsurprisingly, return the keys and values of a hash. 

```bash
$ ni 1p'my %h = ("foo" => 1, "bar" => 2); r sort keys %h'
bar	foo
```

The function `values` returns values in the same order as the hash's `keys`.

```bash
$ ni 1p'my %h = ("foo" => 1, "bar" => 2, "baz" => 3); 
        my @ks = keys %h; my @vs = values %h; 
        my $same_order = 1; 
        for(my $i = 0; $i <= $#ks; $i++) { 
          if($h{$ks[i]} != $vs[i]) {$same_order = 0; last} 
        } 
        r $same_order ? "Same order" : "Different order"'
Same order
```

### `%ENV`: Hash of Environment Variables

Environment variables are much easier to access and modify in Perl than in any comparable language. To get the value of the variable you want, remember to dereference with `$ENV{varname}`.

```sh
$ ni 1p'%ENV'
...
LOGNAME
bilow
_system_type
Darwin
SHELL
/bin/bash
...
```


## Logical and Bitwise Operations

### Logical Operations

Logical operators come in two flavors, high-precedence and low-precedence. The low-precedence operators `and`, `or`, `not`, and their high-precedence C-like counterparts `&&`, `||`, `!`.

In general, there is little difference between these operations, but tricky errors may arise. In general, it is safe and syntactically pleasing to use the low-precedence operators between statements, and to use the high-precedence operators with scalars and expressions.

```sh
open my $fh, '<', $filename || die "A horrible death!"; ## Fails
open my $fh, '<', $filename or die "A horrible death!"; ## Succeeds
```


### Bit Shifts `<<` and `>>`

Bit shifting is useful because it is an incredibly fast operation; it's very useful for building hash functions and reducing computational burden. 

Bit shifting to the right is (in general) the equivalent of taking the integer part of dividing by the specified power of 2.

```bash
$ ni 1p'125 >> 3'
15
```

```bash
$ ni 1p'int(125/2**3)'
15
```

Bit shifting to the left is equivalent to multiplying by the specified power of 2.


```bash
$ ni 1p'125 << 3'
1000
```

The exception to this rule is when the number of bits to shift is larger than the number of bits of the registers in the underlying hardware. Be careful when using bit shifts with large numbers, and using bit shifts on numbers that might be negative. The results can be quite unexpected.

```sh
$ ni 1p'r 18 << 63, -1 >> 10'
0	18014398509481983
```

### Hexadecimal Numbers

You can write numbers in hexadecimal (base-16) in Perl without specifying a type:

```bash
$ ni 1p'r 0x3 + 0xa, 0x3 + 0xA'
13	13
```

### Bitwise `&` and `|`

These operations can be useful for unwinding loops in programs; like bit shifts, they're very fast and convenient for running on binary-like data.

```bash
$ ni 1p'r 0x3 & 0xa, 0x3 | 0xa'
2	11
```

They also work on decimal numbers:


```bash
$ ni 1p'r 3 & 10, 3 | 10'
2	11
```

## Common Tricks


### Text is numbers

In any nice langauge, strings and numbers are different data types, and trying to use one as another (without an explicit cast) raises an error. Take a look at the following example:

```bash
$ ni 1p'my $v1="5"; r $v1 * 3, $v1 x 3, $v1 . " golden rings"'
15	555	5 golden rings
```

It's unsurprising that the Perl infix `x` operator (string duplication) and the Perl infix `.` operator (string concatenation) work, but if you come from a friendly language that just wants you to be sure you're doing the right thing, the idea that you can multiply a string by a number and get a number is frustrating. But it gets worse.

```bash
$ ni 1p'my $v2="4.3" * "6.7"; r $v2'
28.81
```

You can perform floating point multiplication on two string variables with zero consequences.  This is complicated, but not ambiguous; if it is possible to cast the two strings (silently) to numbers, then Perl will do that for you automatically. Strings that start with valid numbers are cast to the longest  component parseable as a float or integer, and strings that do not are cast to zero when used in an arithmetic context.

```bash
$ ni 1p'my $v1="hi"; r $v1 * 3, $v1 x 3, $v1 . " golden rings"'
0	hihihi	hi golden rings
```

```bash
$ ni 1p'my $v1="3.14hi"; r $v1 * 3, $v1 x 3, $v1 . " golden rings"'
9.42	3.14hi3.14hi3.14hi	3.14hi golden rings
```

```bash
$ ni 1p'my $v1="3.1E17"; r $v1 * 3, $v1 x 3, $v1 . " golden rings"'
930000000000000000	3.1E173.1E173.1E17	3.1E17 golden rings
```


### Barewords are strings

In Perl, a "bareword" is an sequence of characters with no sigil prefix, for example:

```bash
$ ni n3p'r a, one'
1	one
2	one
3	one
```

This is useful for speed but not great for building maintainable code; `ni` now raises a warning like:

> `Unquoted string "one" may clash with future reserved word at perl code context line 2.`

Generally, be careful and quote strings that are meant to be strings (though this rule can be ignored if you are writing a throwaway script).

The use of barewords as strings has an important implication for hash lookups; we can use an unquoted string to look up terms, for example:

```bash
$ ni 1p'my %h = ("foo" => 32); $h{foo}'
32
```
However, the default behavior is for a hash to look up the value of the string the bareword represents.

As a result, there's a conflict when using the output of a function with no arguments (for example, `a`):

```sh
$ ni ifoo p'my %h = ("foo" => 32); $h{a}'
```

Returns nothing; in fact it is looking for the value with the key `"a"`.

```bash
$ ni ifoo p'my %h = ("foo" => 32, "a" => "hello"); $h{a}'
hello
```

In this case we prefix with a single `+` to indicate that the bareword in braces should be interpreted as a function.


```bash
$ ni ifoo p'my %h = ("foo" => 32); $h{+a}'
32
```

### `perldoc`	
Since `ni` sits on top of Perl, so we can take credit for the excellent Perl docs, which are often better than Google/StackOveflow for syntax help. You can get them at `perldoc -f <function>` at the command line.

```sh
$ perldoc -f my
...
my EXPR
my TYPE EXPR
my EXPR : ATTRS
my TYPE EXPR : ATTRS
   A "my" declares the listed variables to be local (lexically) to
   the enclosing block, file, or "eval".  If more than one value
   is listed, the list must be placed in parentheses.
...
```


## Conclusion

Perl is much-maligned for its syntax; much of that malignancy comes from people whose only exposure to the language is hearing about the [Obfuscated Perl Contest](https://en.wikipedia.org/wiki/Obfuscated_Perl_Contest). Perl is also known for its religious overtones; here `ni` author Spencer Tipping drop the scales from your eyes about the language in this section from his short intro to the language, [Perl in 10 Minutes](https://github.com/spencertipping/perl-in-ten-minutes). 


>Python, Ruby, and even Javascript were designed to be good languages -- and just as importantly, to **feel** like good languages. Each embraces the politically correct notion that values are objects by default, distances itself from UNIX-as-a-ground-truth, and has a short history that it's willing to revise or forget. These languages are convenient and inoffensive by principle because that was the currency that made them viable.

>Perl is different.

>In today's world it's a neo-noir character dropped into a Superman comic; but that's only true because it changed our collective notion of what an accessible scripting language should look like. People often accuse Perl of having no design principles; it's "line noise," pragmatic over consistent. This is superficially true, but at a deeper level Perl is uncompromisingly principled in ways that most other languages aren't. Perl isn't good; it's complicated, and if you don't know it yet, it will probably change your idea of what a good language should be.








1067 doc/ni_by_example_3.md
# `ni` by Example, Chapter 3 (beta release)

## Introduction

In this section, we introduce `ni`-specific Perl extensions. 
`ni` was developed at [Factual, Inc.](https://factual.com), which works with
mobile location data; these geographically-oriented operators are open-sourced
and highly efficient. There's also a [blog post](https://www.factual.com/blog/how-geohashes-work) if you're interested in
learning more.

The next set of operators work with multiple lines of input data; this allows
reductions over multiple lines to take place. This section ends with a
discussion of more I/O functions.


## `ni`-specific Perl Functions

### Geographic Perl Functions

#### `llg` & `ghe`: Latitude and Longitude to geohash
Geohashes are an efficient way of encoding a position on the globe, and is also useful for determining neighboring locations. 

The geohashing algorithm works by splitting first on longitude, then by latitude. Thus, geohashes with an odd number of binary bits of precision will be (approximately) squares, and geohashes with an even number of digits will be (approximately) rectangles with their longer side parallel to the equator.

base-32 characters | Approximate geohash size
--- |  ----
1 | 5,000km x 5,000km
2 | 1,250km x 625km
3 | 160km x 160km
4 | 40km x 20km
5 | 5km x 5km
6 | 1.2km x 600m
7 | 150m x 150m
8 | 40m x 20m
9 | 5m x 5m
10 | 1.2m x 60cm
11 | 15cm x 15cm
12 | 4cm x 2cm

`llg($lat, $lng, $precision)` returns either a geohash in a special base-32 alphabet, or as a long integer. `ghe` is a synonym of `llg` provided for backwards the purpose of backwards compatibility. 

If `$precision > 0`, the geohash is specified with `$precison` base-32 characters. When geohashes are specified in this way, they are referred to in short as `gh<$precision>`, for example gh6, gh8, or gh12. If `$precision < 0`, it returns an integer geohash with `-$precision` bits of precision.

Examples:

```bash
$ ni i[34.058566 -118.416526] p'llg(a, b, 7)'
9q5cc25
```
 

```bash
$ ni i[34.058566 -118.416526] p'llg(a, b, -35)'
10407488581
```

The default is to encode with 12 base-32 characters, i.e. a gh12, or 60 bits of precision.

```bash
$ ni i[34.058566 -118.416526] p'llg(a, b)'
9q5cc25twby7
```

The parentheses are also often unnecessary, because of the prototyping:

```bash
$ ni i[34.058566 -118.416526] p'llg a, b, 9'
9q5cc25tw
```

#### `gll` and `ghd`: Geohash to latitude and longitude

`ni` provides two prototypes for geohash decoding:

`gll($gh_base32)` Returns the corresponding latitude and longitude (in that order) of the center point corresponding to that geohash. `ghd` is a synonym of `gll` provided for backwards the purpose of backwards compatibility. 


`gll($gh_int, $precision)` decodes the input integer as a geohash with `$precision` bits and returns the  latitude and longitude (in that order) of the center point corresponding to that geohash.  As with `llg`, parentheses are not always necessary.

Examples:

```bash
$ ni i[34.058566 -118.416526] p'r gll llg a, b'
34.058565851301	-118.416526280344
```

```bash
$ ni i[34.058566 -118.416526] p'r gll llg(a, b, -41), 41'
34.0584754943848	-118.416652679443
```

#### `g3b` and `gb3`: geohash transcoding from binary to base-32

`g3b` (geohash base-32 to binary) and `gb3` (geohash binary to base-32) transcode between base-32 and binary geohashes.

```
$ ni i9q5cc25tufw5 p'r g3b a'
349217367909022597
```

`gb3` takes a binary geohash and its precision in binary bits, and returns a base-32 geohash.

```bash
$ ni i[349217367909022597 9q5cc25tufw5] p'r gb3 a, 60; r gb3 g3b b, 60;'
9q5cc25tufw5
9q5cc25tufw5
```


#### `gh_dist`: distance between geohash centroids
It is also useful to compute the distance between the center points of geohashes; this is implemented through `gh_dist`.

```bash
$ ni i[95qcc25y 95qccdnv] p'gh_dist a, b, mi'
1.23981551084308
```

When the units are not specified, `gh_dist` gives its answers in kilometers, which can be specified explicitly as "km". Other options include feet ("ft") and meters ("m"). To specify meters, you will need to use quotation marks, as the bareword `m` is taken.

```bash
$ ni i[95qcc25y 95qccdnv] p'gh_dist a, b'
1.99516661267524
```

You can also pass in binary geohashes, along with a precision.

```bash
$ ni i[95qcc25y 95qccdnv] p'gh_dist g3b a, g3b b, 40'
1.99516661267524
```

```bash
$ ni i[95qcc25y 95qccdnv] p'gh_dist g3b a, g3b b, 40, "m"'
1995.16661267524
```


#### `lat_lon_dist`: distance between points on the globe
This subroutine implements the haversine distance formula. Like `gh_dist`, it also takes units ("mi", "km", "ft", "m"), and will return the distance in kilometers if no other information is given.

```bash
$ ni 1p'lat_lon_dist 31.21984, 121.41619, 34.058686, -118.416762'
10426.7380460312
```

#### `ghb`: geohash bounding box

For plotting, it is useful to get the latitude and longitude coordinates of  the box that is mapped to a particular geohash. `ghb` returns the coordinates of that box in order: northernmost point, southernmost point, easternmost point, westernmost point.

```bash
$ ni 1p'r ghb "95qc"'
18.6328123323619	18.45703125	-125.156250335276	-125.5078125
```

### Time Perl Functions

`tpe` and `tep` are the most flexible and powerful time functions in `ni`'s arsenal for converting between Unix timestamps and date. Other important functions here are used for localization by lat/long or geohash, and several syntactic sugars are provided for common mathematical and semntic time operations.

    
#### `tpe`: time parts to epoch
`tpe(@time_pieces)`: Returns the epoch time in GMT (see important note below)
and assumes that the pieces are year, month, day, hour, minute, and second, 
in that order. 

```bash
$ ni 1p'tpe(2017, 1, 22, 8, 5, 13)'
1485072313
```

You can also specify a format string and call the function as `tpe($time_format, @time_pieces)`.

```bash
$ ni 1p'tpe("mdYHMS", 1, 22, 2017, 8, 5, 13)'
1485072313
```

#### `tep`: time epoch to parts

`tep($epoch_time)`: returns the year, month, day, hour, minute, and second in human-readable format from the epoch time.

```bash
$ ni 1p'r tep tpe 2017, 1, 22, 8, 5, 13'
2017	1	22	8	5	13
```

A specific format string can also be provided, in which case `tep` is called as `tep($time_format, $epoch_time)`.

#### `tsec`: approximately convert epoch to local time

`tep($raw_timestamp + tsec($lat, $lng))` returns the approximate date and time at the location `$lat, $lng` at a Unix timestamp of `$raw_timestamp`.

For example, let's say you have the Unix timestamp and want to know what time it is at the coordinates: 34.058566<sup>0</sup> N, 118.416526<sup>0</sup> W.

```bash
$ ni i[34.058566 -118.416526] \
     p'my $epoch_time = 1485079513; my $tz_offset = tsec(a, b); 
       my @local_time_parts = tep($epoch_time + $tz_offset); 
       r @local_time_parts'
2017	1	22	2	41	13
```

This correction cuts the globe into 4-minute strips by degree of longitude.
It is meant for approximation of local time, not the actual time, which depends much more on politics and introduces many more factors to think about.

#### `ghl` and `gh6l`: approximate conversion to local time from geohash/gh60 

`ghl` and `gh6l` get local time from an input geohash input in base-32 (`ghl`) or base-10 representation of a the geohash-60 in binary (`gh6l`).

```bash
$ ni i[34.058566 -118.416526] p'llg a, b' \
     p'my $epoch_time = 1485079513; 
       my @local_time_parts = tep ghl($epoch_time, a); 
       r @local_time_parts'
2017	1	22	2	41	13
```

```bash
$ ni i[34.058566 -118.416526] p'llg a, b, -60' \
     p'my $epoch_time = 1485079513; 
       my @local_time_parts = tep gh6l($epoch_time, a); 
       r @local_time_parts'
2017	1	22	2	41	13
```


#### `i2e` and `e2i`: ISO 8601 time <=> epoch time

ISO 8601 is a standardized time format defined by the International Organization for Standards. More information on formats is available [here](https://en.wikipedia.org/wiki/ISO_8601). `ni` implements decoding for date-time-timezone formatted ISO data into Unix timestamps. 

A similar non-ISO format (allowing for a space between date and time, and decimal precision to the time, which is ignored), is also supported.

```bash
$ ni i2017-06-24T18:23:47+00:00 i2017-06-24T19:23:47+01:00 \
     i2017-06-24T15:23:47-03:00 i2017-06-24T13:08:47-05:15 \
     i20170624T152347-0300 i20170624T182347Z \
     i2017-06-24T18:23:47+00:00 i"2017-06-24 18:23:47.683" p'i2e a'
1498328627
1498328627
1498328627
1498328627
1498328627
1498328627
1498328627
1498328627
```

`ni` can also format epoch timestamps in an ISO 8601-compatible form. To do this, input an epoch timestamp and either a floating number of hours, or a timezone format string, for example `"+10:00"`.

```bash
$ ni i2017-06-24T18:23:47+00:00 p'i2e a' \
     p'r e2i a; r e2i a, -1.5; r e2i a, "+3";
       r e2i a, "-05:45"'
2017-06-24T18:23:47Z
2017-06-24T16:53:47-01:30
2017-06-24T21:23:47+03:00
2017-06-24T12:38:47-05:45
```

These all represent the same instant:

```bash
$ ni i2017-06-24T18:23:47+00:00 p'i2e a' \
     p'r e2i a; r e2i a, -1.5; r e2i a, "+3";
       r e2i a, "-05:45"' p'i2e a'
1498328627
1498328627
1498328627
1498328627
```

#### `tpi`: time parts to ISO 8601
Takes 7 mandatory arguments: year, month, day, hour, minute, second, and time zone. The time zone can either be reported as a string `-08:00` or a number `-8`.

```bash
$ ni 1p'r tpi tep(tpe(2018, 1, 14, 9, 12, 31)), "Z"'
2018-01-14T09:12:31Z
```

To verify correctness:

```bash
$ ni 1p'r i2e tpi tep(1515801233), "Z"'
1515801233
```

#### `usfe`: US Formatted time (mm/dd/yy hh:mm:ss) to epoch
Takes a US formatted time and converts it to epoch time.

```sh # dumb test doesn't work on mac
$ ni i'2/14/18 0:46' p'r usfe a'
1518569160
```


#### `dow`, `hod`, `how`, `ym`: Day-of-Week, Hour-of-Day, Hour-of-Week, Year-and-Month shorthands

These functions give the 3-letter abbreviation for day of week, hour of day, and hour of week, and year + month.

```bash
$ ni i[34.058566 -118.416526] p'llg a, b, -60' \
     p'my $epoch_time = 1485079513; dow gh6l($epoch_time, a)'
Sun
```

```bash
$ ni i[34.058566 -118.416526] p'llg a, b, -60' \
     p'my $epoch_time = 1485079513; hod gh6l($epoch_time, a)'
2
```

```bash
$ ni i[34.058566 -118.416526] p'llg a, b, -60' \
     p'my $epoch_time = 1485079513; how gh6l($epoch_time, a)'
Sun_02
```

```bash
$ ni i[34.058566 -118.416526] p'llg a, b, -60' \
     p'my $epoch_time = 1485079513; ym gh6l($epoch_time, a)'
2017-01
```

#### `ttd`, `tth`, `tt15`, `ttm`: truncate to day, hour, quarter-hour, and minute

These functions truncate dates, which is useful for bucketing times; they're much faster than calls to the POSIX library, which can make them more practical in performance-environments (`HS`, for example).

```bash
$ ni i1494110651 p'r tep ttd(a); r tep tth(a);
                   r tep tt15(a); r tep ttm(a); r tep a'
2017	5	6	0	0	0
2017	5	6	22	0	0
2017	5	6	22	30	0
2017	5	6	22	44	0
2017	5	6	22	44	11
```


## Buffered Readahead and Multiline Selection

So far, we have only seen many ways to operate on data, but only one way to reduce it, the counting operator `c`. Buffered readahead allows us to perform operations on many lines at onceThese operations are used to convert columnar data into arrays of lines.


### `rl`, `rw`, `ru`, `re`, `r1`: Buffered Readahead

In general, the types of reductions that can be done with buffered readahead and multiline reducers can also be done with streaming reduce (discussed in a later chapter); however, the syntax for  buffered readahead is often much simpler. Generating arrays of lines using readahead operations is a common motif in `ni` scripts:

* `rl(n)`: read `n` lines
  * `@lines = rl(n)`: `n` is optional, and if it is not given, only one line will be read.
* `rw`: read while
  * `@lines = rw {condition}`: read lines while a condition is met
* `ru`: read until
  * `@lines = ru {condition}`: read lines until a condition is met
* `re`: read equal
  * `@lines = re {condition}`: read lines while the value of the condition is equal.
* `r1`: read equal
  * `@lines = r1`: Read all the lines in the stream.


```
$ ni n10 p'r rl 3'
1	2	3
4	5	6
7	8	9
10
```

```bash
$ ni n10p'r rw {a < 7}'
1	2	3	4	5	6
7
8
9
10
```

```bash
$ ni n10p'r ru {a % 4 == 0}'
1	2	3
4	5	6	7
8	9	10
```

```bash
$ ni n10p'r re {int(a**2/30)}'
1	2	3	4	5
6	7
8	9
10
```


### `a_` through `l_`: Multiline Selection operations 
You have now seen two ways to generate arrays of lines: buffered readahead and data closures. In order to access data from a specific column of a line array, you will need to use multiline operators `a_` through `l_`, which are the multiline analogs to the line-based operators `a/a()` through `l/l()`.


```bash
$ ni i[j can] i[j you] i[j feel] \
     i[k the] i[k love] i[l tonight] \
     p'my @lines = re {a}; r @lines;'
j	can	j	you	j	feel
k	the	k	love
l	tonight
```

`re {a}` will give us all of the lines where `a()` has the same value (i.e. the first column is the same. What gets stored in the variable`my @lines` is the array of text lines where `a()` has the same value: `("j\tcan", "j\tyou", "j\tfeel")`. 

To get data from one particular column of this data, we can use the multiline selectors; let's say we only wanted the second column of that data--we can get that by applying `b_` to `@lines`.

```bash
$ ni i[j can] i[j you] i[j feel] \
     i[k the] i[k love] i[l tonight] \
     p'my @lines = re {a}; r b_(@lines)'
can	you	feel
the	love
tonight
```

That's given us the second element of each line that started with the 

As with most everything in `ni`, we can shorten this up considerably; we can drop the parentheses around `@lines`, and use `reA` as a shorthand for `re {a}`

```bash
$ ni i[j can] i[j you] i[j feel] \
     i[k the] i[k love] i[l tonight] \
     p'my @lines = reA; r b_ @lines'
can	you	feel
the	love
tonight
```

And if we want to do this in a single line, we can combine multiline selection with buffered readahed:

```bash
$ ni i[j can] i[j you] i[j feel] \
     i[k the] i[k love] i[l tonight] \
     p'r b_ reA'
can	you	feel
the	love
tonight
```

The last two examples are used commonly. The former, more explicit one is often used when we want more than one reduction:

```bash
$ ni i[j can] i[j you] i[j feel] \
     i[k the] i[k love] i[l tonight] \
     p'my @lines = reA; r b_ @lines; r a_ @lines'
can	you	feel
j	j	j
the	love
k	k
tonight
l
```

Another common motif is getting the value of 

### `reA ... reL`: Reduce while multiple columns are equal

In the previous section, we covered `reA` as syntactic sugar for `re {a}`

```bash
$ ni i[a x first] i[a x second] \
     i[a y third] i[b y fourth] p'r c_ reA'
first	second	third
fourth
```

This syntactic sugar is slightly different for `reB, reC, ..., reL`.

Let's take a look at what happens with `re {b}`:

```bash
$ ni i[a x first] i[a x second] \
     i[a y third] i[b y fourth] p'r c_ re {b}'
first	second
third	fourth
```

In general, that's not quite what we want; when we do reduction like this, we've probably already sorted our data appropriately, so we'll want to reduce over *all* of the columns; writing a function that reduces over columns `a` and `b` is a little clunky, so we use `reb` as a syntactic sugar for that function.

```bash
$ ni i[a x first] i[a x second] \
     i[a y third] i[b y fourth] p'r c_ reB'
first	second
third
fourth
```

This is our desired output.

### Quick Detour: More Row Operations

Let's say we get some temperature data and we want to compute
some statistics around it:

```bash
$ ni i[LA 75] i[LA 80] i[LA 79] i[CHI 62] i[CHI 27] i[CHI 88] \
	 p'my $city = a; my @temps = b_ rea; r $city, mean(@temps), std(@temps)'
LA	78	2.16024689946929
CHI	59	24.9933324442073
```

#### Append and prepend streams

To present this data, we'll want to add a header of `City, Average Temperature, Temperature Standard Deviation`. To do this, we can prepend to the stream using the `^` operator.

```bash
$ ni i[LA 75] i[LA 80] i[LA 79] i[CHI 62] i[CHI 27] i[CHI 88] \
	  p'my $city = a; my @temps = b_ rea; 
	    r $city, mean(@temps), std(@temps)' \
	  ^[i[City "Average Temperature" "Temperature Standard Deviation"] ]
City	Average Temperature	Temperature Standard Deviation
LA	78	2.16024689946929
CHI	59	24.9933324442073
```


If we wanted to add data for another city, we could do it using append with the `+` operator

```
$  ni i[LA 75] i[LA 80] i[LA 79] i[CHI 62] i[CHI 27] i[CHI 88] \
	  p'my $city = a; my @temps = b_ rea; 
	    r $city, mean(@temps), std(@temps)' \
	  ^[i[City "Average Temperature" "Temperature Standard Deviation"] ] +[ i[ABQ 67 10] ]
City	Average Temperature	Temperature Standard Deviation
LA	78	2.16024689946929
CHI	59	24.9933324442073
ABQ	67	10
```

#### `mdtable`: Convert the stream to a Markdown table

Now, let's display this data nicely; the `mdtable` operation does this automatically:

```
$  ni i[LA 75] i[LA 80] i[LA 79] i[CHI 62] i[CHI 27] i[CHI 88] \
	  p'my $city = a; my @temps = b_ rea; 
	    r $city, mean(@temps), std(@temps)' \
	  ^[i[City "Average Temperature" "Temperature Standard Deviation"] ] +[ i[ABQ 67 10] ] mdtable
|City|Average Temperature|Temperature Standard Deviation|
|:----:|:----:|:----:|
|LA|78|2.16024689946929|
|CHI|59|24.9933324442073|
|ABQ|67|10|
```

In Markdown, the above output turns into a nicely-formatted table.

|City|Average Temperature|Temperature Standard Deviation|
|:----:|:----:|:----:|
|LA|78|2.16024689946929|
|CHI|59|24.9933324442073|
|ABQ|67|10|



### Caveats

* `$ ni ::data[n5] 1p'a(data)'` and `$ ni ::data[n5] 1p'a data'` will raise syntax errors, since `a/a()` are not prepared to deal with the more than one line data in the closure.
* `$ ni ::data[n5] 1p'a_ data'` works, because `a_` operates on each line.

```bash
$ ni ::data[n5] 1p'a_ data'
1
2
3
4
5
```


### `a__` through `l__`: Select-to-end-of-line
These are useful for collecting data with an unknown shape.

```bash
$ ni i[m 1 x] i[m 2 y s t] \
     i[m 3 yo] i[n 5 who] i[n 6 let the dogs] p'r b__ reA'
1	x	2	y	s	t	3	yo
5	who	6	let	the	dogs
```

In particular, these operations can be used in conjunction with Hadoop streaming to join together data that have been computed separately.


## `ni`-specific Array Processors

These functions pair well with the multiline reducers introduced in the previous section.


### `min`, `max`, `minstr`, `maxstr`

Recall that text is numbers (and numbers are text) in Perl. Thus, there are two sets of methods for finding the minimum and maximum, depending on whether you want it in a numeric context (`min`, `max`) or in a string context (`minstr`, `maxstr`)


```bash
$ ni i[1 2 3] p'r min F_; r max F_'
1
3
```

```bash
$ ni i[c a b] p'r minstr F_; r maxstr F_'
a
c
```

Be careful using these functions with both numeric and string arguments in the same line:

```sh
# this code emits warnings and has unexpected output
$ ni i[1 2 3 a b c] p'r min F_; r max F_; r minstr F_; r maxstr F_'
c
3
1
c
```

### `sum`, `prod`, `mean`
These functions provide the sum, product, and average of a numeric array:

```bash
$ ni i[2 3 4] p'r sum(F_), prod(F_), mean(F_)'
9	24	3
```

### `uniq`, `freqs`

`uniq` returns an array of the unique elements of an array.

```bash
$ ni i[a c b c c a] p'my @uniqs = uniq F_; r sort @uniqs'
a	b	c
```

`freqs` returns a reference to a hash that contains the count of each unique element in the input array.

```bash
$ ni i[a c b c c a] p'my %h = %{freqs F_}; 
                      r($_, $h{$_}) for sort keys %h'
a	2
b	1
c	3
```


### `any`, `all`, `argmax`, `argmin`
These functions take two arguments: the first is a code block or a function, and the second is an array. 

`any` and `all` return the logical OR and logical AND, respectively of the code block mapped over the array.


```bash
$ ni i[2 3 4] p'r any {$_ > 3} F_; r all {$_ > 3} F_'
1
0
```


`argmax` returns the value in the array that achieves the maximum of the block passed in, and `argmin` returns the value in the array that achieves the minimum of the function. 


```bash
$ ni i[aa bbb c] p'r argmax {length} F_; r argmin {length} F_'
bbb
c
```

If there are any ties, the first element is picked.

```bash
$ ni i[aa bbb c ddd e] p'r argmax {length} F_; r argmin {length} F_'
bbb
c
```

### `zip`: Interleave two arrays

Given a list of keys `@ks` and a list of values `@vs`; how would you construct a hash where the `$ks[i]` is associated to `$vs[i]` for every index `i`? One way is to write a loop; `zip` short-circuits this loop.

```bash
$ ni 1p'my @ks = ("u", "v"); my @vs = (1, 10); r zip \@ks, \@vs'
u	1	v	10
```

This output can be cast as a hash:

```bash
$ ni 1p'my @ks = ("u", "v");
	my @vs = (1, 10); my %h = zip \@ks, \@vs; r $h{"v"}'
10
```

It is also possible to `zip` more than 2 arrays:

```bash
$ ni 1p'my @ks = ("u", "v");
	my @vs = (1, 10); my @ws =("foo", "bar");
	r zip \@ks, \@vs, \@ws'
u	1	foo	v	10	bar
```

If the arrays are of unequal length, the data will be output only up to the length of the shortest array.

```bash
$ ni 1p'my @ks = ("u", "v");
	my @vs = (1, 10, "nope", 100, 1000,); r zip \@ks, \@vs'
u	1	v	10
```


### `cart`: Cartesian Product
To generate examples for our buffered readahead, we'll take a short detour the builtin `ni` operation `cart`.

```bash
$ ni 1p'cart [10, 20], [1, 2, 3]'
10	1
10	2
10	3
20	1
20	2
20	3
```

The output of `cart` will have the first column varying the least, the second column varying the second least, etc. so that the value of the last column will change for every row if its values are all distinct.


Note that `cart` takeas array references (in square brackets), and returns array references. `ni` will interpret these array references as rows, and expand them. Thus `r`, when applied to `cart`, will likely not produce your desired results.

```sh
$ ni 1p'r cart [1], ["a", "b", "c"]'
ARRAY(0x7ff2bb109568)   ARRAY(0x7ff2ba8c93c8)   ARRAY(0x7ff2bb109b80)
```

### Functional Programming Basics: `take`, `drop`, `take_while`, `drop_while`


`take` and `drop` get (or get rid of) the specified number of elements from an array.

```bash
$ ni i[1 2 3 4 5 6 7] p'r take 3, F_; r drop 3, F_'
1	2	3
4	5	6	7
```

`take_while` and `drop_while` take an additional block; they `take` or `drop` while the function is true.

```bash
$ ni i[1 2 3 4 5 6 7] p'r take_while {$_ < 3} F_;
                        r drop_while {$_ < 3} F_'
1	2
3	4	5	6	7
```

Some day, `ni` will get lazy sequences, and this will be useful. Until that day...


## Hash Constructors

### `p'%h = <key_col><val_col>_ @lines'`: Hash constructor

Hash constructors are useful for filtering or adding data. There are many hash constructor functions all with the same syntax. For example, `my %h = ab_ @lines` returns a hash where the keys are taken from column `a` and the values are taken from column `b`. `my %h = fd_ @lines` will return a hash where 


```bash
$ ni i[a 1] i[b 2] i[foo bar] \
     p'my @lines = rw {1};
       my %h = ab_ @lines; my @sorted_keys = sort keys %h;
       r @sorted_keys; r map {$h{$_}} @sorted_keys'
a	b	foo
1	2	bar
```

There's a nice piece of Perl syntactic sugar for the last return statement that gets all of the values out of a hash associated with the elements of an array:

```bash
$ ni i[a 1] i[b 2] i[foo bar] \
     p'my @lines = rw {1};
       my %h = ab_ @lines; my @sorted_keys = sort keys %h;
       r @sorted_keys; r @h{@sorted_keys}'
a	b	foo
1	2	bar
```

Hashes are often combined with closures to do filtering operations:

```bash
$ ni ::passwords[idragon i12345] i[try this] i[123 fails] \
     i[dragon does work] i[12345 also works] \
     i[other ones] i[also fail] \
     rp'^{%h = ab_ passwords} exists($h{+a})'
dragon	does	work
12345	also	works
```

#### Caveat

Constructing hashes from closures can get very large; if you have more than 1 million keys in the hash, the hash will likely grow to several gigabytes in size. If you need to use a hash with millions of keys, you'll often be better off using a Bloom filter, described in Chapter 6. 


### `p'%h = <key_col><val_col>S @lines'`: Accumulator hash constructor

This is useful for doing reduction on data you've already reduced; for example, you've counted the number of neighborhoods in each city in each country and now want to count the number of neighborhoods in each country.

```bash 
$ ni i[x k 3] i[x j 2] i[y m 4] i[y p 8] i[y n 1] p'r acS reA'
x	5
y	13
```

If you have ragged data, where a value may not exist for a particular column, a convience method `SNN` gives you the non-null values. See the next section for the convenience methods `kbv_dsc`.

```bash 
$ ni i[y m 4 foo] i[y p 8] i[y n 1 bar] \
     p'%h = dcSNN reA; 
       @sorted_keys = kbv_dsc %h;
       r($_, $h{$_}) for @sorted_keys'
foo	4
bar	1
```


### `p'kbv_asc %h'` and `p'kbv_dsc %h'`: Sort hash keys by value

This is syntactic sugar for Perl's sort function applied to keys of a hash.

```bash 
$ ni i[x k 3] i[x j 2] i[y m 4] i[y p 8] i[y n 1] i[z u 0] \
     p'r acS reA' p'r kbv_dsc(ab_ rl(3))'
y	x	z
```


```bash 
$ ni i[x k 3] i[x j 2] i[y m 4] i[y p 8] i[y n 1] i[z u 0] \
     p'r acS reA' p'r kbv_asc(ab_ rl(3))'
z	x	y
```


## String Operations

### `squote`, `dquote`, `squo`, `dquo`: single and double quote strings

Escaping quotes is a pain; `ni` provides `squote` and `dquote` to single- and double-quote strings; `squo` and `dquo` provide literal single and double quotes.

```bash
$ ni 1p'r squote a, dquote a, squo, dquo'
'1'	"1"	'	"
```



### `jjc`, `jjp`, `jju`, `jjw`: join with _one_ comma; pipe; underscore; whitespace


```bash
$ ni i[how are you] p'r jjc(F_),  jjp(F_), jju(F_), jjw(F_)' 
how,are,you	how|are|you	how_are_you	how are you
```


### `jjcc`, `jjpp` `jjuu`, `jjww`: join with _two_ commas;  pipes; underscores; whitespaces


```bash
$ ni i[how are you] p'r jjcc(F_), jjpp(F_), jjuu(F_), jjww(F_)'
how,,are,,you	how||are||you	how__are__you	how  are  you
```


### `ssc`, `ssp` `ssu`, `ssw` : split on _one_ comma; hyphen; pipe; forward slash; underscore; whitespace


```bash
$ ni i[how are you] p'r jjc(F_), jjp(F_), jju(F_), jjw(F_)' p'r ssc a; r ssp b; r ssu c; r ssw d;'
how	are	you
how	are	you
how	are	you
how	are	you
```


### `scc`, `shh`, `spp` `sss`, `suu`, `sww` : split on _two_ commas; hyphens; pipes; forward slashes; underscores; whitespaces


```bash
$ ni i[how are you] p'r jjcc(F_), jjpp(F_), jjuu(F_), jjww(F_)' p'r sscc a; r sspp b; r ssuu c; r ssww d;'
how	are	you
how	are	you
how	are	you
how	are	you
```

### `startswith` and `endswith`

```bash
$ ni ifoobar p'r startswith a, "fo"; r endswith a, "obar";'
1
1
```

### `restrict_hdfs_path`
`ni` tends to work better with globs (`*`) than with lists of file paths; this allows the restriction of file paths from MapReduce Jobs

```bash
$ ni ihdfst:///user/bilow/tmp/test_ni_job/part-* \
     ihdfst:///user/bilow/tmp/test_ni_job p'r restrict_hdfs_path a, 100'
hdfst:///user/bilow/tmp/test_ni_job/part-00*
hdfst:///user/bilow/tmp/test_ni_job/part-00*
```

## I/O Perl Functions

### `wf`: write to file

`wf $filename, @lines`: write `@lines` to a file called `$filename`

```sh
$ ni i[file1 1] i[file1 2] i[file2 yo] p'wf a, b_ reA'
file1
file2
$ ni file1
1
2
$ ni file2
yo
```

### `af`: append to file

```sh
$ ni i[file3 1] i[file3 2] i[file4 yo] i[file3 hi] p'af a, b_ reA'
file3
file4
file3
$ ni file3
1
2
hi
$ ni file4
yo
```

`af` is not highly performant; in general, if you have to write many lines to a file, you should process and sort the data in such a way that all lines can be written to the same file at once with `wf`. `wf` will blow your files away though, so be careful.


## JSON I/O

We'll spend the rest of this chapter discussing more exotic types of I/O, including `JSON`, `zip`, `xlsx`, and various web resources.

### `D:<field1>,:<field2>...`: JSON Destructure

`ni` implements a very fast JSON parser that is great at pulling out string and numeric fields.  As of this writing (2018-07-30), the JSON destructurer does not support list-based fields in JSON.
  
```bash
$ ni i'{"a": 1, "foo":"bar", "c":3.14159}' D:foo,:c,:a
bar	3.14159	1
```

### `p'json_decode <json_string>`: Decode JSON to Perl Hash Reference

`json_decode` will fully decode JSON into a Perl object (in this case, a hash reference. Decoding, as you might expect, is much slower than destructuring.

```bash
$ ni i'{"a": 1, "foo":"bar", "c":3.14159}' p'my $h = json_decode a; r $h->{"a"}, $h->{"foo"}, $h->{"c"};'
1	bar	3.14159
```


### `p'json_encode <hash or array reference>`: JSON Encode

The syntax of the row to JSON instructions is similar to hash construction syntax in Ruby. 
  
```bash
$ ni i'{"a": 1, "foo":"bar", "c":3.14159}' D:foo,:c,:a p'json_encode {foo => a, c => b, a => c, treasure=>"trove"}'
{"a":1,"c":3.14159,"foo":"bar","treasure":"trove"}
```

The output JSON will have its keys in sorted order.

### Other JSON parsing methods
Some aspects of JSON parsing are not quite there yet, so you may want to use (also very fast) raw Perl to destructure your JSONs.

See `core/pl/json.pm`

- `get_scalar`
- `get_array`
- `get_flat_hash`

## Compressed Archive Input

### `zip://`, `tar://`, `xlsx://`: List from compressed archive

- To list all the files in a `zip` archive:
  - `$ ni zip:///path/to/file.zip`
- To list the sheets in an `tar` or `tar.gz` archive:
  - `$ ni tar:///path/to/file.tar`
- To list the sheets in an Excel workbook:
  - `$ ni xlsx:///path/to/file.xlsx`



### `zipentry://`, `tarentry://`, `xlsxsheet://`: Read from compressed archive

- To get the data from a single file in a `zip` archive:
  - `$ ni zipentry:///path/to/file.zip:<sub_file_name>`
- To get the data from a single file in a `tar` or `tar.gz` archive:
  - `$ ni tarentry:///path/to/file.tar:<sub_file_name>`
- To get the data from a single sheet in an excel workbook as TSV:
  - `$ ni xlsxsheet:///path/to/file.xlsx:<sheet-number>`


## Web Source Input

### `https://`, `http://`, `sftp://`, `s3cmd://`: Read from web sources 

- Read from web resources: 
 - `$ ni http://path/to/file.txt`
 - `$ ni https://path/to/file.txt`
 - `$ ni sftp://path/to/file.txt`
 - `$ ni s3cmd://path/to/file.txt`
- Write to web resources:
 - `$ ni data \>http://path/to/file.txt`
 - `$ ni data \>https://path/to/file.txt`
 - `$ ni data \>s3cmd://path/to/file.txt`
 - Note this does not work for `sftp`.

## `ni` Philosophy and Style

If you've made it this far in the tutorial, you now have enough tools to be extremely productive in `ni`. If you're ready to get off the crazy ride of this tutorial and get to work, here's a great point to stop. Before you go, though, it will help to take a few minutes to think through `ni`'s philosophy and style, and how those two intersect.

### `ni` optimizes at-will programmer productivity
Many data science projects start with a request that you have never seen before; in this case, it's often easier to start from very little and be able to build rapidly, than it is to have a huge personal library of Python scripts and Jupyter notebooks that you can bend to fit the task at hand.

`ni` is great at generating throwaway code, and this code can be made production-ready through `ni` scripting, discussed in the next chapter.

### Mastery counts

Just because you can read a Python script and understand what it does at a basic level does not mean you can code in Python, and Python can trick very intelligent people into thinking they know what they're doing even when they don't. The opposite is true of `ni`. It will be inherently obvious when you don't know something in `ni`, because if you don't know something, it'll be likely that the part of the spell you're reading won't make sense.

This is a gruff approach to programming, but it's not unfriendly. `ni` doesn't allow you to just get by--your only option is mastering `ni` one piece at a time.

### Outsource hard jobs to more appropriate tools

`ni` is a domain-specific language; its domain is processing single lines and chunks of data that fit in memory

* Because of this philosophy, `ni` is fantastic for data munging and cleaning.
* Because of this philosophy, large-scale sorting is not a `ni`-ic operation, while gzip compression is.
* Because of this philosophy, `ni` relies heavily on Hadoop for big data processing. Without Hadoop, most sufficiently complicated operations become infeasible from a runtime perspective once the amount of data exceeds a couple of gigabytes uncompressed.

Some jobs that are difficult for `ni`, and some ways to resolve them:

* Sorting
  * Challenge: Requires buffering of entire stream (possibly to disk, which is slow)
  * Solution: Hadoop Streaming will do much of the heavy lifting for you in any sort, and will distribute the computation so it's easy.
* Matrix Multiplication
  * Challenge: Difficult to implement in a streaming context
  * Solution: Numpy operations 
* SQL Joins
  * Challenge: SQL joins can take more than one line
  * Solution:
    * Small Data: There are several options here. You can use `N'...'` and do the join in numpy, you can use `N'...'` with `import pandas as pd` to do the join in pandas, or you can pipe data in and out of `join -t $'\t'`
    * Large Data: HDFS Joins
* Iterating a `ni` process over directories where the directory provides contextual information about its contents.
  * Challenge: This is something `ni` can probably do, but I'm not sure how to do it offhand.
  * Solution: Write out the `ni` spell for the critical part, embed the spell in a script written in Ruby/Python, and call it using `bash -c`.
664 doc/ni_by_example_4.md
# `ni` by Example, Chapter 4 (alpha release)

Welcome to the fourth part of the tutorial. At this point, you should be familiar with fundamental row and column operations; sorting, I/O and compression. You've also covered the basics of Perl, as well as many important `ni` extensions to Perl.

The key concept that we will cover (and really, the key to `ni`'s power) is the ability of `ni` to package itself and execute in-memory on remote machines. To that end, we will explain the use of `ni` on local Docker instances; over `ssh` on remote machines, and how to use `ni` to write simple and powerful Hadoop Streaming jobs. 

Other key concepts for this tutorial include streaming reduce operations, data closures, and cell operations. We'll also cover more `ni`-specific Perl extensions, and some important parts of Perl that will be particularly useful in `ni`.

Before we get into anything too useful, however, we need to take a detour into how `ni` works at a high level. It's not completely necessary to know this in order to use `ni`, but understanding this will help you think like `ni`. 

## `ni` is self-modifying

`ni` is written in [self-modifying Perl](https://github.com/spencertipping/writing-self-modifying-perl), and the ability to rewrite its source code is the key to its virality. In biological terms, it is useful to think of `ni` is truly viral; it can be run in-memory on any machine with bash and Perl.


### `ni` evaluation basics
Part of the reason `ni` spells are easy to build is because they are pipelined by default, and in particular, they are pipelined with Unix pipes; the output of one `ni` operation is piped as input to the next operation.

```
ni <op1> <op2> <op3> ... <opN>
``` 
is, for the most part, equivalent to 

```
ni <op1> | ni <op2> | ni <op3> | ... | ni <opN>
```

`ni --explain` works by telling you what each `<op>` above is.

However, this isn't quite the whole story. 

### `::closure_name[...]`: Create a data closure

```bash
$ ni ::five[n5] n3p'r a, five'
1	12345
2	12345
3	12345
```
Any `ni` operations executable on the machine from whose context `ni` is being executed can be turned into a data closure. This caveat will become more important when we start using `ni` to execute on machines other than the ones we develop on.  The closure can be referenced within a Perl snippet as  `p'... closure_name ...'`

```bash
$ ni --explain ::five[n5] n3p'r a, five'
["memory_data_closure","five",[["n",1,6]]]
["n",1,4]
["perl_mapper","r a, five"]
```

In chapter 1, we described `ni` evaluating different operators as follows:

`$ ni <op1> <op2> ... <opN> == $ ni <op1> | ni <op2> | ... | ni <opN>`

Data closures provide a counterexample to the basics of `ni` evaluation written above. 

```bash
$ ni ::five[n5] | ni n3p'r a, five'
1	five
2	five
3	five
```

The reason that the example including pipes gives different results than the example with no pipes is that **creating the data closure modifies `ni` itself**.  In the piped example, the first `ni` is modified but is not used; the second `ni` is your system `ni`, which remains unmodified. The second `ni` therefore cannot access the data closure built in the first `ni`.


### Data Closure Evaluation and `ni` self-modification
Data closures, regardless of where they are written in a ni spell, will be evaluated before everything else, and in the order that they are written.

That means that `$ ni ::five[n5] n3p'r a, five'` ie equivalent to `$ ni n3p'r a, five' ::five[n5]`, even though in the latter, it looks like it's referencing something that was computed later in the pipeline.

Data closures are (or will be shortly implemented such that they are) computed in order; that means you can use one data closure to compute another, so long as the one computed from is expressed in the stream before the one which uses it to do some computation.

We can rewrite a `ni` pipeline a little more accuartely as the following:

```sh
$ ni ::dataclosure1 ... ::dataclosureM <op1> <op2> ... <opN> 
```

```sh
$ ni ::dataclosure1 ... ::dataclosureM (export to) ni_prime
$ ni_prime op1 | ni_prime op2 | ... | ni_prime opN
```

We will see how `ni` actually does this in the following sections.


## `ni` is a quine

A _quine_ (pronounced: KWINE) is a program that prints its source code when it is run. If you haven't run into quines before (or the equivalent terms selfrep or self-representing program), and you go out and start looking at them, they can be mind-bending and near-impossible to read. That is the correct reaction; you should start becoming comfortable with that feeling.

We'll write a classic quine in Scheme (or Lisp), then a quine in Perl, and then demonstrate that `ni` is a quine without getting too deep into the details.

### Scheme/Lisp micro-tutorial
If you're already familiar with Lisp syntax, skip ahead to the next section. If you're not familiar with either of those languages, they're much more worth learning than `ni`, but it's probably more urgent that you learn `ni` for some reason, so this mini-tutorial will teach you enough to understand our first example quine.

Start by checking out [repl.it](http://www.repl.it). Select Scheme and you'll be taken to a Scheme REPL.

Here's what you need to know:

* Function applcation in Scheme/Lisp starts with an open parenthesis.
  * `(+ 1 2)` yields `3`. 
  * `(* 5 6 7)` yields `210`
* Scheme lists are written in parentheses and are delimited by spaces.
* The function `list` returns a list of its arguments:
  * `(list 1 3 5)` yields `(1 3 5)`
* The function `quote` takes one argument and returns its literal value:
  * `(quote 5)` yields `5`
  * `(quote (list 1 2 3))` yields `(list 1 2 3)`. Note that the list function was not evaluated.
* `lambda` defines an anonymous function with any number of named parameters.
  * `(lambda (u v) (u + v))` yields a lambda (i.e. an anonymous function) that adds two values.
  * `((lambda (u v) (u + v)) 4 5)` yields 9, because the 4 and the 5 are passed as arguments to the lambda.

### A simple quine in Scheme
Let's build a quine, starting with this piece:

```
(lambda (x)
   (list x (list (quote quote) x))
```

`lambda` creates an anonymous function which, on input x, returns a list with first element `x`. The second element of the list is also a list. The first element of the sublist is the result of  `(quote quote)`, and the second element is `x`. To make the operation of this function more concrete, head over to  and look at what happens when we do the following:

```
((lambda (x)
    (list x (list (quote quote) x)))
  1)
=> (1 (quote 1))
```
So when we apply ths function to an argument, we get back the argument, followed by a list consisting of `quote` and the argument.

Already that should feel like a step in the right direction; we have a function that takes a piece of data, reproduces that data and then a quoted representation of that data. In quines with this structure, this function is often referred to as "the code."

What we need now is the appropriate piece of data to feed to the code. We know our data has to reproduce our code, so that means what we feed to our code must be a string representation of itself. We do this by applying `quote` to the text of the code.

```
((lambda (x)
  (list x (list (quote quote) x)))
 (quote
  (lambda (x)
   (list x (list (quote quote) x)))))
=> ((lambda (x) (list x (list (quote quote) x))) (quote (lambda (x) (list x (list (quote quote) x)))))
```

Note that not all quines are structured this way (with code and data to interpret the code), but these are the simplest types of quines to write and explain.

For those inclined to theoretical computer science, [David Madore's tutorial on quines](http://www.madore.org/~david/computers/quine.html) is excellent.  For more examples quines, see [Gary P. Thompson's page](http://www.nyx.net/~gthompso/quine.htm).

### A quine in Perl

```
#!/usr/bin/perl
eval($_=<<'_');
print "#!/usr/bin/perl\neval(\$_=<<'_');\n${_}_\n"
_
```

This code uses heredoc syntax, which is a way of writing multi-line strings in bash, POSIX, and Perl (and other Perl-influenced languages like PHP and Ruby). Enrichment on heredocs is available[... here](http://www.tldp.org/LDP/abs/html/here-docs.html).

Heredocs start with `<<` followed by a delimiter which is the instruction to the interpreter of where the string stops. In this case, the delimiter is the character `_`. Surrounding the delimiter with single quotes, as above, allows for string interpolation within heredocs; without these quotes around the delimiter, no string interpolation is allowed.

Heredocs can be parsed in non-obvious ways, and the non-obvious parsing is used in this quine. The heredoc can be parsed starting on the line after the `<<` and the delimiter, and that is what is used here. Due to the parsing, the string `print "#!/usr/bin/perl\neval(\$_=<<'_');\n${_}_\n"` is stored into `$_`.


If you found the previous paragraphs on heredocs inscrutable, don't worry too much because it's not so important; like the quine we saw in the previous section, this quine is composed of code:

```sh
#!/usr/bin/perl
eval($_=<<'_');
print 
```
and data:

```sh
"#!/usr/bin/perl\neval(\$_=<<'_');\n${_}_\n"
_
```

What makes this quine a bit more difficult to read is that there is some overlap between the code and the data involving the assignment statement. Also, it's Perl.


Copy the lines into a file `quine.pl` and run: 

```sh
$ cat quine.pl | perl
#!/usr/bin/perl
eval($_=<<'_');
print "#!/usr/bin/perl\neval(\$_=<<'_');\n${_}_\n"
_
```

Most of the trickery is done using the heredoc syntax, which are parsed in a non-obvious way. At a high level, the code works like this:

1. `$_` is set to the string value prescribed by the heredoc; since the heredoc 
2. `eval $_` happens, causing the string of code written in the third line.
3. inside `eval $_`, `print "#!... ${_}..."` happens -- notice the reference back to `$_`, which contains the code being evaled

The key here is that because the code is inside a single-quoted heredoc, it can be interpolated directly into its own representation.

### Quines, so what?

When studying quines, most of the examples you see don't do anything (other than print themselves), which should make us ask why they're even worth studying.

Consider what happens when we pipe the output of a quine back to an interpreter. Copying our quine from above into `quine.pl`:

```
$  cat quine.pl | perl | perl | perl
#!/usr/bin/perl
eval($_=<<'_');
print "#!/usr/bin/perl\neval(\$_=<<'_');\n${_}_\n"
_
```

We can keep connecting output pipes to input pipes and getting the same output. If we think about pipes more generally, we might imagine taking a quine, passing its output as text over ssh, and executing that quine using perl on another machine. A quine can be passed from machine to machine, always with the same output; it is a fixed point of the code under the evaluation/interpretation operator.



### `//ni`: Print `ni`'s _current_ source
As a reminder, you should be using a vanilla (to the greatest extent possible) bash shell for these commands. If you're not running a bash shell, `bash` at the terminal will pop you into a bash shell.


`ni` is a quine. To get `ni` to print its source, run:

```sh
$ ni //ni
#!/usr/bin/env perl
$ni::self{license} = <<'_';
ni: https://github.com/spencertipping/ni
Copyright (c) 2016 Spencer Tipping | MIT license
....
_
....
```

Like the example Perl quine above, `ni` uses the tricky interpretation of the heredoc syntax, and the semicolon at the end of the line is not subsumed into the multi-line string. Also, because `ni` is self-modifying, `//ni` cannot be said to print `ni`'s source per se; instead it prints `ni`'s source at the time that it is called.

This provides us with a surprising power. We can now execute `ni` indirectly by piping `ni`'s source to `perl -`. The `-` instructs perl to read code from the command line.  More generally,

> `$ ni ...` is equivalent to `ni //ni | perl - ...`

If we think about a pipe more generally, as passing data not just from one process to another, but from one machine to another, you should envision the possibilities of offloading work from one machine to another that's better equipped to solve your target problem.


## `ni` is a self-modifying quine

In the section on `ni` being self-modifying, it was mentioned that `ni` execution follows a structure something like this:

```sh
$ ni ::dataclosure1 ... ::dataclosureM <op1> <op2> ... <opN> 
```

is equivalent to

```sh
$ ni ::dataclosure1 ... ::dataclosureM (export to) ni_prime
$ ni_prime op1 | ni_prime op2 | ... | ni_prime opN
```

In fact, this `ni_prime` is a local modification of `ni`, which incorporates data closures. The details are outside the scope of how this occurs are outside the scope of this tutorial, but here's some evidence that this is going on.

```sh
$ ni //ni | wc -c
  743514
```

```sh
$ ni ::my_closure[n10] //ni | wc -c
  743569
```

If we've really inserted a data closure into `ni` as a quine, `ni` is really a quine, then we should be able to execute it, for example, by passing the code to perl.

```bash
$ ni ::five[n5] //ni | perl - 1p'five'
1
2
3
4
5

```

This is really quite magical; we've taken `ni`, made a simple but powerful modification to its source, then passed the entire source to `perl` (which had no idea what it would receive), and it was able to access something that doesn't exist in the installed version of `ni`. It is because `ni` is a quine that allows it to be self-modifying.


## SSH, Containers, and Horizontal Scaling

We've covered why `ni` can be indirectly executed on the same machine using the identity `$ ni ...` == `$ ni //ni | perl - ...`. The natural next steps are to explore indirect execution of `ni` scripts on virtual machines and on machines you control via `ssh`. While horizontal scaling (running a process on multiple cores) has nothing to do with the indirect execution in containerized operations, it has functional and semantic similarity with these other operators in this section.

### `C`: execute in a container

Running in containers requires that Docker be installed on your machine. It is easy to install from [here](https://www.docker.com/).

Running containers can be especially useful to take advantage of better OS-dependent utilities. For example, Mac OS X's `sort` is painfully slow compared to Ubuntu's. If you are developing on a Mac, there will be a noticeable performance change using `$ ni n1E7 g` vs `$ ni n1E7 Cubuntu[g]`.


### `s`: execute over `ssh`

You will need to set up your hosts properly in your `.ssh/config` to use a named host. For example, if you log in with the command `ssh user.name@host.name:port.number`, you would create an alias for that host by entering the following lines in your `.ssh/config` 

```
host <alias>
    HostName <host.name>
    Port <port.number>
    User <user.name>
```

You would access this as `$ ni ... s<alias>[...]`. The alias used in most of the other `ni` docs is `dev`.

Inside the brackets, you will have access to the filesystem of the remote machine (but not the machine from which `ni` was originally called). 

### `S`: Horizontal Scaling 
Remember that `ni` should be I/O bounded; as such, `ni` provides a very easy interface to multiprocessing using the horizontal scaling operator, `S`. 

`$ ni S<# cores>[...]`: distributes the computation of `...` across `<# cores>` processors. 

Running an operator with `S8` on a machine with only two cores is not going to give 8x the computing power. In fact, if you request more cores than you have, you'll likely end up slowing your progress.  

  
## Hadoop Streaming MapReduce

`ni` and MapReduce complement each other very well; in particular, the MapReduce paradigm provides efficient large-scale sorting and massive horizontal scaling to `ni`, while `ni` provides significant concision and progrmmer ease in comparison to writing and submitting scripts. `ni` is often also low-overhead and very fast when written appropriately.

### MapReduce Fundamentals

MapReduce landed with a splash in 2004 with this [excellent paper](https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf) by Jeffrey Dean and Sanjay Ghemawat of Google and (with Hadoop) in many ways ushered in the era of "big data."

To understand how to best use `ni` with MapReduce, it's important to understand how it works.

The MapReduce paradigm breaks down into three steps:

1. Map
2. Combine (optional)
3. Reduce

In general, a mapper will read in large, often unstructured data, and output  more highly structured information, which will be combined into statements about the original data by the reduce operation.  Because both map and reduce occur across many processors, there is often high network overhead transferring data from mappers to reducers. A combiner is used to reduce the amount of data passed between mappers and reducers.

### MapReduce Example: Word Count

The classic example of a MapReduce job is counting the words in a document.  Let's see how it fits with the MapReduce technique.

If we were going to count the words in a document on a single machine, we might follow a process like the following:

1. Read in a line of text
2. Split the line into words
3. Emit each word on its own line
4. Sort the words alphabetically
5. Count the sorted words.

Let's see how this would work in MapReduce.

* **Mapper**
  1. Read in a line of text
  2. Split the line into words
  3. Hash each word (mod number of reducers) to determine which reducer to send each word to.
* ** Shuffle (sort words per reducer) **
* ** Reducer **
  1. Reducer receives sorted words
  2. Count the sorted words.


We could also write this job with a combiner, decreasing network overhead at the cost of some slightly more complicated code.

* **Mapper**
  1. Read in a line of text
  2. Split the line into words
  3. Sort words and emit one word per line to the combiner
* **Combiner**
  1. Count sorted words and emit key-value pairs in the form of (word, count)
* ** Shuffle (sort words per reducer) **
* ** Reducer **
  1. Reducer receives sorted key-value pairs 
  2. Sum up the counts, reducing over the individual words.



### Taking advantage of MapReduce with `ni`
An important difference in philosophy between MapReduce and `ni` is how expensive sorting is; any MapReduce job you write will have the output of the mapper sorted (so long as your job has a reducer), so you always get (a ton of) sorting done for free. In `ni`, on the other hand, sorting is one of the most expenisve operations you can do because it requries buffering the entire stream to disk.

This makes clear a point that we introduced above in our discussion of containerized `ni` operations, and `ni` operations over `ssh`: one of the most powerful ways to use `ni` is to write what would otherwise be complicated scripts in `ni`'s concise and powerful syntax, and then push these scripts to platforms more suited to the task at hand using `ni` interops.

The key thing to remember for leveraging MapReduce's sort and shuffle with `ni` is the following:

> You can assume the output of each mapper and combiner, and the input of each combiner and reducer, is sorted.


### How `ni` Interacts with Hadoop Streaming MapReduce
When `ni HS...` is called, `ni` packages itself, its closures, **and its instructons** and submits itself as a mapper/combiner/reducer to the configured Hadoop server.

Because `ni` includes its data closures on submission, if these closures are too large, the Hadoop server will refuse the job.


### `HS[mapper] [combiner] [reducer]`: Hadoop Streaming MapReduce Job

`HS` creates a hadoop streaming job with a given mapper, combiner, and reducer (specified as `ni` operators). Any `ni` snippet can be used for the mapper, combiner, and reducer. 

Two shorthands for common Hadoop Streaming jobs exist:

* `_` skips the mapper/reducer/combiner. 
* `:` applies the trivial operation (i.e. redirect STDIN to STDOUT) for the mapper/reducer/combiner.

A useful Hadoop Streaming job that repartitions your data, for example, to be used in an HDFS join is the following:

`$ ni ... HS:_:`

It has a trivial map step, no combiner, and a trivial reducer; it looks like nothing is being done, but due to the shuffle in the MapReduce 

If the reducer step is skipped with `_`, the output may not be sorted, as one might expect from a Hadoop operation. Use `:` for the reducer to ensure that output is sorted correctly.



## Developing Hadoop Streaming Jobs

Because Hadoop is such an important part of `ni`'s power, we're devoting a section not just to the operator, but to the principles of development using `HS`. `HS` is, in fact actually a combination of two operations, `H` and `S`. `H` initiates a Hadoop Job, and `S` indicates that the job is a streaming job.

`ni` handles the creation of input and output paths for Hadoop, and the output of a Hadoop Streaming job is a path to the data where your data is stored, or more accurately, it is a `ni` command to read all the data from the output directory of 

### Fundamental Theorem of MapReduce

You can convert a hadoop streaming job to a `ni` job without Hadoop streaming via the following identity:

> `$ ni ... HS[mapper][combiner][reducer]` = `$ ni ... mapper gA combiner gA reducer`

This identity allows you to iterate fast, completely within `less` and the command line.
  
**Exercise**: Write a `ni` spell that counts the number of instances of each word in the `ni` source using Hadoop Streaming job. Start by writing the job for a single All of the tools needed for it (except the Hadoop cluster) are included in the first two chapters of this tutorial. Once you have it working, see how concise you can make your program.

### `HDS[mapper][combiner][reducer]`: Hadoop Develop Streaming (... coming soon)

I have this great idea to apply the fundamental theorem to `ni` jobs so the only thing you have to do is replace `HS` with `HDS` and you get a test-run of your job. It's been a little hard to cook up though.

## Architecting Hadoop Streaming Pipelines

Now that you have an idea of how to write a job that runs, it's important to think about how to write jobs that actually work. One of the most fun and frustrating things about Hadoop is that techniques that would solve a problem on a gigabyte of data and a single machine fail painfully when applied to a terabyte of data distributed over thousands of machines.

There is a big difference between jobs that can run and jobs that actually work in MapReduce, and you need to be aware of Hadoop's architecture and configuration to take advantage of it.

### MapReduce Pipelining Case Study

You are given the transactions from every Starbucks in the world, in the form of five columns: `Transasction ID, Store ID, Item ID, Date, Price`. You're instructed to identify the highest revenue item by store, by day.

On a gigabyte of data, this would be easy; you could use SQL or `pandas` to do something like:

```sh
day_store_item_df = 
	(raw_df.groupby(['Store ID', 'Date', 'Item ID'])['Price'].sum()
	 .reset_index().sort_values(['Price'], ascending=False)
	 .groupby(['Store ID', 'Date', 'Item ID'])
	 .first())
```

This idea doesn't translate over to MapReduce flawlessly. Let's take a look at one way to do this, using the store ID as the reduce key.

If we were to do that, all of the data from every store will go to the same reducer, and we'll have data on each reducer that is sorted by store. For simplicity, let's assume each store gets its own reducer.

We're first faced with the problem of one reducer having potentially a hundred times more data to process than another (if we use fewer stores than reducers, this problem persists in reduced form); this makes the job more prone to failure, as the longest-running reducers are also, in general, the most liable to fail or be pre-empted and killed by a scheduler.

Compounding this problem is that we need to do a secondary sort of the data on each reducer, to order the data by date and by item id.  You might also try to get around this sort by using a hash; this may work when the number of dates and item ids is smaller than several million, but when working with several terabytes of data, this number might grow to billions (consider the effect of getting data by hour or minute, rather than by day), and the combinatorial effects must always be considered.

A better approach is to first collect the data using a compound reduce key of `Store ID - Date - Item ID`. This will give us a good amount of randomization, approximately equal amounts of data per reducer, and a very easy and straightforward reduce step.

We likely want to collect the data by store, but running another MapReduce job using only `Store ID` as the reduce key may still be a bad idea, since there will still need to be a secondary sort of size on the order of `# of items x # of Days`. Instead, we can re-shard using `Store ID - Date` as the reduce key, and sort or hash something on the order of `# of items`.

At this point, we have the highest revenue item for each store and date; we may be able to stream the data out directly from HDFS, or run a trivial job to reshard the data by store.

### Single Step Down Principle

In each MapReduce pass, the whole dataset is swallowed, but it often can't be digested completely. When building a pipeline on a multi-terabyte dataset using MapReduce, I've found the following principle to be valuable: 

> Take a smaller step on a larger dataset rather than running the same larger task on multiple smaller datasets.

Some other ideas to keep in mind:

1. You must take advantage of randomization to run performant MapReduce.
1. Run as few separate jobs as possible.
1. Run the largest number of mappers and reducers that your cluster will allow, while maintaining a map time of at least 1 minute.
1. Your average reducer time should be under 5 minutes, if possible.
1. Your slowest reducer should take no more than twice as much time as your average reducer.
1. Be very careful of running a secondary sort in the reduce phase; often you're better off running a second job. 
1. Compress your data to the greatest extent possible.

### Hadoop Streaming MapReduce Limitations

#### Number of files

Hadoop (2.x) is only configured to accept up to at most 100,000 files per job. Instead of doing the sensible thing and failing before the job starts, Hadoop will fail after hitting the limit in the number of files. In general, you should not run over more than 80,000 files.  Be careful when you use wildcard characters in Hadoop paths.

#### Avoiding SIGPIPE

`ni`'s `r<number>` operator uses `head`, which is very fast; however, when `head` finishes, it sends a SIGPIPE signal; this signal will kill your Hadoop Streaming job if received before all of the data is consumed.

To remedy this, there is a "safe" version of `r<number>` called `rs<number>`, which has the exact same functions and specification as `r`, except that consumes the entire stream; it is significantly slower, but it will not fire off a SIGPIPE.

```bash
$ ni n1000 rs5
1
2
3
4
5
```

#### Number of Input Partfiles

It is hard-coded in Hadoop to not accept more than 100,000 input files as input for a single job. The error that you get if you try to use more than  this is not particularly informative, so try to keep this in mind.

#### Number of Mappers x Reducers

Mappers communicate their data to reducers over wired connections; the number of these connections that must be made is equal to the number of mappers times the number of reducers.

Because these connections are done over wire, they will fail with some frequency, and if the number of these failures gets too high, the entire `HS` job will fail.

In general, keep `(# of mappers) x (# of reducers) < 100 million` to avoid this issue.

#### More Notes on Hadoop Streaming
There are a number of Hadoop-specific issues that may make jobs that you can run on your machine not run on Hadoop. See the [optimization](optimization.md) docs or the [debugging](debugging.md) docs for more information.

### `^{...}`: `ni` configuration

As noted above, you need to take advantage of randomization to run successful MapReduce pipelines. Because our reducers receive sorted input, it's often the case that a Hadoop streaming job will fail as a result of too much data going to a single reducer. However, without instructions, `ni` will default to partitioning and sorting data to reducers using the first tab-delimited column. If this is not the default behavior you want, `ni` options can be set through environment variables in your `.bash_profile`. Setting ni configuration variables on the fly is often desirable, particularly in the context of hadoop operations, where increasing or decreasing the number of mappers and reducers, changing the way that data is partitioned and sorted.


```sh
$ ni ^{Hpkpo="-k1,1 -k2,2" Hpkco="-k1,1nr -k3,3" Hjr=128} HS...
```

Some caveats about hadoop job configuration; Hadoop some times makes decisions about your job for you; often these are in complete disregard of what you demanded from Hadoop. When this happens, repartitioning your data may be helpful.

```sh
export NI_HADOOP_JOBCONF="mapreduce.job.reduces=256"
```

Hadoop jobs are generally intelligent about where they spill their contents; if you want to change where in your HDFS this output goes, you can set the `NI_HDFS_TMPDIR` enviornment variable.

```sh
export NI_HDFS_TMPDIR=/user/my_name/tmp
```


## HDFS I/O

### `hdfst://<path>` and `hdfs://<path>`: HDFS I/O

Hadoop Distributed File System (HDFS) is a redundant distributed file system that was based on a 2003 [paper](https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf) by Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung of Google.

HDFS stores files in triplicate, and distributes copies of files across different nodes in a cluster. This helps prevent data loss in the event of hard drive failure, and allows for MapReduce jobs to use data-local processing, which decreases network overhead (which is often rate-limiting in Hadoop MapReduce jobs).

There are two `ni` operators 

`$ ni hdfs://<abspath> ...`

This is equivalent to `$ hadoop fs -cat <abspath> | ni ...`

`$ ni hdfst://<abspath> ...`

This is equivalent to `$ hadoop fs -text <abspath> | ni ...`

Files are often stored in compressed form on HDFS, so `hdfst` is usually the operator you want. 

Also, note that the paths for the HDFS I/O operators must be absolute; thus HDFS I/O operators start with **three** slashes, for example: `$ ni hdfst:///user/bilow/data ...`


### Using HDFS paths in Hadoop Streaming Jobs

If you want to use data in HDFS for Hadoop Streaming jobs, you need to use the path as literal text, which uses the `i` operator (the literal text operator from Chapter 1)

```sh
$ ni ihdfst://<abspath> HS...
```

This will pass the directory path directly to the Hadoop Streaming job, which is the behavior you want (in general). 

If you do not use path, as in:

```sh
$ ni hdfst://<abspath> HS...
```

`ni` will read all of the data out of HDFS to the machine from which ni is being called, stream that data to an HDFS temp-path, and run the Hadoop job using the temp folder. That's a huge amount of overhead compared to just quoting the path.  If you run the code on a quoted path, your Hadoop Streaming job should start in under 3 minutes. If you don't quote the path, it might take hours. Quote the damn path.


## HDFS Joins

HDFS joins provide a way to join 2 large datasets on HDFS in a streaming way, and is useful for example, when one of the datasets is too large to fit in a data closure.

To do an HDFS join, first, the datasets must be sorted. As mentioned in Chapter 1, joins in `ni` are designed to belarger on the left. In the map-side join context, we require that each file on the left side of the join match with exactly one file on the right side of the join. Multiple files on the left can be joined to a single file on the right, however.

To be more concrete, if you want to join 50 files to 1000 files, the 50 files must be on the right side of the join and the 1000 files must be on the left, since 50 goes into 1,000 and not vice versa.

### `hdfsj`: HDFS Join resource

`hdfsj:///` paths are used to find the path to join to a file; they will identify the path to join automatically from the path and environment variables.

The overall paradigm can be written something like this:

```sh
$ ni ihdfst:///.../<left side path>/... \
	HS[ j[hdfsj:///.../<right_side_path>/... ] ] ...
```

### `hdfsc`: Map-side file concatenation

As stated above, Hadoop limits the number of partfiles per map/reduce job to 100,000 (`10^5`). There are times when this is not enough; moreover, Hadoop 2.x requires every mapper to be run in a separate container, which means that every individual map file incurs a fixed cost of container startup that can equal the cost of running the container when the amount of data per map file is small.

`hdfsc` gets around these restrictions, allowing you to write jobs that run on up to 10,000,000,000 (`10^10`) files. It does this by concatenating the output of a large number of partfiles within the same folder on HDFS, and running their concatenation through the same mapper container.

In practical terms, this means that it will be most useful to use `hdfsc` to run between 10 medium-sized and 1000 small files through a single mapper; running more files through a single mapper will likely result in having very long-running mappers, which is bad in general.

Practically speaking, `hdfsc` is good for extending the number of partfiles that can be run through a single job up to approximately 10 million (`10^7`). Going up another order of magnitude will likely result in significantly degraded performance, unless the input files are incredibly small.

Here's how to use it:

```
ni ihdfst://input_path/.../part-000* \
   HS[zn hdfsc://1000 mapper] [combiner] [reducer]
```

Assume there are 100,000 files in the input path. Only 100 mappers will be engaged for this task; each mapper will read 1000 files; in particular, the mapper assigned to process `part-00015` will read all of the partfiles of the form `part-*15.lzo_deflate`; this ensures equal distribution of files among mappers. `zn` is a necessary first step to throw away all of the input data, since `hdfsc` will output the text of the file from which it is called, in addition to all of the other files matching the pattern.

#### Caveats
 - zn is necessary to consume the input stream, which will be re-created using hdfsc; this leads to a small amount of overhead. 
 - the number of leading zeroes in the input path must match the number of zeroes in the hdfsc://<number> path
 - `hdfsc` only works on files that are given as partfiles. 

## Hadoop Operations in Perl

The output of hadoop jobs can be moved inside a perl context:

```sh
ni data HS[<job>] p'hdfs_mv a, /user/bilow/output_path/'
```

You can also specify normal paths to move.

```sh
ni i[/user/bilow/tmp/output /user/bilow/data/product] p'hdfs_mv a, b'
```

You also have access to:

- `hadoop fs -du -h hdfsPath` via `p'hddu hdfsPath'`
- `hadoop fs -mkdir -p hdfsPath ` via `p'hdmp hdfsPath'`
- `hadoop fs -rm -r hdfsPath` via `p'hddu /path/'`
- `hadoop fs -put localFile hdfsPath` via `p'hdpt localFile hdfsPath'`
- `hadoop fs -get hdfsPath localFile` via `p'hdgt hdfsPath localFile'`
- `hadoop fs -ls -h hdfsPath` via `p'hdls hdfsPath'`
- `yarn application -kill app_id` via `p'yak app_id`

If you just want the HDFS path from an `hdfst:///` or `hdfs://` path:


## Conclusion

The classic word count program for Hadoop can be written like this:

>`$ ni //ni HS[FW Z1]_c`

If you've never had the opportunity to write the word count MapReduce program in another language, take a look at the state of the art in:

* [Python](http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/)
* [Ruby](http://www.bigfastblog.com/map-reduce-with-ruby-using-hadoop)
* [Java](https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html)
* [Go](http://go-wise.blogspot.com/2011/09/go-on-hadoop.html)
* [Perl](http://www.perlmonks.org/?node_id=859535)

Compare the `ni` solution to Java. The `ni` spell can be written in 5 seconds, and explained in 30.  It's easily tested, readable, and concise, and beautiful. You should be excited about the possibilities just over the horizon.
493 doc/ni_by_example_5.md
# `ni` by Example Chapter 5 (alpha release)
Welcome to Chapter 4. At this point you have enough skills to read the other `ni` documentation on your own. As a result, this chapter should read a little briefer because it is focused on introducing you to the possibilities of each operator.

Unlike the other chapters thus far, this chapter has no theme; it's a list of useful operations. This chapter covers some of the interplay between `ni` and `bash`, HDFS joins using `nfu`, The `ni` monitor, cell operations, stream splitting, vertical column operations, sparse matrix operations, Ruby and Lisp operators, ni-specific perl operators, and has another Perl chapter.


## Calling`ni` from other programming languages

You've already been using `ni` within bash, so you've always been using `ni` from another langauge. In this section, we'll make the connections more explicit, and briefly discuss how to use `ni` from Ruby.

### `ni` and bash

[Spencer](https://github.com/spencertipping) refers to `ni` as Huffman-encoded bash, but we haven't given the treatment of `ni` and bash fully yet. If you're already familiar with bash, this will likely be review.

`e` also can use brackets rather than quotes to execute commands. However, this exposes the code that would have been quoted to bash, which might do something you don't want it to.

When you run a script without quotes, bash will first scan for metacharacters. So the script

```sh
$ ni e[seq 10 | grep 1]
```

is run as 

```sh
~/bin/ni "e[seq" "10" | /bin/grep "1]"
```

because bash will execute the pipe first.

The correct way to execute the script: 

```sh
$ni e'seq 10 | grep 1'
``` 

turns into 
```sh
exec("/bin/sh", "-c", "seq 10 | grep 1/")
```

This is a non-obvious feature of the bracketed version of `e`: `e[ word1 word2 ... wordN ]` turns into `exec("word1", "word2", ..., "wordN")`. You'll get shell character expansion with quotes, but not with brackets, the idea being that if you're using brackets, bash has already had a chance to expand the metacharacters like `$foo`.

### `ni` and Ruby
Aside from bash, Ruby feels like the best scripting language from which to call `ni`. Ruby has an easy and simple syntax for calling shell commands using backticks (i.e. `` `cmd` `` will run using the shell). 

Ruby backticks will execute using `/bin/sh` and not `/bin/bash`. There are a few caveats for running in `bin/sh`, which are covered in the [debugging docs](debugging.md).

### `ni` and Python

It's very easy to incorporate `ni` into Python is a very natural environment for adding `ni` as a command in your scripts.

```python
import subprocess

def ni(cmd):
	ni_cmd = ' '.join(cmd) if isinstance(cmd, list)
	subprocess.call("ni {}".format(ni_cmd))
```

### `ni` and Jupyter

`ni` can really shine in Jupyter; asynchronous processing turns out to be much easier in a Jupyter notebook than it is in a standard Python workflow.

Shelling out in Jupyter is really easy; simply prefix your command with 

Working in Jupyter, you'll want to set your 


## Stream Interleaving, Duplication, and Buffering
You've seen one of these operators before, the very useful `=\>`, which we've used to write a file in the middle of a stream. The way this works is by duplicating the input stream, and sending one of the duplicated streams silently to an output file. 


### `%`: Interleave Streams

The bare `%` will interleave streams as the data is output, and will consume both streams fully. For example `$ ni nE5fAA %[n100]` will output the second stream non-deterministically; it depends how fast that data is able to stream out.

You can also call `%#` with a positive number, in which case the streams will be interleaved with a ratio of `first stream : second stream :: #:1.` You can also call `%-#`, and the streams will be interleaved with a ratio: `first stream : second stream :: 1:#.`

Interleaving streams with a numeric argument will cut off the output stream when either stream is exhausted.


###  `=`: Duplicate Stream and Discard
This operation is most useful for writing a file in-stream, perhaps with some modifications.

```bash
$ ni n10 =[r5 \>short] r3fAA
1	1
2	2
3	3
```

```bash
$ ni short
1
2
3
4
5
```

One thing to be aware of is that the stream's duplication does not block the stream, and that data written to the output file should not be used as input later in the same `ni` spell. 

If you need to do something like this, you may be better off writing two `ni` spells, or using a `ni` [script](script.md).


### `B<op>`: Buffer operation

Likely the most important buffering operation is `Bn`, which buffers data to null. This is especially useful in developing Hadoop Streaming jobs. Hadoop streaming jobs require you to read the entire piece of data in the partfile; this will error out if you try to run `r1000` to get a smaller chunk. 

## Intermediate Column Operations
These operations are used to add columns vertically to to a stream, either by merging or with a separate computation.

### `w`: Append column to stream

`w` adds a column to the end of a stream, up to the minimum length of either stream.

```bash
$ ni ia ib ic w[n3p'a*a']
a	1
b	4
c	9
```

### `W`: Prepend column stream

`W` operates like `w`, except its output column is prepended. 

```bash
$ ni 1p'"a".."e"' p'split / /' Wn
1	a
2	b
3	c
4	d
5	e
```
  

### `v`: Vertical operation on columns

We can upper-case the letters in the previous example via:

```bash
$ ni 1p'"a".."e"' p'split / /' Wn p'r a, uc(b)'
1	A
2	B
3	C
4	D
5	E
```

However `ni` also offers a shorter syntax using the `v` operator.

```bash
$ ni 1p'"a".."e"' p'split / /' Wn vBpuc
1	A
2	B
3	C
4	D
5	E
```

**Important Note**: As of 2017-03-30, this operator is too slow to use in production.

Also note that the Perl upper-case operator is written as `puc`, without quotes, as it's good `ni` style to do so.

### `Y` - dense-to-sparse transformation
`Y` Explodes each row of the stream into several rows, each with three columns:

* The index of the row that the input data that came from
* The index of the column that the input data came from
* The value of the input stream at the row and column specified by the first two columns.


```bash
$ ni i[operator could you help me] i[ place this call ] i[see the number on the matchbook]  FW Y r10
0	0	operator
0	1	could
0	2	you
0	3	help
0	4	me
1	0	place
1	1	this
1	2	call
2	0	see
2	1	the
```

### `X` - sparse-to-dense transformation
`X` inverts `Y`: it converts a specifically-formatted 3-column stream into a multiple-column stream. The specification for what the input matrix must look like is described above in the `Y` operator.

```bash
$ ni i[operator could you help me] i[ place this call ] i[see the number on the matchbook] FW Y r10 X 
operator	could	you	help	me
place	this	call
see	the
```

### `Z<n_cols>` - unflatten
`Z` takes data in the form of a single column and returns the same data reshaped into rows with the specified number of columns. Any overhanging data is pushed onto an incomplete row.

```bash
$ ni 1p'"a".."l"' Z4
a	b	c	d
e	f	g	h
i	j	k	l
```


## Join operations

`ni` implements two join operations, a join on sorted rows `j`, and a join on unsorted rows `J`. 


### `J` - streaming join unsorted rows
`J` is useful when the right side of your join is small enough to fit in memory, and does not require that either the left or the right side of your join be sorted. This is useful for most local operations, and joins against small data on the map side in Hadoop contexts. 




### `j` - streaming join sorted rows

`j` is useful 

Streaming joins are performed by matching two sorted streams on the value of their first column. 

Example:

```
$ ni 1p'"a".."e"' p'split / /' :letters gA- wn gA +[letters] wn gABn j[letters]
a	5	1	a
b	4	2	b
c	3	3	c
d	2	4	d
e	1	5	e
```

This operation is a little long-winded, and it will probably help to look at some of the intermediate steps.

```bash
$ ni 1p'"a".."e"' p'split / /' :letters gA- wn gA
a	5
b	4
c	3
d	2
e	1
```

This is probably a terrible way to generate the letters a through e, joined with then numbers 5 through 1, respectively.

```bash
$ ni 1p'"a".."e"' p'split / /' :letters gA- wn gA +[letters]
a	5
b	4
c	3
d	2
e	1
a
b
c
d
e
```

We've checkpointed our list of letters into a file called `letters`, which allows us to reuse it. The `+` operator appends one stream to another, so at this stage the first half of our stream has numbers appended, and one without.

```bash
$ ni 1p'"a".."e"' p'split / /' :letters gA- wn gA +[letters] wn
a	5	1
b	4	2
c	3	3
d	2	4
e	1	5
a	6
b	7
c	8
d	9
e	10
```

We append another column of numbers; note that `w` adds new columns to every row, but does not make sure that the rows are the same length, so the 


```bash
$ ni 1p'"a".."e"' p'split / /' :letters gA- wn gA +[letters] wn gABn
a	5	1
a	6
b	4	2
b	7
c	3	3
c	8
d	2	4
d	9
e	1	5
e	10
```

We sort the data (necessary to perform the join) first ascending lexicographically by column `A`, and then ascending numerically by column `B`.


## Cell Operations

Cell operations are similar to column operations, in that they are keystroke-efficient ways to do transformations on a single column of the input data.


### Hashing Algorithms
* `,h`: Murmurhash (deterministic 32-bit hash function)
* `,H`: Murmurhash and map the result into the unit interval.
* `,z`: Intify (hash and then convert hash values to integers starting with 1)
* `,m`: MD5 hash

Likely the most important of these functions is the deterministic hashing function, which does a good job of compacting long IDs into 32-bit integers.  This hashing should be good-enough for reasonable-sized data.

Using a little math, with ~40 million IDs, there will be only be about 1% hash collisions, and with 400 million IDs, there will be 10% hash collisions.  See [this](http://math.stackexchange.com/questions/35791/birthday-problem-expected-number-of-collisions) for an explanation.

Let's check that invariant:

```
$ ni n4E7 ,hA Cubuntu[o] uc
39814375
```

That means we had about 200,000 hash collisions in 40 million IDs, a rate of about .5%, which is good enough for our back-of-the envelope calculations.



### Cell Math Operations
* `,e<b>`: exponent b<sup>x</sup> -- deafults to e<sup>x</sup>
* `,l<b>`: logarithm (log<sub>b</sub>x) -- defaults to natural log
* `,j<amt>`: Jitter (add uniform random noise in the range `[-amt/2, amt/2]`)
* `,q<amt>`: Round to the nearest integer multiple of `<amt>`

These operations are mostly self-explanatory; jitter is often used for `ni --js` operations to create rectangular blocks of color.

```
# Test disabled for floating point imprecision.
$ ni n5 fAAAAAA ,eB ,eC2 ,lD ,lE3 ,eF ,lF
1	2.71828182845905	2	0	0	1
2	7.38905609893065	4	0.693147180559945	0.630929753571457	2
3	20.0855369231877	7.99999999999999	1.09861228866811	1	3
4	54.5981500331442	16	1.38629436111989	1.26185950714291	4
5	148.413159102577	31.9999999999999	1.6094379124341	1.46497352071793	5
```


### Column Math Operations
* `,a`: Running average
* `,d`: Difference between consecutive rows
* `,s`: Running sum 

You can use these `,a` and `,s` to get the average and sum of all data in the stream using, for example:

```bash
$ ni nE4 fAAA ,aA ,sB ,dC r~1
5000.5	50005000	1
```


## Numpy Operations

Writing Perl reducers is among the most challenging aspects of `ni` development, and it is arguably more error-prone than most other operations because proper reduction depends on an input sort. 

Moreover, Perl reducers are good with data, but they're still not great with math. If you had considered doing matrix multiplication in `ni` up to this point, you'd be pretty much out of luck. 

However, `ni` provides an interface to numpy (and all of the other Python packages on your machine), which gives you access to hugely powerful mathematical operations.  There are several associated costs, however: 1) the entire stream must be buffered into memory (though you can use partitioned matrix operations to get around this in some cases); 2) there are some arbitrary-feeling limitations on I/O; 3) the syntax is clunky compared to Perl.

It's great, you're gonna love it.

### `N'x = ...'`: Numpy matrix operations

The stream input to `N'...'` is converted into a matrix, where each row and column of the input is converted to a corresponding cell in a numpy matrix, `x`.

The values streamed out of `N'...'` are the values of `x`, so all operations that you want to do to the stream must be saved back into `x`. Compared to the Perl syntax, this is inelegant, and if `ni`'s gotten into your soul yet, it should make you more than a little frustrated.
 
However, the gains in power are quickly manifested:


```bash
$ ni n3p'r map a*$_, 1..3' N'x = x + 1'
2	3	4
3	5	7
4	7	10
```

```bash
$ ni n5p'r map a . $_, 1..3' N'x = x.T'
11	21	31	41	51
12	22	32	42	52
13	23	33	43	53
```

```
$ ni n1N'x = random.normal(size=(4,3))'
-0.144392928715457      0.823863130371182       -0.0884075304437077
-0.696189074356781      1.5246371050062 -2.33198542804912
1.40260347893123        0.0910618083600519      0.851396708020142
0.52419501996823        -0.546343207826548      -1.67995253555456
```

```bash
$ ni i[1 0] i[1 1] N'x = dot(x, x.T)'
1	1
1	2
```



### How `N'x = ...'` works
What `ni` is actually doing here is taking the code that you write and inserting it into a Python environment (you can see the python used with `ni e[which python]`

Any legal Python script is allowable, so if you're comfortable with `pandas` and you have it installed, you can execute scripts like:

```
ni ... N'import pandas as pd; 
		 df = pd.DataFrame(x); ... ; 
		 df.to_excel(...); 
		 x = df.reset_index().values;' 
		 ...
```

The last line is key, because the data that is streamed out of this operation must be stored in the variable `x`.  You can also use indented code within `N'...'`, and it will be processed correctly.

Also, like other operators, `N'...'` requires at least a row for input. `ni N'x = random.rand(size=(5,5)); x = dot(x, x.T)'` will return nothing, but adding a dummy row `ni n1N'x = random.rand(size=(5,5)); x = dot(x, x.T)'` will.

This is not (yet) the cleanest or most beautiful syntax [and that matters!], but it works.



## `m'...'`: Ruby
You have always had permission to use Ruby, but I've held off documenting it until you can do so responsibly. Why does Ruby require responsibility, whereas Python/numpy gets a pass (mostly)?

1. The Ruby driver operates in a streaming context, whereas the numpy environment `N` performs operations in-memory. As a result, the Python environment can do things that `ni` alone cannot do. The Ruby operators are weak-tea versions of cutting-edge Perl operators.
1. That means the primary use of Ruby in `ni` should be for its extensive and customizable libraries (i.e. gems). Thus, most of your Ruby code should look something like: `ni ... m'require "lib1"; require "lib2"; <do stuff with those libraries>'`
1. Because the primary use of Ruby is access to Ruby gems, your code becomes less portable. Here's a [good article](http://zachmoshe.com/2015/02/23/use-ruby-gems-with-hadoop-streaming.html) about using Ruby gems with Hadoop Streaming. It's really complicated!
1. Unlike Perl, where text is numbers, the Ruby driver requires that you explicitly cast to a datatype. Just saying, those extra keystrokes add up. Concretely: `ni n4m'r a, a + 1'` will complain about conversion of Fixnum to String without a proper cast.

### `m'a' ... m'q'`: Ruby Column Accessors

You can get the first 17 tab-delimited columns using the Ruby `a` through `q` operators. However, when using these functions to get numeric values, you must use explicit casts to coerce the value:

* `f`: `to_f`
* `i`: `to_i`
* `s`: `to_s`

To fix the example above, you need to run:

```bash
$ ni n4m'r a, ai + 1'
1	2
2	3
3	4
4	5
```

### `m'fields'`: Array of fields.
Analogous to `p'F_ ...'`. `fields` is a Ruby array, so you can use array syntax to get particular fields, for example: 

```bash
$ ni i[operator could you help me] i[ place this call ] i[see the number on the matchbook] FWr2m'r fields[0..3]'
operator	could	you	help
place	this	call
```

### `m'r ...'`: Print row
Analogous to `p'r ...'`.


## `l"..."`: Lisp

Lisp is in the same boat as Ruby, as a language that `ni` supports. Lisp operates in a streaming context, which is much better learned (and in most cases executed) in Perl. Lisp ends up even lower on the totem pole than Ruby because it can be a huge pain to install (on Mac, you have to bootstrap installation of SBCL by installing some other Lisp first).

So, if Ruby has gems, why even support Lisp? Here's why:

```bash
$ ni n4fAA l"(r (sr ('+ a) ('* b)))"
10	24
```

Streaming reduce is ugly in Perl, but smooth and easily understood in Lisp. There's something here, and it's worth working on.

### `l"a" ... l"q"`: Lisp Column Accessors

Analogous to the Perl and Ruby column accessors.

### `l"(r ...)"`: Print row

Analogous to `p'r ...'`; prints its arguments.

Look, if you're a damn Lisp programmer, you're smart enough to learn Perl. Just do that. I don't know Lisp. Go read these [docs](lisp.md).
  
  
## Conclusion
You've reached the end of chapter 5 of `ni` by Example, which coincides comfortably with the end of my current understanding of the language. Check back for more chapters to come, and more old ideas made fresh, useful, and fast.
576 doc/ni_by_example_6.md
# Future Chapter 6 Below


## More functions

### DOS file cleaning

```sh
$ ni <DOSFILE> cleandos
```

### URL encode/decode in perl context

TODO: write real docs

```sh
p'url_encode'
p'url_decode'
```

This will replace the CR/LFs in DOS with just LFs.

## Advanced Perl
### Array references
Many other languages use square brackets to represent literal arrays; in Perl, these are used for array references:

```sh
$ ni 1p'my @arr = [1, 2, 3]; r @arr'
ARRAY(0x7fa7e4184818)
```

This code has built a length-1 array containing an array reference; if you really wanted to create an array reference, you'd more likely do it explicitly.

```sh
$ ni 1p'my $arr_ref = [1, 2, 3]; r $arr_ref'
ARRAY(0x7fa7e4184818)
```

To dereference the reference, use the appropriate sigil:

```bash
$ ni 1p'my $arr_ref = [1, 2, 3]; r @$arr_ref'
1	2	3
```

Back to the first example, to dereference the array reference we've (probably unintentionally) wrapped in an array, do:


```bash
$ ni 1p'my @arr = [1, 2, 3]; r @{$arr[0]}'
1	2	3
```


### Custom Sorting
You can implement a custom sort by passing a block to `sort`.

Let's say you wanted to sort by the length of the string, rather than the order:


```bash
$ ni i[romeo juliet rosencrantz guildenstern hero leander] \
     p'my @arr = F_; r sort {length $a <=> length $b } F_'
hero	romeo	juliet	leander	rosencrantz	guildenstern
```

To reverse the sort, reverse `$b` and `$a`.

```bash
$ ni i[romeo juliet rosencrantz guildenstern hero leander] \
     p'my @arr = F_; r sort {length $b <=> length $a } F_'
guildenstern	rosencrantz	leander	juliet	romeo	hero
```

More details are available in the [perldocs](https://perldoc.perl.org/functions/sort.html).




## JSON Tools

### `accumulate`

```
ni 1p'my %h1 = ("foo" => "u", "bar" => undef, "baz" => "drank", "horse" => "", "lst" => ["car", "cadr"], "hash" => {"secret" => "key", "lst2" => ["cubs"]}); my %h2 = ("bar" => "x", "foo" => "j", "horse" => "tiger", "lst" => ["caddr"], "hash" => {"worth" => "it", "lst2" => [34]}); %h3 = ("lst" => ["cadddr", "bye"], "hash" => {"word" => "up", "lst2" => ["verj"]}); %h = accumulate(\%h1, \%h2, \%h3); dump_data \%h'
```

### `dump_data`
`ni`'s hacky `Data::Dumper` because we're too hardcore for SILLY LIBRARIES

### `freqify`
Convert lists to hashes of their frequencies. This is useful!!

```
my $h = {"foo" => {"bar" => [u,u,u,u,v,baz,baz], "qux" => [ay, ay, bee]}};
my @keys = (foo, [bar, qux]); freqify $h, \@keys;
$h => {"foo" => {"bar" => {"u" => 4, "v" => 1, "baz" => 2},
                 "qux" => {"ay" => 2, "bee" => 1}}}
```

## indexed hashing
```
ni ::test[i[a,b,c,d hi] i[c1,c2,c3 foo] i[u,v,w yo]] ::test2[i[ba,bb,bc this] i[ux,uy,uc that]] 1p'^{@pair = abc test; @pair2 = abc test2} @ks = ("ux", "bb", "c1"); $j ="bb"; @ls = ihash_def(\@ks, 1, @pair, @pair2); @ls'
```

### `pl` Pushback Queue




## Hash

* Generate a list of things you want to filter, and put it in a data closure. `::ids[list_of_ids]`
* Convert the data closure to a hash using a begin block (`^{%id_hash = ab_ ids}`)
* Filter another dataset (`ids_and_data`) using the hash (`exists($id_hash{a()})`)
* `$ ni ::ids[list_of_ids] ids_and_data rp'^{%id_hash = ab_ ids} exists($id_hash{a()})'`

## Warnings

**WARNING**: `ni` will let you name your files the same name as `ni` commands. `ni` will look for filenames before it uses its own operators. Therefore, be careful not to name your files anything too obviously terrible. For example:

```bash
$ ni n5 \>n1.3E5
n1.3E5
```

```bash
$ ni n1.3E5
1
2
3
4
5
```
because `ni` is reading from the file named `n10`.

## Understanding the `ni` monitor

At this point, you've probably executed a long-running enough `ni` job to see the `ni` monitor appear at the top of your screen. 

* Negative numbers = non-rate-determining step
* Positive numbers = rate-determining step
* Large Positive numbers = slow step

Some things to keep in mind when examining the output of the monitor: if you have access to more compute resources for slow steps, you can use them for that step alone, and this can be done in a very simple way via the `S` horizontal scaling operator.

You may also want to consider refactoring your job to make use of Hadoop Streaming with `HS`, depending on what's suited to your job. More details are available in the [monitor docs](monitor.md) and in the [optimization docs](optimization.md).


## Even More Perl for Ni

### Other syntaxes for `map`


`map` can also take an expression rather than a block, but this syntax is tricky 


The following example is taken from [Perl Monks](http://www.perlmonks.org/?node_id=613280)

You'd probably be even more surprised by the result of this:
my @in = qw(aaa bbb ccc);
my @out = map { s/.$/x/ } @in;
print "@in\n=>\n@out\n";
[download]
which prints:
aax bbx ccx
=>
1 1 1
[download]
Yeah, the original is modified. Basically: never modify $_ in a map, and remember that the "output" of s/// is the success count/code. To get what you want, you need to localize $_ and reuse it as the last expression evaluated in the block:
my @in = qw(aaa bbb ccc);
my @out = map { local $_ = $_; s/.$/x/; $_ } @in;
print "@in\n=>\n@out\n";
[download]
which indeed shows:
aaa bbb ccc
=>
aax bbx ccx



### `our` and `local`



### `use strict` and the `::` prefix within `p'...'`

When `use strict` is enabled, Perl will complain when you try to create a variable in a Perl snippet that does not start with `::`.

The reasons for this are very specific to Perl; if you are a true Perl nerd, you can look them up, but you do not need to know them if you just accept that variables need to start with `::` when you apply `use strict`. 

It is probably a good idea to `use strict` when the variables you define are sufficiently complex; otherwise you're probably okay not using it.


### Subroutines

Perl is a multi-paradigm language, but the dominant paradigm for Perl within `ni` is procedural programming. Unlike the object-oriented languages with which you are likely familiar, where methods are objects (often "first-class" objects, [whatever that means](http://stackoverflow.com/questions/245192/what-are-first-class-objects)) procedural languages focus on their functions, called "subroutines."  

Perl subroutines store the variables with which they are called in a default variable named `@_`. Before continuing, take a moment to think about how one would refer the elements in `@_`.

Subroutines are stored and referenced with the following syntax:

```
*x = sub {"hi"}
$v = &x         # $v will be set to "hi"
```


Here's how you'd write a function that copies a stream of values 4 times in `ni`, using Perl.

```bash
$ ni n3p'*v = sub {$_[0] x 4}; &v(a)'
1111
2222
3333
```

To review the syntax, the *name* of the variable is `_`, and within the body of the subroutine, the array associated with that name, `@_` is the array of values that are passed to the function.  To get any particular scalar value within `@_`, you tell Perl you want a scalar (`$`) from the variable with name `_`, and then indicate to Perl that of the variables named `_`, you want to reference the array, by using the postfix `[0]`.

Subroutines can also be called without the preceding `&`, or created using the following syntax:

```bash
$ ni 1p'sub yo {"hi " . $_[0]} yo a'
hi 1
```

Note that in these examples, a new function will be defined for every line in the input, which is highly inefficient. In the next section, we will introduce begin blocks, which allow functions to be defined once and then used over all of the lines in a Perl mapper block.

## Streaming Reduce
In earlier drafts of `ni` by example, streaming reduce had a much greater role; however, with time I've found that most operations that are done with streaming reduce are more simply performed using buffered readahead; moreover, buffered readahead.  Streaming reduce is still useful and very much worth knowing as an alternative, highly flexible, constant-space set of reduce methods in Perl.

Reduction is dependent on the stream being appropriately sorted, which can make the combined act of sort and reduce expensive to execute on a single machine. Operations like these are (unsurprisingly) good options for using in the combiner or reducer steps of `HS` operations.

These operations encapsulate the most common types of reduce operations that you would want to do on a dataset; if your operation is more complicated, it may be more effectively performed using buffered readahead and multi-line reducers.

### `sr`: Reduce over entire stream

Let's look at a simple example, summing the integers from 1 to 100,000: 

```bash
$ ni n1E5p'sr {$_[0] + a} 0'
5000050000
```

Outside of Perl's trickiness,that the syntax is relatively simple; `sr` takes an anonymous function wrapped in curly braces, and one or more initial values. A more general syntax is the following: 
 
 ```
@final_state = sr {reducer} @init_state
```

To return both the sum of all the integers as well as their product, as well as them all concatenated as a string, we could write the following:

```bash
$ ni n1E1p'r sr {$_[0] + a, $_[1] * a, $_[2] . a} 0, 1, ""'
55	3628800	12345678910
```
A few useful details to note here: The array `@init_state` is read automatically from the comma-separated list of arguments; it does not need to be wrapped in parentheses like one would use to explicitly declare an array in Perl. The results of this streaming reduce come out on separate lines, which is how `p'...'` returns from array-valued functions


### `se`: Reduce while equal
`sr` is useful, but limited in that it will always reduce the entire stream. Often, it is more useful to reduce over a specific set of criteria.

Let's say we want to sum all of the 1-digit numbers, all of the 2-digit numbers, all of the 3-digit numbers, etc. The first thing to check is that our input is sorted, and we're in luck, because when we use the `n` operator to generate numbers for us, they'll come out sorted numerically, which implies they will be sorted by their number of digits.

What we'd like to do is, each time a number streams in, to check if it  number of digits is equal to the number of digits for the previous number we saw in the stream. If it does, we'll add it to a running total, otherwise, we emit the running total to the output stream and start a new running total.

In `ni`-speak, the reduce-while-equal operator looks like this:

```
@final_state = se {reducer} \&partition_fn, @init_state
```

`se` differs from `sr` only in the addition of the somewhat cryptic `\&partition_fn`. This is an anonymous function, which is can be expressed pretty much a block with the perl keyword `sub` in front of it. For our example, we'll use `sub {length}`, which uses the implicit default variable `$_`, as our partition function.

**NOTE**: The comma after `partition_fn` is important.

```bash
$ ni n1000p'se {$_[0] + a} sub {length}, 0'
45
4905
494550
1000
```

That's pretty good, but it's often useful to know what the value of the partition function was for each partition (this is useful, for example, to catch errors where the input was not sorted). This allows us to see how `se` interacts with row-based operators.

```bash
$ ni n1000p'r length a, se {$_[0] + a} sub {length}, 0'
1	45
2	4905
3	494550
4	1000
```

One might worry that the row operators will continue to fire for each line of the input while the streaming reduce operator is running. In fact, the streaming reduce will eat all of the lines, and the first line will only be used once.

If your partition function is sufficiently complicated, you may want to write it once and reference it in multiple places.

```bash
$ ni n1000p'sub len($) {length $_}; r len a, se {$_[0] + a} \&len, 0'
1	45
2	4905
3	494550
4	1000
```

The code above uses a Perl function signature `sub len($)` tells Perl that the function has one argument. The signature for a function with two arguments would be written as `sub foo($$)`. This allows the function to be called as `len a` rather than the more explicit `len(a)`. The above code will work with or without the begin block syntax.


### `sea` through `seq`: Reduce with partition function `a()...q()`

It's very common that you will want to reduce over one of the columns in the data. For example, we could equivalently use the following spell to perform the same sum-over-number-of digits as we did above. 

```bash
$ ni n1000p'r a, length a' p'r b, se {$_[0] + a} \&b, 0'
1	45
2	4905
3	494550
4	1000
```

`ni` offers a shorthand for reducing over a particular column and everything to
its left:

```bash
$ ni n1000p'r length a, a' p'r a, sea {$_[0] + b} 0'
1	45
2	4905
3	494550
4	1000
```


### `rc`: Compound reduce

Consider the following reduction operation, which computes the sum, mean, min and max.

```bash
$ ni n100p'my ($sum, $n, $min, $max) = sr {$_[0] + a, $_[1] + 1,
                                            min($_[2], a), max($_[3], a)}
                                           0, 0, a, a;
            r $sum, $sum / $n, $min, $max'
5050	50.5	1	100
```

For common operations like these, `ni` offers a shorthand:

```bash
$ ni n100p'r rc \&sr, rsum "a", rmean "a", rmin "a", rmax "a"'
5050	50.5	1	100
```



## Data Development with `ni` and Hadoop

If you screw up your partitioning, you're ruined. 

JSON => Raw TSV => Cleaned TSV => Filtered TSV => Joined TSV => Statistics

If there's a potential problem with a column, you cannot use it as the first column in a reduce. If you do, Hadoop is very unforgiving; you'll end up having to bail on a particular slice of your data, or restart from the last nearly-equally-partitioned step.

Let's say you have data with 3 columns: `user_id`, `geohash`, `timestamp`. 

It's likely that both some of the users and some of the geohashes are spurious.  This will cause us difficulty down the line, for example when we want to join data to each record using geohash as the joining key.

### `:checkpoint_name[...]`: Checkpoints

Developing and deploying to producion `ni` pipelines that involve multiple Hadoop streaming steps involves a risk of failure outside the programmer's control; when this happens, we don't want to have to run the entire job again. 

Checkpoints allow you to save the results of difficult jobs while continuing to develop in `ni`.

Checkpoints and files share many commonalities. The key difference between a checkpoint and a file are:

1. A checkpoint will wait for an `EOF` before writing to the specified checkpoint name, so the data in a checkpoint file will consist of all the output of the operator it encloses. A file, on the other hand, will accept all output that is streamed in, with no guarantee that it is complete.
2. If you run a `ni` pipeline with checkpoints, and there are files that correspond to the checkpoint names in the directory from which `ni` is being run, then `ni` will use the data in the checkpoints in place of running the job. This allows you to save the work of long and expensive jobs, and to run these jobs multiple times without worrying that bhe steps earlier in the pipeline that have succeeded will have to be re-run.

An example of checkpoint use is the following:

```bash
$ rm -f numbers                 # prevent ni from reusing any existing file
$ ni nE6gr4 :numbers
1
10
100
1000
```

This computation will take a while, because `g` requires buffering to disk; However, this result has been checkpointed, thus more instuctions can be added to the command without requiring a complete re-run.


```bash
$ ni nE6gr4 :numbers O
1000
100
10
1
```

Compare this to the same code writing to a file:

```
$ ni nE6gr4 =\>numbers
1000
100
10
1
```

Because the sort is not checkpointed, adding to the command is not performant, and everything must be recomputed.

```
$ ni nE6gr4 =\>numbers O
1000
100
10
1
```

One caveat with checkpoint files is that they are persisted, so these files must be cleared between separate runs of `ni` pipelines to avoid collisions. Luckily, if you're using checkpoints to do your data science, errors like these will come out fast and should be obvious.


### Developing Hadoop Streaming pipelines with checkpoints

As of now, `ni` auto-generates the names for the Hadoop directories, and these can be hard to remember off the top of your head. If you want to 


### Tools for Data Development

1. A good markdown editor; I like Laverna, and it should work on basically all platforms.
2. Infinite patience
3. A reasonable test set.


## Plotting with `ni --js`
Check out the [tutorial](tutorial.md) for some examples of cool, interactive `ni` plotting.

**TODO**: Say something useful.


## Stream Duplication and Compression
In this section, we'll cover two useful operations

We recognize the first and last operators instantly; the middle two operators are new.

### `=[...]`: Divert Stream

The `=` operator can be used to divert the stream Running the spell puts us back in `less`:

```bash
$ ni n10 =[\>ten.txt] z\>ten.gz
ten.gz
```

The last statement is another `\>`, which, as we saw above, writes to a file and emits the file name. That checks out with the output above.

To examine the contents 

Let's take a look at this with `--explain`:

```bash
$ ni --explain n10 =[\>ten.txt] z\>ten.gz
["n",1,11]
["divert",["file_write","ten.txt"]]
["sh","gzip"]
["file_write","ten.gz"]
```


Looking at the output of `ni --explain`:

```
...
["divert",["file_write","ten.txt"]]
...
```

We see that, after `"divert"`, the output of `ni --explain` of the operator within brackets is shown as a list.

`=` is formed of two parallel lines, this may be a useful mnemonic to remember how this operator functions; it takes the input stream and duplicates it.  One copy is diverted to the operators within the brackets, while the other copy continues to the other operations in the spell.

One of the most obvious uses of the `=` operator is to sink data to a file midway through the stream while allowing the stream to continue to flow.

For simple operations, the square brackets are unnecessary; we could have equivalently written:

`ni n10 =\>ten.txt z\>ten.gz`

This more aesthetically-pleasing statement is the preferred `ni` style. The lack of whitespace between `=` and the file write is critical.


##Custom Compound Reduce
#### `rfn`: Custom compound reduce

**TODO: Understand this**

## Partitioned Matrix Operations

Operations on huge matrices are not entirely `ni`ic, since they may require space greater than memory, whichwill make them slow. However, operators are provided to improve These operations are suited best to 


* `X<col>`, `Y<col>`, `N<col>`: Matrix Partitioning
  * **TODO**: understand how these actually work.
* `X`: sparse-to-dense transformation
  * In the case that there are collisions for locations `X`, `X` will sum the values
  * For example: `ni n010p'r 0, a%3, 1' X`

## Disk-Backed Data Closures

* `@:[disk_backed_data_closure]`

## Binary Operations
In theory, this can save you a lot of space. But I haven't used this in practice.

## Less Useful `ni`-specific Perl Extensions


### Array Functions
  * `clip`
  * `within`
  

   
## Writing Your Own `ni` Extensions
**TODO** Understand how this works

## Obscure Interops/Extensions

* [SQL](sql.md)
* [PySpark](pyspark.md)
* [Scripting](script.md)
* [HTTP Operations](net.md)
* [Defining `ni` functions](fn.md)

## More `ni` modules

* Image
* Binary
* Bytestream
* gnuplot


## Perl Operations
`ni` and Perl go well together philosophically. Both have deeply flawed lexicons and both are highly efficient in terms of developer time and processing time. `ni` and Perl scripts are both difficult to read to the uninitiated. They demand a much higher baseline level of expertise to understand what's going on than, for example, a Python script. 

In addition to Perl, `ni` offers direct interfaces to Ruby and Lisp. While all three of the languages are useful and actively maintained, `ni` is written in Perl, and it is by far the most useful of the three. If you haven't learned Perl yet, but you're familiar with another scripting language, like Python or Ruby, I found [this course](https://www.udemy.com/perltutorial/learn/v4/) on Udemy useful for learning Perl's odd syntax.

We'll start with the following `ni` spell.

`$ ni /usr/share/dict/words rx40 r10 p'r substr(a, 0, 3), substr(a, 3, 3), substr(a, 6)'`

The output here will depend on the contents of your `/usr/share/dict/words/`, but you should have 3 columns; the first 3 letters of each word, the second 3 letters of each word, and any remaining letters. On my machine it looks like this:

```sh
aba     iss     ed
aba     sta     rdize
abb     rev     iature
abd     uct     ion
abe     tme     nt
abi     gai     l
abj     udg     e
abl     est     
abo     lis     h
abo     rti     vely
```

Notice that `ni` has produced tab-delimited columns for us; these will be useful for the powerful column operators we will introduce in this section and the next.

```bash
$ ni --explain /usr/share/dict/words rx40 r10 p'r substr(a, 0, 3), substr(a, 3, 3), substr(a, 6)'
["cat","/usr/share/dict/words"]
["row_every",40]
["head","-n",10]
["perl_mapper","r substr(a, 0, 3), substr(a, 3, 3), substr(a, 6)"]
```

We have reviewed every operator previously except the last. 
166 doc/ni_fu.md
# `ni`-fu

`ni`-fu is a companion piece to the [cheatsheet](cheatsheet_op.md). The cheatsheet serves as a reference to `ni` operators, while `ni`-fu serves as a reference for `ni` programming in general, covering topics like configuration, plotting, debugging, and coding best practices.

## How do I write `ni`?

`ni` is a stream-processing language, and each piece of `ni` code (which we call a spell) is a pipeline composed of operators (which maybe we should call "runes" or "glyphs" or something, but we don't). 

This makes it very easy to see `ni` code very easy to debug, even for a beginner.

All you need to do to see a `ni` spell in action is to run each piece from beginning to end.

For example, consider the spell:

`$ ni n3 fAA p'r alph a, a' OB`

If you don't know what this code does, split it up at whitespace between operators, yielding:

```
n3
fAA
p'r alph a, a'
OB
```

To see how this pipeline works, first run it using just the first operator:

```
$ ni n3
1
2
3
```

Pretty straightforward. Now, run the pipeline once again, using the first two operators:

```
$ ni n3 
1	1
2	2
3	3
```

A little more interesting; if you didn't know before, you can use `f` to duplicate columns in the stream. Once more, using the first 3 operators:


```
$ ni n3 fAA p p'r alph a, b'
A	1
B	2
C	3
```

The perl mapper `p'r alph a, b'` printed the Nth capital letter of the alphabet and 

And finally, putting everything together:

```
$ ni n3 fAA p'r alph a, b' OB
C	3
B	2
A	1
```

`OB` sorted the data in reverse numerical order based on column B.

You can see each stage of the pipeline did one transformation to its input data. Thus, if you have a spell whose output you don't understand or know is incorrect, by stepping through the operators, you should be able to see where the data transformation goes wrong.


## What should I know about `ni` configuration?

`ni` has dozens of configuration variables, which can be modified in your `~/.bash_profile`. A few of the most important ones to know about are covered here:

* `NI_PAGER`
  * The default `ni` pager is `less`. Generally, this is a safe and sensible choice. However, when using `ni` inside a Jupyter notebook, for exmaple, `less` will block the notebook, and you'll want to use `cat` or `head -n1000` as your pager, which won't block.
* `NI_NO_MONITOR`
  * The `ni` monitor occasionally causes issues (that are MapReduce-related, if I recall correctly). After working with `ni` for several months, I got a good feel for how fast each operation was and turned off the monitor.
* `NI_HADOOP_MAPREDUCE_CONF` 
  * This is a good place to store your Hadoop MapReduce Job defaults. The format of the 
* `NI_HADOOP_STREAMING_JAR`
  * You'll want to have some control over the Hadoop Streaming JAR that `ni` uses.

## What is `ni` is bad at?

`ni` is good at a lot of things; it's fast, it runs everywhere, it spins up Hadoop Streaming jobs easily, interacts in ways that are highly intuitive with the command line, and much more. However, `ni` has weaknesses of which you should also be aware.

### Processing arbitrary text
  * Newlines in text **will** result in unexpected behavior, since `ni` will interpret the newiline as the beginning of a new line of the stream.
  * On the other hand, `ni` is blazing fast and very flexible when working with structured text.

### Arbitrary JSON operations
  * `ni` _can_ do arbitrary JSON operations, but they are slow.
  * On the other hand, `ni` is blazing fast at doing **very specific** JSON operations.

### Sorting data on a single machine
  * This is not so much a weakness of `ni` as it is a weakness of your machine. It takes an excruciating amount of time to sort a gigabyte compared to processing it. 
  * When you have large quantities of data that need to be sorted, you should use `ni`'s very intuitive MapReduce bindings.

### Fancy Math and Stats
  * `ni` includes `numpy` bindings, but remember that this introduces a dependency on system configuration that should generally be avoided.
  * `ni` is data-processing and data-cleaning first, not math-first language; Spark with MLLib is probably the most appropriate tool if you're looking to do large matrix operations.
  * `ni` does a good job of finding counts and sums, but things like complicated averages, standard deviation, etc. are better done in Python or R.
* That's it. I think. For now.

## Basic `ni` Philosophy and Style

### `ni` is written for concision, fast testing, and productivity.

* Because `ni` processes streams of data in a streaming way, you should be able to build pipelines up from front-to-back, checking the integrity of the output at each step, for example by taking some rows using `r30` and/or sinking the output to a file.
* As a result of this, `ni` spells can be developed completely in the command line; there is:
  * No compilation (in the most common sense).
  * No need for a text editor.
  * No need to switch windows.
  * Nothing stopping you from joyful hacking.
* If you find a common operation is taking a while, there's probably a faster way to do it. Ask. It may require more Perl, though.

### Everything is optional *unless its absence would create ambiguity*.

* Consider the following three `ni` spells, all with the same output.
  * Explicit: `ni n10p'r "HELLO"' p'r lc(a)'`
  * Concise: `ni n10p'HELLO' p'lc a'`
  * Compact: `ni n10pHELLO plc`
* The technical details behind the `ni` parser are out of scope for this tutorial, but note the `ni` parser doesn't **need** quotes around perl snippets if their meaning is clear. It's a matter of programmer style whether you prefer to use them, but over time you'll be able to read both paradigms and likely end up preferring compact code when the meaning is clear.
* `ni` carries over some of the philosophy of implicit and default values from Perl, so you don't need to tell the lowercase function `lc` on what to operate; it will operate on the entire input line.



### `ni` is not meant to be easy to read for those who do not speak `ni`.

* This principle naturally follows from the two, but it is worth articulating to understand why the `ni` learning curve is steep. If you come to `ni` from a Python/Ruby background, with their almost English-like syntax, you may find `ni` unfriendly at first. 
* If you're coming from a heavy-featured scripting language, try to take joy in the speed of development that `ni` provides. `ni`'s row and column selection operations are much easier to discuss than `pandas`' `.loc` and `.ix`, for example.
* Just as most `ni` spells are built front-to-back, they are best understood by `ni` learners back-to-front. By repeatedly clipping operations off the end, you can see the entire sequence of intermediate outputs of the processing pipeline, and the magic of `ni`--building complex processing pipelines from single letters--becomes clear.
* `ni` is magic. Magic is not meant to be understood by the uninitiated. That's why wizards live in towers and why `ni` snippets are properly referred to as spells.


## Understanding the `ni` monitor
More details [here](monitor.md). Overall:

* Negative numbers = non-rate-determining step
* Positive numbers = rate-determining step
* Large Positive numbers = slow step


## Plotting with `ni --js`
Check out the [examples](examples.md) for some examples of cool, interactive `ni` plotting.

### Formula Bar
You can enter ni formulas into the top bar (without the explicit `ni` call).

### Controls

- D : Distance
  - D represents the distance from the camera to the origin
- R : Rotation
  - The first R component is the angle between the image and the plane of the image and the plane of the screen
  - The second R component is the rotation of the image within the plane of the screenin degrees
- x : Dimensional Scaling
  - The first component controls scaling in the direction of the width of the screen;
  - The second component controls scaling in the direction of the depth of the screen;
  - The third component controls scaling in the direction of the height of the screen.

### Viewing a 3D plot to 2D

Set the second x component to 0 to flatten the image's depth dimension; then
set the first R component to 0 and the second R component to 90 to show a
front-facing view of your plot.
340 doc/cheatsheet_op.md
# `ni` Operator Cheatsheet (alpha release)

## Preface

This cheatsheet is meant to be an exhaustive reference to the operators that compose `ni` as a language, except for its many Perl extensions (which have [their own cheatsheet](cheatsheet_perl.md)). This document is designed such that it can be read in order and it should make sense, though it's quite long and light on details.

However, there's a lot more to achieving fluency than just knowing the words; if you use `ni` regularly, you'll be well-rewarded for walking through [`ni` by Example](ni_by_example_1.md), the more formal tutorial. And if you ever write your own `ni` pipelines, you should read [`ni`-fu](ni_fu.md) to learn how to debug them. I guarantee it will save you time.

## Input Operations

* `n`: Integer stream
  * `n#`: Stream the sequence `1..#`, one number per line
  * `n0#`: Stream the sequence `0..#-1`, one number per line
  * `n`: Stream the sequence `1..`, one number per line.
* `<filename>`: File input
  * Automatically decompresses the file and streams out one line of the file out at a time.
  * Files are automatically decompressed from `gzip`, and `bzip`, `xzip` and `lzo` decompression are also supported if you have the binaries.
* `e[<script>]`: Evaluate script
  * evaluate `<script>` in bash, and stream out the results one line at a time.
  * Can also be written `e'<script'`
  * `$ ni n10 e'wc -l'` will count lines.
* `i<text>`: Literal text input
  * `$ ni iOK!` -- add the literal text `OK!` (and a newline) to the stream.
  * `$ ni i'a cat'` -- add the literal text `a cat` (and a newline) to the stream. The quotes are necessary to instruct the `ni` parser where the boundaries of the string are. Double quotes will work as well.
  * `$ ni i[these cats]` -- add a tab-separated line consisting of `these   cats`, and a newline.
* `D:<field1>,:<field2>...`: JSON Destructure
  * `ni` can easily grab scalar fields (i.e. strings, numbers, and nulls) from JSON, For example: `$ ni i'{"hi":5,"there":"alive"}' D:there,:hi` yields `alive	5`
  * The JSON destructurer does _not_ support pulling out list-based fields or nested hashes within JSON.
* `1`: Dummy pulse
  * `$ ni 1` is syntactic sugar for `$ ni n1`. It is useful for launching scripts in Perl, Ruby, Lisp, or Python from `ni`.
  * The `1` operator is primarily used to make a perl script run; it's often more useful in test than in actual development.

## File Operations and Compression
* ` \>filename`: Redirect stream to file and emit filename
  * Consumes the stream and outputs it to the file named `filename`, and emits the filename.
  * Note that there is **no whitespace** between the angle-bracket and the filename.
  * This "literal right angle bracket" operator `\>` is usually much more useful than a file redirect `>`, since the filename(s) output to the stream can be opened using the "literal left angle bracket" operator, `\<`.
* `\<`: Read from filenames
  * Normally when `ni` sees a filename in its instructions, it will open the file and `cat` its contents to the stream.
  * However, if you have a list of filenames, 
  * This tool can be powerful in combination with Hadoop operations, described later.
* `z`: Compress stream
  * Defaults to `gzip` compression, but `xzip`, `bzip`, and others are available. See [`ni` by Example Chapter 1](ni_by_example_1.md) for details.

## Basic Row Operations

The operator `r` is used to filter rows.

  * `$ ni <data> r3` - take the first 3 rows of the stream
    * **CAVEAT:** `r#` is a wrapper over the Unix utility `head`, and emits a `SIGPIPE` which will break Streaming MapReduce jobs. To use `r` in the context of MapReduce, use the safe row operator `rs` instead.
    * `$ ni <data> rs3` - take the first 3 rows of the stream and do not emit a `SIGPIPE`. 
  * `$ ni <data> r-3` - take everything after the first 3 rows of the stream
  * `$ ni <data> r~3` - take the last 3 rows of the stream
  * `$ ni <data> rx100` - take the first row in the stream, and every 100th row that follows. 
  * `$ ni <data> r.05` - sample 5% of the rows in the stream.
    * The sampling here is deterministic (conditioned on the environment variable `NI_SEED`) and will always return the same set of rows.
  * `$ ni <data> r/<regex>/` - take rows where `<regex>` matches.

## Basic Column Operations
Columns are referenced "spreadsheet-style"--the first column is `A`, the second is `B`, etc.

* `f`: Take columns
  * `$ ni <data> fAA` - select the first column and duplicate it
  * `$ ni <data> fAD.` - select the first column and all remaining columns starting with the fourth
  * `$ ni <data> fB-E` - select columns 2-5
  * `$ ni <data> fCAHDF` - selects columns 3, 1, 8, 4, 6, and streams them out in that order.
  * `$ ni <data> f#<N1>,#<N2>`, selects data from (zero-indexed columns <number1> and <number2>).
      * This can be used to select columns beyond the 26th column. `$ ni <data> f#87,#45,#9,#18` will take the 88th, 46th, 10th, and 19th columns from the data source.
      * Every column operation written with letters can be rewritten using the numeric form:
          * `$ ni <data> f#0,#0` is equivalent to `$ ni <data> fAA`
          * `$ ni <data> f#0,#3.` is equivalent to `$ ni <data> fAD.`
          * `$ ni <data> f#1-#4` is equivalent to `$ ni <data> fB-E`
          * `$ ni <data> f#2,#0,#7,#3,#5` is equivalent to `$ ni <data> fCAHDF`
* `r<cols>` - take row if exists
  * `$ ni <data> rCF` - take rows where columns 3 and 6 are nonempty.
* `F`: Split stream into columns
  * `F:<char>`: split on character
      * **WARNING**: this does not work with certain characters that need to be escaped; use `F/regex/` below for more flexibility (at the cost of less concision).
  * `F/regex/`: split on occurrences of regex. If present, the first capture group will be included before a tab is appended to a field.
  * `Fm/regex/`: don't split; instead, look for matches of regex and use those as
  the field values.
  * `FC`: split on commas (doesn't handle special CSV cases)
  * `FV`: parse CSV "correctly", up to newlines in fields.
  * `FS`: split on runs of horizontal whitespace
  * `FW`: split on runs of non-word characters
  * `FP`: split on pipe symbols
* `x`: Exchange columns
  * `x`: exchange the first two columns. 
      * `$ ni data x` is equivalent to `$ ni data fBA.`
  * `xC`: exchange column 3 with column 1. 
      * `$ni data xC` is equivalent to `$ ni data fCBA.`
  * `xBE`: exchange columns 2 and 5 with columns 1 and 2. 
      * This runs in order, so `B` will be switched with `A` first, and whatever is in the second column now will be switched with column `E`. 
      * `$ ni data xBE` is equivalent to `$ ni data fBECDA.`

  
## Sort, Unique & Count Operations

* **WARNING**: Sorting is often a rate-limiting step in `ni` jobs, as data will need to be buffered to disk if a sort is too large to fit in memory. If your data is larger than **1 GB**, you should consider distributing your workload using Hadoop operations.
* `g`: General sorting
  * `gB` - sort rows ascending by the lexicographic value of the second column
    * Lexicographic value is determined by the ordering of characters in the ASCII table.
    * `ni ia iC g` will put the capital `C` before the lower-case `a`, because capital Latin letters precede lowercase Latin letters in ASCII.
  * `gC-` - sort rows *descending* by the lexicographic value of the third column
   * `gCA-` - sort rows first by the lexicographic value of the third column, ascending. For rows with the same value for the third column, sort by *descending* value of the first column.
  * `gDn` - sort rows ascending by the *numerical* value of the fourth column.
  * `gEnA-` - sort rows ascending by the numerical value of the fifth column; in the case where values in the fifth column are equal, sort by the lexicographic value of the first column, descending.
    * **CAVEAT**: The numeric sort works on integers and floating-point numbers written as decimals. The numeric sort will **not** work on numbers written in exponential/scientific notation
* `u`: unique sorted rows
  * `$ ni <data> fACgABu`: get the lexicographically-sorted unique values from the first and third columns of `<data>`.
* `c`: count sorted rows
  * `$ ni <data> fBgc`: return the number of times each unique value of the second column occurs in `<data>`
  * Note that the above operation is superior to `$ ni <data> gBfBc` (which will give the same results), since the total amount of data that needs to be sorted is reduced.
* `o` and `O`: Numeric sorting
  * `o`: Sort rows ascending (numerical)
    * `oA` is syntactic sugar for `$ ni <data> gAn`
  * `O`: sort rows descending (numerical)
    * `OB` is equivalent to `$ ni <data> gBn-` 
  * **Important Note**: `o` and `O` sorts *cannot be chained together* or combined with `g`. There is no guarantee that the output of `$ ni <data> gAoB` will have a lexicographically sorted first column, and there is no guarantee that `$ ni <data> oBOA` will have a numerically sorted second column. If you want to sort by multiple conditions, you must use `g`.

## Cell Operations 
`$ ni <data> ,<op><columns>`

These provide keystroke-efficient ways to do transformations on a single column of the input data. Of particular use is the deterministic hashing function, which does a good job of compacting long IDs into 32-bit integers.


* `,a`: Running average
* `,d`: Difference between consecutive rows
* `,e`: Natural exponential (`e**x`)
* `,h`: Murmurhash (deterministic 32-bit hash function)
* `,j<amt>`: Jitter (add uniform random noise in the range `[-amt/2, amt/2]`)
* `,l`: Natural log (`ln x`)
* `,s`: Running sum 
* `,q`: Quantize
* `,z`: Intify (hash and then convert hash values to integers starting with 1)
* `,t`: Convert timestamp to readable ISO 8601 form
* `,g`: Geohash encode
* `,G`: Geohash decod3


## HDFS I/O & Hadoop Streaming
### How `ni` Interacts with Hadoop Streaming
When `ni HS...` is called, `ni` packages itself as a `.jar` to the configured Hadoop server, which includes all the instructions for Hadoop to run `ni`.

When `ni` uploads itself, it will also upload all data that is stored in data closures; if these closures are too large, the Hadoop server will refuse the job.

### Hadoop Operators
* `hdfs://<path>`: HDFS `cat`
  * Equivalent to `hadoop fs -cat <path>`
* `hdfst://<path>`: HDFS `text`
  * Equivalent to `hadoop fs -text <path>`
* `hdfsj://<path>`: HDFS `join`
  * Identifies the correct file within the directory `<path>` that should be joined with the map file (in a Hadoop Streaming context), `$ENV{mapreduce_map_input_file}` 
* `HS[mapper] [combiner] [reducer]`: Hadoop Streaming Job
  * Any `ni` snippet can be used for the mapper, combiner, and reducer. Be careful that all of the data you reference is available to the Hadoop cluster; `w/W` operations referencing a local file are good examples of operations that may work on your machine that may fail on a Hadoop cluster with no access to those files.
  * `_` -- skip the mapper/reducer/combiner. 
  * `:` -- apply the trivial operation (i.e. redirect STDIN to STDOUT) for the mapper/reducer/combiner
  * If the reducer step is skipped with `_`, the output may not be sorted, as one might expect from a Hadoop operation. Use `:` for the reducer to ensure that output is sorted correctly.
  * Remember that you will be limited in the size of the `.jar` that can be uploaded to your Hadoop job server; you can upload data closures that are large, but not too large.
* Using HDFS paths in Hadoop Streaming Jobs:
  * `ni ... ihdfst://<path> HS...`
  * The path must be input as literal text (with `i`) so that `ni` knows to get the data during the Hadoop job.
  * <span style="color:red">**WARNING**</span> if you do not use a literal path, for example with `ni hdfst://...`, `ni` will try to download all of the data, then upload the data to HDFS, and then run the job.
  * If you find that a job takes over a minute to start, you may want to check that you haven't made this error.


## SSH and Containers
* `s<host>[...]`: execute `[...]` in `<host>`
  * You will need to set up your hosts properly in your `.ssh/config` to use a named host. 
  * Remember that within the bracketed operator, you will have access to the `<host>` filesystem.
* `C<container_name>[...]`: execute `[...]` in `<container_name>`
  * Running in containers requires that Docker be installed on your machine.
  * Running containers can be especially useful to take advantage of better OS-dependent utilities.
  * For example, Mac OS X's `sort` is painfully slow compared to Ubuntu's. If you are developing on a Mac, there will be a noticeable performance difference increase if you replace: `ni n1E7 g` with `ni n1E7 Cubuntu[g]`, because the sort will be done in the faster Ubuntu container.
  * Containers are also useful for testing the portability of your code.


## Horizontal Scaling
Note that you will need sufficient processing cores to effectively horizontally scale. If your computer has 2 cores and you call `S8`, it may slow your work down, as `ni` tries to spin up more processes than your machine can bear.

* `S`: Horizontal Scaling 
  * `$ ni <data> S<# cores>[...]`: distributes the computation of `...` across `<# cores>` processors.

## Intermediate Column Operations
We can weave together row, column, and Perl operations to create more complex row operations. We also introduce some more advanced column operators.

* `j` - streaming join
  * This will (inner) join two streams using one or more of their columns as a key; if not specified, the key will be the first column  which is assumed to be sorted.
  * Adding columns to the operator will use those as the join column. `jAB` will join on the first two columns the left and the right datasets.
* `w`: Append column to stream
  * `$ ni <data> w[np'a*a']`
  * `w` will add columns only up to the length of the input stream
* `W`: Prepend column stream
  * `$ ni <data> Wn` - Add line numbers to the stream (by prepending one element the infinite stream `n`)
  * `W` will add rows only up to the length of the input stream
* `v`: Vertical operation on columns
  * **Important Note**: This operator is too slow to use in production.


## Data Closures and Checkpoints
Data closures are compiled into the `ni` source before the pipeline is executed. This allows them to serve the function of a broadcasted dataset across nodes in a distributed context. Closures can be accessed from within Perl snippets by using their name.

* `::closure_name[...]`: Create a data closure
  * A common motif for closures is using them as a filter:

```
$ ni ::good_points[i100 i3 i76] \
	n100 rp'^{%h = ab_ good_points} exists($h{+a})'
```

  * Here we've created a closure called `good_points` which contains the data `100\n3\n76\n` as a string (initially). We use some Perl (see the [Perl Cheatsheet](cheatsheet_perl.md) for details) to convert those lines into a Perl hash called `%h`, whose keys are  and we check whether the value of the first column `+a` exists as a key in the hash
  * Closures are computed separately from each other, which means that one closure cannot in general reference the value of another closure. If you find a situation where you need to create a closure that depends on the value of another closure, this is likely not (currently) good `ni` style, and you should look for another way to solve the problem.

* `@:[disk_backed_data_closure]`: Create disk-backed data closure.
  * A disk-backed data closure operates in much the same way as a regular data closure.
  * In general, backing your data closures to disk is a way to get around memory restrictions on machines when using particularly large data closures.
  * Disk-backed data closures may fail in environments where you have restrictions about writing to disk (_e.g._ in Hadoop mappers or reducers).
* `:<checkpoint_name>`: Create a checkpoint
  * Checkpoints are useful for building extended pipelines, especially ones with long-running or expensive operations (_e.g._ Hadoop MapReduce jobs).
  * The use of checkpoints is a bit too tricky for your author's taste, but you are likely smarter than he.
  * Here's an appropriate (if contrived) use of checkpoints:
     * `$ ni nE7 g :alpha_numbers r3`
     * With the checkpoint, the result of `$ ni nE7 g` will be stored in `:alpha_numbers`, and you can re-run the spell quickly.
     * Without the checkpoint, the entire sort would have to be re-run each time, which takes a painfully long amount of time.
     * In the background, `ni` is sinking the data from `$ni nE7 g` to a file called `alpha_numbers`. 
     * **<span style="color:red">WARNING</span>**: Once a checkpoint has been written once, it will remain the same. For example, if, after running `$ ni nE7 g :alpha_numbers r10` you run `$ ni n1000 g :alpha_numbers r10`, `ni` will start using the previous `alpha_numbers` checkpoint data. This failure mode is silent, so **BE CAREFUL!!** (Or don't use them, like me).
     * Checkpoints are also disk-backed, which means they suffer from many of the same limitations as disk-backed data closures. 

## Filename-Prepending File Operations
* `W\<`: Read from files and prepend filename
  * The `\<` operator will read data from files, but will not state which file each line came from.
  * `W\<` does the same thing as `\<` except it prepends a column to the output data with the name of the file the data came from.
* ` W\>`: Redirect filename-prepended stream to files
  * This operator consumes stream data with lines of the form `<filename> <data1> <data2> ... <dataN>` and outputs the lines `<data1> <data2> ... <dataN>` to `<filename>`, and outputs `<filename>`
  * Be aware that input data should be in sorted order; `ni i[a.txt 1] i[b.txt 2] i[a.txt 3]` will leave file `a.txt` with only one line with the value `3`.


## Matrix Operations
* `Y` - dense-to-sparse transformation
  * Explodes each row of the stream into several rows, each with three columns:
    * The index of the row that the input data that came from
    * The index of the column that the input data came from
    * The value of the input stream at the row + column specified by the first two columns.
* `X` - sparse-to-dense transformation
  * `X` inverts `Y`; it converts a specifically-formatted 3-column stream into a multiple-column stream.
  * In the case that there are collisions for locations `X`, `X` will sum the values
  * For example: `ni n010p'r 0, a%3, 1' X`
  * The specification for what the input matrix must look like is described above in the `Y` operator.
* `N'x = ...'`: Numpy matrix operations
  * Dense matrices can be transformed using Numpy-like operations
  * The entire input matrix (i.e. the stream) is referred to as `x`.
  * Example: `ni n10p'r map a*$_, 1..10' N'x = x + 1'` creates a matrix and adds one to every element with high keystroke efficiency.
  * Example `ni n5p'r map a*$_, 1..10' N'x = x.T'`
  * You also have available the entire numpy package at your disposal:
    * Example: `ni n10p'r map a*$_, 1..10' N'x = dot(x, x.T)'`
    * Example: `ni 1N'x = random.normal(size=(5,3))'`
  * Note that your statements must always store the matrix back in the variable `x`.

## Stream Operations

* `%<#>[stream]`: interleave streams
  * This is the most useful of the operations, especially for plotting data using `ni --js`.
  * `%`
  * **CAVEAT**: Interleaving is not an exact operation (though it's negligibly close for large datasets), and output can somewhat depend on the speed with which the two streams are generated.
* `=`: duplicate this stream and discard its output
  * The best use of this operation is to sink data to a file in the middle of a pipeline without impeding its progress.
  * `$ ni n100 =\>hundo.txt fAA p'r a*3, b' \>other.txt` will sink the stream after `$ ni n100` to a file called `hundo.txt`, while still allowing the data to be processed through the rest of the pipeline.
* `+`: append a stream
  * In general, a stream written later in the spell will be appended automatically to the stream that comes before it; I rarely use this.
  * `$ ni ia +ib` yields `a`, then `b`, the same as `$ ni ia ib` would. Not very useful.
* `^`: prepend a stream 
  * This is a more useful operator than `+` in theory, but it is also rarely used, since it in general makes more sense to order the streams.
  * `$ni ia ^ib` yields `b` then `a`. Slightly useful!



## Partitioned Matrix Operations
One improvement of `ni` over its predecessor, [`nfu`](github.com/spencertipping/nfu) is that mathematical operations on tall and wide matrices have better support through partitioning.

Some matrix operations are not performant in `ni` because they may require space greater than memory. If you're doing a lot of complex matrix operations, `ni` may not be the right tool. However, `ni` does provide some 

* `Y<col>`: Dense-To-Sparse Transform with Partitioning


```bash
$ ni i[a b c d] i[a b x y] i[a b foo bar] YC
a	b	0	0	c
a	b	0	1	d
a	b	1	0	x
a	b	1	1	y
a	b	2	0	foo
a	b	2	1	bar
```

`Y` has reduced over the first two columns of the data, and kept their values in the first two columns of its output. The next two columns represent the row and column in the matrix as the normal `Y` operator does, and and the final column has the value.

* `N<col>`: Numpy on Dense Partitioned Matrix

Reduces over the columns before `<col>`, and then does the standard `N` operation.

```bash
$ ni i[a b 1 5] i[a b 100 500] i[a b -10 -20] \
     i[c d 1 0] i[c d 1 1] \
      NC'x = dot(x.T, x)'
a	b	10101	50205
a	b	50205	250425
c	d	2	1
c	d	1	1
```

* `X<col>`: Sparse-To-Dense Transform of Partitioned Data

`X<col>` inverts `Y<col>`.

```bash
$ ni i[a b c d] i[a b x y] i[a b foo bar] YC XC
a	b	c	d
a	b	x	y
a	b	foo	bar
```


## Things other than Perl 

Don't use things other than Perl. Here are other things:

*  `m'<...>'`: Ruby
   * applies the Ruby snippet `<...>` to each row of the stream 
*  `l'<...>'`: Lisp
   * applies the Lisp snippet `<...>` to each row of the stream 

I have only ever used the Ruby extension, and only to us a library not written in `ni`.

Keep in mind that code written in any other language will not be portable and result in configuration headaches. For example, if you have a Ruby gem installed on your local machine and are able to run a `ni` spell on your local, you will have to install the same gem on your remote machine to use it over SSH. Moreover, if you want to run the same task on your Hadoop cluster, you'll have to have the gem installed on every node of the cluster 

When I need another language for its library, I'll usually create a copy of the (part of the) library that I need and add it to `ni` instead.


## Binary Operations
The primary use of binary operations is to operate on data that is most effectively represented in raw binary form (for example, `.wav` files). See the [binary docs](binary.md) until I figure out something useful.
415 doc/cheatsheet_perl.md
# `ni` Perl Cheatsheet (alpha release)

`ni` fully supports Perl 5 with backwards compaitibility to 5.08, and most of your `ni` scripts likely should be written in Perl. 

`$ ni data p'<...>'` applies the Perl snippet `<...>` to each row of the stream.

## Printing and Returning Data
  * `p'r ..., ..., ...'`: Print all comma separated expressions to one tab-delimited row to the stream.
  * `p'<statements>; <$val1>, <$val2>, ...'`: Returns each element `<$val1>`, `<$val2>`,... on its own line.
  * Examples:
      * `ni 1p'20, 30'` returns `20` and `30` on separate lines.
      * `ni 1p'r 20, 30'` returns `20	30` on a single, tab-separated line.
      * Recall that `1` is the same thing as `n1`.
  * The `p'...; r ..., ...'` operator is used more frequently, 
  * There are some tricks to how `ni` prints data from references.
  * For example:
      * `$ ni 1p'[hi, there]'` returns `hi	there` on a single tab-separated line:
      * `$ ni 1p'r [hi, there]'` prints `ARRAY(0x7fa31dbc5b60)`.



## Basic Perl Syntax

### Data Types

Perl has a relatively small number of data types, and for the purpose of this cheatsheet you really only need to know about these three:

* Scalars -- numbers, strings
* Arrays -- Arrays are written with parentheses
* Hashes -- 
* References: References are in fact just a special type of scalar used to refer to one of the other data types
  * Array references are written inside square brackets
  * Hash references are written inside curly braces

### Sigils

Perl variables are indexed with "sigils" to signify their type. This can be a little tricky for Perl beginners, so let's review quickly.

* `$x` is a scalar (a number, string, or reference to one of the other types).
* `@x` is an array.
* `$x[0]` is a scalar (its sigil is `$`), whose value is the first element of the array `@x`. Perl knows that you're referring to an the array `@x` because you're indexing with square brackets.
* `%h` is a hash.
* `$h{"bar"}` is a scalar (its sigil is `$`), and it is the value of `%h` associated with the key `"bar"`. Perl nows you're referring to the hash `%h` because you're indexing it with curly braces.
* Because sigils make the langauge very explicit, it is possible (though not advisable) to have a hash `%u`, an array `$u`, and a scalar `$u`, which have nothing to do with each other.
* `foo` (without a preceding sigil) is called a "bareword." There are Parsing rules for barewords are If there is a function with no arguments called `foo`, 


### Caveats

* There are no key errors and no index errors in Perl
* If you try to reference a key or index that does not exist, the hash or array will automatically create 
* If you try to operate on an undefined value, it will define itself to be compatible with the operation you use and default to zero, the empty string, the empty array/hash, etc.


### Lexical scoping

Perl is lexically scoped; in general, when using `ni`, you will want to prefix every variable you define within a Perl mapper as scoped to the block, using the keyword `my`, as in `$ ni n10 p'my $x = 0; r $x'`

The exception to this rule is for variables defined within a begin block. In this case `my` is not used at all. See: `$ ni n10 p'^{$x = 0} $x += 1; r $x'`.

### Reference Basics

* To convert an object to a reference, use a backslash.
* Example: `my $x = "nice ref!"; my $xref = \$x; r $xref` will print something like `SCALAR(0x7fc809a8ed20)`. 
* To convert a reference back to a particular value type, wrap the reference in curly braces and prepend with the correct sigil.
* Example: `$ ni 1p'my $x = "nice ref!"; my $xref = \$x; r ${$xref}'` prints `nice ref!`.
* The curly braces are not always necessary, so you may also see confusing-at-first-blush compound sigils, as in: `$ ni 1p'my $x = "nice ref!"; my $xref = \$x; r $$xref'` which also prints `nice ref!`.
* Dereferencing is time-consuming and can significantly degrade performance when used carelessly.

  
## Field Selection

### `a` through `l`: Short field access
  * `a` through `l` are functions that access the first through twelfth fields of an input data stream. 
  * `$ ni i[one two three four] p'r d, b'` prints `four	two` to the output stream. 
* In the context of hash lookup, the functions `a` through `l` without parentheses will be interpreted as strings; in this case, you must use the more explicit `a()` syntax. 
  * `$h{a}` tries to retrieve the key associated with the string `"a"` from the hash `%h`.
  * `$h{a()}` or `$h{+a}` tries to retrieve the key associated with the value of the function `a`, _i.e._ the value in the first column.

```
$ ni ihi p'my %h = ("hi", "bye", "a", "eiou");
           r $h{a}, $h{+a}, $h{a()}'
``` 
returns `aeio	bye	bye`. Inside hash-lookup braces (among other places), prefixing a bareword with the `+` operator tells Perl to interpret it as a function call. This is useful in a number of contexts where 

### `F_`, `FM`, `FT`, `FR` : Explicit field access

* `F_`: returns the values of the tab-separated columns as an array.
  * `F_(@inds)` will return the values of 
* `FM`: returns the index of the largest defined index in `F_` (`== @r = F_; $#r`)
* `FR $n`, `FT $n`: `F_` fRom, `F_` To
  * `FR $n` returns `F_` starting from and including position `$n` to the end of `F_`. 
  * `FT $n` returns `F_` starting from index `0` up to and including index `$n-1`. 
  * `F_ == FT $n, FR $n`.

## `rp'...'`: Take rows with Perl

This operator combines the `r` operator from the [operator cheatsheet](cheatsheet_op.md) with Perl, and takes every line that evaluates to true.

* `$ ni <data> rp'<...>'` - take rows where the Perl snippet `<...>` returns a truthy value in Perl. 
* Be careful using `rp'...'` with numeric values, because `0` is falsey in Perl. `$ ni n10 p'r a, 0' rp'b'` returns an empty stream. 

## Important Perl Builtins

If you are unfamiliar with these functions, they are explained more extensively in [Chapter 2 of `ni` by example](ni_by_ex_2.md).


### String Utilities
* `lc`
* `uc`
* `substr`
* `split`
* `join`

### List Utilities
* `map`
* `grep`
* `keys`
* `values`
 
### Regular Expressions
* `$<v> =~ /regex/` -- standard regex form
* `$<v> =~ s/regex//` -- substitution
* `$<v> = tr/regex//` -- transliteration (also can be done with `y/regex//`)

### Logical and Existence Operators
* `exists` -- truthy when a key exists in a hash, falsey otherwise
* `defined` -- truthy when a value is not `undef`, falsey otherwise
* `&&`, `||` -- high priority boolean operators; use to perform boolean operations directly on scalar values 
* `//` -- "logical-defined OR"; `//` is identical to `||`, except it returns the first value if it is *defined* rather than if it is *truthy*.
* `&&`, `||`, and `//` return the last value evaluated, unlike the corresponding C operators, which return `0` and `1`.
* `and`, `or` -- low priority boolean operators; use to logically join compound statements


### BEGIN and END Blocks
* `p'^{<begin_block>} ...'`: Begin block
  * A begin block is indicated by attaching a caret (`^`) to a block of code (encolsed in `{ }`). Outside of begin blocks, the Perl code is evaluated for every row; inside a begin block, the code is evaluated once and this evaluation occurs before any other code in the mapper is evaluated.
  * Begin blocks are useful for converting data closures to Perl data structures, and defining things like constants and counters that should be maintained over runs with different rows.
* `p'...; END {<end_block>}'`
  * Similar to a begin block, these run only once the last line of the input stream has been processed. These are useful for emitting the value of counters and data structures that have been accumulated over all of the rows of a computation.



## Useful `ni`-specific Perl Subroutines


### Line Utilities

* Line Reading
	* `rl($n)`: read lines
	  * returns an array consisting of the next `$n` lines of the stream, including the current line.
	  * When `rl` is executed without an argument, the current line is ignored, the next line in the stream is added to the pushback queue. 
	* `pl($n)`: peek lines
	  * `pl` ignores the current line, peeks ahead `$n` lines until the global pushback queue is full. Once the pushback queue is full, it does not pull in additional lines, and returns the value of the pushback queue.
* Buffered Readahead
   * Whereas `rl` and `pl` tab split their data, the buffered readahead options do not.
	* `rw`: read while
	  * `@lines = rw {condition}`: read lines while a condition is met
	* `ru`: read until
	  * `@lines = ru {condition}`: read lines until a condition is met
	* `re`: read equal
	  * `@lines = re {condition}`: read lines while the value of the condition is equal.
	  * `@lines = re { b }` will put text lines into `@lines` where `b` is constant.


### List Utlities

* List Access
  * `first(@r)`: first element of `@r` (`== $r[0]`)
  * `final(@r)`: last element of `@r` (`== $r[-1]`)
  * `rando(@r)`: a random element of `@r`
* Math and Logic Operations
  * `max(@r)`, `min(@r)`: numeric `max` and `min`
  * `maxstr(@r)`, `minstr(@r)`: lexicographic `max` and `min`
  * `deltas(@r)`, `totals(@r)`: differences of consecutive elements, and running sum of elements.
  * `argmax(&block, @r)`, `argmin(&block, @r)`: returns the value of the element of `@r` that maximizes (minimizes) `&block`.
  * `indmax(&block, @r)`, `indmin(&block, @r)`: returns the index of the element of `@r` that maximizes (minimizes) `&block`.
  * `any(&block, @r)`, `all(&block, @r)`
     * Returns logical `or` (`and`) of `&block` applied to all of the elements of `@r`.
* Count and Unique
  * `uniq(@r)`: list of unique elements of `@r`
  * `freqs(@r)`: hash of the count of each unique element in `@r`
    * `freqs` returns a reference; it's commonly used as `p'...; my %h = %{freqs @r}; ...'`.
* Functional Programming
  * `take($n, @r)`, `drop($n, @r)`: take or drop the first `$n` elements of `@r` and return the result.
  * `take_while(&block, @r)`, `drop_while(@r, &block)`: takes or drops elements from `@r` while the block `&block` is true. 
  * `take_every($n, @r)`, `take_even(@r)`, `take_odd(@r)`: takes every `$n`th value, every value at an even index in the list, and every odd value of the list.
  * `reduce(&block, $start, @r)` executes 
     * Returns the result of iteratively applying `$start = &block($start, shift @r)`.
  * `reductions(&block, $start, @r)`
      * Returns a list consisting of all of the intermediate values computed in `reduce`.
* Cartesian Product
  * `cart`: Cartesian Product
* Functions on arrays of text lines
  * A number of functions described later (namely `re`, `ru`, `rw`) will read in lines of text without tab-splitting them.   
  * `a_`, `b_`, and others: get column from lines
     * 
  * `a__`, `b__`, and others: get many columns from lines
     * 

### Math Utilities
* `sum`, `prod`, `mean`, `log2`: standard math functions
* `quant($x, $q)`: rounds `$x` to the nearest `$q`.
* `dot`, `cross`: scalar and vector products
* `l1norm`, `l2norm`: L1 and L2 vector norms
* `interp($f, @r)`: interpolate `$f` numbers between every pair of values in `@r`.
* `proj($v1_ref, $v2_ref)`, `orth($v1_ref, $v2_ref)`: vector projection 
* `rdeg`, `drad`: radius to degrees
* `prec`: polar to rectangular
* `rpol`: rectangular to polar
* `entorpy`: Shannon Entorpy in bits
* `haversine`: haversine formula for arc length

### Geographic Functions
The operators in this section refer specifically to the 
`$ ni <data> p'...'`

* `llg` and `ghe`: Latitude and Longitude to geohash
  * `ghe` is a synonym of `llg` provided for backwards compatibility. `llg` should be favored as more explicit.
  * `llg($lat, $lng, $precision)`
    * If `$precision > 0`, returns a geohash with `$precision` base-32 characters of precision. 
    * If `$precision < 0`, returns a geohash with `$precision` (base-2) bits of precision.
* `gll` and `ghd`: geohash to latitude and longitude
  * `ghd` is a synonym of `gll` provided for backwards compatibility. `gll` should be favored as more explicit.
  * `gll($gh_base32)`
     * Returns the corresponding latitude and longitude (in that order) of the center point corresponding to that geohash.
  * `gll($gh_int, $precision)`
    * If the number of bits of precision is specified, `gll` will decode the input integer as a geohash with $precision bits. Returns the  latitude and longitude (in that order) of the southwesternmost point corresponding to that geohash.
* `g3b` and `gb3`: geohash transcoding
  * 
* `ghb`: geohash box
  * `ghb` takes a base-32 geohash and returns the latitude and longitudes corresponding to the north, south, east, and west corners of a box on the earth enclosing this point.
* `lat_lon_dist`: arc distance between points on the earth
  * `lat_lon_dist` computes the distance in kilometers between two points on the earth, accounting for the earth's curvature.
* `gh_dist`: arc distance between two base-32 geohashes
  * Similar to `lat_lon_dist`, this computes the distance along the earth between the centroids of two geohashes.

#### Tagged Geohashes
A tagged geohash is a binary data format that is used to indicate the precision and value of a geohash in a single 8-byte value.

### Time Functions
* `tpe`: time parts to epoch
  * `tpe(@time_pieces)`: Returns the epoch time and assumes that the pieces are year, month, day, hour, minute, and second, in that order.
  * `tpe($time_format, @time_pieces)`: Returns the epoch time, using `$time_format` to determine what the ordered `@time_pieces` are.
* `tep`: time epoch to parts
  * `tep($epoch_time)`: returns the year, month, day, hour, minute, and second in human-readable formatfrom the epoch time.
  * `tep($time_format, $epoch_time)`: returns the specified parts of the date using following `$time_format`.
* `tsec`: Timezone offset in seconds
  * `tep($raw_timestamp + $tsec($lat, $lng))` returns the approximate date and time at the location `$lat, $lng` at a Unix timestamp of `$raw_timestamp`.
* `i2e($iso_8601_time_string)`: ISO-8601 to Epcoh
  * Converts a time in ISO-8601 form to an epoch timestamp.
* `e2i($timestamp, $timezone)`: Epoch to ISO-8601
  * Converts a timestamp in epoch form to ISO-8601
* `ym`: year and month
  * Input: a unix timestamp (seconds since the epoch)
  * Output: the year and month
  * Example: `$ ni i1508348294 p'r ym a'` returns `2017_10`
* `how`: hour of day and weekday
  * Input: a unix timestamp (seconds since the epoch)
  * Output: the day of week and hour of day
  * Example: `$ ni i1508348294 p'r how a'` returns `Wed_17`
* `ttd`, `tth`, `tt15`, `ttm`: Truncate to day, hour, quarter-hour, minute
  * Input: a unix timestamp (seconds since the epoch)
  * Output:
      * `ttd`: the first second of the day that of the argument
      * `tth`: the first second of the hour of the argument
      * `tt15`: the first second of the quarter-hour of the argument 
      * `ttm`: the first second of the minute of the argument
  * Example: `$ ni i1508348294 p'r ttd a, tth a, tt15 a, ttm a'` returns `1508284800	1508346000	1508347800	1508348280`
* `ghl($timestamp, $gh)` and `gh6l($timestamp, $gh60)`: geohash localtime and geohash-60 localtime
  * Input:
  * Output:
  * Example:


### File Utilities

* File Reading
  * `rf`: reads the lines of a file and returns the result as a newline-separated string
  * `rfl`: reads the lines of a file and returns each line as one element of an array.
  * `rfc`: does `rf`, and returns the output after `chomp`ing any trailing newlines.
* File Writing
  * `wf`: write to file
  * `af`: append to file

### Directory Operations
  * `dirbase`: splits the path path `a/b/c` into the base directory name and the final directory or filename. `$ ni ix/y/z p'r dirbase a` returns `x/y	z`.
  * `basename`: splits the last filename or directory off a path. `$ ni ix/y/z p'r dirbase a` returns `x/y`.
  * `dirname`: splits the last filename or directory off a path. `$ ni ix/y/z p'r dirname a` returns `z`.
  * `mkdir_p`: make a directory and all necessary enclosing directories.


### String Utilities
* `startswith($target, $prefix)`, `endswith($target, $suffix)`: returns `1` if the `$target` string starts with (ends with) `$prefix` (`$suffix`).
* `alph($n)`: returns the `$n`th lowercase letter of the alphabet.

### Hash Utilities

* `kbv_dsc(%h)`, `kbv_asc(%h)`: returns the keys of `%h` sorted by the associated value
* `merge_hashes(\%h1, \%h2, \%h3, ...)`, `merge_two_hashes`: merges two hashes using the following recursive strategy:
  * If a key exists in the first hash or the second hash, but not both, add the key and its associated value to the first hash
  * If the key exists in both the first and se
* `sum_hashes`, `sum_two_hashes`: 
* `accumulate_hashes`, `accumulate_two_hashes`
* Hash Constructors
  * `ab_` and others
  * `abS` and others
  * `abSNN` and others
  * `abC` and others
* `p'%h = <col_1><col_2>_ @lines`: Hash constructor
  * Hash constructors are useful for filtering large datasets without having to invoke an expensive sort or an HDFS join. Hash constructors are useful inside of begin blocks, often using the following workflow:
    * Generate a list of things you want to filter, and put it in a data closure. `::ids[list_of_ids]`
    * Convert the data closure to a hash using a begin block (`^{%id_hash = ab_ ids}`)
    * Filter another dataset (`ids_and_data`) using the hash (`exists($id_hash{a()})`)
    * `$ ni ::ids[list_of_ids] ids_and_data rp'^{%id_hash = ab_ ids} exists($id_hash{a()})'`

### JSON Utilities

* Full-Featured but slow
  *  `p'json_encode {hash reference}`: JSON Encode
  * `json_decode`
* Partial-Featured but fast
  * `get` methods 
 	 * `get_scalar($k, $json_str)`
 	 * `get_array($k, $json_str)`
 	 * `get_hash($k, $json_str)`
 * `merge` methods
 	 * `string_merge_hashes($hash_str1, $hash_str2)`: merges two hashes 
 * `delete` methods
   * `delete_scalar($k, $json_str)` 
   * `delete_array($k, $json_str)` 
   * `delete_hash($k, $json_str)` 


### Debugging Utilities
* `dump_data`


## Basic Perl Reducers

The operations here are generally dependent on sorting to function properly, which can make them very expensive to execute on a single machine.

### Streaming Reduce
These operations encapsulate the most common types of reduce operations that you would want to do on a dataset; if your operation is more complicated, it may be more effectively performed using the buffered readahead and line-array reducers.

* `sr`: Reduce over entire stream
  * `$ ni n1E5p'sr {$_[0] + a} 0'`: sum the integers from 1 to 100,000
* `se`: Reduce while equal
  * `@final_state = se {reducer} \&partition_fn, @init_state`
* `sea` through `seq`: Reduce with partition function `a()...q()`
* `rc`: Compound reduce
* `rfn`: Custom compound reduce




## Multiline Reducers
These operations can be used to reduce the data output by the readahead functions. Look at the input provided by the first perl statement, 

* `ni n1p'cart ["a", "b", "c"], [1, 2]' p'sum b_ re {a}'`
* `ni n1p'cart ["a", "b", "c"], [1, 2]' p'sum a_ re {b}'`

`reA` is the more commonly used shorthand for `re {a}`

* `ni n1p'cart ["a", "b", "c"], [1, 2]' p'r all {a_($_)} reB'`
* `ni n1p'cart ["a", "a", "b", "c"], [1, 2]' p'r uniq a_ reB'`
* `ni n1p'cart ["a", "b", "c"], [1, 2]' p'r maxstr a_ reB'`
* `n1p'cart ["a", "b", "c"], [1, 2]' p'r reduce {$_ + $_[0]} 0, b_ reA'` 

`reB` reduces where both of the first _two_ columns are equal, and `reC` reduces where the first _three_ columns, etc.

## Data Closures in Perl Mappers

Data closures are useful in that they travel with `ni` when `ni` is sent somewhere else, for example over ssh, or as a jar to a Hadoop cluster. Importantly, closures can be accessed from within Perl snippets by using their name.

* `closure_name::[...]`: Create a data closure
  * Any legal `ni` snippet that is executable on the machine from whose context `ni` is being executed.
  * The closure can be referenced within a Perl snippet as  `p' ... closure_name ...'`
* `a_` through `l_`: Multiline Selection Operators
  * Data closures are transferred as an array of lines; in order to access data from a specific column of the data closure, you will need to use multiline operators `a_` through `l_`, which are the multilineanalogs to the line-based operators `a/a()` through `l/l()`.
  * `ni ::data[n1p'cart [1,2], [3,4]'] n1p'a_ data'` works, because `a_` is operating on each element of the array.
  * `ni ::data[n1p'cart [1,2], [3,4]'] n1p'a(data)'` and `ni ::data[n1p'cart [1,2], [3,4]'] n1p'a data'` will raise syntax errors, since `a/a()` are not prepared to deal with the more than one line data in the closure.

## Intermediate Perl Utilities

### Functions

In `ni` you generally should not be defining Perl functions (also called "subroutines").

Perl function definitions are denoted with the keyword `sub`.

Perl functions are often written with a signature that allows them to be written without parentheses. In general, you should use the simplest written form of a function.

### References

* You cannot nest lists or hashes in Perl like you can in Python, and everything that is passed into a Perl function is passed as a flat list;
* Similarly, Perl subroutines also can only return scalars and flat lists. If you want to return multiple lists, or a hash, they must be returned as references.




## Annoyingly Advanced Perl
* `use strict` and the `::` prefix in a Perl Environment
  * When `use strict` is enabled, Perl will complain when you try to create a variable in a Perl snippet that does not start with `::`.
  * The reasons for this are very specific to Perl; if you are a true Perl nerd, you can look them up, but you do not need to know them if you just accept that variables need to start with `::` when you apply `use strict`.
  * It is probably a good idea to `use strict` when the variables you define are sufficiently complex; otherwise you're probably okay not using it.

### Global variables you shouldn't touch
*  `@F`: array of values of the current line. 
 *  Since many other functions depend on `@F`, it is recommended that you use `F_` to access the data indirectly rather than through `@F` itself.
 *  `@F` is re-set every time a fresh line hits the beginning of the Perl mapper.
* `@q`: global pushback queue
  * `@q` persists between fresh lines, and allows past lines to be stored. It is used by `rl` and `pl` to store lines, as well as for the buffered readahead functions `re`, `ru`, `rw`
  * Like `@F`, many functions rely on `@q`; you should not edit or access it directly, and instead use the functions that interact with it.
  * If you want to to store your own array of lines that persists through fresh lines, use a BEGIN block, for example`p'^{@x;} ...; push @x, $data; ...`
126 doc/binary.md
# Binary decoding
ni's row transform operators won't work on binary data because they seek to the
nearest newline. If you want to parse binary data you should use the `b`
operator, which does block reads and provides a byte cursor.

## Generating binary data
You can't use `r()` to emit binary unless you want newlines, but you can print
bytes directly to standard output using `wp` (write-packed) or `ws` (write
string). For example, let's synthesize a one-second wav file:

```bash
$ ni n1p'wp "A4VA8VvvVVvvA4V",
         qw|RIFF 176436 WAVEfmt 16 1 2 44100 176400 4 16 data 176400|' \
     +n44100p'my $v = 32767 * sin a*440*tau/44100;
              wp "ss", $v, $v' \
  > test.wav
```

Note that normally you'd specify the endian-ness of `s` by saying `s<` instead.
However, old versions of Perl don't support endian modifiers so I have to leave
it out of the examples here.

## Perl decoder
The decoding interface consists of four functions:

- `$offset = bi`: absolute offset of the next byte
- `$bytes = pb(n)`: peek and return N bytes
- `$bytes = rb(n)`: consume and return N bytes
- `@value = rp("packstring")`: read, unpack, and consume bytes by pack pattern

For example, we can decode samples from the WAV file above. `bp` means "binary
read with perl":

```bash
$ ni test.wav bp'rp "A4VA8VvvVVvvA4V" if bi == 0;       # skip the header
                 r rp"ss"' r10
2052	2052
4097	4097
6126	6126
8130	8130
10103	10103
12036	12036
13921	13921
15752	15752
17521	17521
19222	19222
```

A faster approach is to use the `bf` operator to read fixed-length packed
records (internally it uses more efficient logic to manage the queue of
incoming bytes):

```bash
$ ni test.wav bf'ss' r-15r10
10103	10103
12036	12036
13921	13921
15752	15752
17521	17521
19222	19222
20846	20846
22389	22389
23844	23844
25205	25205
```

If we wanted to find the dominant frequencies, for example (the `,qB.01`
quantizes the magnitudes so the test case doesn't depend on float rounding):

```bash
$ ni test.wav bp'bi?r rp "ss":rb 44' fA N'x = fft.fft(x, axis=0).real' \
     Wn rp'a <= 22050' OB r5,qB.01
441	45263289.95
14941	755.22
7341	745.63
8461	667.75
12181	620.78
```

### Packed searching/lookup
Perl's normal data structures are optimized for performance rather than small
memory footprint, but sometimes you're up against a hard memory limit. For cases
like this, you can use things like [bloom filters](bloom.md) or, for associative
lookups, binary-search tables.

Let's suppose we want to build a lookup table for the `sin` function. In text
we'd do this:

```sh
$ ni numbers... p'r a, sin(a)' > lookup-table
```

Then we'd have TSV/ascii, which isn't very efficient. If we `pack` each value
into `Nd` (network byte-order `long` followed by a `double`, so 12 bytes per
entry), then we get a much smaller table:

```bash
$ ni nE4 op'wp"Nd", a, sin(a)' > binary-lookup
```

Importantly, we use `o` before `p` because the entries need to be sorted by
lookup key.

#### Lookups
Let's use this lookup table in a random-access way. We can read the whole table
into memory using `ri`, "read into", and then we can use the `bsflookup`
function to binary-search fixed records. Its signature is:

```pl
bsflookup($packed_table,        # contents of binary-lookup
          $key_unpacker,        # "N"
          $record_length,       # 12
          $target_key,          # a number
          $value_unpacker)      # "x4d" (remember to skip over the key)
```

```bash
$ ni nE4 eshuf p'^{ri $table, "<binary-lookup"}
                 r a, sin(a), bsflookup $table, "N", 12, a, "x4d"' \
               rp'b ne c' e'wc -l'      # any records have a failed lookup?
0
```

If a lookup fails, `bsflookup` will return `undef`. You can access the insertion
location for the missing record using `bsf`, which takes the first four args to
`bsflookup` and returns a record index. (`bsflookup` uses `bsf` internally.)
112 doc/closure.md
# Data closures
Sometimes it's useful to bundle data with ni so that it's available on a
different filesystem. Data closures do exactly this.

There are two kinds of data closures, memory-resident and disk-backed, with the
obvious implications. Both types of data closures are accessible to scripts you
write inside ni; for example:

```bash
$ ni n5                         # some data
1
2
3
4
5
$ ni ::foo[n5]                  # ...in a memory-resident closure
```

Once you have a closure, it's visible to mappers, row filters, and any other
embedded script as a constant. It also becomes accessible as its own data
stream:

```
$ ni ::foo[n5] //:foo                   # closures are streams
1
2
3
4
5
$ ni ::foo[n5] n1p'r split /\n/, foo'   # and strings inside languages
1	2	3	4	5
```

The operative feature of closures is that they travel with ni, for instance
into a docker container:

```lazytest
if ! [[ $SKIP_DOCKER ]]; then
```

```bash
$ ni ::foo[n5] Cubuntu[//:foo]
1
2
3
4
5
$ ni ::foo[n5] Cubuntu[n1p'r split /\n/, foo']
1	2	3	4	5
```

```lazytest
fi                      # $SKIP_DOCKER
```

Disk-backed closures have almost exactly the same semantics, and are
automatically deleted when ni exits:

```bash
$ rm -r /tmp/* || :
$ ni :@foo[n10] //@foo e[wc -l]         # disk-backed data closure
10
$ ls /tmp | wc -l
0
$ ni :@foo[nE5] :@bar[nE4] //@foo //@bar gr9
1
1
10
10
100
100
1000
1000
10000
```

Disk-backed closures turn into file URIs inside language environments.

```bash
$ ni :@foo[nE6] \
      n1p'open my $fh, "<", foo =~ /^file:\/\/(.*)/ or die $!;
          print while <$fh>;()' e[wc -c]
6888896
```

They also travel with ni into tempfiles on remote systems, and ni maps the
names accordingly:

```lazytest
if ! [[ $SKIP_DOCKER ]]; then
```

```bash
$ ni :@foo[nE5] :@bar[nE4] Cubuntu[//@foo //@bar gr9]
1
1
10
10
100
100
1000
1000
10000
$ ni :@foo[nE6] Cubuntu[ \
    n1p'open my $fh, "<", foo =~ /^file:\/\/(.*)/ or die $!;
        print while <$fh>;()'] e[wc -c]
6888896
```

```lazytest
fi                      # $SKIP_DOCKER
```
235 doc/col.md
# Column operations
ni models incoming data as a tab-delimited spreadsheet and provides some
operators that allow you to manipulate the columns in a stream accordingly. The
two important ones are `f[columns...]` to rearrange columns, and `F[delimiter]`
to create new ones.

ni refers to columns using letters: `A` to `Z`, though you can also use the
form `#N` to address the Nth column, where `#0` == `A` and `#25` == `Z`. This
second form can be useful for large data files.

## Reordering
First let's generate some data, in this case an 8x8 multiplication table:

```bash
$ ni n8p'r map a*$_, 1..8'
1	2	3	4	5	6	7	8
2	4	6	8	10	12	14	16
3	6	9	12	15	18	21	24
4	8	12	16	20	24	28	32
5	10	15	20	25	30	35	40
6	12	18	24	30	36	42	48
7	14	21	28	35	42	49	56
8	16	24	32	40	48	56	64
```

The `f` operator takes a multi-column spec and reorders, duplicates, or deletes
columns accordingly.

```bash
$ ni n8p'r map a*$_, 1..8' fA      # the first column
1
2
3
4
5
6
7
8
```

```bash
$ ni n8p'r map a*$_, 1..8' fDC     # fourth, then third column
4	3
8	6
12	9
16	12
20	15
24	18
28	21
32	24
```

```bash
$ ni n8p'r map a*$_, 1..8' fAA     # first column, duplicated
1	1
2	2
3	3
4	4
5	5
6	6
7	7
8	8
```

```bash
$ ni n8p'r map a*$_, 1..8' fA-D    # first four columns
1	2	3	4
2	4	6	8
3	6	9	12
4	8	12	16
5	10	15	20
6	12	18	24
7	14	21	28
8	16	24	32
```

You can also choose "the rest of the columns" using `.` within your column
spec. This selects everything to the right of the rightmost column you've
mentioned.

```bash
$ ni n8p'r map a*$_, 1..8' fDA.    # fourth, first, "and the rest (i.e. 5-8)"
4	1	5	6	7	8
8	2	10	12	14	16
12	3	15	18	21	24
16	4	20	24	28	32
20	5	25	30	35	40
24	6	30	36	42	48
28	7	35	42	49	56
32	8	40	48	56	64
```

```bash
$ ni n8p'r map a*$_, 1..8' fBA.    # an easy way to swap first two columns
2	1	3	4	5	6	7	8
4	2	6	8	10	12	14	16
6	3	9	12	15	18	21	24
8	4	12	16	20	24	28	32
10	5	15	20	25	30	35	40
12	6	18	24	30	36	42	48
14	7	21	28	35	42	49	56
16	8	24	32	40	48	56	64
```

```bash
$ ni n8p'r map a*$_, 1..8' x       # even easier (see below)
2	1	3	4	5	6	7	8
4	2	6	8	10	12	14	16
6	3	9	12	15	18	21	24
8	4	12	16	20	24	28	32
10	5	15	20	25	30	35	40
12	6	18	24	30	36	42	48
14	7	21	28	35	42	49	56
16	8	24	32	40	48	56	64
```

## Exchanging
You can swap columns into leading positions using the `x` operator:

```bash
$ ni n8p'r map a*$_, 1..8' xC r2   # swap third column into first position
3	2	1	4	5	6	7	8
6	4	2	8	10	12	14	16
```

```bash
$ ni n8p'r map a*$_, 1..8' xGHr2   # swap seventh, eighth columns into first two
7	8	3	4	5	6	1	2
14	16	6	8	10	12	2	4
```

```bash
$ ni n8p'r map a*$_, 1..8' xr2     # swap first two columns
2	1	3	4	5	6	7	8
4	2	6	8	10	12	14	16
```

## Splitting
The `F` operator gives you a way to convert non-tab-delimited data into TSV.
`F` has the following uses:

- `F:<char>`: split on character
- `F/regex/`: split on occurrences of regex. If present, the first capture
  group will be included before a tab is appended to a field.
- `Fm/regex/`: don't split; instead, look for matches of regex and use those as
  the field values.
- `FC`: split on commas (doesn't handle special CSV cases)
- `FV`: parse CSV "correctly", up to newlines in fields
- `FS`: split on runs of horizontal whitespace
- `FW`: split on runs of non-word characters
- `FP`: split on pipe symbols

`FV` does things to preserve cell boundaries for CSV files whose cells contain
`\n` and `\t`. In particular, `\n` becomes `\r` and `\t` becomes eight spaces.

```bash
$ cat > pathological.csv <<'EOF'
"foo
	bar",bif,"baz ""bok""
biffski"
,,,
,"",,biffski

1,2,3,4
EOF
$ ni ./pathological.csv FV p'r map je($_), F_'
"foo\r        bar"	"bif"	"baz \"bok\"\rbiffski"

""	""	""	"biffski"

1	2	3	4
```

### Examples


## Vertical operator application
A situation that comes up a lot in real-world workflows is that you want to
apply some mapper code to a specific column. For example, if we want to
uppercase the third column of a dataset, we can do it like this:

```bash
$ ni i[who let the dogs out] i[who? who?? who???] p'r FT 2, uc(c), FR 3'
who	let	THE	dogs	out
who?	who??	WHO???
```

But that requires a lot of keystrokes. More concise is to use `v` to pipe column C to a separate ni process:

```bash
$ ni i[who let the dogs out] i[who? who?? who???] vCpuc
who	let	THE	dogs	out
who?	who??	WHO???
```

**CAVEAT**: The `v` operator is **WAY** too slow to use in production code. Be a hero and speed it up.

## Left/right juxtaposition
ni has the `+` and `^` operators to join streams vertically, but you can also join them horizontally, row by row. This is done using `w` and `W` (for "with"):

```bash
$ ni i[who let the dogs out] Z1
who
let
the
dogs
out
```

```bash
$ ni i[who let the dogs out] Z1 wn   # right-juxtapose numbers
who	1
let	2
the	3
dogs	4
out	5
```

```bash
$ ni i[who let the dogs out] Z1 Wn   # left-juxtapose numbers
1	who
2	let
3	the
4	dogs
5	out
```

As shown above, the output stream is only as long as the shorter input. This is useful in conjunction with infinite generators like `n`; for example, you can prepend line numbers to an arbitrarily long data stream like this:

```bash
$ ni nE5p'a*a' Wn r~3
99998	9999600004
99999	9999800001
100000	10000000000
```
85 doc/container.md
# Containerized pipelines
```lazytest
# These tests only get run in environments where docker is installed
# (centos 5 uses i386 libraries and doesn't support docker, for example).
if ! [[ $SKIP_DOCKER ]]; then
```

Some ni operators depend on tools you may not want to install on your machine.
If you want to use those operators anyway, though, you can run them inside a
Docker container with the tools installed. ni provides the `C` operator to
containerize a stream transformation:

```bash
$ ni nE4 Cubuntu[gr4] O
1000
100
10
1
```

The above is executed roughly like this, except that ni pipes itself into Perl
rather than invoking itself by name:

```sh
$ ni nE4 \
  | docker run --rm -i ubuntu ni gr4 \
  | ni O
```

A common use case is for something like NumPy:

```bash
$ docker build -q -t ni-test/numpy - <<EOF > /dev/null
FROM ubuntu
RUN apt-get update
RUN apt-get install -y python-numpy
CMD /bin/bash
EOF
$ ni n100 Cni-test/numpy[N'x = x + 1'] r4
2
3
4
5
```

## Dynamic images
The examples above are a little awkward in that (1) they require you to tag the
docker images, and (2) they require a separate command to build them in the
first place. To get around this, ni lets you define image generators and
includes predefined ones for Ubuntu and Alpine:

```bash
$ ni n100 CU+python-numpy+sbcl[N'x = x + 1' l'(1+ a)'] r4
3
4
5
6
$ ni n100 CA+py-numpy@community+sbcl@testing[N'x = x + 1' l'(1+ a)'] r4
3
4
5
6
```

## Running in an existing container
ni can run `docker exec` and do the same interop it does when it creates a new
container.

```bash
$ docker run --detach -i --name ni-test-container ubuntu >/dev/null
$ ni Eni-test-container[n100g =\>/tmp/in-container Bn] r4
1
10
100
11
$ [[ -e /tmp/in-container ]] || echo 'file not in host (good)'
file not in host (good)
$ ni Eni-test-container[/tmp/in-container] | wc -l
100
$ docker rm -f ni-test-container >/dev/null
```

```lazytest
fi                      # $SKIP_DOCKER (lazytest condition)
```
241 doc/examples.md
# Examples of ni misuse
All of these use `ni --js` (see [visual.md](visual.md) for a brief overview).
If you're working through these on the command line, you can use `ni
--explain` to help figure out what's going on:

```sh
$ ni --explain //ni FWpF_ plc gc
["meta_image"]
["split_regex","(?^:[^\\w\\n]+)"]
["perl_mapper","F_"]
["perl_mapper","lc"]
["row_sort","-t","\t"]
["count"]
```

**NOTE:** Some of the screenshots here are from older versions of ni, so some
details may have changed since.

## Simple 2D letter/letter co-occurrence matrix
![img](http://spencertipping.com/ni-example-letter-cooccurrence.png)

```
http://localhost:8090/#%7B%22ni%22%3A%22%2Fusr%2Fshare%2Fdict%2Fwords%20plc%20pr%2F%5Ba-z%5D%2Fg%20pcart%5BF_%5D%2C%5BF_%5D%20p'r%20map%20ord%2C%20F_'%20%2CjAB%2C%22%2C%22vm%22%3A%5B1%2C0%2C0%2C0%2C0%2C1%2C0%2C0%2C0%2C0%2C1%2C0%2C0%2C0%2C0%2C1%5D%2C%22d%22%3A1.1348179443582629%7D
```

Equivalent ni command:

```sh
$ ni /usr/share/dict/words plc pr/[a-z]/g pcart[F_],[F_] p'r map ord, F_'
```

### How it works
- `/usr/share/dict/words`: cat the file; we get one word per line
- `plc`: short for `p'lc $_'`: lowercase each line
- `pr/[a-z]/g`: short for `p'r /[a-z]/g'`:
  - `/[a-z]/g`: in list context, return every occurrence of a lowercase letter
  - `r(@list)`: join with tabs and print an output line
- `pcart[F_],[F_]`: short for `p'cart [F_], [F_]'`:
  - `F_`: return a list of tab-delimited fields (the lowercase letters from
    `pr/[a-z]/g`)
  - `cart [@xs], [@ys], ...`: Cartesian product of N arrays: in this case,
    returns `[$xi, $yi]` pairs, which represent every combination of lowercase
    letters within this word
  - `cart` returns array references, which ni automatically joins with tabs to
    convert to output rows.

At this point we have each pair of co-occurring letters on a single line,
tab-delimited. The last step is to convert to ASCII:

- `p'r map ord, F_`: convert each tab-delimited field to its ASCII value:
  - `F_`: the list of fields
  - `map ord, @list`: short for `map ord($_), @list`: convert each list element
    to ASCII
  - `r @list`: tab-join and write output line

This gives us a long stream of integer pairs. If we plot them now, we'll get a
bunch of dots on the screen:

![img](http://spencertipping.com/ni-example-letter-cooccurrence-dots.png)

If, however, we move each dot by a random vector chosen from a 0.9x0.9
rectangle, we'll end up with stochastically-shaded squares with visible
boundaries. This is a common thing to do when dot plotting, so ni provides the
"jitter" cell operator.

- `,`: enter cell-transform context (essentially a new namespace for letters)
  - `jAB,`: jitter cells in columns A and B uniformly;
    - `,`: ...by 0.9. ni provides this shorthand because it's common to do
      this. (The alternative would be `,jAB.9`, but that's extra typing with a
      lot of right-hand travel.)

## Simple 3D sine wave
![img](http://spencertipping.com/ni-example-simple-3dsine.png)

```
http://localhost:8090/#%7B%22ni%22%3A%22nE3p'r%20a%2C%20%24_%20for%200..999'%20r'%2F0(%5C%5Ct%7C%24)%2F'%20p'r%20a%2C%20sin(a%2F100)*sin(b%2F100)%2C%20b'%20%2B%5Bid%3A0%2C4%2C0%20id%3A0%2C-4%2C0%20FC%5D%22%2C%22vm%22%3A%5B0.9900140741662761%2C0%2C0.14096855306306652%2C0.038856304985337244%2C-0.043561678568934545%2C0.9510565162951593%2C0.30593117358776106%2C0.03263707571801566%2C-0.13406906098332957%2C-0.3090169943749491%2C0.9415593364597573%2C0%2C0%2C0%2C0%2C1%5D%2C%22d%22%3A0.8750031755957807%7D
```

Equivalent ni command:

```sh
$ ni nE3p'r a, $_ for 0..999' r'/0(\t|$)/' p'r a, sin(a/100)*sin(b/100), b'
```

### How it works
- `nE3`: generate integers from 1 to 1000, inclusive. `E3` is shorthand for
  `1e3`, which is 1000.
- `p'r a, $_ for 0..999'`: for each row, emit 1000 rows, one for each value in
  the second column. This emits the plane of input points for which we'll
  evaluate the product of two sines.
- `r'/0(\t|$)/'`: punches holes in the plane to form a grid. I'll explain this
  below and show what it looks like if we omit it.
- `p'r a, sin(a/100)*sin(b/100), b'`: the plane coordinates are `a` and `b`, so
  for each plane point we emit a 3D point at `<a, f(a, b), b>`.
- `@[i0,4,0 i0,-4,0 FC]`: two extra data points to expand the min/max along
  the Y axis. This results in flatter output.

### `r'/0(\t|$)/'` for the grid
If we preview just `nE3p'r a, $_ for 0..999'`, we'll see a uniform plane:

![img](http://spencertipping.com/ni-example-simple-3dsine-plane.png)

We'd have a grid if every point were divisible by 10 along either the X or the
Y axis. We could use Perl like this: `rp'(a%10==0) || (b%10==0)'`, but an
equivalent assertion is that either of the two numbers ends in a zero. The
regex `/0(\t|$)/` detects this case: the first number is followed by a tab, the
second number by the end of the line.

![img](http://spencertipping.com/ni-example-simple-3dsine-grid.png)

### View scaling
This uses a sub-ni instance to append some data to the stream. We just need two
more data points whose Y coordinates expand the range to [-4, 4] so the
plotting interface scales the sine wave down vertically.

- `+[...]`: append a new stream:
  - `i0,4,0`: append the literal text `0,4,0`
  - `i0,-4,0`: append the literal text `0,-4,0`
  - `FC`: fieldsplit on commas: this turns commas into tabs so the two points
    occupy three columns each.

## Simple ASCII co-occurrence of ni source code
![img](http://spencertipping.com/ni-example-ascii-cooccurrence.png)

```
http://localhost:8090/#%7B%22ni%22%3A%22%2F%2Fni%20psplit%2F%2F%20pord%20p'r%20pl%203'%20%2CjABC.5%22%2C%22vm%22%3A%5B0.3052176877315164%2C0%2C-0.9522826067380442%2C0.025659824046920767%2C0.15198698116928847%2C0.9871813119337595%2C0.04871360101460337%2C-0.00521898518107074%2C0.9400755930513635%2C-0.15960281128089038%2C0.30130519740018513%2C-0.060644007110305605%2C0%2C0%2C0%2C1%5D%2C%22d%22%3A1.4140702339178333%7D
```

Equivalent ni command:

```sh
$ ni //ni psplit// pord p'r pl 3'
```

### How it works
- `//ni`: append ni's source code verbatim
- `psplit//`: a compact form of `p'split //'`, which will return each character
  on a separate line.
- `pord`: a compact form of `p'ord $_'`, which will transform each line into
  its ASCII value.
- `p'r pl 3'`: non-destructively read the next three lines and place them on a
  single row. `pl($n)` peeks `n` lines ahead, returning them as an array.

At this point we have triples of ASCII values. The web UI provides some
shading to handle point collisions, but it can only offer so much dynamic
range; typically if you're relying on shading to tell you something, you'll
want to jitter each data point a little. (See the 2D letter/letter
co-occurrence from `/usr/share/dict/words` for an example.)

- `,`: cell transformation context
  - `jABC.5`: jitter columns A, B, and C by a random value whose range is
    centered at 0 and is 0.5 across. ASCII values are integers, so jittering
    each one by 0.5 preserves its identity while adding some spatial resolution
    and better shading to the plot.

## Co-occurrence of manpage words in quasi-donut form
![img](http://spencertipping.com/ni-example-cooccurrence-quasidonut.png)

```
http://localhost:8090/#%7B%22ni%22%3A%22%2Fusr%2Fshare%2Fman%2Fman1%20%5C%5C%3CFWp'r%20F_(%24_-2..%24_)%20for%202..FM'%20%2ChABzC%20p'r%20prec((a%20%26%200xffff)%20%2B%200xffff%2C%20int((b%20%26%200xffff)%20%2F%200xffff*270))%2C%20c'%20fACB%22%2C%22vm%22%3A%5B-0.9841092569237042%2C0%2C-0.17756398969608223%2C0.07311827956989259%2C0.03298935921795422%2C0.9825897456859218%2C-0.18283624873452747%2C0.4633668730031738%2C0.17447255547845722%2C-0.185788567121162%2C-0.9669756644878278%2C-0.06165651783795804%2C0%2C0%2C0%2C1%5D%2C%22d%22%3A0.6482182956356948%7D
```

Equivalent ni command:

```sh
$ ni /usr/share/man/man1 \<FWp'r F_($_-2..$_) for 2..FM' \
  ,hABzC p'r prec((a & 0xffff) + 0xffff, int((b & 0xffff) / 0xffff*270)), c' \
  fACB
```

### How it works
- `/usr/share/man/man1` produces a list of filenames (all manpages in `man1`)
- `\<` cats each file in a stream of filenames (all manpage text in `man1`)
- `FW` splits on non-word characters
- `p'r F_($_-2..$_) for 2..FM'` is a 3-wide sliding window of words per line:
  - `2..FM` generates the index of the last word in each window
  - `$_-2..$_` generates the indexes of all words in the current window
  - `r F_(@indexes)` outputs a row of fields at numerically-specified
    `@indexes`

A preview of the output at this point:

```sh
$ ni /usr/share/man/man1 \<FWp'r F_($_-2..$_) for 2..FM' r10
        DO      NOT
DO      NOT     MODIFY
NOT     MODIFY  THIS
MODIFY  THIS    FILE
THIS    FILE    It
FILE    It      was
It      was     generated
was     generated       by
generated       by      help2man
by      help2man        1
```

Now we use cell operators to transform things into numbers.

- `,`: the cell operator prefix, which continues until the next CLI argument:
  - `hAB`: 32-bit murmurhash each cell in columns A and B (unbiased)
  - `zC`: assign successive integers to distinct values in column C (biased)

At this point we have a cube of word cooccurrence:

![img](http://spencertipping.com/ni-example-cooccurrence-hhz-cube.png)

```
http://localhost:8090/#%7B%22ni%22%3A%22%2Fusr%2Fshare%2Fman%2Fman1%20%5C%5C%3CFWp'r%20F_(%24_-2..%24_)%20for%202..FM'%20%2ChABzC%22%2C%22vm%22%3A%5B-0.1455274825751139%2C0%2C-0.9893542094796254%2C-0.04019689987431912%2C0.4626508778259456%2C0.8839247529105698%2C-0.06805289441946762%2C-0.01019337018835886%2C0.874514675155316%2C-0.46762915990349385%2C-0.12863534407689978%2C-0.08768024724094528%2C0%2C0%2C0%2C1%5D%2C%22d%22%3A1.6594267918484475%7D
```

I haven't implemented axes and range display yet, but `A` and `B` take on the
full range of 32-bit integer values and `C` contains positive integers up to
the number of distinct words we have -- we can calculate it easily, in this
case by just taking the maximum:

```sh
$ ni /usr/share/man/man1 \<FWZ1 ,z Or1
84480
```

Alternatively, we can reverse-sort within the UI and use the preview window:

![img](http://spencertipping.com/ni-example-cooccurrence-hhz-preview.png)

ni provides a quasidonut constructor library in the form of two functions,
`prec(rho, theta) = (x, y)` and `rpol(x, y) = (rho, theta)`. These convert
between rectangular and polar coordinates. In this case we want `prec`, and
here's what we're doing with it:

```pl
(a & 0xffff)            # low 16 bits of the hash (just to truncate; could be pretty much anything)
(a & 0xffff) + 0xffff   # push to the upper half of the range [0, 0x1ffff]: this increases the radius and creates a ring

(b & 0xffff) / 0xffff   # truncate b to the range [0, 1]
... / 0xffff * 270      # now extend to the range [0, 270]: 3/4 of a donut

r prec(rho, theta), c   # output x and y as points on circles, z is preserved
```

From there we just flip into the viewport coordinate system, where Z points
away from the camera.
17 doc/extend.md
# Extending ni
You can extend ni by writing a library. For example, suppose we want a new
operator `wc` that counts lines by shelling out to `wc -l`:

```bash
$ mkdir my-library
$ echo my-lib.pl > my-library/lib
$ cat > my-library/my-lib.pl <<'EOF'
defoperator count_lines => q{exec 'wc', '-l'};
defshort '/wc', pmap q{count_lines_op}, pnone;
EOF
$ ni --lib my-library n100wc
100
```

Most ni extensions are about defining a new operator, which involves extending
ni's command-line grammar.
76 doc/fn.md
# Function definitions
ni lets you define aliases using the `defexpander` internal function. These
support arguments of arbitrary parse types and provide basic substitution. For
example, let's define a shorthand for fractional numbers:

```bash
$ mkdir fractional
$ echo fractional.pl > fractional/lib
$ cat >fractional/fractional.pl <<'EOF'
defexpander ['/frac', n => pc integer, step => pc number],
            'n$n', 'pa * $step';
EOF
```

Now we can load the library and use the new operator:

```bash
$ ni --lib fractional frac 10 .5
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
$ ni --lib fractional frac4.5
0.5
1
1.5
2
```

You can also define a nullary function, which is just a regular shorthand:

```bash
$ ni --run 'defexpander "/evens", qw[np2*a]' evens r10
2
4
6
8
10
12
14
16
18
20
```

## Using Perl functions
You can use an arbitrary Perl expression instead of an expansion template:

```bash
$ mkdir fractional2
$ echo fractional2.pl > fractional2/lib
$ cat >fractional2/fractional2.pl <<'EOF'
defexpander ['/frac', n => pc integer, step => pc number],
  sub {
    my %args = @_;
    ("+n$args{n}", "pa * $args{step}");
  };
EOF
$ ni --lib fractional2 frac 10 .5
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
```
36 doc/geohash.md
# Geohash functions
ni has fairly extensive support for
[geohashes](https://en.wikipedia.org/wiki/Geohash), both in base-32 and in
binary forms. It uses the [Factual bitwise
algorithm](https://www.factual.com/blog/how-geohashes-work/) and some
surrounding Perl-specific optimizations for base-32 transcoding.

There are a few operators and functions that operate on geohashes:

- Perl context functions
  - `$gh = llg/ghe/geohash_encode($lat, $lng, $precision)`: encode a geohash
  - `($lat, $lng) = gll/ghd/geohash_decode($gh [, $bits])`: decode a geohash
  - `$dist = gh_dist($gh1, $gh2, unit = "km")`
  - `($n, $s, $e, $w) = ghb/geohash_box($gh)`
- Cell operators
  - `,g`: encode comma-delimited column values to a geohash
  - `,G`: decode a column of geohashes to comma-delimited lat/lng

## Geohashes in the perl context
```bash
$ ni nE4p'my ($lat, $lng) = (rand() * 180 - 90, rand() * 360 - 180);
          my $bits        = int clip 1, 60, rand(61);
          my $b32_digits  = int(($bits + 4) / 5);
          my $gh_base32   = llg $lat, $lng, $b32_digits;  # positive = letters
          my $gh_binary   = llg $lat, $lng, -$bits;       # negative = bits
          my $gh2_b32     = ghe ghd($gh_base32), $b32_digits;
          my $gh2_bin     = ghe ghd($gh_binary, $bits), -$bits;
          my $b32_ok      = $gh2_b32 eq $gh_base32;
          my $bin_ok      = $gh2_bin == $gh_binary;

          r $b32_ok ? "B32 OK" : "B32 FAIL $lat $lng $gh_base32 $gh2_b32";
          r $bin_ok ? "BIN OK" : "BIN FAIL $lat $lng $gh_binary $gh2_bin"' \
     gcfB.
B32 OK
BIN OK
```
107 doc/git.md
# Git interop
**TODO:** convert these to unit tests

ni can use git to read commits, trees, and blobs. The entry point,
`git://repopath`, will give you a list of local and remote branches. For
example:

```sh
$ ni git://.
gitcommit://.:refs/heads/archive/concatenative  6971535d4edc37a28740fccd8a3f09a6158cba29
gitcommit://.:refs/heads/archive/cva    7da9f1e77164f5a6c9b93803b5f8114b657c68b8
gitcommit://.:refs/heads/archive/genopt a99830c4ad3c75cf05b2ee025e26a2281bf9e911
gitcommit://.:refs/heads/archive/lisp   4cab9e54a641262dca5beff0d0b4310100bb6c3c
gitcommit://.:refs/heads/archive/native d4b3be5e97418ac9334773e0ff121f4f25333944
gitcommit://.:refs/heads/archive/perl   1343c5d42c1028f4094d4eaa30dbcf6e2e1d221b
gitcommit://.:refs/heads/archive/self-hosting   dd7ffd268c6718a5900d801a3100907512752c27
gitcommit://.:refs/heads/cheatsheet_v1.0        0ec7b3e405837f83106c38aa5e0514371195ce9d
...
```

Reading a commit will give you a TSV of possible facets:

```sh
$ ni git://. r1 fA
gitcommit://.:refs/heads/archive/concatenative

$ ni git://. r1 fA \<
gitcommitmeta://.:refs/heads/archive/concatenative      githistory://.:refs/heads/archive/concatenative gitdiff://.:refs/heads/archive/concatenative    gittree://.:refs/heads/archive/concatenative
```

## Commit metadata
```sh
$ ni git://. r1 fA \< fA
gitcommitmeta://.:refs/heads/archive/concatenative

$ ni git://. r1 fA \< fA \<
tree 6ef2f88a860e26b81eca3649b2f81992c285a199
parent ddfafe9307ca18cd059ed8efa1d3cfdbe98a0ffe
author Spencer Tipping <spencer@spencertipping.com> 1427636233 +0000
committer Spencer Tipping <spencer@spencertipping.com> 1427636233 +0000

Fixed a parse bug
```

## Commit history
```sh
$ ni git://. r1 fA \< fB
githistory://.:refs/heads/archive/concatenative

$ ni git://. r1 fA \< fB \<
gitcommit://.:6971535d4edc37a28740fccd8a3f09a6158cba29  Spencer Tipping 1427636233      Fixed a parse bug
gitcommit://.:ddfafe9307ca18cd059ed8efa1d3cfdbe98a0ffe  Spencer Tipping 1427377653      Preliminary tag support for bootstrap interpreter
gitcommit://.:d360dfe6c6183bdaca0552a1a49a3631e955b312  Spencer Tipping 1427377113      Resolved the problem
gitcommit://.:226c1b8d27fc02129981d0f73535f3e69797c8af  Spencer Tipping 1427293623      Minor changes, still thinking about the untyped-data problem. No great ideas yet apart from adding value metadata (which seems wrong).
gitcommit://.:c062e734d23ece6b3137354af30abc3da7320d2a  Spencer Tipping 1427289277      Hrm, untyped
...
```

## Commit diffs
```sh
$ ni git://. r1 fA \< fC
gitdiff://.:refs/heads/archive/concatenative

$ ni git://. r1 fA \< fC \<
diff --git a/src/boot-interpreter.pl b/src/boot-interpreter.pl
index cea0535..e21e314 100644
--- a/src/boot-interpreter.pl
+++ b/src/boot-interpreter.pl
@@ -79,7 +79,7 @@ sub parse {
     next if $k eq 'comment' || $k eq 'ws';
     if ($k eq 'opener') {
       push @stack, [];
-      push @tags, $+{opener} =~ s/.$//r;
+      push @tags, $+{opener};
     } elsif ($k eq 'closer') {
       my $last = pop @stack;
       die "too many closing brackets" unless @stack;
```

## Commit trees
```sh
$ ni git://. r1 fA \< fD
gittree://.:refs/heads/archive/concatenative

$ ni git://. r1 fA \< fD \<
gitblob://.:8320be96e5579a9d559f289f759c63d41af263f0    100644  .gitignore
gitblob://.:222d36ccaa470b62600c8e7e55e1b4d3182af1f6    100644  README.md
gitblob://.:f808160232229a181196f3c9b2efd921b7241a7e    100755  build
gittree://.:c3b8b3b4bbd90198f197894341ca83ce0f49f698    040000  doc
gitblob://.:02d46a53c14e141a8ea43bc39667d83d84977034    100755  gen-tests
gitblob://.:8ec3efe84f53125f611a3785f24968d987e3832b    100755  run-tests
gittree://.:225bd52669273772cc5b88165df6cf598cc7c61f    040000  src
gittree://.:b88775b02aace595d17f7c607e874dbcd91c8e62    040000  tools
gitblob://.:32dc3893527c8b87e601003dd40f6e63b520ad86    100755  verify-transcript
```

## Example: find every revision of `dev/tests.sh`
```sh
$ ni git://. fA \< fB \< fAgu \< fD \< rp'c eq "dev"' fA\< rp'c eq "tests.sh"'
gitblob://.:a653261f3582234f8a5875221acbb892550b3b55    100644  tests.sh
gitblob://.:aeef8ad0315c5b00c7472e75bdf15aa1145e4a70    100644  tests.sh
gitblob://.:f2ed4a2c8d1bf4599d8074ebab2973be6d97aa51    100644  tests.sh
gitblob://.:c3e84a5dfefc7a84cd3476dfc11dafa15921dde6    100644  tests.sh
...
```

You could then use `fA\<` or `fA W\<` to get the contents of each.
163 doc/hadoop.md
# Hadoop operator
The `H` operator runs a Hadoop job. Here's what it looks like to use Hadoop
Streaming:

```sh
$ ni ihdfs:///input/path HS[mapper] [combiner] [reducer] > output-hdfs-path
```

For example, the ubiquitous word count:

```sh
# locally
$ ni README.md FW Z1 gcOx
ni      27
md      26
doc     25
com     16
spencertipping  12
https   11
to      9
the     9
github  9
and     9
...

# on hadoop streaming
$ ni ihdfs:///user/spencer/textfiles/part* HSFWZ1 _ c \<Ox
word1   count1
word2   count2
...
```

See [Hadoop in Ni By Example](ni_by_example_4.md#hadoop-streaming-mapreduce) for
a much better usage guide.

## Local setup
```sh
$ docker run --detach -i -m 2G --name ni-test-hadoop \
    sequenceiq/hadoop-docker \
    /etc/bootstrap.sh -bash
```

```lazytest
# unit test setup; you won't have to run this
if ! [[ $SKIP_DOCKER ]]; then
```

Let's start up a container and use `HS` to run a Streaming job. `H` is a
delegator, meaning that you always specify a profile (in this case `S` for
Streaming) before any command arguments.

(Note: The `until docker exec` silliness below is because we have to wait for
the hadoop container to boot up correctly. Sometimes the container gets into a
bad state and doesn't become available, in which case we nuke it and start
over. This is all just for unit testing; you won't have to worry about this
stuff if you're using ni to run hadoop jobs.)

```lazytest
# more unit test setup
start_time=0;
until docker exec -i ni-test-hadoop \
      /usr/local/hadoop/bin/hadoop fs -mkdir /test-dir; do
  if (( $(date +%s) - start_time > 60 )); then
    docker rm -f ni-test-hadoop >&2
    docker run --detach -i -m 2G --name ni-test-hadoop \
      sequenceiq/hadoop-docker \
      /etc/bootstrap.sh -bash >&2
    start_time=$(date +%s)
  fi
done
```

`S` takes three lambdas: the mapper, the combiner, and the reducer. There are
two special cases you can use instead of a normal bracketed lambda:

- `_`: skip this stage of the pipeline. If you use this for the combiner and
  reducer, then your job will be map-only.
- `:`: identity lambda. `HS:_:` is a simple way to repartition your input data,
  for example.

Hadoop input paths are specified using the input stream to a hadoop command. If
you specify something that doesn't start with `hdfs://` or `hdfst://`, the
stream will be uploaded to an HDFS tempfile and used as the job input. Notice
that we use `\<` after the hadoop command: `H` emits the output path, but not
the output data -- so if we want the data we need to read it.

```bash
$ NI_HADOOP=/usr/local/hadoop/bin/hadoop \
  ni n5 Eni-test-hadoop [HS[p'r a, a*a'] _ _ \<]
1	1
2	4
3	9
4	16
5	25
```

With a reducer:

```bash
$ ni n5 ^{hadoop/name=/usr/local/hadoop/bin/hadoop} \
          Eni-test-hadoop [HS[p'r a, a*a'] _ [p'r a, b+1'] \<] o
1	2
2	5
3	10
4	17
5	26
```


## Jobconf
You can pass in jobconf options using the `hadoop/jobconf` variable or by
setting `NI_HADOOP_JOBCONF` (note the different output; if you use multiple
reducers, you'll see the shard boundaries):

```bash
$ ni i'who let the dogs out who who who' \
	 ^{hadoop/name=/usr/local/hadoop/bin/hadoop \
      hadoop/jobconf='mapred.map.tasks=10
      					  mapred.reduce.tasks=4'} \
     Eni-test-hadoop [HS[p'r a, a*a'] _ [p'r a, b+1'] \<] o
1	2
2	5
3	10
4	17
5	26
```

### Jobconf shorthand

The names of Hadoop configuration variables are generally quite long; to see the whole list, you can see the whole list in a Perl context using `%mr_generics`. Let's look at a few:

```bash
$ ni 1p'%mr_generics' Z2 e'grep memory' gA
Hcmm	mapreduce.cluster.mapmemory.mb
Hcrm	mapreduce.cluster.reducememory.mb
Hjtmmm	mapreduce.jobtracker.maxmapmemory.mb
Hjtmrm	mapreduce.jobtracker.maxreducememory.mb
Hmmm	mapreduce.map.memory.mb
Hrmm	mapreduce.reduce.memory.mb
Hrmt	mapreduce.reduce.memory.totalbytes
Htttm	mapreduce.tasktracker.taskmemorymanager.monitoringinterval
```

Use the abbreviations in the first column in your configuration; for example, to set your mappers to have 3072 MB of memory and reducers to have 4096 MB, you could do the following:

```bash
$ ni i'who let the dogs out who who who' \
	 ^{hadoop/name=/usr/local/hadoop/bin/hadoop \
      Hrmm=4096 Hmmm=3072} \
     Eni-test-hadoop [HS[p'r a, a*a'] _ [p'r a, b+1'] \<] o
1	2
2	5
3	10
4	17
5	26
```


```lazytest
docker rm -f ni-test-hadoop >&2

fi                      # $SKIP_DOCKER (lazytest condition)
```
63 doc/json.md
# JSON operators
## Background
Perl has a standard JSON library since 5.14, but it's written in pure Perl and
decodes at about 1MiB/s (vs the ~60MiB/s for the native version, but that isn't
installed by default). Older versions of Perl don't include any JSON support at
all.

To work around this, ni implements a medium-speed pure Perl JSON parser
(~5MiB/s) and some very fast alternatives for cases where you don't need to do
a full object parse.

Internally, ni uses its own JSON library for pipeline serialization and to
generate the output of `--explain`.

## Full encode/decode

### Perl driver
```bash
$ ni i[hi there] i[my friend] p'json_encode [F_]'
["hi","there"]
["my","friend"]
```

`json_decode` inverts and always returns a reference:

```bash
$ ni i[hi there] i[my friend] p'json_encode [F_]' p'r @{json_decode a}'
hi	there
my	friend
```

## Sparse extraction
It's uncommon to need every field in a JSON object, particularly when you're testing specific hypotheses on rich data. This makes it likely that JSON decoding will be pipeline bottleneck simply due to the ratio of bytes pre-vs-post-decode. ni helps to mitigate this by providing a very fast destructuring operator that works like `jq` (but 2-3x faster):

```bash
$ ni i[who let the dogs out?! who? who?? who???] Z1 p'r pl 3' r5 \
     p'json_encode {type    => 'trigram',
                    context => {w1 => a, w2 => b},
                    word    => c}'
{"context":{"w1":"let","w2":"the"},"type":"trigram","word":"dogs"}
{"context":{"w1":"the","w2":"dogs"},"type":"trigram","word":"out?!"}
{"context":{"w1":"dogs","w2":"out?!"},"type":"trigram","word":"who?"}
{"context":{"w1":"out?!","w2":"who?"},"type":"trigram","word":"who??"}
{"context":{"w1":"who?","w2":"who??"},"type":"trigram","word":"who???"}
```

A destructuring specification consists of a comma-delimited list of extractors:

```bash
$ ni i[who let the dogs out?! who? who?? who???] Z1 p'r pl 3' r5 \
     p'json_encode {type    => 'trigram',
                    context => {w1 => a, w2 => b},
                    word    => c}' \
      D:w1,:w2,:word
let	the	dogs
the	dogs	out?!
dogs	out?!	who?
out?!	who?	who??
who?	who??	who???
```

### Types of extractors
The example above used the `:field` extractor, which means "find the first occurrence of a field called `field`, and return its value."
28 doc/libraries.md
# Libraries
A library is just a directory with a `lib` file in it. `lib` lists the names of
files to be included within that library, one per line, and in doing so
specifies the order of inclusion (which sometimes matters if you're defining
stuff in Perl). Most libraries will include at least one Perl file, which ni
evaluates in the `ni` package. ni will assume that any file ending in `.pl`
should be evaluated when the library is loaded. (Importantly, libraries are
loaded _before_ the main CLI arguments are parsed, which is why it's possible
to add new syntax.)

ni has two library-loading options:

- `ni --lib X ...`: load the `X` library before executing the pipeline
- `ni --extend X [...]`: load the `X` library and rewrite yourself to include
  it in the future (and then execute the pipeline if you got one)

`--extend` is useful in a scripted context when you're building a site-specific
ni executable, e.g.:

```sh
#!/bin/bash
[[ -x /bin/ni ]] || get_ni_from_somewhere
ni --extend site-lib1           # this modifies ni in place
ni --extend site-lib2
```

`--extend` is idempotent, and you can use it to install a newer version of an
already-included library.
113 doc/lisp.md
# Common Lisp driver
ni supports Common Lisp via SBCL, which is available using the `l` and `L`
operators. For example:

```bash
$ ni n4l'(+ a 2)'
3
4
5
6
```

If you don't have SBCL installed locally, you can use the `C` (containerize)
operator to run a Docker image:

```lazytest
if ! [[ $SKIP_DOCKER ]]; then
```

```bash
$ docker build -q -t ni-test/sbcl - <<EOF > /dev/null
FROM ubuntu
RUN apt-get update
RUN apt-get install -y sbcl
CMD /bin/bash
EOF
$ ni Cni-test/sbcl[n4l'(+ a 2)']
3
4
5
6
```

```lazytest
fi                      # $HAVE_DOCKER
```

## Basic stuff
`a` to `q` are one-letter functions that return the first 17 tab-delimited
values from the current line. `(r ...)` is a function that takes a list of
values and prints a tab-delimited row. For example:

```bash
$ ni n4l'(r a (1+ a))'                  # generate two columns
1	2
2	3
3	4
4	5
$ ni n4l'(r a (1+ a))' l'(r (+ a b))'   # ... and sum them
3
5
7
9
```

Note that whitespace is required after every `l'code'` operator; otherwise ni
will assume that everything following your quoted code is also Lisp.

It is possible to omit `r` altogether; then you're returning one or more
values, each of which will become a row of output:

```bash
$ ni n2l'a (+ a 100)'                   # return without "r"
1
101
2
102
```

## Streaming lookahead
This is implemented in terms of reducers, and gives you the ability to reduce
arbitrarily many rows in constant space. There are two parts to this. First,
the streaming reduce functions `se` and `sr`; and second, compound reducers
(very useful, and explained in the next section).

### `sr`
Reduces the entire data stream:

```
sr (reducer value [initial-value])* => reduced-value*
```

For example, to sum arbitrarily many numbers in constant space:

```bash
$ ni n10000l"(sr ('+ a))"
50005000
```

Or to reduce multiple columns into a row:

```bash
$ ni n4fAA l"(r (sr ('+ a) ('* b)))"
10	24
```

### `se`
Reduces over a contiguous group of rows for which the partition function
remains equal. (Mnemonic is "stream while equal".)

```
se function value-form partition-form [initial-value] => reduced-value
```

For example, to naively get a comma-delimited list of users by login shell:

```bash
$ ni /etc/passwd F::gG l"(r g (se (partial #'join #\,) a g))"
/bin/bash	root
/bin/false	syslog
/bin/sh	backup,bin,daemon,games,gnats,irc,libuuid,list,lp,mail,man,news,nobody,proxy,sys,uucp,www-data
/bin/sync	sync
```
250 doc/matrix.md
# Matrix operations

## Sparse and Dense Matrix Operations (`X` and `Y`)
ni provides a handful of operations that make it easy to work with sparse and dense matrices. The first two are `Y` (dense to sparse) and `X` (sparse to dense), which work like this:

```bash
$ ni //ni FWr10
	usr	bin	env	perl
	ni	is_lib	caller	
	ni	self	license	_	
ni	https	github	com	spencertipping	ni
Copyright	c	2016	Spencer	Tipping	MIT	license

Permission	is	hereby	granted	free	of	charge	to	any	person	obtaining	a	copy
of	this	software	and	associated	documentation	files	the	Software	to	deal
in	the	Software	without	restriction	including	without	limitation	the	rights
to	use	copy	modify	merge	publish	distribute	sublicense	and	or	sell
```

A sparse matrix is represented as a series of `row col value` tuples:

```bash
$ ni //ni FW Yr10
0	0	
0	1	usr
0	2	bin
0	3	env
0	4	perl
1	0	
1	1	ni
1	2	is_lib
1	3	caller
1	4	
```

`X` inverts `Y` exactly:

```bash
$ ni //ni FW fABCD Y X r10
	usr	bin	env
	ni	is_lib	caller
	ni	self	license
ni	https	github	com
Copyright	c	2016	Spencer

Permission	is	hereby	granted
of	this	software	and
in	the	Software	without
to	use	copy	modify
```

`X` is also additive in the event of cell collisions; this makes it useful as a
reducer:

```bash
$ ni n010p'r 0, a%3, 1' X
4	3	3
```

## 1-D Matrix Operations (`Z`)
Data in row form can be flattened (lengthened?) into a column via `pF_`.

```bash
$ ni i[a b] i[c d] Z1
a
b
c
d
```

Inverting that operation, converting a column to a row with a specified number of fields is done using `Z`, which takes the number of fields as a parameter. 

```bash
$ ni i[a b] i[c d] Z1 Z2
a	b
c	d
```
 

## NumPy interop
You can transform dense matrices with NumPy using the `N` operator. Your code is evaluated in an imperative context and side-effectfully transforms the input matrix, which is called `x`.

```bash
$ ni n10p'r map a*$_, 1..10'
1	2	3	4	5	6	7	8	9	10
2	4	6	8	10	12	14	16	18	20
3	6	9	12	15	18	21	24	27	30
4	8	12	16	20	24	28	32	36	40
5	10	15	20	25	30	35	40	45	50
6	12	18	24	30	36	42	48	54	60
7	14	21	28	35	42	49	56	63	70
8	16	24	32	40	48	56	64	72	80
9	18	27	36	45	54	63	72	81	90
10	20	30	40	50	60	70	80	90	100
$ ni n10p'r map a*$_, 1..10' N'x = x + 1'
2	3	4	5	6	7	8	9	10	11
3	5	7	9	11	13	15	17	19	21
4	7	10	13	16	19	22	25	28	31
5	9	13	17	21	25	29	33	37	41
6	11	16	21	26	31	36	41	46	51
7	13	19	25	31	37	43	49	55	61
8	15	22	29	36	43	50	57	64	71
9	17	25	33	41	49	57	65	73	81
10	19	28	37	46	55	64	73	82	91
11	21	31	41	51	61	71	81	91	101
```

`N` gets the full input stream unless you use a partition:

```bash
$ ni n4N'x = x.T'
1	2	3	4
```

This example raises an important issue: ni always imports NumPy arrays as 2D objects, never 1D (even if it's just a column of numbers). It will, however, promote any 1D arrays into column vectors.

```bash
$ ni n4N'x = reshape(x, (-1))'
1
2
3
4
```

## Partitioned matrices
The operations above caused the entire input stream to be read into memory, which is not very scalable. Each matrix operator allows you to specify that the first N columns represent a partition identifier: if you indicate this, then
each matrix ends when the partition fields change.

For example, suppose we've got a bunch of words and we want to partition our analysis by the first letter. We start by splitting that into its own column:

```bash
$ ni //license plc FW Z1 p'r/(.)(.*)/' g r10
2	016
a	
a	
a	bove
a	ction
a	ll
a	n
a	nd
a	nd
a	nd
```

Now we can apply matrix operators with the `B` qualifier, indicating that matrices start at column B and everything left of that is the partition ID. Let's form letter occurrence matrices by expanding into sparse form.

```bash
$ ni //license plc FWpF_ p'r split//' g r10
2	0	1	6
a
a
a	b	o	v	e
a	c	t	i	o	n
a	l	l
a	n
a	n	d
a	n	d
a	n	d
$ ni //license plc FWpF_ p'r split//' g YB r10
2	0	0	0
2	0	1	1
2	0	2	6
a	1	0	b
a	1	1	o
a	1	2	v
a	1	3	e
a	2	0	c
a	2	1	t
a	2	2	i
$ ni //license plc FWpF_ p'r split//' gYB fABD gcfBCDA r10
2	0	6	1
a			2
a	b	v	1
a	c	i	1
a	l		1
a	n		9
a	r	s	1
a	s		1
a	s	o	1
a	u	h	1
```

At this point we have partitioned sparse matrices, and each row has the form
`first-letter row-number subsequent-letter frequency`. We can convert these to
dense matrices by using `,z` to assign a number to each subsequent letter (so
that each gets a unique column index), then sorting and using `X`.

```bash
$ ni //license plc FWpF_ p'r split//' \
      gYBfABDgcfBCDA ,zC o XB r10
a		2
a			1
a				1
a		1
a		9
a					1
a		1				1
a							1
b		2
b		1
```

Now the matrix is in a form that NumPy can process. The `N` operator automatically zero-fills to the right to make sure the matrix is rectangular (as opposed to the ragged edges we have above).

```bash
$ ni //license plc FWpF_ p'r split//' \
     gYBfABDgcfBCDA,zCo XB \
     NB'x *= 2' YB,qD.01XB r10
a	0	4	0	0	0	0	0
a	0	0	2	0	0	0	0
a	0	0	0	2	0	0	0
a	0	2	0	0	0	0	0
a	0	18	0	0	0	0	0
a	0	0	0	0	2	0	0
a	0	2	0	0	0	2	0
a	0	0	0	0	0	0	2
b	0	4
b	0	2
```

You can use multiline code with Python and ni will fix the indentation so everything works. For example:

```bash
$ ni //license plc FWpF_ p'r split//' \
     gYBfABDgcfBCDA,zCo XB \
     NB'x *= 2
        x += 1' r10
a	1	5	1	1	1	1	1
a	1	1	3	1	1	1	1
a	1	1	1	3	1	1	1
a	1	3	1	1	1	1	1
a	1	19	1	1	1	1	1
a	1	1	1	1	3	1	1
a	1	3	1	1	1	3	1
a	1	1	1	1	1	1	3
b	1	5
b	1	3
```

It also works with blocks that require indentation:

```bash
$ ni //license plc FWpF_ p'r split//' \
     gYBfABDgcfBCDA,zCo XB \
     NB'if True:
          x = x + 1' r3
a	1	3	1	1	1	1	1
a	1	1	2	1	1	1	1
a	1	1	1	2	1	1	1
```
107 doc/monitor.md
# Monitors
If you run a pipeline that takes longer than a couple of seconds, ni will emit
monitor output to standard error. It looks like this:

```sh
$ ni nE9S8p'sin(rand())' rp'a > 0.1' ,q0.01 czn
 6106K  2085K/s  -8 905930
 4223K  1427K/s  24 0.735911990151528
 3672K  1251K/s  16 0.3174551373783
  985K   339K/s -19 0.45
 1329K   456K/s -32 ["count"]
```

Each row corresponds to the output side of one pipeline operation:

```sh
$ ni --explain nE9S8p'sin(rand())' rp'a > 0.1' ,q0.01 czn
["n",1,1000000001]
["row_fixed_scale",8,[["perl_mapper","sin(rand())"]]]
["perl_grepper","a > 0.1"]
[["quantize",[1,0],0.01]]
["count"]
["sink_null"]
```

(`sink_null` produces no output, so its monitor will never appear.)

There are four columns:

```
     +------------------------- total output data (from this operator)
     |        +---------------- output data rate
     |        |   +------------ output data "pressure" (more below)
     |        |   |      +----- data preview, or --explain for the operator
     |        |   |      |        (the display alternates between the two)
 6106K  2085K/s  -8 905930
```

## Throughput and data pressure
Data pipeline performance isn't entirely straightforward, particularly when
buffering operators are involved. Most ni operators, however, are written to
stream data quickly from input to output -- in which case the slowest operator
will govern the overall pipeline speed. For example, we can write an
artificially slow map function to reduce the throughput everywhere:

```sh
$ ni nE7 pa+1 zn                        # a few seconds
$ ni nE7 p'sleep 0.1; a + 1' zn         # quite a lot longer
```

Throughput and output data won't help you identify the pipeline bottleneck in
these situations because the pipeline is effectively moving in lock-step. This
is where the concept of data pressure comes in.

To understand how ni computes data pressure, it is helpful to envision each part
of the pipeline as having a monitor that sits in between it and the next
operator, accepting output from the former and sending it to the latter:

```
         +----------+                     +----------+
         |          |                     |          |
         | operator |     +---------+     | operator |
... ==>  |    X     | ==> | monitor | ==> |    Y     | ==> ...
         |          |     +---------+     |          |
         +----------+                     +----------+
```

The output data pressure of process X is `10 * log2(output_time / input_time)`,
where `output_time` is the amount of time the monitor spends waiting for output
from X and `input_time` is the amount of time the monitor spends waiting for
process Y to accept input.

Going back to our two examples above, if you run the second one, you'll see
monitor output like this:

```
 2815K    90K/s 115 ["n",1,10000001]
 2752K    88K/s-116 ["perl_mapper","sleep 0.1; a + 1"]
```

The output pressure from `nE7` is 115, and the output pressure of the Perl
command is -116, meaning `n` was producing data about 3000 times as fast as the
Perl process was consuming it (and the Perl process was producing data about
3000 times _slower_ than `sink_null` was willing to consume it). Intuitively
this makes sense: the Perl command is creating backpressure against `n`, and
`sink_null` is, relatively to the Perl command, creating the opposite (i.e. it
appears to have no backpressure at all, acting like a vacuum).

## Dealing with bottlenecks
The easiest way to solve a bottleneck is to [horizontally scale](scale.md) the
slow sections of the pipeline. This isn't always possible, for example if you
need to sort things, but when it is possible it should produce significant
speedups. For example:

```sh
$ ni nE7 S8p'sleep 0.1; a + 1' zn
33014K   645K/s  49 4356592
21735K   433K/s-117 ["row_fixed_scale",8,[["perl_mapper","sleep 0.1; a + 1"]]]
```

Now the Perl function appears to be only ~32x slower than `n` -- unexpectedly
fast for two reasons. First, `S` maintains large memory buffers that it fills
quickly at pipeline startup; that will distort initial readings, though it will
ultimately even out. Second, `n` produces rows whose length increases as we
read more input; so the `sleep 0.1` in the Perl command has less of an impact
the further we get into the stream. (This is an example of data-dependent
throughput, which happens a lot in practice.)
46 doc/net.md
# Network operators
## HTTP
ni uses `curl` to retrieve HTTP/HTTPS urls. For example:

```bash
$ nc -l 1400 <<'EOF' > /dev/null &      # an enterprise-grade web server
HTTP/1.1 200 OK
Content-length: 12

Hello world
EOF
$ sleep 1; ni http://localhost:1400 n3
Hello world
1
2
3
```

(The `sleep 1` before the ni command is to give the webserver's J2EE stack time
to boot up, which helps the tests work consistently.)

## SSH
You can move a part of your pipeline to another machine via SSH. ni will run
itself on that machine by sending itself over STDIN to `perl`, so it works
whether or not ni exists on the remote system, and whether or not the remote
disk is writable.

The SSH operator is `s` and looks like this:

```sh
$ ni i[who let the dogs out who who who] shostname[gc FW p'r a, length b'] r10
```

Conceptually, here's how ni executes the above:

```sh
$ ni i[who let the dogs out who who who] \
  | ssh hostname "ni gc FW p'r a, length b'" \
  | ni r10
```

You can, of course, nest SSH operators:

```sh
$ ni i[who let the dogs out who who who] shost1[shost2[gc]] r10
```
98 doc/options.md
# Complete ni operator listing
Implementation status:
- T: implemented and automatically tested
- M: implemented and manually tested (so it might be broken)
- P: partially implemented
- I: implemented
- U: unimplemented

## Resources
Scheme     | Status | Example
-----------|--------|--------
`file://`  | M      | `file:///usr/share/dict/words`
`hdfs://`  | M      | `hdfs:///user/x/foobar`
`http://`  | T      | `http://localhost:8090`
`https://` | M      | `https://en.wikipedia.org`
`s3cmd://` | I      | `s3cmd://some/path/to/object`

## Stream operators
Operator | Status | Example      | Description
---------|--------|--------------|------------
`+`      | T      | `+p'foo'`    | Appends a data source evaluated with no input
`^`      | T      | `^file`      | Prepends a data source
`=`      | T      | `=\>f`       | Duplicate stream, ignoring fork output
`\>`     | T      | `\>file`     | Sinks stream into resource, emits resource name
`\>\'R`  | M      | `\>\'R`      | Converts a stream of resource names into a packed resource stream
`\<`     | T      | `\<`         | Opposite of `\>`
`%`      | I      | `%n100`      | Interleave lines, optionally with a bias ratio
`-`      |        |              |
`_`      |        |              |
`\!`     | I      | `\!p'F_==3'` | Assert a condition
`,`      | T      | `,jAB`       | Enter cell context
`:`      | T      | `:foo[nE8z]` | Checkpointed stream
`::`     | M      | `::x[n100]`  | Create an in-memory data closure
`//:`    | M      | `//:x`       | Append closure data
`@`      | U      | `@foo[\>@a]` | Enter named-gensym context
`\##`    | U      | `\>foo \##`  | Cat **and then obliterate** named resource(s)
`1`      | M      | `1p'"hi"'`   | `1` is an alias for `n1`
`a`      |        |              |
`b`      | T      | `bL40`       | Binary operators
`c`      | T      | `c`          | `uniq -c`, but emits proper TSV format
`d`      |        |              |
`e`      | T      | `e[tac]`     | Exec shell command
`f`      | T      | `fACB`       | Reorder, duplicate, or drop fields by column
`g`      | T      | `gA`         | Sort by all or selected columns
`h`      |        |              |
`i`      | T      | `ifoo`       | Append literal text `foo`
`j`      | U      | `j foo`      | Join sorted streams on field values
`k`      |        |              |
`l`      | T      | `l'(1+ a)'`  | Map over rows using Common Lisp
`m`      | T      | `m'a + 1'`   | Map over rows using Ruby
`n`      | T      | `n10`        | Generate or prepend line numbers
`o`      | T      | `oC`         | Numeric sort ascending
`p`      | T      | `p'a + 1'`   | Map over rows using Perl
`q`      |        |              |
`r`      | T      | `r10`        | Select rows by criterion
`s`      | M      | `sfoo[n10]`  | Evaluate a lambda on another machine using SSH
`t`      |        |              |
`u`      | T      | `u`          | Just like `uniq`
`v`      | T      | `vCplc`      | Vertically transform a range of columns
`w`      | T      | `wn100`      | "With": join a stream rightwards
`x`      | T      | `xC`         | Exchange first fields with others
`y`      |        |              |
`z`      | T      | `z4`         | Compress or decompress
`A`      |        |              |
`B`      | T      | `Bn`         | Buffer a stream
`C`      | T      | `Cubuntu[g]` | Containerize a pipeline with Docker
`D`      | PT     | `D:foo`      | Destructure structured text data (JSON/XML)
`E`      | T      | `Efoo[g]`    | Execute a pipeline in an existing Docker
`F`      | T      | `FC`         | Parse data into fields
`G`      | T      | `GA...`      | Gnuplot prefix
`H`      | T      | `HS:::`      | Send named files through hadoop
`I`      | I      | `I[...]`     | Process concatenated image files
`J`      |        |              |
`K`      |        |              |
`L`      | U      | `L'(1+ a)'`  | (Reserved for Lisp driver)
`M`      | U      | `M'svd(x)'`  | Faceted Octave matrix interop
`MM`     | I      | `MM`         | [Map-o-matic](https://github.com/spencertipping/mapomatic)
`N`      | T      | `N'svd(x)'`  | Faceted NumPy matrix interop
`O`      | T      | `OD`         | Numeric sort descending
`P`      | T      | `PLg`        | Evaluate Pyspark lambda context
`Q`      |        |              |
`R`      | U      | `R'a+1'`     | Faceted R matrix interop
`S`      | T      | `S16[rx100]` | Scale across multiple processes
`T`      |        |              |
`U`      |        |              |
`V`      | U      | `VB`         | Pivot and collect on field B
`W`      | T      | `Wn100`      | "With": join a stream leftwards
`X`      | T      | `X`          | Sparse to dense matrix conversion
`Y`      | T      | `Y`          | Dense to sparse matrix conversion
`Z`      | T      | `Z2`         | Fold/unfold stream to specified width


## Cell operators
Operator | Status | Example | Description
---------|--------|---------|------------
`h`      | T      | `,z`    | Turns each unique value into a hash.
`H`      | T      | `,HAB`  | Turns each unique value into a unique number between 0 and 1.
`z`      | T      | `,h`    | Turns each unique value into an integer.
506 doc/perl.md
# Perl interface
**NOTE:** This documentation covers ni's Perl data transformer, not the
internal libraries you use to extend ni. For the latter, see
[extend.md](extend.md) (`ni //help/extend`).

ni also grudgingly supports Ruby: [ruby.md](ruby.md). However, as far as I know
nobody uses this code and I'm likely to cannibalize the `m` operator at some
point.

ni provides the `p` operator to execute a Perl line processor on the current
data stream. For example:

```bash
$ ni n5p'a * a'                 # square some numbers
1
4
9
16
25
```

`p` does a decent job of figuring out where a chunk of code ends where lambdas
are concerned:

```bash
$ ni ::plfoo[n4p'a*a'] //:plfoo
1
4
9
16
```

**NOTE:** The Perl driver won't execute your code at all if the input stream is
empty. If you're using the Perl driver to generate data, you need to feed it a
row using, e.g. `n1` (for which a shorthand is just `1`):

```bash
$ ni +p'1..5'                   # nothing happens here
$ ni +n1p'1..5'                 # the single input row causes `p` to run
1
2
3
4
5
$ ni 1p'"hello"'                # 1 == n1
hello
```

## Basic stuff
`a` to `l` are one-letter functions that return the first 12 tab-delimited
values from the current line. (12 wasn't chosen arbitrarily; the letter `m` is
Perl syntax for regular expressions, so we can't use it.) `r(...)` is a
function that takes a list of values and prints a tab-delimited row. For
example:

```bash
$ ni n4p'r a, a + 1'                    # generate two columns
1	2
2	3
3	4
4	5
$ ni n4p'r a, a + 1' p'r a + b'         # ... and sum them
3
5
7
9
```

Note that whitespace is required after every `p'code'` operator; otherwise ni
will assume that everything following your quoted code is also Perl.

Internally, `a`, `b`, etc are defined like this, which I explain below:

```pl
sub a() {F_ 0}
sub b() {F_ 1}
...
```

### `F_`: the array of fields
The Perl code given to `p` is invoked on each line of input, which is stored in
`$_`. `F_(...)` takes one or more column indexes (as zero-based integers) and
returns the field values. If you don't pass in anything, it returns all of the
fields for the line. For example:

```bash
$ ni /etc/passwd F::r3
root	x	0	0	root	/root	/bin/bash
daemon	x	1	1	daemon	/usr/sbin	/bin/sh
bin	x	2	2	bin	/bin	/bin/sh
$ ni /etc/passwd F::r3p'r F_ 0..3'
root	x	0	0
daemon	x	1	1
bin	x	2	2
$ ni /etc/passwd F::r3p'r F_ 1..3'
x	0	0
x	1	1
x	2	2
$ ni /etc/passwd F::r3p'r scalar F_'            # number of fields
7
7
7
```

If you want to select field ranges to the end of the line (like Perl's
`@_[1..$#_]` construct), `FM` is analogous to `$#_`:

```bash
$ ni /etc/passwd F::r3p'r F_ 3..FM'
0	root	/root	/bin/bash
1	daemon	/usr/sbin	/bin/sh
2	bin	/bin	/bin/sh
$ ni /etc/passwd F::r3p'r FR 3'         # FR(n) == F_(n..FM)
0	root	/root	/bin/bash
1	daemon	/usr/sbin	/bin/sh
2	bin	/bin	/bin/sh
```

### `r`, multiple rows, and return values
`p` executes your Perl code using essentially this template:

```pl
sub row {
  # your code goes here
}
while (<STDIN>) {
  defined $_ && print "$_\n" for row();
}
```

Counterintuitively, `r(...)` doesn't return a value; it returns an empty list
and side-effectfully prints a row. It works this way because that allows you to
generate arbitrarily many rows in constant space.

This design is also what makes it possible to omit `r` altogether; then you're
returning one or more values, each of which will become a row of output:

```bash
$ ni n2p'a, a + 100'                    # return without "r"
1
101
2
102
$ ni n2p'r a, a + 100'                  # use "r" for side effect, return ()
1	101
2	102
$ ni n3p'r $_ for 1..a'                 # use r imperatively, implicit return
1
1
2
1
2
3
```

As a shorthand, any array references you return will become rows:

```bash
$ ni n3p'[a, a+1, a+2]'
1	2	3
2	3	4
3	4	5
```

### `pR`: `require` external source for perl context
Sometimes you want to have access to external functions inside your perl
mappers/greppers/etc; ni gives you the `pR` operator to do this. For example:

```bash
$ cat > functions.pm <<'EOF'
package ni::pl;       # important! this is the package where your perl code runs
sub normalize
{
  my $sum = sum @_;   # required code can call back into ni functions
  map $_ / ($sum || 1), @_;
}
EOF
$ ni pRfunctions.pm 1p'r normalize 1, 2, 5'
0.125	0.25	0.625
```

**NOTE:** If you're using `pR` and you have code that depends on that `pR` to
parse, ni may fail to parse closing brackets. You can either explicitly wrap
subroutines with `()`, or you can use the workarounds suggested by the
perl-parse error message if you run into this. It isn't possible for ni to
figure this out for you because it parses the command line before executing
meta-operators. (And it isn't possible to do this differently because the `pR`
might be inside `s` or similar.)

As usual with ni, any source you require with `pR` will be shipped over SSH and
Docker connections, bundled into Hadoop jars, and generally will be available
wherever your pipeline goes. There are some limitations, though; in particular,
ni doesn't track any files your code _itself_ requires -- so if `functions.pm`
had `require`d `foo.pm`, for instance, ni would only know to ship
`functions.pm` and not `foo.pm`.

Normally this is a feature; it makes it possible for you to `use` or `require`
Perl standard modules without propagating your local version onto
possibly-incompatible remotes (e.g. if you have v5.22 locally but the remote
runs v5.10, it's possible that your local standard libraries will break on the
remote perl).

ni can probably infer sub-inclusions, but this requires some invasive
modification to Perl's `require` mechanism through the use of hooks, and I
haven't implemented it yet. For the moment, sub-inclusions aren't really
handled; although you could `pR` each one, this won't set `%INC` keys and any
sub-`require` statements in your source is likely to fail as a result (since
the files won't exist on the remote end). This is lame and will be fixed at
some point.

`pR` takes ni lambdas, which makes it possible to load source from nonstandard
locations like HTTP:

```bash
$ nc -l 3001 <<'EOF' > /dev/null &
HTTP/1.1 200 OK
Content-Length: 54

package ni::pl;
sub this_worked { r "it worked", @_ }
EOF
$ sleep 1
$ ni pRhttp://localhost:3001 1p'this_worked 5, 6, 7'
it worked	5	6	7
```

## Buffered readahead
`p` code can read forwards in the input stream. This is trivially possible by
calling `rl()` ("read line"), which destructively advances to the next line and
returns it; but more likely you'd use one of these instead:

- `@lines = rw {condition}`: read lines while a condition is met
- `@lines = ru {condition}`: read lines until a condition is met
- `@lines = re {a + b}`: read lines while `a + b` is equal

**NOTE:** `rw`, `ru`, and `re` are destructive operators in that they consume
lines and destroy the context for `a`, `b`, etc.

```bash
$ ni n10p'r ru {a%4 == 0}'              # read forward until a multiple of 4
1	2	3
4	5	6	7
8	9	10
```

The line array returned by `ru` is just an array of flat, tab-delimited strings
(verbatim lines from standard input), but you can extract fields using the
column-accessor functions `a_`, `b_`, etc:

```bash
$ ni n10p'r map a*$_, 1..10' =\>mult-table
1	2	3	4	5	6	7	8	9	10
2	4	6	8	10	12	14	16	18	20
3	6	9	12	15	18	21	24	27	30
4	8	12	16	20	24	28	32	36	40
5	10	15	20	25	30	35	40	45	50
6	12	18	24	30	36	42	48	54	60
7	14	21	28	35	42	49	56	63	70
8	16	24	32	40	48	56	64	72	80
9	18	27	36	45	54	63	72	81	90
10	20	30	40	50	60	70	80	90	100
$ ni mult-table p'r g_ ru {a%4 == 0}'   # extract seventh column from each line
7	14	21
28	35	42	49
56	63	70
```

`a_` etc are defined like this, with an exception for the scalar return case:

```pl
sub a_ {local $_; map((split /\t/)[0], map split(/\n/), @_)}
sub b_ {local $_; map((split /\t/)[1], map split(/\n/), @_)}
...
```

The line split enables more idiomatic handling of data closures:

```bash
$ ni ::squares[n100p'100 - a' p'r a, a*a'] \
     n5p'^{@sq{a_ squares} = b_ squares} $sq{a()}'
1
4
9
16
25
```

## Hash constructors
The above code can be condensed a bit with hash constructors, which are pairs
of columns:

```bash
$ ni ::squares[n100p'100 - a' p'r a, a*a'] n5p'^{%sq = ab_ squares} $sq{a()}'
1
4
9
16
25
```

## Utility functions
ni predefines some stuff you may find useful:

- `sum(@)`, `prod(@)`, `mean(@)`
- `first(@)`, `last(@)`
- `max(@)`, `min(@)`, `maxstr(@)`, `minstr(@)`, `argmax(&@)`, `argmin(&@)`
- `any(&@)`, `all(&@)`, `uniq(@)`, `%f = %{freqs(@)}`
- `reduce {f} $init, @xs`
- `reductions {f} $init, @xs`
- `cart([a1, a2, a3], [b1, b2, b3], ...) = [a1, b1, ...], [a1, b2, ...], ...`:
  Cartesian product

```bash
$ ni n100p'sum rw {1}'
5050
$ ni n10p'prod rw {1}'
3628800
$ ni n100p'mean rw {1}'
50.5
```

The Cartesian product function works, which is a considerable improvement over
its prior behavior:

```bash
$ ni n1p'cart [1,2], [1,2,3], ["a","b"]'
1	1	a
1	1	b
1	2	a
1	2	b
1	3	a
1	3	b
2	1	a
2	1	b
2	2	a
2	2	b
2	3	a
2	3	b
```

## Streaming lookahead
This is implemented in terms of reducers, and gives you the ability to reduce
arbitrarily many rows in constant space. There are two parts to this. First,
the streaming reduce functions `se` and `sr`; and second, compound reducers
(very useful, and explained in the next section).

### `sr`
Reduces the entire data stream:

```pl
@final_state = sr {reducer} @init_state
```

For example, to sum arbitrarily many numbers in constant space:

```bash
$ ni n10000p'sr {$_[0] + a} 0'
50005000
```

### `se`
Reduces over a contiguous group of rows for which the partition function
remains equal. (Mnemonic is "stream while equal".)

```pl
@final_state = se {reducer} \&partition_fn, @init_state
```

**NOTE**: There is _no comma_ between the reducer and the partition function.


For example, to naively get a comma-delimited list of users by login shell:

```bash
$ ni /etc/passwd F::gGp'r g, se {"$_[0]," . a} \&g, ""'
/bin/bash	,root
/bin/false	,syslog
/bin/sh	,backup,bin,daemon,games,gnats,irc,libuuid,list,lp,mail,man,news,nobody,proxy,sys,uucp,www-data
/bin/sync	,sync
```

`se` has shorthands for the first 17 columns: `sea`, `seb`, ..., `seq`; they are called as:

```pl
@final_state = sea {reducer} @init_state
```


## Compound reducers
If you want to do something like calculating the sum of one column, the average
of another one, and the min/max of a third, you'll end up writing some awkward
reducer code. ni provides a facility called compound reduction to deal with
this. For example, here's the hard way:

```bash
$ ni n100p'my ($sum, $n, $min, $max) = sr {$_[0] + a, $_[1] + 1,
                                            min($_[2], a), max($_[2], a)}
                                           0, 0, a, a;
            r $sum, $sum / $n, $min, $max'
5050	50.5	1	100
```

And here's the easy way, using `rc`:

```bash
$ ni n100p'r rc \&sr, rsum "a", rmean "a", rmin "a", rmax "a"'
5050	50.5	1	100
```

### What's going on here
`rsum`, `rmean`, etc, return compound reducers, which are hash references with
keys that indicate (1) the initial state, (2) the reduction function **as a
string**, and (3) the finalizer (which is why `rmean` can return a single
number despite its intermediate state being the separated sum and number).

Compound reducers are compiled functions, which means their arguments are
expressed as strings representing quoted code. This is why we use `"a"` rather
than `a` in the example above: the string `'a'` is spliced into a function body
along with the other reducer expressions and compiled. The result is a very
efficient reducer function that ends up looking like this:

```pl
sub {($_[0] + a, $_[1] + a, $_[2] + 1, min($_[3], a), max($_[4], a))}
```

`rc` hands this function to `sr` and then uses the finalizer functions to
return individual values, one per initial reducer.

### Custom compound reducers
You can easily create your own compound reducer using `rfn`. For example, let's
count the frequency of each lowercase letter in a file:

```bash
$ ni /etc/passwd FWpsplit// r/[a-z]/ \
     p'my %freqs = %{rc \&sr, rfn q{ ++${%1}{a()} && %1 }, {}};
       map r($_, $freqs{$_}), sort keys %freqs'
a	39
b	36
c	14
d	13
e	17
f	1
g	11
h	20
i	46
k	3
l	19
m	14
n	50
o	25
p	15
r	24
s	51
t	15
u	17
v	12
w	12
x	23
y	12
```

Here's what's going on.

- `FW`: split into words
- `psplit//`: the same as `p'split //'`: split the line into individual chars,
  returned as an array so we end up with each on its own output line
- `r/[a-z]/`: keep all lowercase letters from those rows
- `p'...'`: apply perl to rows
  - `rfn q{ ++${%1}{a()} && %1 }, {}`: a reducer whose initial state is the
    empty hash `{}`, and whose reducer function does the following:
    - `q{ ++${%1}{a()} ...}`: `%1` is the reduced quantity, and `a()` is the
      first column of the line. (We wouldn't normally need parens, but if we
      omit them here Perl will assume `a` itself is the key.) We're
      incrementing the entry within the `%{%1}` hash.
    - `&& %1` is a way to return the hash reference as the reduced value (since
      we're modifying it in place). We need to do this without using a comma
      because each reducer function is evaluated in list context.

Of course, in this case it's a lot easier to use the streaming count operator:

```bash
$ ni /etc/passwd FWpsplit// r/[a-z]/gcx
a	39
b	36
c	14
d	13
e	17
f	1
g	11
h	20
i	46
k	3
l	19
m	14
n	50
o	25
p	15
r	24
s	51
t	15
u	17
v	12
w	12
x	23
y	12
```
28 doc/pyspark.md
# PySpark interop
```lazytest
# All of these tests require Docker, so skip if we don't have it
if ! [[ $SKIP_DOCKER ]]; then
```

ni's `P` operator compiles a series of stream operators into PySpark. It takes
a context as its first argument, then a lambda of stream operations. Like other
ni commands, data is streamed into and out of the PySpark context. For example,
using the `L` (for "local") Spark profile:

```bash
$ ni Cgettyimages/spark[PL[n10] \<o]
1
2
3
4
5
6
7
8
9
10
```

```lazytest
fi              # $SKIP_DOCKER
```
348 doc/row.md
# Row operations
These are fairly well-optimized operations that operate on rows as units, which
basically means that ni can just scan for newlines and doesn't have to parse
anything else. They include:

- Take first/last N
- Take uniform-random or periodic sample
- Rows matching regex
- Rows containing specified fields
- Rows satisfying code
- Reorder rows
- Count identical rows
- Joining sorted rows

## First/last
Shorthands for UNIX `head` and `tail`.

```bash
$ ni n10r3                      # take first 3
1
2
3
$ ni n10r~3                     # take last 3
8
9
10
$ ni n10r-7                     # drop first 7
8
9
10
```

Using commands like `r10` can break pipes and cause you to get less data than
you might expect; see "pipe signals" in [warnings.md](warnings.md) (`ni
//help/warnings`) for details.

A "safe" version of `ni`'s "take first N" command exists, called `rs`. `rsN` will have the same result as `rN`, but `rs` will be much slower and should only be used when a pipe signal must be avoided, for example during a [Hadoop Streaming](hadoop.md) job.

```bash
$ ni n10 rs3
1
2
3
```

## Sampling
```bash
$ ni n10000rx4000               # take the 1st of every 4000 rows
1
4001
8001
$ ni n10000r.0002               # sample uniformly, P(row) = 0.0002
1
6823
8921
9509
```

It's worth noting that uniform sampling, though random, is also deterministic;
by default ni seeds the RNG with 42 every time (though you can change this by
exporting `NI_SEED`). ni also uses an optimized Poisson process to sample rows,
which minimizes calls to `rand()`.

**NOTE:** If you're sampling from a large dataset, you will often get some
speedup by parallelizing the row operator. For example:

```sh
$ ni /path/to/large/data rx100          # ~300MB/s
$ ni /path/to/large/data S8rx100        # ~800MB/s
```

See [scale.md](scale.md) for details about horizontal scaling.

## Row matching

There are several ways you can keep only rows matching a certain criterion.

The simplest way is to use a regex:
```bash
$ ni n10000r/[42]000$/
2000
4000
$ ni n1000r/[^1]$/r3
2
3
4
```

These regexes are evaluated by Perl, which is likely to be faster than `grep`
for nontrivial patterns.

You can also row match using code in any language that ni supports. At current,
it supports Perl, Ruby, and Common Lisp.

`rp` means "select rows for which this Perl expression returns true".

```bash
$ ni n10000rp'$_ % 100 == 42' r3
42
142
242
```

The expression has access to column accessors and everything else described in
[perl.md](perl.md) (`ni //help/perl`).

Note that whitespace is always required after quoted code.

**TODO:** other languages

## Column assertion
In real-world data pipelines it's common to have cases where you have missing
data. To remove those, you can select only rows which provide a nonempty value
for one or more columns:

```bash
$ ni n1000p'r/(.)(.*)/' r15     # until 10, the second field is empty
1	
2	
3	
4	
5	
6	
7	
8	
9	
1	0
1	1
1	2
1	3
1	4
1	5
$ ni n1000p'r/(.)(.*)/' rB r8   # rB = "rows for which field B exists"
1	0
1	1
1	2
1	3
1	4
1	5
1	6
1	7
```

```bash
$ ni n10rB | wc -l              # no field B here, so no output
0
```

```bash
$ ni n10p'r a; ""' rA | wc -l   # remove blank lines
10
```

### Set membership
You can also assert that a column's value is one of a set of things. If you
want to do this for a very large set, you should consider using [bloom
filters](bloom.md).

```bash
$ ni n100 riA[n4 p'a*2']        # intersect column A with values from n4 p'a*2'
2
4
6
8
```

An uppercase `I` does the opposite, rejecting specified values:

```bash
$ ni n10 rIAn5
6
7
8
9
10
```

## Sorting
ni has four operators that shell out to the UNIX sort command. Two are
alpha-sorts:

```bash
$ ni n100n10gr4                 # g = 'group'
1
1
10
10
$ ni n100n100gur4               # u = 'uniq'
1
10
100
11
```

The idea behind `g` as `group` is that this is what you do prior to an
aggregation; i.e. to group related rows together so you can stream into a
reducer.

ni also has two `order` operators that sort numerically:

```bash
$ ni n100or3                    # o = 'order': sort numeric ascending
1
2
3
$ ni n100Or3                    # O = 'reverse order'
100
99
98
```

### Specifying sort columns
When used without options, the sort operators sort by a whole row; but you can
append one or more column specifications to change this. I'll generate some
multicolumn data to demonstrate this (see [perl.md](perl.md) (`ni //help/perl`)
for an explanation of the `p` operator).

```bash
$ ni n100p'r a, sin(a), log(a)' > data          # generate multicolumn data
$ ni data r4
1	0.841470984807897	0
2	0.909297426825682	0.693147180559945
3	0.141120008059867	1.09861228866811
4	-0.756802495307928	1.38629436111989
```

Now we can sort by the second column, which ni refers to as `B` (in general, ni
uses spreadsheet notation: columns are letters, rows are numbers):

```bash
$ ni data oBr4
11	-0.999990206550703	2.39789527279837
55	-0.99975517335862	4.00733318523247
99	-0.999206834186354	4.59511985013459
80	-0.993888653923375	4.38202663467388
```

Columns can be suffixed with `g`, `n`, and/or `-` modifiers to modify how they
are sorted (these behave as described for `sort`'s `-k` option), and ni prefers
this interpretation:

```bash
$ ni data oBg r4                # 'g' is a modifier of B, not another sort
11	-0.999990206550703	2.39789527279837
55	-0.99975517335862	4.00733318523247
99	-0.999206834186354	4.59511985013459
80	-0.993888653923375	4.38202663467388
$ ni data oB g r4               # 'g' is a sorting operator
1	0.841470984807897	0
10	-0.54402111088937	2.30258509299405
100	-0.506365641109759	4.60517018598809
11	-0.999990206550703	2.39789527279837
```

### Grouped sort
The `gg` operator sorts key-grouped bundles of rows; this is a piecewise sort.
For example, to sort words within lengths:

```bash
$ ni i{foo,bar,bif,baz,quux,uber,bake} p'r length, a' ggAB
3	bar
3	baz
3	bif
3	foo
4	bake
4	quux
4	uber
```

The first column specifies the grouping key, and subsequent columns are
interpreted as for the `g` operator.

```bash
$ ni i{foo,bar,bif,baz,quux,uber,bake} p'r length, a' ggAB-
3	foo
3	bif
3	baz
3	bar
4	uber
4	quux
4	bake
$ ni n10p'r "a", a' ggABn- r4
a	10
a	9
a	8
a	7
```


## Counting
ni gives you the `c` operator to count runs of identical rows (just
like `uniq -c`).

```bash
$ ni i[who let the dogs out who who who] Z1 c # unsorted count
1	who
1	let
1	the
1	dogs
1	out
3	who
```

```bash
$ ni  i[who let the dogs out who who who] Z1 gc # sort first to group words
1	dogs
1	let
1	out
1	the
4	who
```

```bash
$ ni i[who let the dogs out who who who] Z1 gcO # by descending count
4	who
1	the
1	out
1	let
1	dogs
```

## Joining

You can use the `j` operator to inner-join two streams. 
```bash
$ ni i[foo bar] i[foo car] i[foo dar] i[that no] i[this yes] \
     j[ i[foo mine] i[not here] i[this OK] i[this yipes] ]
foo	bar	mine
foo	car	mine
foo	dar	mine
this	yes	OK
this	yes	yipes
```

Without any options, `j` will join on the first tab-delimited column of both streams, however, `j` can join on multiple columns by referencing the columns by letter:

```bash
$ ni i[M N foo] i[M N bar] i[M O qux] i[X Y cat] i[X Z dog] \
     jAB[ i[M N hi] i[X Y bye] ]
M	N	foo	hi
M	N	bar	hi
X	Y	cat	bye
```


In general, the streams you are joining should be pre-sorted (though `j` will not fail if the streams aren't sorted).

The join here is slightly *asymmetric*; the left side of the join is streamed, while the right side is buffered into memory. This is useful to keep in mind for joins in a Hadoop Streaming context; the **left** side of the join should be larger (i.e. have more records) than the right side.
143 doc/ruby.md
# Ruby interface
The `m` operator (for "map") lets you use a Ruby line processor to transform
data. The Ruby and [Perl](perl.md) drivers work differently, in part to reflect
the cultural differences between the two languages. It also doesn't rely on new
Ruby features like `Enumerable::Lazy`, because it's tested to be compatible
back to Ruby 1.8.7.

```bash
$ ni n5m'ai * ai'               # square some numbers
1
4
9
16
25
```

Like `p`, `m` has lambda-end detection using Ruby syntax checking:

```bash
$ ni ::rbfoo[n4m'ai*ai'] //:rbfoo
1
4
9
16
```

## Basic stuff
`a` to `q` are one-letter functions that return the first 17 tab-delimited
values from the current line. `r(...)` is a function that takes a list of
values and returns a tab-delimited row. You can suffix a value to coerce it:

- `f`: `to_f`
- `i`: `to_i`
- `s`: `to_s`

```bash
$ ni n4m'r a, ai + 1'                   # generate two columns
1	2
2	3
3	4
4	5
$ ni n4m'r a, ai + 1' m'r ai + bi'      # ... and sum them
3
5
7
9
```

Note that whitespace is required after every `m'code'` operator; otherwise ni
will assume that everything following your quoted code is also Ruby.

### `fields`: the array of fields
The Ruby code given to `m` is invoked on each line of input, which is stored in
`$l` and is the receiver. `$l` isn't split into fields until you call `fields`,
at which point the split happens and the fields are cached for efficiency.

```bash
$ ni /etc/passwd F::r3
root	x	0	0	root	/root	/bin/bash
daemon	x	1	1	daemon	/usr/sbin	/bin/sh
bin	x	2	2	bin	/bin	/bin/sh
$ ni /etc/passwd F::r3m'r fields[0..3]'
root	x	0	0
daemon	x	1	1
bin	x	2	2
$ ni /etc/passwd F::r3m'r fields[1..3]'
x	0	0
x	1	1
x	2	2
$ ni /etc/passwd F::r3m'r fields.size'
7
7
7
```

### `r`, multiple rows, and return values
If your code returns an Enumerable, you'll get an output line for each entry.
If it returns a string, you'll have a single output line. `r()` is a function
that joins on tabs and returns the result (unlike the `r` function in the Perl
driver):

```bash
$ ni n2m'[a, ai + 100]'                 # multiple lines
1
101
2
102
$ ni n2m'r a, ai + 100'                 # multiple columns
1	101
2	102
```

ni will remove newlines from every string you give it. This makes it easier to
use backticks without any filtering.

## Buffered readahead
`m` code can read forwards in the input stream:

- `lines = rw {|l| condition}`: read lines while a condition is met
- `lines = ru {|l| condition}`: read lines until a condition is met
- `lines = re {|l| l.ai + l.bi}`: read lines while `ai + bi` is equal

```bash
$ ni n10m'r ru {|l| l.ai%4 == 0}'       # read forward until a multiple of 4
1	2	3
4	5	6	7
8	9	10
```

`ru`, etc return arrays of Line objects, and there are two ways to break them
into columns. Let's generate some columnar data:

```bash
$ ni n10m'r (1..10).map {|x| ai*x}' =\>mult-table
1	2	3	4	5	6	7	8	9	10
2	4	6	8	10	12	14	16	18	20
3	6	9	12	15	18	21	24	27	30
4	8	12	16	20	24	28	32	36	40
5	10	15	20	25	30	35	40	45	50
6	12	18	24	30	36	42	48	54	60
7	14	21	28	35	42	49	56	63	70
8	16	24	32	40	48	56	64	72	80
9	18	27	36	45	54	63	72	81	90
10	20	30	40	50	60	70	80	90	100
```

The first way is to access the fields on each line individually:

```bash
$ ni mult-table m'r ru {|l| l.ai%4 == 0}.map(&:g)'      # access column G
7	14	21
28	35	42	49
56	63	70
```

The other way is to invoke field accessor methods on the whole array:

```bash
$ ni mult-table m'r ru {|l| l.ai%4 == 0}.g'
7	14	21
28	35	42	49
56	63	70
```
25 doc/scale.md
# Pipeline scaling
The scaling operator `S` lets you work around bottlenecks by adding horizontal
scale to a section of your pipeline. For example, suppose we have this:

```bash
$ ni nE6 p'sin(a/100)' rp'a >= 0' =\>slow-sine-table e[wc -l]
500141
```

On a multicore machine, this will run more slowly than it should because
`p` processes data serially. We can parallelize it across four processes like
this:

```bash
$ ni nE6 S4[p'sin(a/100)' rp'a >= 0'] =\>parallel-sine-table e[wc -l]
500141
$ diff <(ni slow-sine-table o) <(ni parallel-sine-table o) | head -n10
```

`S` works by reading blocks of input and finding line boundaries. It then sends
groups of lines to the child processes as their input fds become available.

Scaling makes no guarantees about the ordering of the output rows, nor where
exactly the input will be split. In practice the input splits tend to be large
for performance reasons.
55 doc/script.md
# Scripting interface
It's common to have a shell script you'd like to integrate into a ni pipeline,
and possibly also into the ni image itself. This allows you to do something
more graceful than `ni e[sh my-script args...]`.

ni's scripting interface makes this possible. All you need to do is write a
normal library and include it into the ni image. For example, here's a
scripting extension that echoes its command-line arguments:

```bash
$ mkdir echo-script
$ echo echo.pl >> echo-script/lib
$ echo echo.sh >> echo-script/lib
$ cat > echo-script/echo.sh <<'EOF'
#!/bin/sh
echo "$@"
EOF
$ cat > echo-script/echo.pl <<'EOF'
defshort '/echo' => pmap q{script_op 'echo-script', "./echo.sh $_"},
                    shell_command;
EOF
```

Now let's use the library:

```bash
$ ni --lib echo-script echo[1 2 3]
1 2 3
```

Script libraries can also include subdirectories; for example:

```bash
$ mkdir -p echo2/bin
$ { echo echo2.pl; echo bin/echo2; } > echo2/lib
$ cat > echo2/echo2.pl <<'EOF'
defshort '/echo2' => pmap q{script_op 'echo2', "bin/echo2 $_"},
                     shell_command;
EOF
$ cat > echo2/bin/echo2 <<'EOF'
#!/bin/sh
echo "$# argument(s)"
echo "$@"
EOF
```

Usage is exactly as before. Note, however, that if the operator name collides
with a directory, as it does here, you need to use `'foo bar'` rather than
`[foo bar]` to disambiguate.

```bash
$ ni --lib echo2 echo2'foo bar'
2 argument(s)
foo bar
```
35 doc/sql.md
# SQL interop
ni defines a parsing context that translates command-line syntax into SQL
queries. We'll need to define a SQL connection profile in order to use it:

```bash
$ mkdir sqlite-profile
$ echo sqlite.pl > sqlite-profile/lib
$ cat > sqlite-profile/sqlite.pl <<'EOF'
defoperator sqlite => q{
  my ($db, $query) = @_;
  exec 'sqlite', '-separator', "\t", $db, $query;
};
defsqlprofile S => pmap q{sqlite_op $$_[0], $$_[1]},
                        pseq pc filename, sql_query;
EOF
```

Now we can create a test database and use this library to access it.

```bash
$ sqlite test.db <<'EOF'
CREATE TABLE foo(x int, y int);
INSERT INTO foo(x, y) VALUES (1, 2);
INSERT INTO foo(x, y) VALUES (3, 4);
INSERT INTO foo(x, y) VALUES (5, 6);
EOF
$ ni --lib sqlite-profile QStest.db foo[rx=3]
3	4
$ ni --lib sqlite-profile QStest.db foo rx=3
3	4
$ ni --lib sqlite-profile QStest.db foo Ox
5	6
3	4
1	2
```
530 doc/stream.md
# Stream operations
## Files
ni accepts file names and opens their contents in less.

```bash
$ echo test > foo
$ ni foo
test
```

Files append themselves to the data stream:

```bash
$ ni foo foo
test
test
```

ni automatically decompresses common formats (gz, lzo, lz4, xz, bzip2),
regardless of file extension:

```bash
$ echo test | gzip > fooz
$ ni fooz
test
$ cat fooz | ni
test
```

## Stream Generation
In addition to reading files, ni can generate data:

### Integer Streams

The `n` operator generates a stream of integers of a given length; if the
length is not given, `ni n` will generate an infinite stream.

```bash
$ ni n4                         # integer generator
1
2
3
4
$ ni n04                        # integer generator, zero-based
0
1
2
3
```

```sh
$ ni n                          # infinite stream of ints
1
2
3
4
5
.
.
.
```

### Pulse Stream
Many operators, for example the perl operator `p'...'` and the numpy operator
`N'...'` require an input stream. In some cases, you want to generate a dummy
stream. For this purpose you can use `n1` or its shorthand `1` to cause the
operator in question to execute.


```bash
$ ni ::word[1p'"pretty"'] n3 w[np'r word']
1	pretty
2	pretty
3	pretty
```

### Literal Text

The `i` operator puts whitespace-delimited literal text into the stream.

```bash
$ ni ifoo                       # literal text
foo
$ ni i[foo bar]                 # literal two-column text
foo	bar
$ ni i[ foo[] [bar] ]           # literal two-column text with brackets
foo[]	[bar]
```

The example above can be written equivalently as:

```bash
$ ni ::word[ipretty] n3 w[np'r word']
1	pretty
2	pretty
3	pretty
```

### bash commands
```bash
$ ni e'seq 4'                  # output of shell command "seq 4"
1
2
3
4
```

### Whitespace

```bash
$ ni 1p'"hi"' +1p'"there"'
hi
there
```

Note that the whitespace between `hi` and `there`. If this is missing, the `ni`
parser will interpret it as follows:


```bash
$ ni 1p'hi'1p'there'
hi1pthere
```

This is important to keep in mind for `ni` in general, where commands are often
very compact: sometimes whitespace (or a lack thereof) is needed for clarity.
See [debugging.md](debugging.md) for some of the common cases where whitespace
(or lack thereof) is important.

## Transformation
ni can stream data through a shell process, which is often shorter than
shelling out separately:

```bash
$ ni n3 | sort
1
2
3
$ ni n3 e'sort'                 # without +, e acts as a filter
1
2
3
$ ni n3e'sort -r'
3
2
1
$ ni n3e[ sort -r ]             # easy way to quote arguments
3
2
1
$ ni n3e[sort -r]
3
2
1
```

And, of course, ni has shorthands for doing all of the above:

```bash
$ ni n3 g       # g = sort
1
2
3
$ ni n3g        # no need for whitespace
1
2
3
$ ni n3gA-      # reverse-sort by first field
3
2
1
$ ni n3O        # NOTE: capital O, not zero; more typical reverse numeric sort
3
2
1
```

Notice that ni typically doesn't require whitespace between commands. The only
case where it does is when the parse would be ambiguous without it (and
figuring out when this happens requires some knowledge about how the shell
quotes things, since ni sees post-quoted arguments). ni will complain if it
can't parse something, though.

See [row.md](row.md) (`ni //help/row`) for details about row-reordering
operators like sorting.

### Important note about `e`
`e'sort -r'` and `e[sort -r]` are not quite identical; the difference comes in
when you use shell metacharacters:

```bash
$ mkdir test-dir
$ touch test-dir/{a,b,c}
$ ni e'ls test-dir/*'                   # e'' sends its command through sh -c
test-dir/a
test-dir/b
test-dir/c
$ ni e[ls test-dir/*] 2>/dev/null || :  # e[] uses exec() directly; no wildcard expansion
$ ni e[ ls test-dir/* ]                 # using whitespace avoids this problem
test-dir/a
test-dir/b
test-dir/c
```

## Stream combiners
ni has four operators that combine streams:

- `+`: append a stream to this one
- `^`: prepend a stream to this one
- `=`: duplicate this stream through a process, discarding its output

Visually, here's what these stream combiners do:

```
$ ni n10 n5 g           # stdin --> n10 --> n5 --> g --> stdout


                        #                  /dev/null --> n5 --> g
                        #                  ----------------------
                        #                           |
$ ni n10 +[n5 g]        # ni stdin --> n10 -------append--> ni stdout


                        #                        ni stdin --> n10
                        #                        ----------------
                        #                             |
$ ni n10 ^[n5 g]        # /dev/null --> n5 --> g ---append---> ni stdout


                        #                  n5 --> g --> /dev/null
                        #                 /
$ ni n10 =[n5 g]        # ni stdin --> n10 -----------> ni stdout
```

Usage examples:

```bash
$ { echo hello; echo world; } > hw
$ ni n3 +hw
1
2
3
hello
world
$ ni n3 ^hw
hello
world
1
2
3
$ ni hw =e[wc -l]               # output from 'wc -l' is gone
hello
world
```

## Data generation
In addition to files, ni can generate data in a few ways:

```bash
$ ni n4                         # integer generator
1
2
3
4
$ ni n04                        # integer generator, zero-based
0
1
2
3
$ ni ifoo                       # literal text
foo
```

## Using a shell process
ni can stream data through a shell process using the `e` command, which is often
shorter than shelling out separately.

The following commands are equivalent to `ni n3 | sort`:

```bash
$ ni n3 e'sort'
1
2
3
$ ni n3e'sort -r'
3
2
1
$ ni n3e[sort -r]
3
2
1
```

By default, `e` acts as a filter. To keep your current stream and append the
result of the shell command, use the `+` operator.

```
$ ni n2 +e'seq 3 5'                  # append output of shell command "seq 4"
1
2
3
4
5
```

### Important note about `e`
`e'sort -r'` and `e[sort -r]` are not quite identical; the difference comes in
when you use shell metacharacters:

```bash
$ mkdir test-dir
$ touch test-dir/{a,b,c}
$ ni e'ls test-dir/*'                   # e'' sends its command through sh -c
test-dir/a
test-dir/b
test-dir/c
$ ni e[ls test-dir/*] 2>/dev/null || :  # e[] uses exec() directly; no wildcard expansion
$ ni e[ ls test-dir/* ]                 # using whitespace avoids this problem
test-dir/a
test-dir/b
test-dir/c
```

## Writing files
You can write a file in two ways. One is, of course, using shell redirection:

```bash
$ ni n3 >file                   # nothing goes to the terminal
$ ni file
1
2
3
```

The other way is to use ni's `\>` operator:

```bash
$ ni n3 \>file2                 # writes the filename to the terminal
file2
$ ni file2
1
2
3
$ ni n3 =\>file3                # eats the filename because \> happens inside =
1
2
3
$ ni file3
1
2
3
```

The `\<` operator inverts `\>` by reading files; it's conceptually equivalent
to `xargs cat`:

```bash
$ ni n4 \>file3 \<
1
2
3
4
```

## Reading/writing multiple files
`\<` will already handle multiple files, behaving like `xargs cat`. But
sometimes you want to know which file each line came from; for that you can use
`W\<` (mnemonic: "prepend and read"; see [col.md](col.md) under
"juxtaposition" for `W`). For example:

```bash
$ { echo foo; echo bar; } > file1
$ echo bif > file2
$ ni ifile1 ifile2 \<       # regular file-read on multiple files
foo
bar
bif
$ ni ifile1 ifile2 W\<      # prepend-file read on multiple files
file1	foo
file1	bar
file2	bif
```

The inverse is `W\>`, which takes the stream produced by `W\<` and converts it
back into files. For example, we can add a `.txt` extension to each one:

```bash
$ ni ifile1 ifile2 W\< p'r a.".txt", b' W\>
file1.txt
file2.txt
$ cat file1.txt
foo
bar
$ cat file2.txt
bif
```

You can transform the output into each file by specifying a lambda:

```bash
$ ni ifile1 ifile2 W\< p'r a.".txt2", b' W\>p'uc'
file1.txt2
file2.txt2
$ cat file1.txt2
FOO
BAR
$ cat file2.txt2
BIF
```

## Compression
If you want to write a compressed file, you can use the `z` operator:

```bash
$ ni n3z >file3.gz
$ zcat file3.gz
1
2
3
```

`z` lets you specify which compressor you want to use; for example:

```bash
$ ni igzip z | gzip -dc                 # gzip by default
gzip
$ ni igzip zg | gzip -dc                # explicitly specify
gzip
$ ni igzip zg9 | gzip -dc               # specify compression level
gzip
$ ni ixz zx | xz -dc
xz
$ ni ilzo zo | lzop -dc
lzo
$ ni ibzip2 zb | bzip2 -dc
bzip2
```

```sh
# this one isn't a unit test because not all test docker images have a
# straightforward LZ4 install (some are too old)
$ ni ilz4 z4 | lz4 -dc
lz4
```

ni also provides a universal decompression operator `zd`, though you'll rarely
need it because any external data will be decoded automatically. `zd` has no
effect if the data isn't compressed.

```bash
$ ni n4 z zd
1
2
3
4
$ ni n4 zd
1
2
3
4
```

Not to be outdone, ni provides the ultimate lossy compressor, `zn`, which
achieves 100% compression by writing data to `/dev/null`:

```bash
$ ni n4 zn | wc -c
0
```

## Checkpoints
Checkpoints let you cache intermediate outputs in a pipeline. This can avoid
expensive recomputation. For example, let's expensively get some numbers:

```bash
$ ni n1000000gr4
1
10
100
1000
```

If we wanted to iterate on the pipeline from this point onwards, we could do
this quickly by checkpointing the stream at that point:

```bash
$ ni n1000000gr4 :numbers
1
10
100
1000
```

Now this data will be reused if we rerun it:

```bash
$ ni n1000000gr4 :numbers O
1000
100
10
1
```

ni isn't rerunning the process at all; we can see this by modifying the
checkpoint file:

```bash
$ echo 'checkpointed' > numbers
$ ni n1000000gr4 :numbers O
checkpointed
```

You can write compressed data into a checkpoint. The checkpointing operator
itself will decode any compressed data you feed into it; for example:

```bash
$ ni n100000z :biglist r+5
99996
99997
99998
99999
100000
$ ni n100000z :biglist r+5
99996
99997
99998
99999
100000
```
46 doc/tutorial.md
# ni tutorial
You can access this tutorial by running `ni //help` or `ni //help/tutorial`.

ni parses its command arguments to build and run a data pipeline. You can get
started by using it like a version of `less` that knows how to decompress
things, but it can do a lot more; see the topics below.

```sh
$ ni data-source.gz                     # works like less
$ cat data-source.gz | ni               # same here
$ ni //help/stream                      # view a help topic
```

## The deep end
- [examples.md](examples.md) (`ni //help/examples`)

## Essentials
- [stream.md](stream.md)   (`ni //help/stream`):  intro to ni grammar and data
- [row.md](row.md)         (`ni //help/row`):     row-level operators
- [col.md](col.md)         (`ni //help/col`):     column-level operators
- [perl.md](perl.md)       (`ni //help/perl`):    ni's Perl library
- [lisp.md](lisp.md)       (`ni //help/lisp`):    ni's Common Lisp library
- [ruby.md](ruby.md)       (`ni //help/ruby`):    ni's Ruby library
- [monitor.md](monitor.md) (`ni //help/monitor`): pipeline monitoring

## Stuff worth knowing about
- [net.md](net.md)             (`ni //help/net`):       HTTP/SSH/etc
- [scale.md](scale.md)         (`ni //help/scale`):     parallelizing stuff
- [closure.md](closure.md)     (`ni //help/closure`):   data closures
- [hadoop.md](hadoop.md)       (`ni //help/hadoop`);    Hadoop interop
- [visual.md](visual.md)       (`ni //help/visual`):    visualizing data
- [matrix.md](matrix.md)       (`ni //help/matrix`):    dense/sparse matrices
- [binary.md](binary.md)       (`ni //help/binary`):    decoding binary streams
- [container.md](container.md) (`ni //help/container`): Dockerizing stuff
- [json.md](json.md)           (`ni //help/json`):      working with JSON
- [warnings.md](warnings.md)   (`ni //help/warnings`):  things to look out for

## Reference
- [options.md](options.md) (`ni //help/options`): every CLI option and
  operator, each with example usage

## Extending ni
- [extend.md](extend.md)       (`ni //help/extend`):    how to write a ni
  extension
- [libraries.md](libraries.md) (`ni //help/libraries`): how to load/use a
  library
30 doc/visual.md
# Visualizing data
See also [examples.md](examples.md).

```sh
$ ni --js
http://localhost:8090
```

## Using the web interface
You can view the example in the screenshots by opening the following link on
your system while running `ni --js`:

```
http://localhost:8090/#%7B%22ni%22:%22n2E2p'r%20$_,%20a%20for%200..199'%20p'r(a*10%20+%20$_,%20b*10),%20r(a*10,%20b*10%20+%20$_)%20for%200..9'%20p'r%20a,%20sin(1%20+%20a%20/%20340)%20*%20cos(b*b%20/%2030000)%20+%20sin((a%20+%2050)*b%20/%20120000),%20b'%22,%22v%22:%7B%22br%22:1,%22ot%22:%5B-770.7425674121397,1.8043842499741498,-872.5578946367137%5D,%22os%22:%5B0.3134861808826051,46.99306323157935,0.4025242240336357%5D,%22sa%22:0.03,%22cr%22:%5B24.607594936708868,29.16455696202535%5D,%22cd%22:385.7425530696977,%22axes%22:%5B0,1,2,3%5D%7D%7D
```

![web ui](http://spencertipping.com/ni-jsplot-sinewave.png)

The UI consists of three main components: the ni command editor (top), the plot
(center), and a data preview (left). The data preview is normally hidden, but
you can hover over the left side of the screen to pop it out (click it to
toggle locking):

![data preview](http://spencertipping.com/ni-jsplot-sinewave2.png)

The view angle can be panned, rotated, and zoomed:

- **mouse drag:** pan
- **shift + drag:** 3D rotate
- **ctrl + drag, alt + drag, mousewheel:** zoom
74 doc/warnings.md
# Things to look out for
![img](http://spencertipping.com/ni.png)

![img](http://spencertipping.com/ni2.png)

## `r` and pipe signals
Internally, commands like `r10` will read ten rows and then break the input
pipe, causing the writing process to receive a `SIGPIPE` and terminate.
Normally this is what you want to happen, particularly when the process would
otherwise generate data forever. But there are some situations where it causes
problems; for example:

```bash
$ ni n1000000 =\>not-a-million-things r5
1
2
3
4
5
$ echo $(( $(cat not-a-million-things 2>/dev/null | wc -l) < 1000000 ))
1
```

(The output file might not even get created, depending on when the pipe signal
arrives.)

Here's what I got the last time I tried it:

```sh
$ wc -l not-a-million-things
3100 not-a-million-things
```

This happens because the ni process implementing `=` does basically this:

```
while data = read stdin:
  write data to stdout          # connected to r5
  write data to child process   # connected to \>not-a-million-things
```

Once `r5` (which is implemented with `head -n5`) receives enough data, it
exits, closing its input stream. This causes the next write to generate a pipe
signal and kill the process.

### Workaround
`r` is designed to break pipes, so you need to prepend an operator that will
either buffer or consume the stream first. Any sorting operator will do this
automatically:

```bash
$ ni n1000000 =\>a-million-things gr5
1
10
100
1000
10000
$ wc -l < a-million-things
1000000
```

More idiomatic, though, is to convert `=\>` to a checkpoint, which is fully
buffered:

```bash
$ ni n1000000 :a-million-things-2 r5
1
2
3
4
5
$ wc -l < a-million-things-2
1000000
```
85 doc/wkt.md
# WKT and WKB
ni has some support for polygon geometry using WKT and WKB; in particular, it
supports visualization (using [Map-O-Matic](../core/mapomatic/mapomatic.pl)) and
[point-in-poly queries](../core/pl/wkt.pl).

## Map-O-Matic
Map-O-Matic provides instant map visualization for various types of geographic
data (via MapBox and GeoJSON):

- Points
  - TSV `lat lng` pairs
  - CSV `lat,lng` pairs
  - TSV `lat1,lng1 >lat2,lng2` vectors
  - TSV `lat1,lng1 +lat2,lng2` delta vectors
- WKT/WKB
  - `POINT(X Y)` WKT
  - `POLYGON((X1 Y1, ...))` WKT/WKB
  - `MULTIPOLYGON(((...)))` WKT/WKB
  - `01....`: WKB (e.g. PostGIS binary format)
- Geohashes
  - Base-32 geohashes as boxes or points
  - Tagged binary geohashes as boxes or points
- GeoJSON

You can mix the above types within a datastream. For example, if you wanted to
visualize some geohashes you could use a file like this:

```sh
$ cat > geometries <<EOF
9q5c
9q5cc2
dr5r
34,-118
EOF

$ ni geometries geojsonify        # convert the above to GeoJSON
{"type":"Feature","geometry":{"type":"Polygon","coordinates":[[[-118.4765625,33.92578125],[-118.125000335276,33.92578125],[-118.125000335276,34.1015623323619],[-118.4765625,34.1015623323619],[-118.4765625,33.92578125]]]},"properties":{"title":""}}
{"type":"Feature","geometry":{"type":"Polygon","coordinates":[[[-118.421630859375,34.0576171875],[-118.410644866526,34.0576171875],[-118.410644866526,34.0631101839244],[-118.421630859375,34.0631101839244],[-118.421630859375,34.0576171875]]]},"properties":{"title":""}}
{"type":"Feature","geometry":{"type":"Polygon","coordinates":[[[-74.1796875,40.60546875],[-73.8281253352761,40.60546875],[-73.8281253352761,40.7812498323619],[-74.1796875,40.7812498323619],[-74.1796875,40.60546875]]]},"properties":{"title":""}}
{"type":"Feature","geometry":{"type":"Point","coordinates":[-118,34]},"properties":{"title":""}}

$ ni geometries MM                # run the map-o-matic webserver
WARNING
  You're using ni's builtin Mapbox key, which is shared across
  all ni users. To avoid hitting the free-tier quota, you should
  head to mapbox.com and generate a new key. Keys are free and
  give you about 50000 map views per month. Once you have a key,
  add this line to your .bashrc:

  export NI_MAPBOX_KEY='<your mapbox access token>'

  For example:

  export NI_MAPBOX_KEY='pk.eyJ1Ijoic3BlbmNlcnRpcHBpbmciLCJhIjoiY2plNGducGNxMTR3cTJycnF1bGRkYmJ0NiJ9.aGaYbtzy_cSYfuQ0fawfTQ'

  You can verify that ni is using your key by running this:
  $ ni '$mapbox/key'

http://localhost:32768/           # open this link to see the map
```

![image](http://spencertipping.com/nimap1.png)

### Geometry metadata
You can assign attributes to geometries by appending TSV columns to the right.
ni understands a few different types of metadata values:

- `name=value`: set a GeoJSON property
- `{"name":"value",...}`: merge properties into GeoJSON properties map
- `#rrggbb`: set the color of the geometry
- `0.1`: set color to hue, interpolated from 0 (orange) to 1 (purple)
- `text`: append to the `title` attribute, which results in a tooltip

These properties are visible in a popup table if you click on geometries.

For example, let's look at some geohashes around Albuquerque:

```sh
$ ni i[9whp 9whp '#fa4'] \
     i[9wk2 9wk2 '#797'] \
     i[9wk0 this_is_geohash=9wk0] \
     MM
```

![image](http://spencertipping.com/nimap2.png)
__END__
